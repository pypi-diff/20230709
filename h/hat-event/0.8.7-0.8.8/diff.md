# Comparing `tmp/hat_event-0.8.7-cp39-cp39-win_amd64.whl.zip` & `tmp/hat_event-0.8.8-cp310.cp311-abi3-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,66 +1,66 @@
-Zip file size: 110179 bytes, number of entries: 64
+Zip file size: 110555 bytes, number of entries: 64
 -rw-r--r--  2.0 unx       47 b- defN 23-Feb-14 18:33 hat/event/__init__.py
 -rw-r--r--  2.0 unx     2696 b- defN 22-Jul-20 12:38 hat/event/common/__init__.py
--rw-r--r--  2.0 unx     8551 b- defN 23-May-04 16:43 hat/event/common/data.py
--rw-r--r--  2.0 unx     9158 b- defN 23-Jun-05 15:17 hat/event/common/json_schema_repo.json
--rw-r--r--  2.0 unx     7535 b- defN 23-Jun-05 15:17 hat/event/common/sbs_repo.json
+-rw-r--r--  2.0 unx     8535 b- defN 23-Jul-09 14:18 hat/event/common/data.py
+-rw-r--r--  2.0 unx     9158 b- defN 23-Jul-09 15:41 hat/event/common/json_schema_repo.json
+-rw-r--r--  2.0 unx     7535 b- defN 23-Jul-09 15:41 hat/event/common/sbs_repo.json
 -rw-r--r--  2.0 unx     4235 b- defN 21-Nov-15 15:43 hat/event/common/timestamp.py
 -rw-r--r--  2.0 unx      534 b- defN 23-May-08 19:23 hat/event/common/subscription/__init__.py
--rwxr-xr-x  2.0 unx   122604 b- defN 23-Jun-05 15:17 hat/event/common/subscription/_csubscription.cp39-win_amd64.pyd
+-rwxr-xr-x  2.0 unx   122941 b- defN 23-Jul-09 15:41 hat/event/common/subscription/_csubscription.abi3.pyd
 -rw-r--r--  2.0 unx     5758 b- defN 23-May-08 19:41 hat/event/common/subscription/common.py
 -rw-r--r--  2.0 unx     1530 b- defN 23-May-08 19:39 hat/event/common/subscription/csubscription.py
 -rw-r--r--  2.0 unx     2670 b- defN 23-Jun-05 15:08 hat/event/common/subscription/pysubscription.py
 -rw-r--r--  2.0 unx     2550 b- defN 23-Feb-24 00:11 hat/event/eventer/__init__.py
--rw-r--r--  2.0 unx    12723 b- defN 23-Feb-24 00:22 hat/event/eventer/client.py
--rw-r--r--  2.0 unx     6399 b- defN 23-Feb-15 16:23 hat/event/eventer/server.py
+-rw-r--r--  2.0 unx    12692 b- defN 23-Jul-09 14:22 hat/event/eventer/client.py
+-rw-r--r--  2.0 unx     6502 b- defN 23-Jul-09 14:25 hat/event/eventer/server.py
 -rw-r--r--  2.0 unx      521 b- defN 23-Mar-02 17:36 hat/event/mariner/__init__.py
--rw-r--r--  2.0 unx     3605 b- defN 23-Mar-05 14:04 hat/event/mariner/client.py
--rw-r--r--  2.0 unx      508 b- defN 23-Feb-28 16:05 hat/event/mariner/common.py
+-rw-r--r--  2.0 unx     3940 b- defN 23-Jul-09 15:25 hat/event/mariner/client.py
+-rw-r--r--  2.0 unx      481 b- defN 23-Jul-09 15:14 hat/event/mariner/common.py
 -rw-r--r--  2.0 unx     6806 b- defN 23-Mar-03 14:27 hat/event/mariner/encoder.py
--rw-r--r--  2.0 unx     4845 b- defN 23-May-18 11:14 hat/event/mariner/server.py
--rw-r--r--  2.0 unx     1497 b- defN 23-Mar-03 14:37 hat/event/mariner/transport.py
+-rw-r--r--  2.0 unx     5119 b- defN 23-Jul-09 15:24 hat/event/mariner/server.py
+-rw-r--r--  2.0 unx     1509 b- defN 23-Jul-09 15:04 hat/event/mariner/transport.py
 -rw-r--r--  2.0 unx        0 b- defN 21-Jan-29 21:03 hat/event/server/__init__.py
 -rw-r--r--  2.0 unx      138 b- defN 23-Feb-15 17:22 hat/event/server/__main__.py
--rw-r--r--  2.0 unx     4751 b- defN 23-Mar-08 12:47 hat/event/server/common.py
--rw-r--r--  2.0 unx     6872 b- defN 22-Jul-20 19:15 hat/event/server/engine.py
+-rw-r--r--  2.0 unx     5613 b- defN 23-Jul-09 14:55 hat/event/server/common.py
+-rw-r--r--  2.0 unx     6751 b- defN 23-Jul-09 14:57 hat/event/server/engine.py
 -rw-r--r--  2.0 unx     2095 b- defN 23-Feb-15 17:17 hat/event/server/eventer_server.py
 -rw-r--r--  2.0 unx     2330 b- defN 23-Feb-22 02:31 hat/event/server/main.py
--rw-r--r--  2.0 unx     3718 b- defN 23-May-09 14:18 hat/event/server/mariner_server.py
--rw-r--r--  2.0 unx    10755 b- defN 23-Mar-03 16:48 hat/event/server/runner.py
--rw-r--r--  2.0 unx     7439 b- defN 23-Mar-06 13:03 hat/event/server/syncer_client.py
--rw-r--r--  2.0 unx     2062 b- defN 23-May-18 11:57 hat/event/server/syncer_server.py
+-rw-r--r--  2.0 unx     3742 b- defN 23-Jul-09 15:24 hat/event/server/mariner_server.py
+-rw-r--r--  2.0 unx    10721 b- defN 23-Jul-09 14:59 hat/event/server/runner.py
+-rw-r--r--  2.0 unx     7565 b- defN 23-Jul-09 15:00 hat/event/server/syncer_client.py
+-rw-r--r--  2.0 unx     2041 b- defN 23-Jul-09 15:01 hat/event/server/syncer_server.py
 -rw-r--r--  2.0 unx        0 b- defN 21-Jan-30 01:25 hat/event/server/backends/__init__.py
--rw-r--r--  2.0 unx     2231 b- defN 23-Mar-08 12:50 hat/event/server/backends/dummy.py
--rw-r--r--  2.0 unx     5722 b- defN 23-Mar-08 12:50 hat/event/server/backends/memory.py
+-rw-r--r--  2.0 unx     2156 b- defN 23-Jul-09 14:46 hat/event/server/backends/dummy.py
+-rw-r--r--  2.0 unx     5647 b- defN 23-Jul-09 14:47 hat/event/server/backends/memory.py
 -rw-r--r--  2.0 unx      241 b- defN 21-Aug-09 19:28 hat/event/server/backends/lmdb/__init__.py
--rw-r--r--  2.0 unx     9593 b- defN 23-Mar-08 12:52 hat/event/server/backends/lmdb/backend.py
--rw-r--r--  2.0 unx     2172 b- defN 23-Mar-20 20:56 hat/event/server/backends/lmdb/common.py
--rw-r--r--  2.0 unx     2778 b- defN 21-Mar-01 15:46 hat/event/server/backends/lmdb/conditions.py
--rw-r--r--  2.0 unx     6426 b- defN 22-Jul-20 19:15 hat/event/server/backends/lmdb/encoder.py
--rw-r--r--  2.0 unx     1600 b- defN 22-Nov-16 23:15 hat/event/server/backends/lmdb/environment.py
--rw-r--r--  2.0 unx     4459 b- defN 22-Nov-18 21:29 hat/event/server/backends/lmdb/latestdb.py
--rw-r--r--  2.0 unx    17674 b- defN 22-Nov-18 21:29 hat/event/server/backends/lmdb/ordereddb.py
--rw-r--r--  2.0 unx     4953 b- defN 22-Nov-16 23:15 hat/event/server/backends/lmdb/refdb.py
--rw-r--r--  2.0 unx     2161 b- defN 22-Nov-18 21:29 hat/event/server/backends/lmdb/systemdb.py
+-rw-r--r--  2.0 unx     9528 b- defN 23-Jul-09 14:36 hat/event/server/backends/lmdb/backend.py
+-rw-r--r--  2.0 unx     2498 b- defN 23-Jul-09 14:39 hat/event/server/backends/lmdb/common.py
+-rw-r--r--  2.0 unx     2779 b- defN 23-Jul-09 14:39 hat/event/server/backends/lmdb/conditions.py
+-rw-r--r--  2.0 unx     6427 b- defN 23-Jul-09 14:40 hat/event/server/backends/lmdb/encoder.py
+-rw-r--r--  2.0 unx     1594 b- defN 23-Jul-09 14:40 hat/event/server/backends/lmdb/environment.py
+-rw-r--r--  2.0 unx     4458 b- defN 23-Jul-09 14:42 hat/event/server/backends/lmdb/latestdb.py
+-rw-r--r--  2.0 unx    17619 b- defN 23-Jul-09 14:43 hat/event/server/backends/lmdb/ordereddb.py
+-rw-r--r--  2.0 unx     4947 b- defN 23-Jul-09 14:44 hat/event/server/backends/lmdb/refdb.py
+-rw-r--r--  2.0 unx     2158 b- defN 23-Jul-09 14:45 hat/event/server/backends/lmdb/systemdb.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Sep-29 22:53 hat/event/server/backends/lmdb/convert/__init__.py
 -rw-r--r--  2.0 unx     8667 b- defN 22-Sep-29 22:53 hat/event/server/backends/lmdb/convert/convert_v06_to_v07.py
--rw-r--r--  2.0 unx     6207 b- defN 22-Oct-01 00:44 hat/event/server/backends/lmdb/convert/v06.py
--rw-r--r--  2.0 unx     2477 b- defN 22-Sep-29 22:53 hat/event/server/backends/lmdb/convert/v07.py
+-rw-r--r--  2.0 unx     6153 b- defN 23-Jul-09 14:33 hat/event/server/backends/lmdb/convert/v06.py
+-rw-r--r--  2.0 unx     2444 b- defN 23-Jul-09 14:34 hat/event/server/backends/lmdb/convert/v07.py
 -rw-r--r--  2.0 unx        0 b- defN 22-Oct-03 17:02 hat/event/server/backends/lmdb/manager/__init__.py
 -rw-r--r--  2.0 unx      166 b- defN 22-Oct-03 17:02 hat/event/server/backends/lmdb/manager/__main__.py
 -rw-r--r--  2.0 unx     1254 b- defN 23-Mar-20 20:57 hat/event/server/backends/lmdb/manager/common.py
 -rw-r--r--  2.0 unx     1668 b- defN 23-Mar-20 20:58 hat/event/server/backends/lmdb/manager/copy.py
 -rw-r--r--  2.0 unx      951 b- defN 23-Apr-04 16:29 hat/event/server/backends/lmdb/manager/main.py
 -rw-r--r--  2.0 unx     5625 b- defN 23-Mar-20 20:59 hat/event/server/backends/lmdb/manager/query.py
 -rw-r--r--  2.0 unx      618 b- defN 23-Feb-20 18:22 hat/event/syncer/__init__.py
--rw-r--r--  2.0 unx     3328 b- defN 23-May-18 11:46 hat/event/syncer/client.py
--rw-r--r--  2.0 unx     1587 b- defN 23-May-18 11:19 hat/event/syncer/common.py
--rw-r--r--  2.0 unx    13098 b- defN 23-May-18 11:43 hat/event/syncer/server.py
--rw-r--r--  2.0 unx    11358 b- defN 23-Jun-05 15:17 hat_event-0.8.7.dist-info/LICENSE
--rw-r--r--  2.0 unx     2141 b- defN 23-Jun-05 15:17 hat_event-0.8.7.dist-info/METADATA
--rw-r--r--  2.0 unx      100 b- defN 23-Jun-05 15:17 hat_event-0.8.7.dist-info/WHEEL
--rw-r--r--  2.0 unx      138 b- defN 23-Jun-05 15:17 hat_event-0.8.7.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        4 b- defN 23-Jun-05 15:17 hat_event-0.8.7.dist-info/top_level.txt
--rw-r--r--  2.0 unx        1 b- defN 23-Jun-05 15:17 hat_event-0.8.7.dist-info/zip-safe
--rw-rw-r--  2.0 unx     5883 b- defN 23-Jun-05 15:17 hat_event-0.8.7.dist-info/RECORD
-64 files, 370213 bytes uncompressed, 100669 bytes compressed:  72.8%
+-rw-r--r--  2.0 unx     3320 b- defN 23-Jul-09 14:26 hat/event/syncer/client.py
+-rw-r--r--  2.0 unx     1570 b- defN 23-Jul-09 14:27 hat/event/syncer/common.py
+-rw-r--r--  2.0 unx    13105 b- defN 23-Jul-09 14:29 hat/event/syncer/server.py
+-rw-r--r--  2.0 unx    11358 b- defN 23-Jul-09 15:41 hat_event-0.8.8.dist-info/LICENSE
+-rw-r--r--  2.0 unx     2563 b- defN 23-Jul-09 15:41 hat_event-0.8.8.dist-info/METADATA
+-rw-r--r--  2.0 unx      127 b- defN 23-Jul-09 15:41 hat_event-0.8.8.dist-info/WHEEL
+-rw-r--r--  2.0 unx      138 b- defN 23-Jul-09 15:41 hat_event-0.8.8.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        4 b- defN 23-Jul-09 15:41 hat_event-0.8.8.dist-info/top_level.txt
+-rw-r--r--  2.0 unx        1 b- defN 23-Jul-09 15:41 hat_event-0.8.8.dist-info/zip-safe
+-rw-rw-r--  2.0 unx     5873 b- defN 23-Jul-09 15:41 hat_event-0.8.8.dist-info/RECORD
+64 files, 372412 bytes uncompressed, 101065 bytes compressed:  72.9%
```

## zipnote {}

```diff
@@ -15,15 +15,15 @@
 
 Filename: hat/event/common/timestamp.py
 Comment: 
 
 Filename: hat/event/common/subscription/__init__.py
 Comment: 
 
-Filename: hat/event/common/subscription/_csubscription.cp39-win_amd64.pyd
+Filename: hat/event/common/subscription/_csubscription.abi3.pyd
 Comment: 
 
 Filename: hat/event/common/subscription/common.py
 Comment: 
 
 Filename: hat/event/common/subscription/csubscription.py
 Comment: 
@@ -165,29 +165,29 @@
 
 Filename: hat/event/syncer/common.py
 Comment: 
 
 Filename: hat/event/syncer/server.py
 Comment: 
 
-Filename: hat_event-0.8.7.dist-info/LICENSE
+Filename: hat_event-0.8.8.dist-info/LICENSE
 Comment: 
 
-Filename: hat_event-0.8.7.dist-info/METADATA
+Filename: hat_event-0.8.8.dist-info/METADATA
 Comment: 
 
-Filename: hat_event-0.8.7.dist-info/WHEEL
+Filename: hat_event-0.8.8.dist-info/WHEEL
 Comment: 
 
-Filename: hat_event-0.8.7.dist-info/entry_points.txt
+Filename: hat_event-0.8.8.dist-info/entry_points.txt
 Comment: 
 
-Filename: hat_event-0.8.7.dist-info/top_level.txt
+Filename: hat_event-0.8.8.dist-info/top_level.txt
 Comment: 
 
-Filename: hat_event-0.8.7.dist-info/zip-safe
+Filename: hat_event-0.8.8.dist-info/zip-safe
 Comment: 
 
-Filename: hat_event-0.8.7.dist-info/RECORD
+Filename: hat_event-0.8.8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## hat/event/common/data.py

```diff
@@ -1,38 +1,41 @@
 import enum
 import importlib.resources
 import typing
 
 from hat import chatter
 from hat import json
 from hat import sbs
+import hat.monitor.common
+
 from hat.event.common.timestamp import (Timestamp,
                                         timestamp_to_sbs,
                                         timestamp_from_sbs)
-import hat.monitor.common
 
 
-with importlib.resources.path(__package__, 'json_schema_repo.json') as _path:
+with importlib.resources.as_file(importlib.resources.files(__package__) /
+                                 'json_schema_repo.json') as _path:
     json_schema_repo: json.SchemaRepository = json.SchemaRepository(
         json.json_schema_repo,
         hat.monitor.common.json_schema_repo,
         json.SchemaRepository.from_json(_path))
     """JSON schema repository"""
 
-with importlib.resources.path(__package__, 'sbs_repo.json') as _path:
+with importlib.resources.as_file(importlib.resources.files(__package__) /
+                                 'sbs_repo.json') as _path:
     sbs_repo: sbs.Repository = sbs.Repository(chatter.sbs_repo,
                                               sbs.Repository.from_json(_path))
     """SBS schema repository"""
 
 
-EventTypeSegment = str
+EventTypeSegment: typing.TypeAlias = str
 """Event type segment"""
 
 
-EventType: typing.Type = typing.Tuple[EventTypeSegment, ...]
+EventType: typing.TypeAlias = typing.Tuple[EventTypeSegment, ...]
 """Event type"""
 
 
 Order = enum.Enum('Order', [
     'DESCENDING',
     'ASCENDING'])
 
@@ -59,48 +62,48 @@
 
 class EventPayload(typing.NamedTuple):
     type: EventPayloadType
     data: typing.Union[bytes, json.Data, 'SbsData']
 
 
 class SbsData(typing.NamedTuple):
-    module: typing.Optional[str]
+    module: str | None
     """SBS module name"""
     type: str
     """SBS type name"""
     data: bytes
 
 
 class Event(typing.NamedTuple):
     event_id: EventId
     event_type: EventType
-    timestamp: 'Timestamp'
-    source_timestamp: typing.Optional['Timestamp']
-    payload: typing.Optional[EventPayload]
+    timestamp: Timestamp
+    source_timestamp: Timestamp | None
+    payload: EventPayload | None
 
 
 class RegisterEvent(typing.NamedTuple):
     event_type: EventType
-    source_timestamp: typing.Optional['Timestamp']
-    payload: typing.Optional[EventPayload]
+    source_timestamp: Timestamp | None
+    payload: EventPayload | None
 
 
 class QueryData(typing.NamedTuple):
-    server_id: typing.Optional[int] = None
-    event_ids: typing.Optional[typing.List[EventId]] = None
-    event_types: typing.Optional[typing.List[EventType]] = None
-    t_from: typing.Optional['Timestamp'] = None
-    t_to: typing.Optional['Timestamp'] = None
-    source_t_from: typing.Optional['Timestamp'] = None
-    source_t_to: typing.Optional['Timestamp'] = None
-    payload: typing.Optional[EventPayload] = None
+    server_id: int | None = None
+    event_ids: list[EventId] | None = None
+    event_types: list[EventType] | None = None
+    t_from: Timestamp | None = None
+    t_to: Timestamp | None = None
+    source_t_from: Timestamp | None = None
+    source_t_to: Timestamp | None = None
+    payload: EventPayload | None = None
     order: Order = Order.DESCENDING
     order_by: OrderBy = OrderBy.TIMESTAMP
     unique_type: bool = False
-    max_results: typing.Optional[int] = None
+    max_results: int | None = None
 
 
 def event_to_sbs(event: Event) -> sbs.Data:
     """Convert Event to SBS data"""
     return {
         'id': _event_id_to_sbs(event.event_id),
         'type': list(event.event_type),
```

## hat/event/eventer/client.py

```diff
@@ -11,15 +11,15 @@
 
 
 mlog: logging.Logger = logging.getLogger(__name__)
 """Module logger"""
 
 
 async def connect(address: str,
-                  subscriptions: typing.List[common.EventType] = [],
+                  subscriptions: list[common.EventType] = [],
                   **kwargs
                   ) -> 'Client':
     """Connect to eventer server
 
     For address format see `hat.chatter.connect` coroutine.
 
     According to Event Server specification, each subscription is event
@@ -61,43 +61,43 @@
     """
 
     @property
     def async_group(self) -> aio.Group:
         """Async group"""
         return self._conn.async_group
 
-    async def receive(self) -> typing.List[common.Event]:
+    async def receive(self) -> list[common.Event]:
         """Receive subscribed event notifications
 
         Raises:
             ConnectionError
 
         """
         try:
             return await self._event_queue.get()
 
         except aio.QueueClosedError:
             raise ConnectionError()
 
-    def register(self, events: typing.List[common.RegisterEvent]):
+    def register(self, events: list[common.RegisterEvent]):
         """Register events
 
         Raises:
             ConnectionError
 
         """
         msg_data = chatter.Data(module='HatEventer',
                                 type='MsgRegisterReq',
                                 data=[common.register_event_to_sbs(i)
                                       for i in events])
         self._conn.send(msg_data)
 
     async def register_with_response(self,
-                                     events: typing.List[common.RegisterEvent]
-                                     ) -> typing.List[typing.Optional[common.Event]]:  # NOQA
+                                     events: list[common.RegisterEvent]
+                                     ) -> list[common.Event | None]:
         """Register events
 
         Each `common.RegisterEvent` from `events` is paired with results
         `common.Event` if new event was successfuly created or ``None`` is new
         event could not be created.
 
         Raises:
@@ -109,15 +109,15 @@
                                 data=[common.register_event_to_sbs(i)
                                       for i in events])
         conv = self._conn.send(msg_data, last=False)
         return await self._wait_conv_res(conv)
 
     async def query(self,
                     data: common.QueryData
-                    ) -> typing.List[common.Event]:
+                    ) -> list[common.Event]:
         """Query events from server
 
         Raises:
             ConnectionError
 
         """
         msg_data = chatter.Data(module='HatEventer',
@@ -190,18 +190,18 @@
         if not f or f.done():
             return
         events = [common.event_from_sbs(e) if t == 'event' else None
                   for t, e in msg.data.data]
         f.set_result(events)
 
 
-Runner = aio.Resource
+Runner: typing.TypeAlias = aio.Resource
 """Component runner"""
 
-ComponentCb = typing.Callable[[Client], Runner]
+ComponentCb: typing.TypeAlias = typing.Callable[[Client], Runner]
 """Component callback"""
 
 
 class Component(aio.Resource):
     """Eventer component
 
     High-level interface for communication with Event Server, based on
@@ -237,15 +237,15 @@
 
     """
 
     def __init__(self,
                  monitor_client: hat.monitor.client.Client,
                  server_group: str,
                  component_cb: ComponentCb,
-                 subscriptions: typing.List[common.EventType] = [],
+                 subscriptions: list[common.EventType] = [],
                  reconnect_delay: float = 0.5):
         self._monitor_client = monitor_client
         self._server_group = server_group
         self._component_cb = component_cb
         self._subscriptions = subscriptions
         self._reconnect_delay = reconnect_delay
         self._async_group = aio.Group()
```

## hat/event/eventer/server.py

```diff
@@ -8,34 +8,36 @@
 
 from hat.event import common
 
 
 mlog: logging.Logger = logging.getLogger(__name__)
 """Module logger"""
 
-ClientId = int
+ClientId: typing.TypeAlias = int
 """Client identifier"""
 
-ClientCb = aio.AsyncCallable[[ClientId], None]
+ClientCb: typing.TypeAlias = aio.AsyncCallable[[ClientId], None]
 """Client connected/disconnected callback"""
 
-RegisterCb = aio.AsyncCallable[[ClientId, typing.List[common.RegisterEvent]],
-                               typing.List[common.Event]]
+RegisterCb: typing.TypeAlias = aio.AsyncCallable[[ClientId,
+                                                  list[common.RegisterEvent]],
+                                                 list[common.Event]]
 """Register callback"""
 
-QueryCb = aio.AsyncCallable[[ClientId, typing.List[common.QueryData]],
-                            typing.List[common.Event]]
+QueryCb: typing.TypeAlias = aio.AsyncCallable[[ClientId,
+                                               list[common.QueryData]],
+                                              list[common.Event]]
 """Query callback"""
 
 
 async def listen(address: str,
-                 connected_cb: typing.Optional[ClientCb] = None,
-                 disconnected_cb: typing.Optional[ClientCb] = None,
-                 register_cb: typing.Optional[RegisterCb] = None,
-                 query_cb: typing.Optional[QueryCb] = None
+                 connected_cb: ClientCb | None = None,
+                 disconnected_cb: ClientCb | None = None,
+                 register_cb: RegisterCb | None = None,
+                 query_cb: QueryCb | None = None
                  ) -> 'Server':
     """Create eventer server instance"""
     server = Server()
     server._connected_cb = connected_cb
     server._disconnected_cb = disconnected_cb
     server._register_cb = register_cb
     server._query_cb = query_cb
@@ -53,15 +55,15 @@
 class Server(aio.Resource):
 
     @property
     def async_group(self) -> aio.Group:
         """Async group"""
         return self._srv.async_group
 
-    def notify(self, events: typing.List[common.Event]):
+    def notify(self, events: list[common.Event]):
         """Notify events to subscribed clients"""
         for conn in self._conns.values():
             conn.notify(events)
 
     async def _on_connection(self, conn):
         client_id = next(self._next_client_ids)
 
@@ -88,29 +90,29 @@
 
 
 class _Connection(aio.Resource):
 
     def __init__(self,
                  conn: chatter.Connection,
                  client_id: int,
-                 register_cb: typing.Optional[RegisterCb],
-                 query_cb: typing.Optional[QueryCb]):
+                 register_cb: RegisterCb | None,
+                 query_cb: QueryCb | None):
         self._conn = conn
         self._client_id = client_id
         self._register_cb = register_cb
         self._query_cb = query_cb
         self._subscription = None
 
         self.async_group.spawn(self._connection_loop)
 
     @property
     def async_group(self) -> aio.Group:
         return self._conn.async_group
 
-    def notify(self, events: typing.List[common.Event]):
+    def notify(self, events: list[common.Event]):
         if not self.is_open or not self._subscription:
             return
 
         events = [event for event in events
                   if self._subscription.matches(event.event_type)]
 
         if not events:
```

## hat/event/mariner/client.py

```diff
@@ -9,56 +9,71 @@
 from hat.event.mariner import common
 from hat.event.mariner.transport import Transport
 
 
 mlog: logging.Logger = logging.getLogger(__name__)
 """Module logger"""
 
-EventsCb = aio.AsyncCallable[[typing.List[common.Event]], None]
+EventsCb: typing.TypeAlias = aio.AsyncCallable[[list[common.Event]], None]
 """Events callback"""
 
 
 async def connect(address: tcp.Address,
                   client_id: str,
-                  client_token: typing.Optional[str] = None,
-                  last_event_id: typing.Optional[common.EventId] = None,
-                  subscriptions: typing.List[common.EventType] = [],
-                  events_cb: typing.Optional[EventsCb] = None,
+                  client_token: str | None = None,
+                  last_event_id: common.EventId | None = None,
+                  subscriptions: list[common.EventType] = [],
+                  events_cb: EventsCb | None = None,
                   ping_delay: int = 30,
                   ping_timeout: int = 10,
                   **kwargs
                   ) -> 'Client':
-    """Connect to mariner server"""
-    client = Client()
-    client._events_cb = events_cb
-    client._ping_delay = ping_delay
-    client._ping_timeout = ping_timeout
-    client._ping_event = asyncio.Event()
+    """Connect to mariner server
 
+    Additional arguments are passed directly to `hat.drivers.tcp.connect`.
+
+    """
     conn = await tcp.connect(address, **kwargs)
 
     try:
-        client._transport = Transport(conn)
-        client._transport.send(common.InitMsg(client_id=client_id,
-                                              client_token=client_token,
-                                              last_event_id=last_event_id,
-                                              subscriptions=subscriptions))
+        transport = Transport(conn)
+
+        msg = common.InitMsg(client_id=client_id,
+                             client_token=client_token,
+                             last_event_id=last_event_id,
+                             subscriptions=subscriptions)
+        await transport.send(msg)
 
-        client.async_group.spawn(client._receive_loop)
-        client.async_group.spawn(client._ping_loop)
+        return Client(transport, events_cb, ping_delay, ping_timeout)
 
     except BaseException:
         await aio.uncancellable(conn.async_close())
         raise
 
-    return client
-
 
 class Client(aio.Resource):
-    """Mariner client"""
+    """Mariner client
+
+    For creation of new instance see `connect` coroutine.
+
+    """
+
+    def __init__(self,
+                 transport: Transport,
+                 events_cb: EventsCb | None,
+                 ping_delay: int,
+                 ping_timeout: int):
+        self._transport = transport
+        self._events_cb = events_cb
+        self._ping_delay = ping_delay
+        self._ping_timeout = ping_timeout
+        self._ping_event = asyncio.Event()
+
+        self.async_group.spawn(self._receive_loop)
+        self.async_group.spawn(self._ping_loop)
 
     @property
     def async_group(self) -> aio.Group:
         """Async group"""
         return self._transport.async_group
 
     async def _receive_loop(self):
@@ -66,15 +81,15 @@
             mlog.debug("starting receive loop")
 
             while True:
                 msg = await self._transport.receive()
                 self._ping_event.set()
 
                 if isinstance(msg, common.PingMsg):
-                    self._transport.send(common.PongMsg())
+                    await self._transport.send(common.PongMsg())
 
                 elif isinstance(msg, common.PongMsg):
                     pass
 
                 elif isinstance(msg, common.EventsMsg):
                     if self._events_cb:
                         await aio.call(self._events_cb, msg.events)
@@ -100,15 +115,15 @@
                 self._ping_event.clear()
 
                 with contextlib.suppress(asyncio.TimeoutError):
                     await aio.wait_for(self._ping_event.wait(),
                                        self._ping_delay)
                     continue
 
-                self._transport.send(common.PingMsg())
+                await self._transport.send(common.PingMsg())
                 await aio.wait_for(self._ping_event.wait(),
                                    self._ping_timeout)
 
         except ConnectionError:
             pass
 
         except asyncio.TimeoutError:
```

## hat/event/mariner/common.py

```diff
@@ -11,17 +11,17 @@
 
 class PongMsg(typing.NamedTuple):
     pass
 
 
 class InitMsg(typing.NamedTuple):
     client_id: str
-    client_token: typing.Optional[str]
-    last_event_id: typing.Optional[EventId]
-    subscriptions: typing.List[EventType]
+    client_token: str | None
+    last_event_id: EventId | None
+    subscriptions: list[EventType]
 
 
 class EventsMsg(typing.NamedTuple):
-    events: typing.List[Event]
+    events: list[Event]
 
 
-Msg = typing.Union[PingMsg, PongMsg, InitMsg, EventsMsg]
+Msg: typing.TypeAlias = PingMsg | PongMsg | InitMsg | EventsMsg
```

## hat/event/mariner/server.py

```diff
@@ -9,34 +9,42 @@
 from hat.event.mariner import common
 from hat.event.mariner.transport import Transport
 
 
 mlog: logging.Logger = logging.getLogger(__name__)
 """Module logger"""
 
-ServerConnectionCb = aio.AsyncCallable[['ServerConnection'], None]
+ServerConnectionCb: typing.TypeAlias = aio.AsyncCallable[['ServerConnection'],
+                                                         None]
 """Server connection callback"""
 
 
 async def listen(address: tcp.Address,
                  connection_cb: ServerConnectionCb,
                  ping_delay: int = 30,
                  ping_timeout: int = 10,
-                 subscriptions: typing.List[common.EventType] = [('*')],
+                 subscriptions: list[common.EventType] = [('*')],
+                 *,
+                 bind_connections: bool = True,
                  **kwargs
                  ) -> 'Server':
-    """Create listening server"""
+    """Create listening server
+
+    Additional arguments are passed directly to `hat.drivers.tcp.listen`.
+
+    """
     server = Server()
     server._connection_cb = connection_cb
     server._ping_delay = ping_delay
     server._ping_timeout = ping_timeout
     server._subscription = common.Subscription(subscriptions)
 
     server._server = await tcp.listen(server._on_connection, address,
-                                      bind_connections=True)
+                                      bind_connections=bind_connections,
+                                      **kwargs)
 
     mlog.debug('listening on %s', address)
     return server
 
 
 class Server(aio.Resource):
     """Mariner server"""
@@ -88,42 +96,42 @@
 
     @property
     def client_id(self) -> str:
         """Client id"""
         return self._client_id
 
     @property
-    def client_token(self) -> typing.Optional[str]:
+    def client_token(self) -> str | None:
         """Client token"""
         return self._client_token
 
     @property
-    def last_event_id(self) -> typing.Optional[common.EventId]:
+    def last_event_id(self) -> common.EventId | None:
         """Laste event id"""
         return self._last_event_id
 
     @property
     def subscription(self) -> common.Subscription:
         """Subscription"""
         return self._subscription
 
-    def send_events(self, events: typing.List[common.Event]):
+    async def send_events(self, events: list[common.Event]):
         """Send events"""
-        self._transport.send(common.EventsMsg(events=events))
+        await self._transport.send(common.EventsMsg(events=events))
 
     async def _receive_loop(self):
         try:
             mlog.debug("starting receive loop")
 
             while True:
                 msg = await self._transport.receive()
                 self._ping_event.set()
 
                 if isinstance(msg, common.PingMsg):
-                    self._transport.send(common.PongMsg())
+                    await self._transport.send(common.PongMsg())
 
                 elif isinstance(msg, common.PongMsg):
                     pass
 
                 else:
                     raise Exception("unsupported msg: %s", msg)
 
@@ -145,15 +153,15 @@
                 self._ping_event.clear()
 
                 with contextlib.suppress(asyncio.TimeoutError):
                     await aio.wait_for(self._ping_event.wait(),
                                        self._ping_delay)
                     continue
 
-                self._transport.send(common.PingMsg())
+                await self._transport.send(common.PingMsg())
 
                 await aio.wait_for(self._ping_event.wait(),
                                    self._ping_timeout)
 
         except ConnectionError:
             pass
```

## hat/event/mariner/transport.py

```diff
@@ -17,27 +17,27 @@
     @property
     def async_group(self) -> aio.Group:
         return self._conn.async_group
 
     async def drain(self):
         await self._conn.drain()
 
-    def send(self, msg: common.Msg):
+    async def send(self, msg: common.Msg):
         msg_json = encoder.encode_msg(msg)
         msg_bytes = json.encode(msg_json).encode('utf-8')
         msg_len = len(msg_bytes)
         len_size = math.ceil(msg_len.bit_length() / 8)
 
         if len_size < 1 or len_size > 8:
             raise ValueError('unsupported msg size')
 
         data = bytes(itertools.chain([len_size],
                                      msg_len.to_bytes(len_size, 'big'),
                                      msg_bytes))
-        self._conn.write(data)
+        await self._conn.write(data)
 
     async def receive(self) -> common.Msg:
         len_size_bytes = await self._conn.readexactly(1)
         len_size = len_size_bytes[0]
 
         if len_size < 1 or len_size > 8:
             raise ValueError('unsupported msg size')
```

## hat/event/server/common.py

```diff
@@ -1,40 +1,69 @@
 """Common event server structures and functionality"""
 
+from hat.event.common import *  # NOQA
+
 import abc
 import enum
 import typing
 
 from hat import aio
 from hat import json
 from hat import util
+
 from hat.event.common import (EventId,
                               Event,
                               QueryData,
                               Subscription,
                               RegisterEvent)
-from hat.event.common import *  # NOQA
 
 
 SourceType = enum.Enum('SourceType', [
     'SYNCER',
     'EVENTER',
     'MODULE',
     'ENGINE'])
 
 
 class Source(typing.NamedTuple):
     type: SourceType
     id: int
 
 
-BackendConf = json.Data
+EventsCb: typing.TypeAlias = typing.Callable[[list[Event]], None]
+"""Events callback"""
+
+
+class Engine(aio.Resource):
+    """Engine ABC"""
+
+    @abc.abstractmethod
+    def register_events_cb(self,
+                           cb: EventsCb
+                           ) -> util.RegisterCallbackHandle:
+        """Register events callback"""
+
+    @abc.abstractmethod
+    async def register(self,
+                       source: Source,
+                       events: list[RegisterEvent]
+                       ) -> list[Event | None]:
+        """Register events"""
+
+    @abc.abstractmethod
+    async def query(self,
+                    data: QueryData
+                    ) -> list[Event]:
+        """Query events"""
+
+
+BackendConf: typing.TypeAlias = json.Data
 """Backend configuration"""
 
-CreateBackend = aio.AsyncCallable[[BackendConf], 'Backend']
+CreateBackend: typing.TypeAlias = aio.AsyncCallable[[BackendConf], 'Backend']
 """Create backend callable"""
 
 
 class Backend(aio.Resource):
     """Backend ABC
 
     Backend is implemented as python module which is dynamically imported.
@@ -93,19 +122,19 @@
         returned."""
 
     @abc.abstractmethod
     async def flush(self):
         """Flush internal buffers and permanently persist events"""
 
 
-ModuleConf = json.Data
+ModuleConf: typing.TypeAlias = json.Data
 
-CreateModule = aio.AsyncCallable[
-    [ModuleConf, 'hat.event.engine.Engine', Source],
-    'Module']
+CreateModule: typing.TypeAlias = aio.AsyncCallable[[ModuleConf, Engine,
+                                                    Source],
+                                                   'Module']
 
 
 class Module(aio.Resource):
     """Module ABC
 
     Module is implemented as python module which is dynamically imported.
     It is expected that this module implements:
```

## hat/event/server/engine.py

```diff
@@ -1,27 +1,24 @@
 """Engine"""
 
 import asyncio
 import collections
 import importlib
 import logging
-import typing
 
 from hat import aio
 from hat import json
 from hat import util
+
 from hat.event.server import common
 
 
 mlog: logging.Logger = logging.getLogger(__name__)
 """Module logger"""
 
-EventsCb = typing.Callable[[typing.List[common.Event]], None]
-"""Events callback"""
-
 
 async def create_engine(conf: json.Data,
                         backend: common.Backend
                         ) -> 'Engine':
     """Create engine
 
     Args:
@@ -63,42 +60,42 @@
     except BaseException:
         await aio.uncancellable(engine.async_close())
         raise
 
     return engine
 
 
-class Engine(aio.Resource):
+class Engine(common.Engine):
 
     @property
     def async_group(self) -> aio.Group:
         """Async group"""
         return self._async_group
 
     def register_events_cb(self,
-                           cb: EventsCb
+                           cb: common.EventsCb
                            ) -> util.RegisterCallbackHandle:
         """Register events callback"""
         return self._register_cbs.register(cb)
 
     async def register(self,
                        source: common.Source,
-                       events: typing.List[common.RegisterEvent]
-                       ) -> typing.List[typing.Optional[common.Event]]:
+                       events: list[common.RegisterEvent]
+                       ) -> list[common.Event | None]:
         """Register events"""
         if not events:
             return []
 
         future = asyncio.Future()
         self._register_queue.put_nowait((future, source, events))
         return await future
 
     async def query(self,
                     data: common.QueryData
-                    ) -> typing.List[common.Event]:
+                    ) -> list[common.Event]:
         """Query events"""
         return await self._backend.query(data)
 
     async def _register_loop(self):
         future = None
         mlog.debug("starting register loop")
```

## hat/event/server/mariner_server.py

```diff
@@ -86,31 +86,31 @@
             events_queue = aio.Queue()
             with self._backend.register_flushed_events_cb(
                     events_queue.put_nowait):
 
                 for last_event_id in self._last_event_ids.values():
                     async for events in self._backend.query_flushed(
                             last_event_id):
-                        self._send_events(events)
+                        await self._send_events(events)
 
                 while True:
                     events = await events_queue.get()
-                    self._send_events(events)
+                    await self._send_events(events)
 
         except ConnectionError:
             pass
 
         except Exception as e:
             mlog.error("connection loop error: %s", e, exc_info=e)
 
         finally:
             mlog.debug("stopping connection loop")
             self.close()
 
-    def _send_events(self, events):
+    async def _send_events(self, events):
         if not events:
             return
 
         last_event_id = self._last_event_ids.get(events[0].event_id.server)
         if last_event_id:
             if events[0].event_id.session < last_event_id.session:
                 return
@@ -121,11 +121,11 @@
 
         events = [event for event in events
                   if self._subscription.matches(event.event_type)]
         if not events:
             return
 
         mlog.debug("sending events")
-        self._conn.send_events(events)
+        await self._conn.send_events(events)
 
         last_event_id = events[-1].event_id
         self._last_event_ids[last_event_id.server] = last_event_id
```

## hat/event/server/runner.py

```diff
@@ -1,12 +1,11 @@
 import asyncio
 import contextlib
 import importlib
 import logging
-import typing
 
 from hat import aio
 from hat import json
 import hat.monitor.client
 import hat.monitor.common
 
 from hat.event.server import common
@@ -172,16 +171,16 @@
 
 
 class EngineRunner(aio.Resource):
 
     def __init__(self,
                  conf: json.Data,
                  backend: common.Backend,
-                 syncer_server: typing.Optional[SyncerServer],
-                 syncer_client: typing.Optional[SyncerClient]):
+                 syncer_server: SyncerServer | None,
+                 syncer_client: SyncerClient | None):
         self._conf = conf
         self._backend = backend
         self._syncer_server = syncer_server
         self._syncer_client = syncer_client
         self._async_group = aio.Group()
         self._syncer_client_states = {}
         self._engine = None
```

## hat/event/server/syncer_client.py

```diff
@@ -22,29 +22,31 @@
 class SyncerClientState(enum.Enum):
     """Connection state"""
     CONNECTED = 0
     SYNCED = 1
     DISCONNECTED = 2
 
 
-ServerId = int
+ServerId: typing.TypeAlias = int
 """Server identifier"""
 
-StateCb = typing.Callable[[ServerId, SyncerClientState], None]
+StateCb: typing.TypeAlias = typing.Callable[[ServerId, SyncerClientState],
+                                            None]
 """Connection state callback"""
 
-EventsCb = typing.Callable[[ServerId, typing.List[common.Event]], None]
+EventsCb: typing.TypeAlias = typing.Callable[[ServerId, list[common.Event]],
+                                             None]
 """Events callback"""
 
 
 async def create_syncer_client(backend: common.Backend,
                                monitor_client: hat.monitor.client.Client,
                                monitor_group: str,
                                name: str,
-                               syncer_token: typing.Optional[str] = None,
+                               syncer_token: str | None = None,
                                **kwargs
                                ) -> 'SyncerClient':
     """Create syncer client
 
     Args:
         backend: backend
         monitor_client: monitor client
```

## hat/event/server/syncer_server.py

```diff
@@ -1,12 +1,11 @@
 """Syncer server"""
 
 import asyncio
 import logging
-import typing
 
 from hat import aio
 from hat import json
 from hat import util
 
 from hat.event.server import common
 import hat.event.syncer
@@ -49,15 +48,15 @@
 
     @property
     def async_group(self) -> aio.Group:
         """Async group"""
         return self._server.async_group
 
     @property
-    def state(self) -> typing.List[hat.event.syncer.ClientInfo]:
+    def state(self) -> list[hat.event.syncer.ClientInfo]:
         """State of all active connections"""
         return self._server.state
 
     def register_state_cb(self,
                           cb: hat.event.syncer.StateCb
                           ) -> util.RegisterCallbackHandle:
         """Register state change callback"""
```

## hat/event/server/backends/dummy.py

```diff
@@ -12,14 +12,15 @@
 """
 
 import typing
 
 from hat import aio
 from hat import json
 from hat import util
+
 from hat.event.server import common
 
 
 json_schema_id = None
 json_schema_repo = None
 
 
@@ -32,41 +33,41 @@
 class DummyBackend(common.Backend):
 
     @property
     def async_group(self) -> aio.Group:
         return self._async_group
 
     def register_registered_events_cb(self,
-                                      cb: typing.Callable[[typing.List[common.Event]],  # NOQA
+                                      cb: typing.Callable[[list[common.Event]],
                                                           None]
                                       ) -> util.RegisterCallbackHandle:
         return util.RegisterCallbackHandle(cancel=lambda: None)
 
     def register_flushed_events_cb(self,
-                                   cb: typing.Callable[[typing.List[common.Event]],  # NOQA
+                                   cb: typing.Callable[[list[common.Event]],
                                                        None]
                                    ) -> util.RegisterCallbackHandle:
         return util.RegisterCallbackHandle(cancel=lambda: None)
 
     async def get_last_event_id(self,
                                 server_id: int
                                 ) -> common.EventId:
         return common.EventId(server_id, 0, 0)
 
     async def register(self,
-                       events: typing.List[common.Event]
-                       ) -> typing.List[typing.Optional[common.Event]]:
+                       events: list[common.Event]
+                       ) -> list[common.Event | None]:
         return events
 
     async def query(self,
                     data: common.QueryData
-                    ) -> typing.List[common.Event]:
+                    ) -> list[common.Event]:
         return []
 
     async def query_flushed(self,
                             data: common.QueryData
-                            ) -> typing.AsyncIterable[typing.List[common.Event]]:  # NOQA
+                            ) -> typing.AsyncIterable[list[common.Event]]:
         for events in []:
             yield events
 
     async def flush(self):
         pass
```

## hat/event/server/backends/memory.py

```diff
@@ -9,14 +9,15 @@
 
 import collections
 import typing
 
 from hat import aio
 from hat import json
 from hat import util
+
 from hat.event.server import common
 
 
 json_schema_id = None
 json_schema_repo = None
 
 
@@ -31,44 +32,44 @@
 class MemoryBackend(common.Backend):
 
     @property
     def async_group(self) -> aio.Group:
         return self._async_group
 
     def register_registered_events_cb(self,
-                                      cb: typing.Callable[[typing.List[common.Event]],  # NOQA
+                                      cb: typing.Callable[[list[common.Event]],
                                                           None]
                                       ) -> util.RegisterCallbackHandle:
         return self._registered_events_cbs.register(cb)
 
     def register_flushed_events_cb(self,
-                                   cb: typing.Callable[[typing.List[common.Event]],  # NOQA
+                                   cb: typing.Callable[[list[common.Event]],
                                                        None]
                                    ) -> util.RegisterCallbackHandle:
         return util.RegisterCallbackHandle(cancel=lambda: None)
 
     async def get_last_event_id(self,
                                 server_id: int
                                 ) -> common.EventId:
         event_ids = (e.event_id for e in self._events
                      if e.server == server_id)
         key = lambda event_id: event_id.instance  # NOQA
         default = common.EventId(server=server_id, session=0, instance=0)
         return max(event_ids, key=key, default=default)
 
     async def register(self,
-                       events: typing.List[common.Event]
-                       ) -> typing.List[typing.Optional[common.Event]]:
+                       events: list[common.Event]
+                       ) -> list[common.Event | None]:
         self._events.extend(events)
         self._registered_events_cbs.notify(events)
         return events
 
     async def query(self,
                     data: common.QueryData
-                    ) -> typing.List[common.Event]:
+                    ) -> list[common.Event]:
         events = self._events
 
         if data.server_id is not None:
             events = _filter_server_id(events, data.server_id)
 
         if data.event_ids is not None:
             events = _filter_events_ids(events, data.event_ids)
@@ -113,15 +114,15 @@
         if data.max_results is not None:
             events = _filter_max_results(events, data.max_results)
 
         return list(events)
 
     async def query_flushed(self,
                             data: common.QueryData
-                            ) -> typing.AsyncIterable[typing.List[common.Event]]:  # NOQA
+                            ) -> typing.AsyncIterable[list[common.Event]]:
         for events in []:
             yield events
 
     async def flush(self):
         pass
```

## hat/event/server/backends/lmdb/backend.py

```diff
@@ -3,14 +3,15 @@
 import collections
 import logging
 import typing
 
 from hat import aio
 from hat import json
 from hat import util
+
 from hat.event.server.backends.lmdb import common
 from hat.event.server.backends.lmdb import environment
 from hat.event.server.backends.lmdb import latestdb
 from hat.event.server.backends.lmdb import ordereddb
 from hat.event.server.backends.lmdb import refdb
 from hat.event.server.backends.lmdb import systemdb
 from hat.event.server.backends.lmdb.conditions import Conditions
@@ -80,34 +81,34 @@
 class LmdbBackend(common.Backend):
 
     @property
     def async_group(self) -> aio.Group:
         return self._async_group
 
     def register_registered_events_cb(self,
-                                      cb: typing.Callable[[typing.List[common.Event]],  # NOQA
+                                      cb: typing.Callable[[list[common.Event]],
                                                           None]
                                       ) -> util.RegisterCallbackHandle:
         return self._registered_events_cbs.register(cb)
 
     def register_flushed_events_cb(self,
-                                   cb: typing.Callable[[typing.List[common.Event]],  # NOQA
+                                   cb: typing.Callable[[list[common.Event]],
                                                        None]
                                    ) -> util.RegisterCallbackHandle:
         return self._flushed_events_cbs.register(cb)
 
     async def get_last_event_id(self,
                                 server_id: int
                                 ) -> common.EventId:
         event_id, _ = self._sys_db.get_last_event_id_timestamp(server_id)
         return event_id
 
     async def register(self,
-                       events: typing.List[common.Event]
-                       ) -> typing.List[common.Event]:
+                       events: list[common.Event]
+                       ) -> list[common.Event]:
         for event in events:
             last_event_id, last_timestamp = \
                 self._sys_db.get_last_event_id_timestamp(event.event_id.server)
 
             if last_event_id >= event.event_id:
                 mlog.warning("event registration skipped: invalid event id")
                 continue
@@ -136,15 +137,15 @@
                                                      event.timestamp)
 
         self._registered_events_cbs.notify(events)
         return events
 
     async def query(self,
                     data: common.QueryData
-                    ) -> typing.List[common.Event]:
+                    ) -> list[common.Event]:
         if (data.server_id is None and
                 data.event_ids is None and
                 data.t_to is None and
                 data.source_t_from is None and
                 data.source_t_to is None and
                 data.payload is None and
                 data.order == common.Order.DESCENDING and
@@ -187,15 +188,15 @@
                                     max_results=data.max_results)
             return list(events)
 
         return []
 
     async def query_flushed(self,
                             event_id: common.EventId
-                            ) -> typing.AsyncIterable[typing.List[common.Event]]:  # NOQA
+                            ) -> typing.AsyncIterable[list[common.Event]]:
         async for events in self._ref_db.query(event_id):
             yield events
 
     async def flush(self):
         async with self._flush_lock:
             if not self._env.is_open:
                 return
```

## hat/event/server/backends/lmdb/common.py

```diff
@@ -1,18 +1,20 @@
+from hat.event.server.common import *  # NOQA
+
 from pathlib import Path
 import abc
 import enum
 import platform
 import typing
 
 import lmdb
 
 from hat import json
+
 from hat.event.server.common import Event, EventId, EventType, Timestamp
-from hat.event.server.common import *  # NOQA
 
 
 default_max_size = (512 * 1024 * 1024 * 1024
                     if platform.architecture()[0] == '64bit'
                     else 1024 * 1024 * 1024)
 
 
@@ -22,59 +24,59 @@
     LATEST_TYPE = 2
     ORDERED_DATA = 3
     ORDERED_PARTITION = 4
     ORDERED_COUNT = 5
     REF = 6
 
 
-ServerId = int
-EventTypeRef = int
-PartitionId = int
+ServerId: typing.TypeAlias = int
+EventTypeRef: typing.TypeAlias = int
+PartitionId: typing.TypeAlias = int
 
-SystemDbKey = ServerId
-SystemDbValue = typing.Tuple[EventId, Timestamp]
+SystemDbKey: typing.TypeAlias = ServerId
+SystemDbValue: typing.TypeAlias = tuple[EventId, Timestamp]
 
-LatestDataDbKey = EventTypeRef
-LatestDataDbValue = Event
+LatestDataDbKey: typing.TypeAlias = EventTypeRef
+LatestDataDbValue: typing.TypeAlias = Event
 
-LatestTypeDbKey = EventTypeRef
-LatestTypeDbValue = EventType
+LatestTypeDbKey: typing.TypeAlias = EventTypeRef
+LatestTypeDbValue: typing.TypeAlias = EventType
 
-OrderedDataDbKey = typing.Tuple[PartitionId, Timestamp, EventId]
-OrderedDataDbValue = Event
+OrderedDataDbKey: typing.TypeAlias = tuple[PartitionId, Timestamp, EventId]
+OrderedDataDbValue: typing.TypeAlias = Event
 
-OrderedPartitionDbKey = PartitionId
-OrderedPartitionDbValue = json.Data
+OrderedPartitionDbKey: typing.TypeAlias = PartitionId
+OrderedPartitionDbValue: typing.TypeAlias = json.Data
 
-OrderedCountDbKey = PartitionId
-OrderedCountDbValue = int
+OrderedCountDbKey: typing.TypeAlias = PartitionId
+OrderedCountDbValue: typing.TypeAlias = int
 
-RefDbKey = EventId
-RefDbValue = typing.Set['EventRef']
+RefDbKey: typing.TypeAlias = EventId
+RefDbValue: typing.TypeAlias = typing.Set['EventRef']
 
 
 class LatestEventRef(typing.NamedTuple):
     key: LatestDataDbKey
 
 
 class OrderedEventRef(typing.NamedTuple):
     key: OrderedDataDbKey
 
 
-EventRef = typing.Union[LatestEventRef,
-                        OrderedEventRef]
+EventRef: typing.TypeAlias = LatestEventRef | OrderedEventRef
 
 
 class EventRefChange(typing.NamedTuple):
     event_id: EventId
-    added: typing.Set[EventRef]
-    removed: typing.Set[EventRef]
+    added: set[EventRef]
+    removed: set[EventRef]
 
 
-ExtFlushCb = typing.Callable[[lmdb.Transaction], typing.Iterable[Event]]
+ExtFlushCb: typing.TypeAlias = typing.Callable[[lmdb.Transaction],
+                                               typing.Iterable[Event]]
 
 
 class Flushable(abc.ABC):
 
     @abc.abstractmethod
     def create_ext_flush(self) -> ExtFlushCb:
         pass
```

## hat/event/server/backends/lmdb/conditions.py

```diff
@@ -1,8 +1,9 @@
 from hat import json
+
 from hat.event.server.backends.lmdb import common
 
 
 class Conditions:
 
     def __init__(self, conf: json.Data):
         self._conditions = [(common.Subscription(i['subscriptions']),
```

## hat/event/server/backends/lmdb/encoder.py

```diff
@@ -1,11 +1,12 @@
 import itertools
 import struct
 
 from hat import json
+
 from hat.event.server.backends.lmdb import common
 
 
 def encode_system_db_key(key: common.SystemDbKey) -> bytes:
     return _encode_uint(key)
```

## hat/event/server/backends/lmdb/environment.py

```diff
@@ -1,13 +1,14 @@
 from pathlib import Path
 import typing
 
 import lmdb
 
 from hat import aio
+
 from hat.event.server.backends.lmdb import common
 
 
 async def create(db_path: Path,
                  max_db_size: int
                  ) -> 'Environment':
     env = Environment()
@@ -48,9 +49,9 @@
                    db_type: common.DbType
                    ) -> lmdb.Cursor:
         return txn.cursor(self._dbs[db_type])
 
     def ext_stat(self,
                  txn: lmdb.Transaction,
                  db_type: common.DbType
-                 ) -> typing.Dict[str, int]:
+                 ) -> dict[str, int]:
         return txn.stat(self._dbs[db_type])
```

## hat/event/server/backends/lmdb/latestdb.py

```diff
@@ -4,18 +4,18 @@
 from hat.event.server.backends.lmdb import common
 from hat.event.server.backends.lmdb import encoder
 from hat.event.server.backends.lmdb import environment
 from hat.event.server.backends.lmdb import refdb
 from hat.event.server.backends.lmdb.conditions import Conditions
 
 
-Changes = typing.Tuple[typing.Dict[common.LatestDataDbKey,
-                                   common.LatestDataDbValue],
-                       typing.Dict[common.LatestTypeDbKey,
-                                   common.LatestTypeDbValue]]
+Changes: typing.TypeAlias = tuple[dict[common.LatestDataDbKey,
+                                       common.LatestDataDbValue],
+                                  dict[common.LatestTypeDbKey,
+                                       common.LatestTypeDbValue]]
 
 
 def ext_create(env: environment.Environment,
                ref_db: refdb.RefDb,
                subscription: common.Subscription,
                conditions: Conditions
                ) -> 'LatestDb':
@@ -65,15 +65,15 @@
 
         self._events[event.event_type] = event
         self._changes[0][ref] = event
 
         return True
 
     def query(self,
-              event_types: typing.Optional[typing.List[common.EventType]]
+              event_types: list[common.EventType] | None
               ) -> typing.Iterable[common.Event]:
         if event_types is None:
             yield from self._events.values()
 
         elif any(any(subtype in ('*', '?')
                      for subtype in event_type)
                  for event_type in event_types):
```

## hat/event/server/backends/lmdb/ordereddb.py

```diff
@@ -1,29 +1,31 @@
 import collections
 import functools
 import itertools
 import typing
 
 from hat import json
+
 from hat.event.server.backends.lmdb import common
 from hat.event.server.backends.lmdb import encoder
 from hat.event.server.backends.lmdb import environment
 from hat.event.server.backends.lmdb import refdb
 from hat.event.server.backends.lmdb.conditions import Conditions
 
 
-Changes = typing.Iterable[typing.Tuple[common.Timestamp, common.Event]]
+Changes: typing.TypeAlias = typing.Iterable[tuple[common.Timestamp,
+                                                  common.Event]]
 
 
 def ext_create(env: environment.Environment,
                ref_db: refdb.RefDb,
                subscription: common.Subscription,
                conditions: Conditions,
                order_by: common.OrderBy,
-               limit: typing.Optional[json.Data]
+               limit: json.Data | None
                ) -> 'OrderedDb':
     db = OrderedDb()
     db._env = env
     db._ref_db = ref_db
     db._subscription = subscription
     db._conditions = conditions
     db._order_by = order_by
@@ -91,25 +93,25 @@
         else:
             raise ValueError('unsupported order by')
 
         self._changes.append((timestamp, event))
         return True
 
     async def query(self,
-                    subscription: typing.Optional[common.Subscription],
-                    server_id: typing.Optional[int],
-                    event_ids: typing.Optional[typing.List[common.EventId]],
-                    t_from: typing.Optional[common.Timestamp],
-                    t_to: typing.Optional[common.Timestamp],
-                    source_t_from: typing.Optional[common.Timestamp],
-                    source_t_to: typing.Optional[common.Timestamp],
-                    payload: typing.Optional[common.EventPayload],
+                    subscription: common.Subscription | None,
+                    server_id: int | None,
+                    event_ids: list[common.EventId] | None,
+                    t_from: common.Timestamp | None,
+                    t_to: common.Timestamp | None,
+                    source_t_from: common.Timestamp | None,
+                    source_t_to: common.Timestamp | None,
+                    payload: common.EventPayload | None,
                     order: common.Order,
                     unique_type: bool,
-                    max_results: typing.Optional[int]
+                    max_results: int | None
                     ) -> typing.Iterable[common.Event]:
         unique_types = set() if unique_type else None
         events = collections.deque()
 
         if order == common.Order.DESCENDING:
             events.extend(self._query_changes(
                 subscription, server_id, event_ids, t_from, t_to,
@@ -149,15 +151,15 @@
 
     def create_ext_flush(self) -> common.ExtFlushCb:
         changes, self._changes = self._changes, collections.deque()
         return functools.partial(self._ext_flush, changes)
 
     def ext_apply_limit(self,
                         now: common.Timestamp,
-                        max_entries_remove: typing.Optional[int] = None,
+                        max_entries_remove: int | None = None,
                         ) -> int:
         if not self._limit:
             return True
 
         with self._env.ext_begin(write=True) as txn:
             entries_count = self._ext_get_entries_count(txn)
             new_entries_count = self._ext_apply_limit(txn, entries_count,
```

## hat/event/server/backends/lmdb/refdb.py

```diff
@@ -2,14 +2,15 @@
 import collections
 import typing
 
 import lmdb
 
 from hat import aio
 from hat import util
+
 from hat.event.server.backends.lmdb import common
 from hat.event.server.backends.lmdb import encoder
 from hat.event.server.backends.lmdb import environment
 
 
 query_queue_size = 100
 
@@ -17,15 +18,15 @@
 class RefDb:
 
     def __init__(self, env: environment.Environment):
         self._env = env
 
     async def query(self,
                     event_id: common.EventId
-                    ) -> typing.AsyncIterable[typing.List[common.Event]]:
+                    ) -> typing.AsyncIterable[list[common.Event]]:
 
         # TODO use other executor to prevent blocking of other query and flush
         #      operations
 
         queue = aio.Queue(query_queue_size)
         loop = asyncio.get_running_loop()
```

## hat/event/server/backends/lmdb/systemdb.py

```diff
@@ -2,15 +2,15 @@
 import typing
 
 from hat.event.server.backends.lmdb import common
 from hat.event.server.backends.lmdb import encoder
 from hat.event.server.backends.lmdb import environment
 
 
-Changes = typing.Dict[common.SystemDbKey, common.SystemDbValue]
+Changes: typing.TypeAlias = dict[common.SystemDbKey, common.SystemDbValue]
 
 
 def ext_create(env: environment.Environment) -> 'SystemDb':
     db = SystemDb()
     db._env = env
     db._cache = {}
     db._changes = {}
@@ -25,16 +25,16 @@
     return db
 
 
 class SystemDb(common.Flushable):
 
     def get_last_event_id_timestamp(self,
                                     server_id: common.ServerId
-                                    ) -> typing.Tuple[common.EventId,
-                                                      common.Timestamp]:
+                                    ) -> tuple[common.EventId,
+                                               common.Timestamp]:
         value = self._cache.get(server_id)
         if value:
             return value
 
         event_id = common.EventId(server=server_id,
                                   session=0,
                                   instance=0)
```

## hat/event/server/backends/lmdb/convert/v06.py

```diff
@@ -7,15 +7,15 @@
 import lmdb
 
 from hat import chatter
 from hat import json
 from hat import sbs
 
 
-EventType: typing.Type = typing.Tuple[str, ...]
+EventType: typing.TypeAlias = typing.Tuple[str, ...]
 """Event type"""
 
 
 EventPayloadType = enum.Enum('EventPayloadType', [
     'BINARY',
     'JSON',
     'SBS'])
@@ -25,24 +25,24 @@
     server: int
     """server identifier"""
     instance: int
     """event instance identifier"""
 
 
 class SbsData(typing.NamedTuple):
-    module: typing.Optional[str]
+    module: str | None
     """SBS module name"""
     type: str
     """SBS type name"""
     data: bytes
 
 
 class EventPayload(typing.NamedTuple):
     type: EventPayloadType
-    data: typing.Union[bytes, json.Data, SbsData]
+    data: bytes | json.Data | SbsData
 
 
 class Timestamp(typing.NamedTuple):
     s: int
     """seconds since 1970-01-01 (can be negative)"""
     us: int
     """microseconds added to timestamp seconds in range [0, 1e6)"""
@@ -75,16 +75,16 @@
         return self.s * 1000000 + self.us
 
 
 class Event(typing.NamedTuple):
     event_id: EventId
     event_type: EventType
     timestamp: Timestamp
-    source_timestamp: typing.Optional[Timestamp]
-    payload: typing.Optional[EventPayload]
+    source_timestamp: Timestamp | None
+    payload: EventPayload | None
 
 
 def decode_uint(x: bytes) -> int:
     return struct.unpack(">Q", x)[0]
 
 
 def decode_timestamp(x: bytes) -> Timestamp:
@@ -97,15 +97,15 @@
 
 
 def decode_json(x: bytes) -> json.Data:
     return json.decode(str(x, encoding='utf-8'))
 
 
 def decode_uint_timestamp_uint(x: bytes
-                               ) -> typing.Tuple[int, Timestamp, int]:
+                               ) -> tuple[int, Timestamp, int]:
     res = struct.unpack(">QQIQ", x)
     return res[0], Timestamp(res[1] - (1 << 63), res[2]), res[3]
 
 
 def decode_event(event_bytes: bytes) -> Event:
     event_sbs = _sbs_repo.decode('HatEvent', 'Event', event_bytes)
     return _event_from_sbs(event_sbs)
@@ -239,9 +239,9 @@
     return SbsData(module=_optional_from_sbs(data['module']),
                    type=data['type'],
                    data=data['data'])
 
 
 def _optional_from_sbs(data: sbs.Data,
                        fn=lambda i: i
-                       ) -> typing.Optional[typing.Any]:
+                       ) -> typing.Any | None:
     return fn(data[1]) if data[0] == 'value' else None
```

## hat/event/server/backends/lmdb/convert/v07.py

```diff
@@ -1,17 +1,18 @@
 from pathlib import Path
 import platform
-import typing
 
 import lmdb
 
 from hat import json
+
 from hat.event.server.backends.lmdb import common
 from hat.event.server.backends.lmdb import encoder
 
+
 EventType = common.EventType
 EventId = common.EventId
 EventPayloadType = common.EventPayloadType
 EventPayload = common.EventPayload
 Timestamp = common.Timestamp
 Event = common.Event
 DbType = common.DbType
@@ -19,33 +20,33 @@
 EventTypeRef = common.EventTypeRef
 PartitionId = common.PartitionId
 LatestEventRef = common.LatestEventRef
 OrderedEventRef = common.OrderedEventRef
 EventRef = common.EventRef
 
 SystemDbKey = ServerId
-SystemDbValue = typing.Tuple[EventId, Timestamp]
+SystemDbValue = tuple[EventId, Timestamp]
 
 LatestDataDbKey = EventTypeRef
 LatestDataDbValue = Event
 
 LatestTypeDbKey = EventTypeRef
 LatestTypeDbValue = EventType
 
-OrderedDataDbKey = typing.Tuple[PartitionId, Timestamp, EventId]
+OrderedDataDbKey = tuple[PartitionId, Timestamp, EventId]
 OrderedDataDbValue = Event
 
 OrderedPartitionDbKey = PartitionId
 OrderedPartitionDbValue = json.Data
 
 OrderedCountDbKey = PartitionId
 OrderedCountDbValue = int
 
 RefDbKey = EventId
-RefDbValue = typing.Set[EventRef]
+RefDbValue = set[EventRef]
 
 encode_system_db_key = encoder.encode_system_db_key
 encode_system_db_value = encoder.encode_system_db_value
 encode_latest_data_db_key = encoder.encode_latest_data_db_key
 encode_latest_data_db_value = encoder.encode_latest_data_db_value
 encode_latest_type_db_key = encoder.encode_latest_type_db_key
 encode_latest_type_db_value = encoder.encode_latest_type_db_value
```

## hat/event/syncer/client.py

```diff
@@ -6,28 +6,28 @@
 
 from hat.event.syncer import common
 
 
 mlog: logging.Logger = logging.getLogger(__name__)
 """Module logger"""
 
-SyncedCb = aio.AsyncCallable[[], None]
+SyncedCb: typing.TypeAlias = aio.AsyncCallable[[], None]
 """Synced callback"""
 
-EventsCb = aio.AsyncCallable[[typing.List[common.Event]], None]
+EventsCb: typing.TypeAlias = aio.AsyncCallable[[list[common.Event]], None]
 """Events callback"""
 
 
 async def connect(address: str,
                   client_name: str,
                   last_event_id: common.EventId,
-                  synced_cb: typing.Optional[SyncedCb] = None,
-                  events_cb: typing.Optional[EventsCb] = None,
-                  client_token: typing.Optional[str] = None,
-                  subscriptions: typing.List[common.EventType] = [('*',)]
+                  synced_cb: SyncedCb | None = None,
+                  events_cb: EventsCb | None = None,
+                  client_token: str | None = None,
+                  subscriptions: list[common.EventType] = [('*',)]
                   ) -> 'Client':
     """Connect to remote syncer server"""
     client = Client()
     client._synced_cb = synced_cb
     client._events_cb = events_cb
 
     client._conn = await chatter.connect(common.sbs_repo, address)
```

## hat/event/syncer/common.py

```diff
@@ -6,16 +6,16 @@
 
 from hat.event.common import EventId, EventType
 
 
 class SyncerReq(typing.NamedTuple):
     last_event_id: EventId
     client_name: str
-    client_token: typing.Optional[str]
-    subscriptions: typing.List[EventType]
+    client_token: str | None
+    subscriptions: list[EventType]
 
 
 def syncer_req_to_sbs(syncer_req: SyncerReq) -> sbs.Data:
     """Convert SyncerReq to SBS data"""
     return {'lastEventId': _event_id_to_sbs(syncer_req.last_event_id),
             'clientName': syncer_req.client_name,
             'clientToken': _optional_to_sbs(syncer_req.client_token),
```

## hat/event/syncer/server.py

```diff
@@ -18,26 +18,26 @@
 
 class ClientInfo(typing.NamedTuple):
     """Client connection information"""
     name: str
     synced: bool
 
 
-StateCb = typing.Callable[[typing.List[ClientInfo]], None]
+StateCb: typing.TypeAlias = typing.Callable[[list[ClientInfo]], None]
 """Syncer state change callback"""
 
-QueryCb = typing.Callable[[common.EventId],
-                          typing.AsyncIterable[typing.List[common.Event]]]
+QueryCb: typing.TypeAlias = typing.Callable[[common.EventId],
+                                            typing.AsyncIterable[list[common.Event]]]  # NOQA
 """Query callback"""
 
 
 async def listen(address: str,
-                 query_cb: typing.Optional[QueryCb] = None,
-                 subscriptions: typing.List[common.EventType] = [('*',)],
-                 token: typing.Optional[str] = None
+                 query_cb: QueryCb | None = None,
+                 subscriptions: list[common.EventType] = [('*',)],
+                 token: str | None = None
                  ) -> 'Server':
     """Create listening syncer server"""
     server = Server()
     server._query_cb = query_cb
     server._subscription = common.Subscription(subscriptions)
     server._token = token
     server._state = {}
@@ -60,25 +60,25 @@
 
     @property
     def async_group(self):
         """Async group"""
         return self._server.async_group
 
     @property
-    def state(self) -> typing.List[ClientInfo]:
+    def state(self) -> list[ClientInfo]:
         """State of all active connections"""
         return list(self._state.values())
 
     def register_state_cb(self,
                           cb: StateCb
                           ) -> util.RegisterCallbackHandle:
         """Register state change callback"""
         return self._state_cbs.register(cb)
 
-    def notify(self, events: typing.List[common.Event]):
+    def notify(self, events: list[common.Event]):
         """Notify clients of new events"""
         self._notify_cbs.notify(events)
 
     async def flush(self):
         """Send flush requests and wait for flush responses"""
         if not self.is_open:
             await self.wait_closed()
```

## Comparing `hat_event-0.8.7.dist-info/LICENSE` & `hat_event-0.8.8.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `hat_event-0.8.7.dist-info/METADATA` & `hat_event-0.8.8.dist-info/METADATA`

 * *Files 18% similar despite different names*

```diff
@@ -1,59 +1,90 @@
 Metadata-Version: 2.1
 Name: hat-event
-Version: 0.8.7
+Version: 0.8.8
 Summary: Hat event
 Home-page: https://github.com/hat-open/hat-event
 License: Apache-2.0
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: Apache Software License
-Requires-Python: >=3.8
+Requires-Python: >=3.10
 Description-Content-Type: text/x-rst
 License-File: LICENSE
 Requires-Dist: appdirs (~=1.4.4)
-Requires-Dist: hat-aio (~=0.7.4)
-Requires-Dist: hat-chatter (~=0.5.10)
-Requires-Dist: hat-drivers (~=0.6.10)
-Requires-Dist: hat-json (~=0.5.15)
+Requires-Dist: hat-aio (~=0.7.8)
+Requires-Dist: hat-chatter (~=0.5.11)
+Requires-Dist: hat-drivers (~=0.7.0)
+Requires-Dist: hat-json (~=0.5.19)
 Requires-Dist: hat-monitor (<0.8.0,>=0.6.10)
-Requires-Dist: hat-sbs (~=0.6.3)
-Requires-Dist: hat-util (~=0.6.7)
-Requires-Dist: lmdb (~=1.4.0)
+Requires-Dist: hat-sbs (~=0.6.4)
+Requires-Dist: hat-util (~=0.6.10)
+Requires-Dist: lmdb (~=1.4.1)
+
+.. _online documentation: https://hat-event.hat-open.com
+.. _git repository: https://github.com/hat-open/hat-event.git
+.. _PyPI project: https://pypi.org/project/hat-event
+.. _pydoit: https://pydoit.org
+.. _Hat Open: https://hat-open.com
+.. _Končar Digital: https://www.koncar.hr/en
+
 
 hat-event - Event server and communication libraries
 ====================================================
 
-This component is part of Hat Open project - open-source framework of tools and
-libraries for developing applications used for remote monitoring, control and
-management of intelligent electronic devices such as IoT devices, PLCs,
-industrial automation or home automation systems.
-
-Development of Hat Open and associated repositories is sponsored by
-`Končar Digital <https://www.koncar.hr>`_.
-
 For more information see:
 
-    * hat-event documentation - `<https://hat-event.hat-open.com>`_
-    * hat-event git repository - `<https://github.com/hat-open/hat-event.git>`_
-    * Hat Open homepage - `<https://hat-open.com>`_
+* `online documentation`_
+* `git repository`_
+
 
-.. warning::
+Runtime requirements
+--------------------
 
-    This project is currently in state of active development. Features,
-    functionality and API are unstable.
+* python >=3.10
 
 
 Install
 -------
 
-::
+`hat-event` is available as `PyPI project`_::
 
     $ pip install hat-event
 
 
+Build
+-----
+
+Build tool used for `hat-event` is `pydoit`_. It can be installed
+together with other python dependencies by running::
+
+    $ pip install -r requirements.pip.dev.txt
+
+For listing available doit tasks, use::
+
+    $ doit list
+
+Default task::
+
+    $ doit
+
+creates wheel package inside `build` directory.
+
+
+Hat Open
+--------
+
+`hat-event` is part of `Hat Open`_ project - open-source framework of
+tools and libraries for developing applications used for remote monitoring,
+control and management of intelligent electronic devices such as IoT devices,
+PLCs, industrial automation or home automation systems.
+
+Development of Hat Open and associated repositories is sponsored by
+`Končar Digital`_.
+
+
 License
 -------
 
 Copyright 2020-2023 Hat Open AUTHORS
 
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
```

## Comparing `hat_event-0.8.7.dist-info/RECORD` & `hat_event-0.8.8.dist-info/RECORD`

 * *Files 8% similar despite different names*

```diff
@@ -1,64 +1,64 @@
 hat/event/__init__.py,sha256=nIQrqyPevwuBP-5p0MrmV1iLnevMXoz8t5moAAl21HI,47
 hat/event/common/__init__.py,sha256=vnT2TYTXVSPRfvj2g1r-a443bkvc474LIJ-bqfuYl6s,2696
-hat/event/common/data.py,sha256=vWrcZ9oUIok1NB8A9R9Q7atQrFjA0vEqygzKWfU2Qag,8551
+hat/event/common/data.py,sha256=y0Cc2meBbs16a7WOLh8gO6M4zduwELRDZt9MMLEQ_6A,8535
 hat/event/common/json_schema_repo.json,sha256=-_KxbXErlJHsY68dO4iV9iTbJVFobCdEUv0K3xAqvNo,9158
 hat/event/common/sbs_repo.json,sha256=xB-UJLbiWz520YMcTay0ZajzhQueA0pstxdSYvc0cT8,7535
 hat/event/common/timestamp.py,sha256=iBAx2DfReKUUygntIUqcMhlKB_odAHwap5n03qqjitU,4235
 hat/event/common/subscription/__init__.py,sha256=2Zf0yFdQeXHEJQcepUIzochi9KUdB_h0IlSd0_zyCUs,534
-hat/event/common/subscription/_csubscription.cp39-win_amd64.pyd,sha256=XRg27trYCMs3VqDdNuiVDJdhk9W9mFZX9bKpBHm6WrQ,122604
+hat/event/common/subscription/_csubscription.abi3.pyd,sha256=qLC3oTi9X4IU6H71X2IsjGEwVmxFGMyPgWBwqQOAXjI,122941
 hat/event/common/subscription/common.py,sha256=rN8DfK-6cmObUFJRB7H77popuzKrHfp_e6giUEVWVv0,5758
 hat/event/common/subscription/csubscription.py,sha256=jon0XjECTZcJ68KZQ-hMFLahNALc62za1TRJzwzoMGQ,1530
 hat/event/common/subscription/pysubscription.py,sha256=olBvh753U3v4Sh5GdoFkuMAky6MqtCTt90TbZ8TRkaE,2670
 hat/event/eventer/__init__.py,sha256=r1o7PfU_dIoawdjuuKsX8RXvrX8w885fcfaKAeCsEWU,2550
-hat/event/eventer/client.py,sha256=WqsboUq0wd4UyrLTdN0LCnnpJhfaJ5QJcdnSmjqjD3c,12723
-hat/event/eventer/server.py,sha256=nUdJOctbw0FQzhxFAcUzjTZ0LLZOHstNQmHEEbQHxsw,6399
+hat/event/eventer/client.py,sha256=yoLnLQSyOrS8AsG0yv9aPxQ4wNpR-Q8hes4nMgTfrQA,12692
+hat/event/eventer/server.py,sha256=fFXNgS63IrjmWvQPDV--MpRYDwAxaNf0mnnjVLnHTGo,6502
 hat/event/mariner/__init__.py,sha256=DRtrP_IgCnY6J2yvuTrC1dXYN-WE3T3anxdCs41FSlg,521
-hat/event/mariner/client.py,sha256=xLX1xWIwoDrELvRaXzfLwiSHXda07gwkLKRqkoIMKFQ,3605
-hat/event/mariner/common.py,sha256=6UjeBxXVx7TeO3x66eIUblUiZyICHddjyo9h7CvL83w,508
+hat/event/mariner/client.py,sha256=kOuBHNzcwX2aP8LmhjEJwdTTSxC7K8_goet-s6E1h2o,3940
+hat/event/mariner/common.py,sha256=Rp7lzgzkAT2ny5KbfH5p1nGh9l2uMmhSMygRL41N6q0,481
 hat/event/mariner/encoder.py,sha256=mNnCyK8QSbXXnGtEWknZY1HmOwjG-g0LGo0_z6SfDBE,6806
-hat/event/mariner/server.py,sha256=4LU-p1tafQUQk6ukdsq3oPVSZPmenRr6KuWdRZEigsU,4845
-hat/event/mariner/transport.py,sha256=CfB4IjiAfb4ZLS7A63kpucGMtyucMfy-1oti4wsRFgc,1497
+hat/event/mariner/server.py,sha256=-wnGsWveQ4AvNudr9mqSR-TEkykfWC-BOHOyilUsB_s,5119
+hat/event/mariner/transport.py,sha256=eXpB4Nd6GYobWCrIA9-ZsjDjiH7LaAKXNopEn94761M,1509
 hat/event/server/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 hat/event/server/__main__.py,sha256=1Wul_omw9id6MncwkZAn-iFK-FaEirfTJ2JcxZzrcig,138
-hat/event/server/common.py,sha256=DP-DQNdqqgo2Va6qDJU7JCJOj1RwFLPgnddEs9ej6Tk,4751
-hat/event/server/engine.py,sha256=sOFra9uf7laluEP4qgAZZvT4jP48QY4IbnjD3wH7Cso,6872
+hat/event/server/common.py,sha256=qhamdFWDUKkdOJ1tyE1DnzWQ2UkRcigTT_Xx0MhBNFY,5613
+hat/event/server/engine.py,sha256=Qk5yDnaPgc5RkNV9ZaGkJgYKFt-GV7hMimATx9Kc0Yg,6751
 hat/event/server/eventer_server.py,sha256=eEPIi3VSms27a2F4IYBmbDkiOUyhC5dEI_Q-zqutRkE,2095
 hat/event/server/main.py,sha256=W_4EJ-vnjeEKtxurRdmsh7grH0eRttqOxBW50J6A6LQ,2330
-hat/event/server/mariner_server.py,sha256=YzZrAnUo9Ohaf0be1SS327zUxCRwM0Sa0CMQ6NXhX5A,3718
-hat/event/server/runner.py,sha256=yXBDaZfbeSBawW7gdgpq6dKp5jt2BCM5PwN6G4R6SQw,10755
-hat/event/server/syncer_client.py,sha256=0YGtxBWevm4NecT3M618tZxGPlWiAFRgFTy0fdxZh5Y,7439
-hat/event/server/syncer_server.py,sha256=PYAp50TGbf0zbuvxXl6jVHhtAmuPFSaHAISrhTkYfQY,2062
+hat/event/server/mariner_server.py,sha256=0ymFFcWA5qBY-T0x9IakPafpyGNrPvlDvAcu896Hoxo,3742
+hat/event/server/runner.py,sha256=t7A2LAN3WK1Ae0eIoJDGBFOu6x24Lb8qe7iLWZsxV0I,10721
+hat/event/server/syncer_client.py,sha256=ZIQdt6hB1Bc2rOm_z65TDRSyzKvx1v0frspl8VFu7Xk,7565
+hat/event/server/syncer_server.py,sha256=EK-8NqYP6e8Jf9-CRxGdTjsSp7liT9GmcuKATJe1A20,2041
 hat/event/server/backends/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-hat/event/server/backends/dummy.py,sha256=BEVbu15jp_hL32NX74lsWlKpqZpUzD6efjeSRquXz9M,2231
-hat/event/server/backends/memory.py,sha256=hgiAT9ffu3IfrJC5g5kNnUNLxBaeRO0xIgDG_j7SFz0,5722
+hat/event/server/backends/dummy.py,sha256=hIgHgWCd0g7beQn4OycknCzWXvf5W3gkrh0E3eD8_4w,2156
+hat/event/server/backends/memory.py,sha256=dvhst047vAT3YLvciz9jheNqSLMICf8zgfQd4AhUN1c,5647
 hat/event/server/backends/lmdb/__init__.py,sha256=KUMfcLQw7ysMtj0MAYSzVIzGs04TXxt0N_JHelYHrn0,241
-hat/event/server/backends/lmdb/backend.py,sha256=90VuldQH7AEMn4HZ5EbjG0-YYYlsJL3Mlia_hg6PkZM,9593
-hat/event/server/backends/lmdb/common.py,sha256=NLXKFLfU7iUNN4myXLei3jNjbx6tT0iNmTlf5oH95V0,2172
-hat/event/server/backends/lmdb/conditions.py,sha256=tD0IkQulyVaBO9VBJFfZdbFfETTpPr1g6LEPt0mkEss,2778
-hat/event/server/backends/lmdb/encoder.py,sha256=OWEwj2GcVhlqPs10kB80pYHyCyLDmvnSSOL98M_nxrM,6426
-hat/event/server/backends/lmdb/environment.py,sha256=u8TdR-2zXXjCuSi66Qf4NhVVOjbKADsQBxJilX9cmeA,1600
-hat/event/server/backends/lmdb/latestdb.py,sha256=i0_g7ZYWLXOjGFVUHnH5QySej7dHjTSrc1BVURZk33U,4459
-hat/event/server/backends/lmdb/ordereddb.py,sha256=-6Bl6w5Gkwu0xTaLu2dLrj76H7Ph_Ogbsmz6IikPs6I,17674
-hat/event/server/backends/lmdb/refdb.py,sha256=nWNd3rHjDdltXIVf7-Yml3eb-avmZiq-3PItgmYRwP0,4953
-hat/event/server/backends/lmdb/systemdb.py,sha256=MhkH3YCpniZdwvFqsfhEjOPHkZc_Hhghpdyb7oE8YTQ,2161
+hat/event/server/backends/lmdb/backend.py,sha256=I4SXfilwfEUXmr_tzhh6zDYKXnfmY7b0bvTGgXOoXzA,9528
+hat/event/server/backends/lmdb/common.py,sha256=7klgg5RXttPi1rLlBPJ5eehiED1aq6DvaB11qBYSkd4,2498
+hat/event/server/backends/lmdb/conditions.py,sha256=en-fcQEOwRyVjbVdhz3MuspYXzj6W2GgwH2CMlzL77Q,2779
+hat/event/server/backends/lmdb/encoder.py,sha256=CP_XBXDNcaNie1-DVVaoY99QKMH_yCJNAGrnCMc28MY,6427
+hat/event/server/backends/lmdb/environment.py,sha256=pg0ypzCBtDbAQNWEQASORRWGgCdjsUQsRYpHhxqIqJg,1594
+hat/event/server/backends/lmdb/latestdb.py,sha256=3OVPDxuJFwaaP4oC81eQVbhuddmkwrdaX8xhTkCCz58,4458
+hat/event/server/backends/lmdb/ordereddb.py,sha256=0xpJv9-knumxWfxiuQbMa67WGwIuZ6iUwtY03FngKj0,17619
+hat/event/server/backends/lmdb/refdb.py,sha256=kpcS9Brg_8Cv5yLZ43em9ghukG8VLoVoReKc2_jV-do,4947
+hat/event/server/backends/lmdb/systemdb.py,sha256=-VJNK_shfZHS3BhP4L3kbWIZ-lqUOSYOBnDuzuEOnYs,2158
 hat/event/server/backends/lmdb/convert/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 hat/event/server/backends/lmdb/convert/convert_v06_to_v07.py,sha256=eVz8lZG2MCAyx0CWgaVqwpTgNHqKJQK3sgCayYCS4Mo,8667
-hat/event/server/backends/lmdb/convert/v06.py,sha256=gI3N7FAeMA2L0hskaCq3azeObInVpv0tRaVx6YsZBtc,6207
-hat/event/server/backends/lmdb/convert/v07.py,sha256=oEIu4h4B4hcWwHTmdFatk21uWlY32J0KM6_EBrLl8ys,2477
+hat/event/server/backends/lmdb/convert/v06.py,sha256=b0mAz0n8qOBO5XhBsveZ_uKSERhqBuhV0yTbZEclTr4,6153
+hat/event/server/backends/lmdb/convert/v07.py,sha256=0mHisr0AZUV-rKlC0uxKijV-0z87TQHEHUvwEcHq3zA,2444
 hat/event/server/backends/lmdb/manager/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 hat/event/server/backends/lmdb/manager/__main__.py,sha256=borAj1oZKFXG-BJLGbmXgdJU0-YsVgHND2Dr6Wtx4zA,166
 hat/event/server/backends/lmdb/manager/common.py,sha256=9mewEno7MiiwDCVmrPOV4xvEJAJkK2Mjm-A93e_Fzc4,1254
 hat/event/server/backends/lmdb/manager/copy.py,sha256=4gLKXi0gf6sdiDwYxHmBO4MST5FCA3xbEzxIelGYIug,1668
 hat/event/server/backends/lmdb/manager/main.py,sha256=aeq1Le7KSjFnlQz5Jlow2PX-KxqVR0UqP0O_NGLLrZo,951
 hat/event/server/backends/lmdb/manager/query.py,sha256=IY8myArfETVrsWhLT8JbwVGf-AwR8neHmA9a7bpgeng,5625
 hat/event/syncer/__init__.py,sha256=cyTxvmwLEVwykxDCWXJ9Z_yf8NFciWP7V5JU0vaNatU,618
-hat/event/syncer/client.py,sha256=euKVYu596dHf3yhv0GsLpgQfL62a4_X2SA04-iAvNC8,3328
-hat/event/syncer/common.py,sha256=Re3MyR87WUf8t9ByumaZkFPEqRFZWSWEKF0twiC8LQA,1587
-hat/event/syncer/server.py,sha256=ZL5-J9-ivYIqS84OXTAmjHWV2VAcKd0F4QNZKNBI2js,13098
-hat_event-0.8.7.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
-hat_event-0.8.7.dist-info/METADATA,sha256=L2v3I433xJYEFkyhU5-PBAieCtYqgIh-x0CGx-13VQM,2141
-hat_event-0.8.7.dist-info/WHEEL,sha256=eep6QWEFiQfg2wcclssb_WY-D33AnLYLnEKGA9Rn-VU,100
-hat_event-0.8.7.dist-info/entry_points.txt,sha256=VRGFweYHw7BjDWzrnHHSZ1MMIkXPnT3o-QLbQPhLE3o,138
-hat_event-0.8.7.dist-info/top_level.txt,sha256=3RuRoRsaXQZNKwr3T2RE9XepBRTk4YpnXUbMiH5nes8,4
-hat_event-0.8.7.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-hat_event-0.8.7.dist-info/RECORD,,
+hat/event/syncer/client.py,sha256=4019FP7jYL6XviXpfrRPdPw000AhtIJ0Qhc8rQVMJH0,3320
+hat/event/syncer/common.py,sha256=rGWOgBrfUpNS9wc8Ob3y10lm0lfRr1rMyBygaIKugFo,1570
+hat/event/syncer/server.py,sha256=8yZKYHqABw-RABJCDAztSJk5j8vek0lIbG9fPCP4OxU,13105
+hat_event-0.8.8.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
+hat_event-0.8.8.dist-info/METADATA,sha256=0Oyi5t7g19Lnnw0c1jTRhgxVG5uGfv2RzdpVLbn6osc,2563
+hat_event-0.8.8.dist-info/WHEEL,sha256=EIDplvKX77HSdIuX_rx4QpXXtuIW5PK_-oQMxkWTHag,127
+hat_event-0.8.8.dist-info/entry_points.txt,sha256=VRGFweYHw7BjDWzrnHHSZ1MMIkXPnT3o-QLbQPhLE3o,138
+hat_event-0.8.8.dist-info/top_level.txt,sha256=3RuRoRsaXQZNKwr3T2RE9XepBRTk4YpnXUbMiH5nes8,4
+hat_event-0.8.8.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+hat_event-0.8.8.dist-info/RECORD,,
```

