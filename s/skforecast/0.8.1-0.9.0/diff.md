# Comparing `tmp/skforecast-0.8.1.tar.gz` & `tmp/skforecast-0.9.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "skforecast-0.8.1.tar", last modified: Sat May 27 09:10:39 2023, max compression
+gzip compressed data, was "skforecast-0.9.0.tar", last modified: Sun Jul  9 15:19:01 2023, max compression
```

## Comparing `skforecast-0.8.1.tar` & `skforecast-0.9.0.tar`

### file list

```diff
@@ -1,229 +1,231 @@
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.134313 skforecast-0.8.1/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1508 2023-05-26 14:40:36.000000 skforecast-0.8.1/LICENSE
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    11713 2023-05-27 09:10:39.134313 skforecast-0.8.1/PKG-INFO
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    10813 2023-05-27 09:04:03.000000 skforecast-0.8.1/README.md
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       38 2023-05-27 09:10:39.134313 skforecast-0.8.1/setup.cfg
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2613 2023-05-23 09:01:29.000000 skforecast-0.8.1/setup.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.102313 skforecast-0.8.1/skforecast/
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.102313 skforecast-0.8.1/skforecast/ForecasterAutoreg/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    49681 2023-05-27 09:01:13.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/ForecasterAutoreg.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       48 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.106313 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2430 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/fixtures_ForecasterAutoreg.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2195 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_create_lags.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4559 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_create_sample_weights.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    20218 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_create_train_X_y.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4822 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_fit.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     6884 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_get_feature_importances.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      241 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_init.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    12687 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7436 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_predict_bootstrapping.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3098 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_predict_dist.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7318 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_predict_interval.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      873 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_recursive_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      729 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_set_fit_kwargs.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1404 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_set_lags.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5955 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_set_out_sample_residuals.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      777 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_set_params.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.106313 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    50905 2023-05-27 09:01:13.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/ForecasterAutoregCustom.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       60 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.110313 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2332 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/fixtures_ForecasterAutoregCustom.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5009 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_create_sample_weights.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    27588 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_create_train_X_y.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     6435 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_fit.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9076 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_get_feature_importances.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3081 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_init.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    13005 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8438 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_predict_bootstrapping.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3316 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_predict_dist.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8136 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_predict_interval.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1937 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_recursive_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      973 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_set_fit_kwargs.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7708 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_set_out_sample_residuals.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1138 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_set_params.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.110313 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    58821 2023-05-27 09:01:13.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       60 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.114313 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2332 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/fixtures_ForecasterAutoregDirect.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4173 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_create_lags.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4771 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_create_sample_weights.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    37994 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_create_train_X_y.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5370 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_filter_train_X_y_for_step.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4552 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_fit.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9213 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_get_feature_importances.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1153 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_init.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    15548 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8453 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_predict_bootstrapping.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3223 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_predict_dist.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3222 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_predict_interval.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      790 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_set_fit_kwargs.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1485 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_set_lags.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8514 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_set_out_sample_residuals.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      819 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_set_params.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.114313 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    66380 2023-05-27 09:01:13.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       70 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.114313 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3601 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/fixtures_ForecasterAutoregMultiSeries.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2102 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_create_lags.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9234 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_create_sample_weights.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    35120 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_create_train_X_y.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9691 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_fit.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7720 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_get_feature_importances.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      403 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_init.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    17658 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    14060 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_bootstrapping.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4117 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_dist.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    15631 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_interval.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1544 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_recursive_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      773 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_set_fit_kwargs.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1477 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_set_lags.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7865 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_set_out_sample_residuals.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      825 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_set_params.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.114313 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    67295 2023-05-27 09:01:13.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/ForecasterAutoregMultiSeriesCustom.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       82 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.118313 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3607 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/fixtures_ForecasterAutoregMultiSeriesCustom.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9903 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_create_sample_weights.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    43529 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_create_train_X_y.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    11355 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_fit.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9113 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_get_feature_importances.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2799 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_init.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    18665 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    15783 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_bootstrapping.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4430 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_dist.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    16918 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_interval.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1871 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_recursive_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1011 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_fit_kwargs.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9355 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_out_sample_residuals.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1149 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_params.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.118313 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    67130 2023-05-27 09:01:13.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/ForecasterAutoregMultiVariate.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       72 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.122313 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3596 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/fixtures_ForecasterAutoregMultiVariate.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4676 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_create_lags.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     6104 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_create_sample_weights.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    53075 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_create_train_X_y.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     6655 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_filter_train_X_y_for_step.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9508 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_fit.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    10671 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_get_feature_importances.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1589 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_init.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    17234 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9547 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_bootstrapping.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3800 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_dist.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3795 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_interval.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      854 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_set_fit_kwargs.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2205 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_set_lags.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9524 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_set_out_sample_residuals.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      897 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_set_params.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.122313 skforecast-0.8.1/skforecast/ForecasterBase/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4759 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterBase/ForecasterBase.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       42 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterBase/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.122313 skforecast-0.8.1/skforecast/ForecasterBase/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterBase/tests/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.122313 skforecast-0.8.1/skforecast/ForecasterSarimax/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    32564 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/ForecasterSarimax.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       48 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.122313 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3742 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/fixtures_ForecasterSarimax.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2850 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_fit.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1551 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_get_feature_importances.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1169 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_init.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    16735 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_predict.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    19506 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_predict_interval.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      715 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_set_fit_kwargs.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1049 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_set_params.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       42 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.122313 skforecast-0.8.1/skforecast/exceptions/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       25 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/exceptions/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2838 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/exceptions/exceptions.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.126313 skforecast-0.8.1/skforecast/exceptions/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/exceptions/tests/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.126313 skforecast-0.8.1/skforecast/model_selection/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      156 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    68405 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/model_selection/model_selection.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.126313 skforecast-0.8.1/skforecast/model_selection/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/model_selection/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2773 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/fixtures_model_selection.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3487 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_backtesting_forecaster.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    38660 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_backtesting_forecaster_no_refit.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    45593 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_backtesting_forecaster_refit.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9274 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_bayesian_search_forecaster.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    26803 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_bayesian_search_optuna.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    25188 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_bayesian_search_skopt.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    28393 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_create_backtesting_folds.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    13396 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_evaluate_grid_hyperparameters.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2705 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_get_metric.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2479 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_grid_search_forecaster.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2752 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection/tests/test_random_search_forecaster.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.126313 skforecast-0.8.1/skforecast/model_selection_multiseries/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      262 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/model_selection_multiseries/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    62309 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_multiseries/model_selection_multiseries.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.130313 skforecast-0.8.1/skforecast/model_selection_multiseries/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/model_selection_multiseries/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2370 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/model_selection_multiseries/tests/fixtures_model_selection_multiseries.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    80857 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_multiseries/tests/test_backtesting_forecaster_multiseries.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    37744 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_multiseries/tests/test_evaluate_grid_hyperparameters.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7318 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_multiseries/tests/test_grid_search_forecaster_multiseries.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8022 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_multiseries/tests/test_random_search_forecaster_multiseries.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.130313 skforecast-0.8.1/skforecast/model_selection_sarimax/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      100 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/model_selection_sarimax/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    33979 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_sarimax/model_selection_sarimax.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.130313 skforecast-0.8.1/skforecast/model_selection_sarimax/test/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/model_selection_sarimax/test/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    38400 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_sarimax/test/test_backtesting_sarimax.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9764 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_sarimax/test/test_evaluate_grid_hyperparameters_sarimax.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2086 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_sarimax/test/test_grid_search_sarimax.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2434 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/model_selection_sarimax/test/test_random_search_sarimax.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.130313 skforecast-0.8.1/skforecast/plot/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       98 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/plot/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5956 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/plot/plot.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.130313 skforecast-0.8.1/skforecast/plot/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/plot/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      573 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/plot/tests/test_plot_residuals.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.130313 skforecast-0.8.1/skforecast/utils/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       20 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/__init__.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.134313 skforecast-0.8.1/skforecast/utils/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    25261 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/utils/tests/test_check_backtesting_input.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1545 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/utils/tests/test_check_exog.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3793 2023-05-26 14:40:47.000000 skforecast-0.8.1/skforecast/utils/tests/test_check_exog_dtypes.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4875 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/test_check_interval.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      787 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/test_check_optional_dependency.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    40682 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/utils/tests/test_check_predict_input.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3029 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/utils/tests/test_check_select_fit_kwargs.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      922 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/test_check_y.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    11595 2023-05-27 09:01:13.000000 skforecast-0.8.1/skforecast/utils/tests/test_exog_to_direct.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5051 2023-05-27 09:01:13.000000 skforecast-0.8.1/skforecast/utils/tests/test_exog_to_direct_numpy.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1369 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/test_expand_index.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3505 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/test_initialize_lags.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8156 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/utils/tests/test_initialize_weights.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2459 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/utils/tests/test_multivariate_time_series_corr.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2470 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/test_preproces_exog.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2648 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/test_preproces_last_window.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2384 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/test_preproces_y.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1477 2023-05-20 18:25:37.000000 skforecast-0.8.1/skforecast/utils/tests/test_save_load_forecaster.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5889 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/utils/tests/test_transform_dataframe.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5245 2023-05-23 09:01:29.000000 skforecast-0.8.1/skforecast/utils/tests/test_transform_series.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    57257 2023-05-27 09:01:13.000000 skforecast-0.8.1/skforecast/utils/utils.py
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.102313 skforecast-0.8.1/skforecast.egg-info/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    11713 2023-05-27 09:10:39.000000 skforecast-0.8.1/skforecast.egg-info/PKG-INFO
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    11546 2023-05-27 09:10:39.000000 skforecast-0.8.1/skforecast.egg-info/SOURCES.txt
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        1 2023-05-27 09:10:39.000000 skforecast-0.8.1/skforecast.egg-info/dependency_links.txt
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      671 2023-05-27 09:10:39.000000 skforecast-0.8.1/skforecast.egg-info/requires.txt
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       17 2023-05-27 09:10:39.000000 skforecast-0.8.1/skforecast.egg-info/top_level.txt
-drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-27 09:10:39.134313 skforecast-0.8.1/tests/
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       46 2023-05-23 09:01:29.000000 skforecast-0.8.1/tests/__init__.py
--rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      139 2023-05-26 14:40:47.000000 skforecast-0.8.1/tests/test_skforecast_version.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.074696 skforecast-0.9.0/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1508 2023-05-31 16:50:11.000000 skforecast-0.9.0/LICENSE
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    15589 2023-07-09 15:19:01.074696 skforecast-0.9.0/PKG-INFO
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    14689 2023-07-09 14:30:47.000000 skforecast-0.9.0/README.md
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       38 2023-07-09 15:19:01.074696 skforecast-0.9.0/setup.cfg
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2613 2023-07-09 14:46:06.000000 skforecast-0.9.0/setup.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.034695 skforecast-0.9.0/skforecast/
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.034695 skforecast-0.9.0/skforecast/ForecasterAutoreg/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    48408 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/ForecasterAutoreg.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       48 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.038695 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2430 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/fixtures_ForecasterAutoreg.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2195 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_create_lags.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4559 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_create_sample_weights.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    20218 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_create_train_X_y.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4822 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_fit.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     6884 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_get_feature_importances.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      241 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_init.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    12687 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7436 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_predict_bootstrapping.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3098 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_predict_dist.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7318 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_predict_interval.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      873 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_recursive_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      729 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_set_fit_kwargs.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1404 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_set_lags.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5955 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_set_out_sample_residuals.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      777 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_set_params.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.038695 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    49395 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/ForecasterAutoregCustom.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       60 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.042695 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2332 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/fixtures_ForecasterAutoregCustom.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5009 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_create_sample_weights.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    27588 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_create_train_X_y.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     6435 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_fit.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9076 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_get_feature_importances.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3081 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_init.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    13005 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8438 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_predict_bootstrapping.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3316 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_predict_dist.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8136 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_predict_interval.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1937 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_recursive_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      973 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_set_fit_kwargs.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7708 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_set_out_sample_residuals.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1138 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_set_params.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.042695 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    60187 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       60 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.046696 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2332 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/fixtures_ForecasterAutoregDirect.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3908 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_create_lags.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4771 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_create_sample_weights.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    43045 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_create_train_X_y.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5368 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_filter_train_X_y_for_step.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5118 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_fit.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9213 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_get_feature_importances.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1633 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_init.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    15709 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8426 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_predict_bootstrapping.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3221 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_predict_dist.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3222 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_predict_interval.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      790 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_set_fit_kwargs.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1485 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_set_lags.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8514 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_set_out_sample_residuals.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      819 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_set_params.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.046696 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    66458 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       70 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.050696 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3602 2023-06-08 08:44:59.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/fixtures_ForecasterAutoregMultiSeries.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2161 2023-06-08 08:44:59.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_create_lags.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    12418 2023-06-08 08:44:59.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_create_sample_weights.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    45392 2023-06-09 13:16:39.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_create_train_X_y.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9693 2023-06-08 08:44:59.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_fit.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7720 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_get_feature_importances.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      403 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_init.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    19850 2023-06-09 13:16:39.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    14060 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_bootstrapping.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4117 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_dist.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    15631 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_interval.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1544 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_recursive_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      773 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_set_fit_kwargs.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1477 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_set_lags.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7865 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_set_out_sample_residuals.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      825 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_set_params.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.054696 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    67704 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/ForecasterAutoregMultiSeriesCustom.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       82 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.054696 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3607 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/fixtures_ForecasterAutoregMultiSeriesCustom.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    13459 2023-06-09 13:16:39.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_create_sample_weights.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    54461 2023-06-09 13:16:39.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_create_train_X_y.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    11331 2023-06-09 13:16:39.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_fit.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9113 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_get_feature_importances.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2799 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_init.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    20939 2023-06-09 13:16:39.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    15783 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_bootstrapping.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4430 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_dist.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    16918 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_interval.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1871 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_recursive_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1011 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_fit_kwargs.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9355 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_out_sample_residuals.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1149 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_params.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.054696 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    68323 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/ForecasterAutoregMultiVariate.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       72 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.058696 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3596 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/fixtures_ForecasterAutoregMultiVariate.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4408 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_create_lags.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     6104 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_create_sample_weights.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    58763 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_create_train_X_y.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     6653 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_filter_train_X_y_for_step.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    10059 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_fit.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    10671 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_get_feature_importances.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2100 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_init.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    17408 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9545 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_bootstrapping.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3800 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_dist.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3795 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_interval.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      854 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_set_fit_kwargs.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2205 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_set_lags.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9524 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_set_out_sample_residuals.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      897 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_set_params.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.058696 skforecast-0.9.0/skforecast/ForecasterBase/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4836 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterBase/ForecasterBase.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       42 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterBase/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.058696 skforecast-0.9.0/skforecast/ForecasterBase/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterBase/tests/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.058696 skforecast-0.9.0/skforecast/ForecasterSarimax/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    31808 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/ForecasterSarimax.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       48 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.062696 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3742 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/fixtures_ForecasterSarimax.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2850 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_fit.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1551 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_get_feature_importances.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1169 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_init.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    16735 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_predict.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    19506 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_predict_interval.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      715 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_set_fit_kwargs.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1049 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_set_params.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       42 2023-06-06 16:38:44.000000 skforecast-0.9.0/skforecast/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.062696 skforecast-0.9.0/skforecast/exceptions/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       25 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/exceptions/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2838 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/exceptions/exceptions.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.062696 skforecast-0.9.0/skforecast/exceptions/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/exceptions/tests/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.062696 skforecast-0.9.0/skforecast/model_selection/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      129 2023-06-09 13:16:39.000000 skforecast-0.9.0/skforecast/model_selection/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    68298 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/model_selection/model_selection.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.066696 skforecast-0.9.0/skforecast/model_selection/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2773 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection/tests/fixtures_model_selection.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3589 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_backtesting_forecaster.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    39617 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_backtesting_forecaster_no_refit.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    54019 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_backtesting_forecaster_refit.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9274 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_bayesian_search_forecaster.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    26850 2023-06-08 08:29:02.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_bayesian_search_optuna.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    25188 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_bayesian_search_skopt.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    48981 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_create_backtesting_folds.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    13396 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_evaluate_grid_hyperparameters.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2705 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_get_metric.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2479 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_grid_search_forecaster.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2752 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection/tests/test_random_search_forecaster.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.066696 skforecast-0.9.0/skforecast/model_selection_multiseries/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      262 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_multiseries/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    60572 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/model_selection_multiseries/model_selection_multiseries.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.066696 skforecast-0.9.0/skforecast/model_selection_multiseries/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_multiseries/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2370 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_multiseries/tests/fixtures_model_selection_multiseries.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)   116060 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/model_selection_multiseries/tests/test_backtesting_forecaster_multiseries.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    37744 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_multiseries/tests/test_evaluate_grid_hyperparameters.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     7318 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_multiseries/tests/test_grid_search_forecaster_multiseries.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8022 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_multiseries/tests/test_random_search_forecaster_multiseries.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.066696 skforecast-0.9.0/skforecast/model_selection_sarimax/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      100 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_sarimax/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    32390 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/model_selection_sarimax/model_selection_sarimax.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.070696 skforecast-0.9.0/skforecast/model_selection_sarimax/test/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_sarimax/test/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    38950 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/model_selection_sarimax/test/test_backtesting_sarimax.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     9764 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_sarimax/test/test_evaluate_grid_hyperparameters_sarimax.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2086 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_sarimax/test/test_grid_search_sarimax.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2434 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/model_selection_sarimax/test/test_random_search_sarimax.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.070696 skforecast-0.9.0/skforecast/plot/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       98 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/plot/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5967 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/plot/plot.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.070696 skforecast-0.9.0/skforecast/plot/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/plot/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      573 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/plot/tests/test_plot_residuals.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.070696 skforecast-0.9.0/skforecast/utils/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       20 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/__init__.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.074696 skforecast-0.9.0/skforecast/utils/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        0 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    29590 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/utils/tests/test_check_backtesting_input.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1545 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_check_exog.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3793 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_check_exog_dtypes.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     4875 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_check_interval.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      787 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_check_optional_dependency.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    40682 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_check_predict_input.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3029 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_check_select_fit_kwargs.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      922 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_check_y.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    11595 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_exog_to_direct.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5051 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_exog_to_direct_numpy.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1369 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_expand_index.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     3505 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_initialize_lags.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     8156 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_initialize_weights.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2459 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_multivariate_time_series_corr.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2470 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_preproces_exog.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2648 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_preproces_last_window.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2384 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_preproces_y.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1477 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_save_load_forecaster.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     2687 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/utils/tests/test_select_n_jobs_backtesting.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     1244 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/utils/tests/test_select_n_jobs_fit_forecaster.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5889 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_transform_dataframe.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)     5245 2023-05-31 16:50:11.000000 skforecast-0.9.0/skforecast/utils/tests/test_transform_series.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    62300 2023-07-09 14:30:47.000000 skforecast-0.9.0/skforecast/utils/utils.py
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.034695 skforecast-0.9.0/skforecast.egg-info/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    15589 2023-07-09 15:19:00.000000 skforecast-0.9.0/skforecast.egg-info/PKG-INFO
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)    11663 2023-07-09 15:19:01.000000 skforecast-0.9.0/skforecast.egg-info/SOURCES.txt
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)        1 2023-07-09 15:19:00.000000 skforecast-0.9.0/skforecast.egg-info/dependency_links.txt
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      690 2023-07-09 15:19:00.000000 skforecast-0.9.0/skforecast.egg-info/requires.txt
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       17 2023-07-09 15:19:00.000000 skforecast-0.9.0/skforecast.egg-info/top_level.txt
+drwxrwxr-x   0 ubuntu    (1000) ubuntu    (1000)        0 2023-07-09 15:19:01.074696 skforecast-0.9.0/tests/
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)       46 2023-05-31 16:50:11.000000 skforecast-0.9.0/tests/__init__.py
+-rw-rw-r--   0 ubuntu    (1000) ubuntu    (1000)      139 2023-06-08 08:06:18.000000 skforecast-0.9.0/tests/test_skforecast_version.py
```

### Comparing `skforecast-0.8.1/LICENSE` & `skforecast-0.9.0/LICENSE`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/PKG-INFO` & `skforecast-0.9.0/PKG-INFO`

 * *Files 22% similar despite different names*

```diff
@@ -1,68 +1,79 @@
 Metadata-Version: 2.1
 Name: skforecast
-Version: 0.8.1
+Version: 0.9.0
 Summary: Forecasting time series with scikit-learn regressors. It also works with any regressor compatible with the scikit-learn API (pipelines, CatBoost, LightGBM, XGBoost, Ranger...).
 Home-page: https://github.com/JoaquinAmatRodrigo/skforecast
 Author: Joaquin Amat Rodrigo and Javier Escobar Ortiz
 Author-email: j.amatrodrigo@gmail.com, javier.escobar.ortiz@gmail.com
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
-Classifier: License :: OSI Approved :: MIT License
+Classifier: License :: OSI Approved :: BSD License
 Description-Content-Type: text/markdown
 Provides-Extra: sarimax
 Provides-Extra: plotting
 Provides-Extra: test
 Provides-Extra: full
 Provides-Extra: all
 License-File: LICENSE
 
 <h1 align="left">
-<img src="https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/images/banner-landing-page-skforecast.png?raw=true#only-light" style= margin-top: 0px;">
-</h1><br>
+<img src="https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/images/banner-landing-page-skforecast.png?raw=true#only-light" style= margin-top: 0px;>
+</h1>
 
 ![Python](https://img.shields.io/badge/python-3.8%20%7C%203.9%20%7C%203.10%20%7C%203.11-blue)
 [![PyPI](https://img.shields.io/pypi/v/skforecast)](https://pypi.org/project/skforecast/)
 [![codecov](https://codecov.io/gh/JoaquinAmatRodrigo/skforecast/branch/master/graph/badge.svg)](https://codecov.io/gh/JoaquinAmatRodrigo/skforecast)
 [![Build status](https://github.com/JoaquinAmatRodrigo/skforecast/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/JoaquinAmatRodrigo/skforecast/actions/workflows/unit-tests.yml/badge.svg)
 [![Project Status: Active](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)
 [![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/JoaquinAmatRodrigo/skforecast/graphs/commit-activity)
 [![License](https://img.shields.io/github/license/JoaquinAmatRodrigo/skforecast)](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/LICENSE)
 [![Downloads](https://static.pepy.tech/personalized-badge/skforecast?period=total&units=international_system&left_color=grey&right_color=blue&left_text=Downloads)](https://pepy.tech/project/skforecast)
 
 
+# About The Project
+
 **Skforecast** is a Python library that eases using scikit-learn regressors as single and multi-step forecasters. It also works with any regressor compatible with the scikit-learn API (LightGBM, XGBoost, CatBoost, ...).
 
 **Why use skforecast?**
 
 The fields of statistics and machine learning have developed many excellent regression algorithms that can be useful for forecasting, but applying them effectively to time series analysis can still be a challenge. To address this issue, the skforecast library provides a comprehensive set of tools for training, validation and prediction in a variety of scenarios commonly encountered when working with time series. The library is built using the widely used scikit-learn API, making it easy to integrate into existing workflows. With skforecast, users have access to a wide range of functionalities such as feature engineering, model selection, hyperparameter tuning and many others. This allows users to focus on the essential aspects of their projects and leave the intricacies of time series analysis to skforecast. In addition, skforecast is developed according to the following priorities:
 
 + Fast and robust prototyping. :zap:
 + Validation and backtesting methods to have a realistic assessment of model performance. :mag:
 + Models must be deployed in production. :hammer:
 + Models must be interpretable. :crystal_ball:
 
-**Documentation: https://skforecast.org** :books:
+**Share Your Thoughts with Us**
+
+Thank you for choosing skforecast! We value your suggestions, bug reports and recommendations as they help us identify areas for improvement and ensure that skforecast meets the needs of the community. Please consider sharing your experiences, reporting bugs, making suggestions or even contributing to the codebase on GitHub. Together, let's make time series forecasting more accessible and accurate for everyone.
+
+
+# Documentation
+
+For detailed information on how to use and leverage the full potential of **skforecast** please refer to the comprehensive documentation available at:
+
+**https://skforecast.org** :books:
 
 
 # Installation
 
 The default installation of skforecast only installs hard dependencies.
 
 ```bash
 pip install skforecast
 ```
 
 Specific version:
 
 ```bash
-pip install skforecast==0.8.1
+pip install skforecast==0.9.0
 ```
 
 Latest (unstable):
 
 ```bash
 pip install git+https://github.com/JoaquinAmatRodrigo/skforecast#master
 ```
@@ -85,89 +96,88 @@
 
 # Dependencies
 
 + Python >= 3.8
 
 ## Hard dependencies
 
-+ numpy>=1.20, <1.25
++ numpy>=1.20, <1.26
 + pandas>=1.2, <2.1
-+ tqdm>=4.57.0, <4.65
-+ scikit-learn>=1.0, <1.3
-+ optuna>=2.10.0, <3.2
-+ joblib>=1.1.0, <1.3.0
++ tqdm>=4.57.0, <4.66
++ scikit-learn>=1.0, <1.4
++ optuna>=2.10.0, <3.3
++ joblib>=1.1.0, <1.4
 
 ## Optional dependencies
 
 + matplotlib>=3.3, <3.8
 + seaborn>=0.11, <0.13
-+ statsmodels>=0.12, <0.14
++ statsmodels>=0.12, <0.15
 + pmdarima>=2.0, <2.1
 
-# Features
+# What is new in skforecast 0.9.0?
 
-+ Create recursive autoregressive forecasters from any regressor that follows the scikit-learn API
-+ Create direct autoregressive forecasters from any regressor that follows the scikit-learn API
-+ Create multi-series autoregressive forecasters from any regressor that follows the scikit-learn API
-+ Include exogenous variables as predictors
-+ Include custom predictors (rolling mean, rolling variance ...)
-+ Multiple backtesting methods for model validation
-+ Grid search, random search and Bayesian search to find optimal lags (predictors) and best hyperparameters
-+ Include custom metrics for model validation and grid search
-+ Prediction interval estimated by bootstrapping and quantile regression
-+ Get predictor importance
-+ Forecaster in production
-
-## What is new in skforecast 0.8.1?
-
-- [x] Support for `pandas 2.0.x`.
-- [x] New user guide on how to include **categorical variables** in the Forecasters.
-- [x] New user guide on how to use **GPU in Google Colab** with XGBoost and LightGBM regressors.
-- [x] Include custom kwargs during fit.
-- [x] The dtypes of exogenous variables are maintained when generating the training matrices with the `create_train_X_y` method in all the Forecasters.
-- [x] Include `gap` argument in backtesting functions to omit observations between training and prediction.
+Visit the [release notes](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/changelog.md) to view all notable changes.
+
+- [x] `ForecasterAutoregDirect` and `ForecasterAutoregMultiVariate` include the `n_jobs` argument in their `fit` method, allowing multi-process parallelization for improved performance.
+- [x] All backtesting and grid search functions have been extended to include the `n_jobs` argument, allowing multi-process parallelization for improved performance.
+- [x] Argument `refit` now can be also an `integer` in all backtesting dependent functions in modules `model_selection`, `model_selection_multiseries`, and `model_selection_sarimax`. This allows the Forecaster to be trained every this number of iterations.
+- [x] `ForecasterAutoregMultiSeries` and `ForecasterAutoregMultiSeriesCustom` can be trained using series of different lengths. This means that the model can handle datasets with different numbers of data points in each series.
 - [x] Bug fixes and performance improvements.
 
-Visit the [release notes](https://github.com/JoaquinAmatRodrigo/skforecast/blob/feature_update_category_docs/changelog.md) to view all notable changes.
 
+# Forecasters
 
-# Documentation
+A **Forecaster** object in the skforecast library is a comprehensive container that provides essential functionality and methods for training a forecasting model and generating predictions for future points in time.
+
+The **skforecast** library offers a variety of forecaster types, each tailored to specific requirements such as single or multiple time series, direct or recursive strategies, or custom predictors. Regardless of the specific forecaster type, all instances share the same API.
 
-The documentation for the latest release is at [skforecast docs](https://skforecast.org).
+| Forecaster | Single series | Multiple series | Recursive strategy | Direct strategy | Probabilistic prediction | Exogenous features | Custom features |
+|:-----------|:-------------:|:---------------:|:------------------:|:---------------:|:------------------------:|:------------------:|:---------------:|
+|[ForecasterAutoreg](https://skforecast.org/latest/user_guides/autoregresive-forecaster.html)|:heavy_check_mark:||:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:||
+|[ForecasterAutoregCustom](https://skforecast.org/latest/user_guides/custom-predictors.html)|:heavy_check_mark:||:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|
+|[ForecasterAutoregDirect](https://skforecast.org/latest/user_guides/direct-multi-step-forecasting.html)|:heavy_check_mark:|||:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:||
+|[ForecasterMultiSeries](https://skforecast.org/latest/user_guides/independent-multi-time-series-forecasting.html)||:heavy_check_mark:|:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:||
+|[ForecasterMultiSeriesCustom](https://skforecast.org/latest/user_guides/custom-predictors.html)||:heavy_check_mark:|:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|
+|[ForecasterMultiVariate](https://skforecast.org/latest/user_guides/dependent-multi-series-multivariate-forecasting.html)||:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:||
+|[ForecasterSarimax](https://skforecast.org/latest/user_guides/forecasting-sarimax-arima.html)|:heavy_check_mark:||:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:||
 
-Recent improvements are highlighted in the [release notes](https://skforecast.org/latest/releases/releases.html).
 
-+ [Introduction to time series and forecasting](https://skforecast.org/latest/user_guides/quick-start-skforecast.html)
+# Main User Guides
+
++ [Introduction to time series and forecasting](https://skforecast.org/latest/introduction-forecasting/introduction-forecasting.html)
 
 + [Recursive multi-step forecasting](https://skforecast.org/latest/user_guides/autoregresive-forecaster.html)
 
++ [Direct multi-step forecasting](https://skforecast.org/latest/user_guides/direct-multi-step-forecasting.html)
+
 + [Independent multi-series forecasting](https://skforecast.org/latest/user_guides/independent-multi-time-series-forecasting.html)
 
 + [Dependent multi-series forecasting (Multivariate forecasting)](https://skforecast.org/latest/user_guides/dependent-multi-series-multivariate-forecasting.html)
 
 + [Backtesting (validation) of forecasting models](https://skforecast.org/latest/user_guides/backtesting.html)
 
 + [Hyperparameter tuning and lags selection of forecasting models](https://skforecast.org/latest/user_guides/hyperparameter-tuning-and-lags-selection.html)
 
 + [Probabilistic forecasting](https://skforecast.org/latest/user_guides/probabilistic-forecasting.html)
 
 + [Using forecasters in production](https://skforecast.org/latest/user_guides/forecaster-in-production.html)
 
 
-# Examples and tutorials 
+# Examples and tutorials
 
 **English**
 
 + [**Skforecast: time series forecasting with Python and Scikit-learn**](https://www.cienciadedatos.net/documentos/py27-time-series-forecasting-python-scikitlearn.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1X1DJF4pZlklIt5srQnyTYoyFVLunr_OQ)
 
-+ [**Forecasting electricity demand with Python**](https://www.cienciadedatos.net/documentos/py29-forecasting-electricity-power-demand-python.html)
++ [**Forecasting electricity demand with Python**](https://www.cienciadedatos.net/documentos/py29-forecasting-electricity-power-demand-python.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1efCKQtuHOlw7MLojIwqi2zrU2NZbG-FP)
 
-+ [**Forecasting web traffic with machine learning and Python**](https://www.cienciadedatos.net/documentos/py37-forecasting-web-traffic-machine-learning.html)
++ [**Forecasting web traffic with machine learning and Python**](https://www.cienciadedatos.net/documentos/py37-forecasting-web-traffic-machine-learning.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QhLkJAAEfvgYoVkQXy58-T_sloNFCV1o)
 
-+ [**Forecasting time series with gradient boosting: skforecast, XGBoost, LightGBM and CatBoost**](https://www.cienciadedatos.net/documentos/py39-forecasting-time-series-with-skforecast-xgboost-lightgbm-catboost.html)
++ [**Forecasting with gradient boosting: skforecast, XGBoost, LightGBM and CatBoost**](https://www.cienciadedatos.net/documentos/py39-forecasting-time-series-with-skforecast-xgboost-lightgbm-catboost.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Imy8ZM3DqPXg7UllRDH9gqWb_XSrqzzh)
 
 + [**Bitcoin price prediction with Python**](https://www.cienciadedatos.net/documentos/py41-forecasting-cryptocurrency-bitcoin-machine-learning-python.html)
 
 + [**Prediction intervals in forecasting models**](https://www.cienciadedatos.net/documentos/py42-forecasting-prediction-intervals-machine-learning.html)
 
 + [**Multi-series forecasting**](https://www.cienciadedatos.net/documentos/py44-multi-series-forecasting-skforecast.html)
 
@@ -178,63 +188,72 @@
 + [**Intermittent demand forecasting**](https://www.cienciadedatos.net/documentos/py48-intermittent-demand-forecasting.html)
 
 
 **Espaol**
 
 + [**Skforecast: forecasting series temporales con Python y Scikit-learn**](https://www.cienciadedatos.net/documentos/py27-forecasting-series-temporales-python-scikitlearn.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mjmccrMA-XxOVXm-3wKSIQ9__oo9dJ5a)
 
-+ [**Forecasting de la demanda elctrica**](https://www.cienciadedatos.net/documentos/py29-forecasting-demanda-energia-electrica-python.html)
++ [**Forecasting de la demanda elctrica**](https://www.cienciadedatos.net/documentos/py29-forecasting-demanda-energia-electrica-python.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/15kQpANRBCLfNf77nmNcV6GjGPoYdOmmF)
 
-+ [**Forecasting de las visitas a una pgina web**](https://www.cienciadedatos.net/documentos/py37-forecasting-visitas-web-machine-learning.html)
++ [**Forecasting de las visitas a una pgina web**](https://www.cienciadedatos.net/documentos/py37-forecasting-visitas-web-machine-learning.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1uw2nyjA9XMcstfkpbWC4zCULN7Qp7MWV)
 
-+ [**Forecasting series temporales con gradient boosting: skforecast, XGBoost, LightGBM y CatBoost**](https://www.cienciadedatos.net/documentos/py39-forecasting-series-temporales-con-skforecast-xgboost-lightgbm-catboost.html)
++ [**Forecasting con gradient boosting: skforecast, XGBoost, LightGBM y CatBoost**](https://www.cienciadedatos.net/documentos/py39-forecasting-series-temporales-con-skforecast-xgboost-lightgbm-catboost.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1UAjX8vUKDoY0XJtq5WtHlJ4qwPvSgLrD)
 
 + [**Prediccin del precio de Bitcoin con Python**](https://www.cienciadedatos.net/documentos/py41-forecasting-criptomoneda-bitcoin-machine-learning-python.html)
 
 + [**Workshop prediccin de series temporales con machine learning Universidad de Deusto / Deustuko Unibertsitatea**](https://youtu.be/MlktVhReO0E)
 
 + [**Intervalos de prediccin en modelos de forecasting**](https://www.cienciadedatos.net/documentos/py42-intervalos-prediccion-modelos-forecasting-machine-learning.html)
 
 + [**Multi-series forecasting**](https://www.cienciadedatos.net/documentos/py44-multi-series-forecasting-skforecast-espaol.html)
 
 + [**Prediccin de demanda intermitente**](https://www.cienciadedatos.net/documentos/py48-forecasting-demanda-intermitente.html)
 
 
-# Donating
-
-If you found skforecast useful, you can support us with a donation. Your contribution will help to continue developing and improving this project. Many thanks!
-
-[![paypal](https://www.paypalobjects.com/en_US/ES/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/donate/?hosted_button_id=D2JZSWRLTZDL6)
+# How to contribute
 
+Primarily, skforecast development consists of adding and creating new *Forecasters*, new validation strategies, or improving the performance of the current code. However, there are many other ways to contribute:
 
-# How to contribute
+- Submit a bug report or feature request on [GitHub Issues](https://github.com/JoaquinAmatRodrigo/skforecast/issues).
+- Contribute a Jupyter notebook to our [examples](https://joaquinamatrodrigo.github.io/skforecast/latest/examples/examples.html).
+- Write [unit or integration tests](https://docs.pytest.org/en/latest/) for our project.
+- Answer questions on our issues, Stack Overflow, and elsewhere.
+- Translate our documentation into another language.
+- Write a blog post, tweet, or share our project with others.
 
 For more information on how to contribute to skforecast, see our [Contribution Guide](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/CONTRIBUTING.md).
 
 
 # Citation
 
 If you use this software, please cite it using the following metadata.
 
 **APA**:
 ```
-Amat Rodrigo, J., & Escobar Ortiz, J. skforecast (Version 0.8.1) [Computer software]
+Amat Rodrigo, J., & Escobar Ortiz, J. skforecast (Version 0.9.0) [Computer software]
 ```
 
 **BibTeX**:
 ```
 @software{skforecast,
 author = {Amat Rodrigo, Joaquin and Escobar Ortiz, Javier},
-license = {MIT},
-month = {5},
+license = {BSD 3-Clause License},
+month = {7},
 title = {{skforecast}},
-version = {0.8.1},
+version = {0.9.0},
 year = {2023}
 }
 ```
 
 View the [citation file](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/CITATION.cff).
 
 
+# Donating
+
+If you found skforecast useful, you can support us with a donation. Your contribution will help to continue developing and improving this project. Many thanks!
+
+[![paypal](https://www.paypalobjects.com/en_US/ES/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/donate/?hosted_button_id=D2JZSWRLTZDL6)
+
+
 # License
 
 [BSD 3-Clause License](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/LICENSE)
```

### Comparing `skforecast-0.8.1/setup.py` & `skforecast-0.9.0/setup.py`

 * *Files 1% similar despite different names*

```diff
@@ -62,13 +62,13 @@
     packages=setuptools.find_packages(),
     classifiers=[
         "Programming Language :: Python :: 3",
         "Programming Language :: Python :: 3.8",
         "Programming Language :: Python :: 3.9",
         "Programming Language :: Python :: 3.10",
         "Programming Language :: Python :: 3.11",
-        "License :: OSI Approved :: MIT License"
+        "License :: OSI Approved :: BSD License"
     ],
     install_requires=requirements_base,
     extras_require=extras_require,
     tests_require=requirements_test,
 )
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/ForecasterAutoreg.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/ForecasterAutoreg.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 ################################################################################
 #                            ForecasterAutoreg                                 #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
 from typing import Union, Tuple, Optional, Callable
 import warnings
 import logging
 import sys
@@ -46,148 +46,114 @@
     """
     This class turns any regressor compatible with the scikit-learn API into a
     recursive autoregressive (multi-step) forecaster.
     
     Parameters
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
-        An instance of a regressor or pipeline compatible with the scikit-learn API.
-        
-    lags : int, list, 1d numpy ndarray, range
-        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
-            `int`: include lags from 1 to `lags` (included).
-            `list`, `numpy ndarray` or `range`: include only lags present in `lags`,
-            all elements must be int.
-
+        An instance of a regressor or pipeline compatible with the scikit-learn API
+    lags : int, list, numpy ndarray, range
+        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1. 
+    
+            - `int`: include lags from 1 to `lags` (included).
+            - `list`, `1d numpy ndarray` or `range`: include only lags present in 
+            `lags`, all elements must be int.
     transformer_y : object transformer (preprocessor), default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
         ColumnTransformers are not allowed since they do not have inverse_transform method.
         The transformation is applied to `y` before training the forecaster. 
-
     transformer_exog : object transformer (preprocessor), default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
     weight_func : Callable, default `None`
         Function that defines the individual weights for each sample based on the
         index. For example, a function that assigns a lower weight to certain dates.
         Ignored if `regressor` does not have the argument `sample_weight` in its `fit`
         method. The resulting `sample_weight` cannot have negative values.
-
     fit_kwargs : dict, default `None`
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
     forecaster_id : str, int, default `None`
         Name used as an identifier of the forecaster.
         **New in version 0.7.0**
     
     Attributes
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
-        
     lags : numpy ndarray
         Lags used as predictors.
-
-    transformer_y : object transformer (preprocessor), default `None`
+    transformer_y : object transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
         ColumnTransformers are not allowed since they do not have inverse_transform method.
         The transformation is applied to `y` before training the forecaster.
-
-    transformer_exog : object transformer (preprocessor), default `None`
+    transformer_exog : object transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
     weight_func : Callable
         Function that defines the individual weights for each sample based on the
         index. For example, a function that assigns a lower weight to certain dates.
         Ignored if `regressor` does not have the argument `sample_weight` in its `fit`
-        method.
-        **New in version 0.6.0**
-        
+        method. The resulting `sample_weight` cannot have negative values.
     source_code_weight_func : str
         Source code of the custom function used to create weights.
-        **New in version 0.6.0**
-        
     max_lag : int
         Maximum value of lag included in `lags`.
-   
     window_size : int
-        Size of the window needed to create the predictors. It is equal to
-        `max_lag`.
-
+        Size of the window needed to create the predictors. It is equal to `max_lag`.
     last_window : pandas Series
         Last window the forecaster has seen during training. It stores the
         values needed to predict the next `step` immediately after the training data.
-        
     index_type : type
         Type of index of the input used in training.
-        
     index_freq : str
         Frequency of Index of the input used in training.
-        
     training_range : pandas Index
         First and last values of index of the data used during training.
-        
     included_exog : bool
         If the forecaster has been trained using exogenous variable/s.
-        
     exog_type : type
         Type of exogenous data (pandas Series or DataFrame) used in training.
-
     exog_dtypes : dict
         Type of each exogenous variable/s used in training. If `transformer_exog` 
         is used, the dtypes are calculated after the transformation.
-        
     exog_col_names : list
         Names of columns of `exog` if `exog` used in training was a pandas
         DataFrame.
-
     X_train_col_names : list
         Names of columns of the matrix created internally for training.
-
     fit_kwargs : dict
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-        
     in_sample_residuals : numpy ndarray
         Residuals of the model when predicting training data. Only stored up to
         1000 values. If `transformer_y` is not `None`, residuals are stored in the
         transformed scale.
-        
     out_sample_residuals : numpy ndarray
         Residuals of the model when predicting non training data. Only stored
         up to 1000 values. If `transformer_y` is not `None`, residuals
         are assumed to be in the transformed scale. Use `set_out_sample_residuals` 
         method to set values.
-        
     fitted : bool
         Tag to identify if the regressor has been fitted (trained).
-
     creation_date : str
         Date of creation.
-
     fit_date : str
         Date of last fit.
-
     skforcast_version : str
         Version of skforecast library used to create the forecaster.
-
     python_version : str
         Version of python used to create the forecaster.
-
-    forecaster_id : str, int default `None`
+    forecaster_id : str, int
         Name used as an identifier of the forecaster.
-        **New in version 0.7.0**
-     
+    
     """
     
     def __init__(
         self,
         regressor: object,
         lags: Union[int, np.ndarray, list],
         transformer_y: Optional[object]=None,
@@ -279,42 +245,44 @@
         return info
 
     
     def _create_lags(
         self, 
         y: np.ndarray
     ) -> Tuple[np.ndarray, np.ndarray]:
-        """       
+        """
         Transforms a 1d array into a 2d array (X) and a 1d array (y). Each row
         in X is associated with a value of y and it represents the lags that
         precede it.
         
         Notice that, the returned matrix X_data, contains the lag 1 in the first
         column, the lag 2 in the second column and so on.
         
         Parameters
-        ----------        
-        y : 1d numpy ndarray
-            Training time series.
+        ----------
+        y : numpy ndarray
+            1d numpy ndarray Training time series.
 
-        Returns 
+        Returns
         -------
-        X_data : 2d numpy ndarray, shape (samples - max(self.lags), len(self.lags))
-            2d numpy array with the lagged values (predictors).
-        
-        y_data : 1d numpy ndarray, shape (samples - max(self.lags),)
-            Values of the time series related to each row of `X_data`.
+        X_data : numpy ndarray
+            2d numpy ndarray with the lagged values (predictors). 
+            Shape: (samples - max(self.lags), len(self.lags))
+        y_data : numpy ndarray
+            1d numpy ndarray with the values of the time series related to each 
+            row of `X_data`. 
+            Shape: (samples - max(self.lags), )
         
         """
           
         n_splits = len(y) - self.max_lag
         if n_splits <= 0:
             raise ValueError(
-                f"The maximum lag ({self.max_lag}) must be less than the length "
-                f"of the series ({len(y)})."
+                (f"The maximum lag ({self.max_lag}) must be less than the length "
+                 f"of the series ({len(y)}).")
             )
         
         X_data = np.full(shape=(n_splits, len(self.lags)), fill_value=np.nan, dtype=float)
 
         for i, lag in enumerate(self.lags):
             X_data[:, i] = y[self.max_lag - lag: -lag]
 
@@ -329,29 +297,29 @@
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None
     ) -> Tuple[pd.DataFrame, pd.Series]:
         """
         Create training matrices from univariate time series and exogenous
         variables.
         
         Parameters
-        ----------        
+        ----------
         y : pandas Series
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `y` and their indexes must be aligned.
 
-        Returns 
+        Returns
         -------
-        X_train : pandas DataFrame, shape (len(y) - self.max_lag, len(self.lags))
-            Pandas DataFrame with the training values (predictors).
-            
-        y_train : pandas Series, shape (len(y) - self.max_lag, )
+        X_train : pandas DataFrame
+            Training values (predictors).
+            Shape: (len(y) - self.max_lag, len(self.lags))
+        y_train : pandas Series
             Values (target) of the time series related to each row of `X_train`.
+            Shape: (len(y) - self.max_lag, )
         
         """
         
         check_y(y=y)
         y = transform_series(
                 series            = y,
                 transformer       = self.transformer_y,
@@ -424,15 +392,15 @@
         """
         Crate weights for each observation according to the forecaster's attribute
         `weight_func`.
 
         Parameters
         ----------
         X_train : pandas DataFrame
-            Dataframe generated with the method `create_train_X_y`, first return.
+            Dataframe created with the `create_train_X_y` method, first return.
 
         Returns
         -------
         sample_weight : numpy ndarray
             Weights to use in `fit` method.
 
         """
@@ -469,27 +437,26 @@
         """
         Training Forecaster.
 
         Additional arguments to be passed to the `fit` method of the regressor 
         can be added with the `fit_kwargs` argument when initializing the forecaster.
         
         Parameters
-        ----------        
+        ----------
         y : pandas Series
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `y` and their indexes must be aligned so
             that y[i] is regressed on exog[i].
-
         store_in_sample_residuals : bool, default `True`
-            If True, in-sample residuals will be stored in the forecaster object
+            If `True`, in-sample residuals will be stored in the forecaster object
             after fitting.
-        Returns 
+
+        Returns
         -------
         None
         
         """
         
         # Reset values in case the forecaster has already been fitted.
         self.index_type          = None
@@ -559,23 +526,21 @@
         Predict n steps ahead. It is an iterative process in which, each prediction,
         is used as a predictor for the next step.
         
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : numpy ndarray
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-            
         exog : numpy ndarray, default `None`
             Exogenous variable/s included as predictor/s.
 
-        Returns 
+        Returns
         -------
         predictions : numpy ndarray
             Predicted values.
         
         """
 
         predictions = np.full(shape=steps, fill_value=np.nan)
@@ -608,31 +573,28 @@
         Predict n steps ahead. It is an recursive process in which, each prediction,
         is used as a predictor for the next step.
         
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
 
-        Returns 
+        Returns
         -------
         predictions : pandas Series
             Predicted values.
-            
+        
         """
 
         if last_window is None:
             last_window = copy(self.last_window)
 
         check_predict_input(
             forecaster_name  = type(self).__name__,
@@ -721,63 +683,58 @@
         """
         Generate multiple forecasting predictions using a bootstrapping process. 
         By sampling from a collection of past observed errors (the residuals),
         each iteration of bootstrapping generates a different set of predictions. 
         See the Notes section for more information. 
         
         Parameters
-        ----------   
+        ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-                        
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
-        boot_predictions : pandas DataFrame, shape (steps, n_boot)
+        boot_predictions : pandas DataFrame
             Predictions generated by bootstrapping.
+            Shape: (steps, n_boot)
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp3/prediction-intervals.html#prediction-intervals-from-bootstrapped-residuals
         Forecasting: Principles and Practice (3nd ed) Rob J Hyndman and George Athanasopoulos.
 
         """
 
         if not in_sample_residuals and self.out_sample_residuals is None:
             raise ValueError(
-                ('`forecaster.out_sample_residuals` is `None`. Use '
-                 '`in_sample_residuals=True` or method `set_out_sample_residuals()` '
-                 'before `predict_interval()`, `predict_bootstrapping()` or '
-                 '`predict_dist()`.')
+                ("`forecaster.out_sample_residuals` is `None`. Use "
+                 "`in_sample_residuals=True` or method `set_out_sample_residuals()` "
+                 "before `predict_interval()`, `predict_bootstrapping()` or "
+                 "`predict_dist()`.")
             )
 
         if last_window is None:
             last_window = copy(self.last_window)
 
         check_predict_input(
             forecaster_name  = type(self).__name__,
@@ -903,65 +860,58 @@
     ) -> pd.DataFrame:
         """
         Iterative process in which each prediction is used as a predictor
         for the next step, and bootstrapping is used to estimate prediction
         intervals. Both predictions and intervals are returned.
         
         Parameters
-        ---------- 
+        ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         interval : list, default `[5, 95]`
             Confidence of the prediction interval estimated. Sequence of 
             percentiles to compute, which must be between 0 and 100 inclusive. 
             For example, interval of 95% should be as `interval = [2.5, 97.5]`.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
-            Values predicted by the forecaster and their estimated interval:
+            Values predicted by the forecaster and their estimated interval.
 
-            - pred: predictions.
-            - lower_bound: lower bound of the interval.
-            - upper_bound: upper bound interval of the interval.
+                - pred: predictions.
+                - lower_bound: lower bound of the interval.
+                - upper_bound: upper bound of the interval.
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp2/prediction-intervals.html
         Forecasting: Principles and Practice (2nd ed) Rob J Hyndman and
         George Athanasopoulos.
-            
+        
         """
         
         check_interval(interval=interval)
 
         predictions = self.predict(
                           steps       = steps,
                           last_window = last_window,
@@ -997,48 +947,41 @@
     ) -> pd.DataFrame:
         """
         Fit a given probability distribution for each step. After generating 
         multiple forecasting predictions through a bootstrapping process, each 
         step is fitted to the given distribution.
         
         Parameters
-        ---------- 
+        ----------
         steps : int
             Number of future steps predicted.
-
         distribution : Object
             A distribution object from scipy.stats.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
-            first iteration of the prediction (t + 1).
-    
+            first iteration of the prediction (t + 1).  
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
             Distribution parameters estimated for each step.
 
         """
 
         boot_samples = self.predict_bootstrapping(
@@ -1075,17 +1018,17 @@
         forecaster.
         
         Parameters
         ----------
         params : dict
             Parameters values.
 
-        Returns 
+        Returns
         -------
-        self
+        None
         
         """
 
         self.regressor = clone(self.regressor)
         self.regressor.set_params(**params)
 
 
@@ -1098,15 +1041,15 @@
         method of the regressor.
         
         Parameters
         ----------
         fit_kwargs : dict
             Dict of the form {"argument": new_value}.
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         self.fit_kwargs = check_select_fit_kwargs(self.regressor, fit_kwargs=fit_kwargs)
 
@@ -1117,20 +1060,22 @@
     ) -> None:
         """
         Set new value to the attribute `lags`.
         Attributes `max_lag` and `window_size` are also updated.
         
         Parameters
         ----------
-        lags : int, list, 1D np.ndarray, range
+        lags : int, list, numpy ndarray, range
             Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
-                `int`: include lags from 1 to `lags`.
-                `list` or `np.ndarray`: include only lags present in `lags`.
 
-        Returns 
+            - `int`: include lags from 1 to `lags` (included).
+            - `list`, `1d numpy ndarray` or `range`: include only lags present in 
+            `lags`, all elements must be int.
+
+        Returns
         -------
         None
         
         """
         
         self.lags = initialize_lags(type(self).__name__, lags)
         self.max_lag = max(self.lags)
@@ -1150,30 +1095,27 @@
         participate in the training process.
         
         Parameters
         ----------
         residuals : numpy ndarray
             Values of residuals. If len(residuals) > 1000, only a random sample
             of 1000 values are stored.
-            
         append : bool, default `True`
             If `True`, new residuals are added to the once already stored in the
             attribute `out_sample_residuals`. Once the limit of 1000 values is
             reached, no more values are appended. If False, `out_sample_residuals`
             is overwritten with the new residuals.
-
         transform : bool, default `True`
             If `True`, new residuals are transformed using self.transformer_y.
-
         random_state : int, default `123`
             Sets a seed to the random sampling for reproducible output.
-            
-        Returns 
+
+        Returns
         -------
-        self
+        None
 
         """
 
         if not isinstance(residuals, np.ndarray):
             raise TypeError(
                 f"`residuals` argument must be `numpy ndarray`. Got {type(residuals)}."
             )
@@ -1264,37 +1206,8 @@
 
         if feature_importances is not None:
             feature_importances = pd.DataFrame({
                                       'feature': self.X_train_col_names,
                                       'importance': feature_importances
                                   })
 
-        return feature_importances
-
-
-    def get_feature_importance(
-        self
-    ) -> pd.DataFrame:
-        """
-        This method has been replaced by `get_feature_importances()`.
-
-        Return feature importances of the regressor stored in the
-        forecaster. Only valid when regressor stores internally the feature
-        importances in the attribute `feature_importances_` or `coef_`.
-
-        Parameters
-        ----------
-        self
-
-        Returns
-        -------
-        feature_importances : pandas DataFrame
-            Feature importances associated with each predictor.
-
-        """
-
-        warnings.warn(
-            ("get_feature_importance() method has been renamed to get_feature_importances(). "
-             "This method will be removed in skforecast 0.9.0.")
-        )
-
-        return self.get_feature_importances()
+        return feature_importances
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/fixtures_ForecasterAutoreg.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/fixtures_ForecasterAutoreg.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_create_lags.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_create_lags.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_create_sample_weights.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_create_sample_weights.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_create_train_X_y.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_create_train_X_y.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_fit.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_fit.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_get_feature_importances.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_get_feature_importances.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_predict.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_predict_bootstrapping.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_predict_bootstrapping.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_predict_dist.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_predict_dist.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_predict_interval.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_predict_interval.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_recursive_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_recursive_predict.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_set_fit_kwargs.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_set_fit_kwargs.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_set_lags.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_set_lags.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_set_out_sample_residuals.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_set_out_sample_residuals.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoreg/tests/test_set_params.py` & `skforecast-0.9.0/skforecast/ForecasterAutoreg/tests/test_set_params.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/ForecasterAutoregCustom.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/ForecasterAutoregCustom.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 ################################################################################
 #                        ForecasterAutoregCustom                               #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
 from typing import Union, Tuple, Optional, Callable
 import warnings
 import logging
 import sys
@@ -46,160 +46,122 @@
     This class turns any regressor compatible with the scikit-learn API into a
     recursive (multi-step) forecaster with a custom function to create predictors.
     
     Parameters
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
-        
     fun_predictors : Callable
-        Function that receives a time series as input (numpy ndarray) and returns
+        Function that receives a time series as input (numpy ndarray) and returns 
         another numpy ndarray with the predictors.
-        
     window_size : int
         Size of the window needed by `fun_predictors` to create the predictors.
-
     name_predictors : list, default `None`
         Name of the predictors returned by `fun_predictors`. If `None`, predictors are
         named using the prefix 'custom_predictor_<i>' where `i` is the index of the position
         the predictor has in the returned array of `fun_predictors`.
-
     transformer_y : object transformer (preprocessor), default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
         ColumnTransformers are not allowed since they do not have inverse_transform method.
         The transformation is applied to `y` before training the forecaster.
-
     transformer_exog : object transformer (preprocessor), default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-    
     weight_func : Callable, default `None`
         Function that defines the individual weights for each sample based on the
         index. For example, a function that assigns a lower weight to certain dates.
         Ignored if `regressor` does not have the argument `sample_weight` in its `fit`
         method. The resulting `sample_weight` cannot have negative values.
-        **New in version 0.6.0**
-
     fit_kwargs : dict, default `None`
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
     forecaster_id : str, int, default `None`
         Name used as an identifier of the forecaster.
         **New in version 0.7.0**
     
     Attributes
     ----------
     regressor : regressor compatible with the scikit-learn API
         An instance of a regressor compatible with the scikit-learn API.
-
     fun_predictors : Callable
         Function that receives a time series as input (numpy ndarray) and returns
         another numpy ndarray with the predictors.
         **New in version 0.7.0**
-
     source_code_fun_predictors : str
         Source code of the custom function used to create the predictors.
         **New in version 0.7.0**
-        
     window_size : int
         Size of the window needed by `fun_predictors` to create the predictors.
-
-    name_predictors : list, default `None`
+    name_predictors : list
         Name of the predictors returned by `fun_predictors`. If `None`, predictors are
         named using the prefix 'custom_predictor_<i>' where `i` is the index of the position
         the predictor has in the returned array of `fun_predictors`.
-
-    transformer_y : object transformer (preprocessor), default `None`
+    transformer_y : object transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
         ColumnTransformers are not allowed since they do not have inverse_transform method.
         The transformation is applied to `y` before training the forecaster.
-
-    transformer_exog : object transformer (preprocessor), default `None`
+    transformer_exog : object transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-        
     weight_func : Callable
         Function that defines the individual weights for each sample based on the
         index. For example, a function that assigns a lower weight to certain dates.
         Ignored if `regressor` does not have the argument `sample_weight` in its `fit`
         method.
-        **New in version 0.6.0**
-
     source_code_weight_func : str
         Source code of the custom function used to create weights.
-        **New in version 0.6.0**
-
     last_window : pandas Series
         Last window the forecaster has seen during training. It stores the
         values needed to predict the next `step` immediately after the training data.
-        
     index_type : type
         Type of index of the input used in training.
-        
     index_freq : str
         Frequency of Index of the input used in training.
-        
     training_range : pandas Index
         First and last values of index of the data used during training.
-        
     included_exog : bool
         If the forecaster has been trained using exogenous variable/s.
-        
     exog_type : type
         Type of exogenous variable/s used in training.
-
     exog_dtypes : dict
         Type of each exogenous variable/s used in training. If `transformer_exog` 
         is used, the dtypes are calculated after the transformation.
-        
     exog_col_names : list
         Names of columns of `exog` if `exog` used in training was a pandas
         DataFrame.
-
     X_train_col_names : list
         Names of columns of the matrix created internally for training.
-
     fit_kwargs : dict
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-        
     in_sample_residuals : numpy ndarray
         Residuals of the model when predicting training data. Only stored up to
         1000 values. If `transformer_y` is not `None`, residuals are stored in the
         transformed scale.
-        
     out_sample_residuals : numpy ndarray
         Residuals of the model when predicting non training data. Only stored
         up to 1000 values. If `transformer_y` is not `None`, residuals
         are assumed to be in the transformed scale. Use `set_out_sample_residuals` 
         method to set values.
-        
     fitted : bool
         Tag to identify if the regressor has been fitted (trained).
-
     creation_date : str
         Date of creation.
-
     fit_date : str
         Date of last fit.
-
     skforcast_version : str
         Version of skforecast library used to create the forecaster.
-
     python_version : str
         Version of python used to create the forecaster.
-
-    forecaster_id : str, int, default `None`
+    forecaster_id : str, int
         Name used as an identifier of the forecaster.
-        **New in version 0.7.0**
 
     """
     
     def __init__(
         self, 
         regressor: object, 
         fun_predictors: Callable, 
@@ -312,28 +274,26 @@
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None
     ) -> Tuple[pd.DataFrame, pd.Series]:
         """
         Create training matrices from univariate time series and exogenous
         variables.
         
         Parameters
-        ----------        
+        ----------
         y : pandas Series
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `y` and their indexes must be aligned.
 
 
-        Returns 
+        Returns
         -------
         X_train : pandas DataFrame
             Pandas DataFrame with the training values (predictors).
-            
         y_train : pandas Series
             Values (target) of the time series related to each row of `X_train`.
         
         """
         
         if len(y) < self.window_size + 1:
             raise ValueError(
@@ -453,15 +413,15 @@
         """
         Crate weights for each observation according to the forecaster's attribute
         `weight_func`.
 
         Parameters
         ----------
         X_train : pandas DataFrame
-            Dataframe generated with the method `create_train_X_y`, first return.
+            Dataframe created with the `create_train_X_y` method, first return.
 
         Returns
         -------
         sample_weight : numpy ndarray
             Weights to use in `fit` method.
 
         """
@@ -498,28 +458,26 @@
         """
         Training Forecaster.
 
         Additional arguments to be passed to the `fit` method of the regressor 
         can be added with the `fit_kwargs` argument when initializing the forecaster.
         
         Parameters
-        ----------        
+        ----------
         y : pandas Series
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `y` and their indexes must be aligned so
             that y[i] is regressed on exog[i].
-
         store_in_sample_residuals : bool, default `True`
-            If True, in-sample residuals will be stored in the forecaster object
+            If `True`, in-sample residuals will be stored in the forecaster object
             after fitting.
 
-        Returns 
+        Returns
         -------
         None
         
         """
         
         # Reset values in case the forecaster has already been fitted.
         self.index_type          = None
@@ -589,27 +547,25 @@
         Predict n steps ahead. It is an iterative process in which, each prediction,
         is used as a predictor for the next step.
         
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : numpy ndarray
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-            
         exog : numpy ndarray, default `None`
             Exogenous variable/s included as predictor/s.
 
-        Returns 
+        Returns
         -------
         predictions : numpy ndarray
             Predicted values.
-            
+        
         """
 
         predictions = np.full(shape=steps, fill_value=np.nan)
 
         for i in range(steps):
             X = self.fun_predictors(y=last_window).reshape(1, -1)
             if np.isnan(X).any():
@@ -643,31 +599,28 @@
         Predict n steps ahead. It is an recursive process in which, each prediction,
         is used as a predictor for the next step.
         
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
 
-        Returns 
+        Returns
         -------
         predictions : pandas Series
             Predicted values.
-            
+        
         """
 
         if last_window is None:
             last_window = copy(self.last_window)
 
         last_window = last_window.iloc[-self.window_size:]
 
@@ -758,48 +711,43 @@
         """
         Generate multiple forecasting predictions using a bootstrapping process. 
         By sampling from a collection of past observed errors (the residuals),
         each iteration of bootstrapping generates a different set of predictions. 
         See the Notes section for more information. 
         
         Parameters
-        ----------   
+        ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-                        
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
-        boot_predictions : pandas DataFrame, shape (steps, n_boot)
+        boot_predictions : pandas DataFrame
             Predictions generated by bootstrapping.
+            Shape: (steps, n_boot)
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp3/prediction-intervals.html#prediction-intervals-from-bootstrapped-residuals
         Forecasting: Principles and Practice (3nd ed) Rob J Hyndman and George Athanasopoulos.
 
@@ -940,65 +888,58 @@
     ) -> pd.DataFrame:
         """
         Iterative process in which each prediction is used as a predictor
         for the next step, and bootstrapping is used to estimate prediction
         intervals. Both predictions and intervals are returned.
         
         Parameters
-        ---------- 
+        ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         interval : list, default `[5, 95]`
             Confidence of the prediction interval estimated. Sequence of 
             percentiles to compute, which must be between 0 and 100 inclusive. 
             For example, interval of 95% should be as `interval = [2.5, 97.5]`.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
-            Values predicted by the forecaster and their estimated interval:
+            Values predicted by the forecaster and their estimated interval.
 
-            - pred: predictions.
-            - lower_bound: lower bound of the interval.
-            - upper_bound: upper bound interval of the interval.
+                - pred: predictions.
+                - lower_bound: lower bound of the interval.
+                - upper_bound: upper bound of the interval.
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp2/prediction-intervals.html
         Forecasting: Principles and Practice (2nd ed) Rob J Hyndman and
         George Athanasopoulos.
-            
+        
         """
         
         check_interval(interval=interval)
         
         predictions = self.predict(
                           steps       = steps,
                           last_window = last_window,
@@ -1034,48 +975,41 @@
     ) -> pd.DataFrame:
         """
         Fit a given probability distribution for each step. After generating 
         multiple forecasting predictions through a bootstrapping process, each 
         step is fitted to the given distribution.
         
         Parameters
-        ---------- 
+        ----------
         steps : int
             Number of future steps predicted.
-
         distribution : Object
             A distribution object from scipy.stats.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
             Distribution parameters estimated for each step.
 
         """
         
         boot_samples = self.predict_bootstrapping(
@@ -1112,17 +1046,17 @@
         forecaster.
         
         Parameters
         ----------
         params : dict
             Parameters values.
 
-        Returns 
+        Returns
         -------
-        self
+        None
         
         """
         
         self.regressor = clone(self.regressor)
         self.regressor.set_params(**params)
 
 
@@ -1135,15 +1069,15 @@
         method of the regressor.
         
         Parameters
         ----------
         fit_kwargs : dict
             Dict of the form {"argument": new_value}.
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         self.fit_kwargs = check_select_fit_kwargs(self.regressor, fit_kwargs=fit_kwargs)
         
@@ -1161,30 +1095,27 @@
         participate in the training process.
         
         Parameters
         ----------
         residuals : numpy ndarray
             Values of residuals. If len(residuals) > 1000, only a random sample
             of 1000 values are stored.
-            
         append : bool, default `True`
             If `True`, new residuals are added to the once already stored in the
             attribute `out_sample_residuals`. Once the limit of 1000 values is
             reached, no more values are appended. If False, `out_sample_residuals`
             is overwritten with the new residuals.
-
         transform : bool, default `True`
             If `True`, new residuals are transformed using self.transformer_y.
-
         random_state : int, default `123`
             Sets a seed to the random sampling for reproducible output.
-            
-        Returns 
+
+        Returns
         -------
-        self
+        None
 
         """
 
         if not isinstance(residuals, np.ndarray):
             raise TypeError(
                 f"`residuals` argument must be `numpy ndarray`. Got {type(residuals)}."
             )
@@ -1275,37 +1206,8 @@
 
         if feature_importances is not None:
             feature_importances = pd.DataFrame({
                                       'feature': self.X_train_col_names,
                                       'importance': feature_importances
                                   })
 
-        return feature_importances
-    
-
-    def get_feature_importance(
-        self
-    ) -> pd.DataFrame:
-        """
-        This method has been replaced by `get_feature_importances()`.
-
-        Return feature importances of the regressor stored in the
-        forecaster. Only valid when regressor stores internally the feature
-        importances in the attribute `feature_importances_` or `coef_`.
-
-        Parameters
-        ----------
-        self
-
-        Returns
-        -------
-        feature_importances : pandas DataFrame
-            Feature importances associated with each predictor.
-
-        """
-
-        warnings.warn(
-            ("get_feature_importance() method has been renamed to get_feature_importances(). "
-             "This method will be removed in skforecast 0.9.0.")
-        )
-
-        return self.get_feature_importances()
+        return feature_importances
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/fixtures_ForecasterAutoregCustom.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/fixtures_ForecasterAutoregCustom.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_create_sample_weights.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_create_sample_weights.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_create_train_X_y.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_create_train_X_y.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_fit.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_fit.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_get_feature_importances.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_get_feature_importances.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_init.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_init.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_predict.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_predict_bootstrapping.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_predict_bootstrapping.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_predict_dist.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_predict_dist.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_predict_interval.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_predict_interval.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_recursive_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_recursive_predict.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_set_fit_kwargs.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_set_fit_kwargs.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_set_out_sample_residuals.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_set_out_sample_residuals.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregCustom/tests/test_set_params.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregCustom/tests/test_set_params.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,27 @@
 ################################################################################
 #                         ForecasterAutoregDirect                              #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
-from typing import Union, Dict, List, Tuple, Any, Optional, Callable
+from typing import Union, Dict, List, Tuple, Optional, Callable
 import warnings
 import logging
 import sys
 import numpy as np
 import pandas as pd
 import sklearn
 import sklearn.pipeline
 from sklearn.base import clone
 import inspect
 from copy import copy
+from joblib import Parallel, delayed, cpu_count
 
 import skforecast
 from ..ForecasterBase import ForecasterBase
 from ..utils import initialize_lags
 from ..utils import initialize_weights
 from ..utils import check_select_fit_kwargs
 from ..utils import check_y
@@ -33,14 +34,15 @@
 from ..utils import preprocess_last_window
 from ..utils import preprocess_exog
 from ..utils import exog_to_direct
 from ..utils import exog_to_direct_numpy
 from ..utils import expand_index
 from ..utils import transform_series
 from ..utils import transform_dataframe
+from ..utils import select_n_jobs_fit_forecaster
 
 logging.basicConfig(
     format = '%(name)-10s %(levelname)-5s %(message)s', 
     level  = logging.INFO,
 )
 
 
@@ -50,164 +52,136 @@
     autoregressive direct multi-step forecaster. A separate model is created for
     each forecast time step. See documentation for more details.
     
     Parameters
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
-        
-    lags : int, list, 1d numpy ndarray, range
-        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
-            `int`: include lags from 1 to `lags` (included).
-            `list`, `numpy ndarray` or range: include only lags present in `lags`.
-            
     steps : int
         Maximum number of future steps the forecaster will predict when using
         method `predict()`. Since a different model is created for each step,
         this value should be defined before training.
+    lags : int, list, numpy ndarray, range
+        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
 
+            - `int`: include lags from 1 to `lags` (included).
+            - `list`, `1d numpy ndarray` or `range`: include only lags present in 
+            `lags`, all elements must be int.
     transformer_y : object transformer (preprocessor), default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
         ColumnTransformers are not allowed since they do not have inverse_transform method.
         The transformation is applied to `y` before training the forecaster.
-
     transformer_exog : object transformer (preprocessor), default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
     weight_func : Callable, default `None`
         Function that defines the individual weights for each sample based on the
         index. For example, a function that assigns a lower weight to certain dates.
         Ignored if `regressor` does not have the argument `sample_weight` in its `fit`
         method. The resulting `sample_weight` cannot have negative values.
-        **New in version 0.6.0**
-
     fit_kwargs : dict, default `None`
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_fit_forecaster.
+        **New in version 0.9.0**
     forecaster_id : str, int, default `None`
         Name used as an identifier of the forecaster.
+        **New in version 0.7.0**
     
     Attributes
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
         An instance of this regressor is trained for each step. All of them 
         are stored in `self.regressors_`.
-
     regressors_ : dict
         Dictionary with regressors trained for each step. They are initialized 
         as a copy of `regressor`.
-        
     steps : int
         Number of future steps the forecaster will predict when using method
         `predict()`. Since a different model is created for each step, this value
         should be defined before training.
-        
     lags : numpy ndarray
         Lags used as predictors.
-        
-    transformer_y : object transformer (preprocessor), default `None`
+    transformer_y : object transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
         ColumnTransformers are not allowed since they do not have inverse_transform method.
         The transformation is applied to `y` before training the forecaster.
-
-    transformer_exog : object transformer (preprocessor), default `None`
+    transformer_exog : object transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-        
     weight_func : Callable
         Function that defines the individual weights for each sample based on the
         index. For example, a function that assigns a lower weight to certain dates.
         Ignored if `regressor` does not have the argument `sample_weight` in its `fit`
-        method.
-        **New in version 0.6.0**
-
+        method. The resulting `sample_weight` cannot have negative values.
     source_code_weight_func : str
         Source code of the custom function used to create weights.
-        **New in version 0.6.0**
-        
     max_lag : int
         Maximum value of lag included in `lags`.
-        
     window_size : int
-        Size of the window needed to create the predictors. It is equal to
-        `max_lag`.
-
+        Size of the window needed to create the predictors. It is equal to `max_lag`.
     last_window : pandas Series
         Last window the forecaster has seen during training. It stores the
         values needed to predict the next `step` immediately after the training data.
-        
     index_type : type
         Type of index of the input used in training.
-        
     index_freq : str
         Frequency of Index of the input used in training.
-        
     training_range : pandas Index
         First and last values of index of the data used during training.
-        
     included_exog : bool
         If the forecaster has been trained using exogenous variable/s.
-        
     exog_type : type
         Type of exogenous variable/s used in training.
-
     exog_dtypes : dict
         Type of each exogenous variable/s used in training. If `transformer_exog` 
         is used, the dtypes are calculated after the transformation.
-        
     exog_col_names : list
         Names of columns of `exog` if `exog` used in training was a pandas
         DataFrame.
-
     X_train_col_names : list
         Names of columns of the matrix created internally for training.
-
     fit_kwargs : dict
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
     in_sample_residuals : dict
         Residuals of the models when predicting training data. Only stored up to
         1000 values per model in the form `{step: residuals}`. If `transformer_y` 
         is not `None`, residuals are stored in the transformed scale.
-        
     out_sample_residuals : dict
         Residuals of the models when predicting non training data. Only stored
         up to 1000 values per model in the form `{step: residuals}`. If `transformer_y` 
         is not `None`, residuals are assumed to be in the transformed scale. Use 
         `set_out_sample_residuals()` method to set values.
-        
     fitted : bool
         Tag to identify if the regressor has been fitted (trained).
-
     creation_date : str
         Date of creation.
-
     fit_date : str
         Date of last fit.
-
     skforcast_version : str
         Version of skforecast library used to create the forecaster.
-
     python_version : str
         Version of python used to create the forecaster.
-
-    forecaster_id : str, int default `None`
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_fit_forecaster.
+        **New in version 0.9.0**
+    forecaster_id : str, int
         Name used as an identifier of the forecaster.
 
-    fit_kwargs : dict, default `None`
-        Additional parameters passed to the `fit` method of the regressor.
-        
     Notes
     -----
     A separate model is created for each forecasting time step. It is important to
     note that all models share the same parameter and hyperparameter configuration.
      
     """
     
@@ -216,14 +190,15 @@
         regressor: object,
         steps: int,
         lags: Union[int, np.ndarray, list],
         transformer_y: Optional[object]=None,
         transformer_exog: Optional[object]=None,
         weight_func: Optional[Callable]=None,
         fit_kwargs: Optional[dict]=None,
+        n_jobs: Optional[Union[int, str]]='auto',
         forecaster_id: Optional[Union[str, int]]=None,
     ) -> None:
         
         self.regressor               = regressor
         self.steps                   = steps
         self.transformer_y           = transformer_y
         self.transformer_exog        = transformer_exog
@@ -252,14 +227,19 @@
             )
 
         if steps < 1:
             raise ValueError(
                 f"`steps` argument must be greater than or equal to 1. Got {steps}."
             )
         
+        if not isinstance(n_jobs, int) and n_jobs != 'auto':
+            raise TypeError(
+                f"`n_jobs` must be an integer or `'auto'`. Got {type(n_jobs)}."
+            )
+
         self.regressors_ = {step: clone(self.regressor) for step in range(1, steps + 1)}
         self.lags = initialize_lags(type(self).__name__, lags)
         self.max_lag = max(self.lags)
         self.window_size = self.max_lag
 
         self.weight_func, self.source_code_weight_func, _ = initialize_weights(
             forecaster_name = type(self).__name__, 
@@ -271,14 +251,22 @@
         self.fit_kwargs = check_select_fit_kwargs(
                               regressor  = regressor,
                               fit_kwargs = fit_kwargs
                           )
 
         self.in_sample_residuals = {step: None for step in range(1, steps + 1)}
         self.out_sample_residuals = None
+
+        if n_jobs == 'auto':
+            self.n_jobs = select_n_jobs_fit_forecaster(
+                              forecaster_name = type(self).__name__,
+                              regressor_name  = type(self.regressor).__name__,
+                          )
+        else:
+            self.n_jobs = n_jobs if n_jobs > 0 else cpu_count()
     
 
     def __repr__(
         self
     ) -> str:
         """
         Information displayed when a ForecasterAutoregDirect object is printed.
@@ -320,83 +308,86 @@
         return info
     
     
     def _create_lags(
         self, 
         y: np.ndarray
     ) -> Tuple[np.ndarray, np.ndarray]:
-        """       
-        Transforms a 1d array into a 2d array (X) and a 1d array (y). Each row
+        """
+        Transforms a 1d array into a 2d array (X) and a 2d array (y). Each row
         in X is associated with a value of y and it represents the lags that
         precede it.
         
         Notice that, the returned matrix X_data, contains the lag 1 in the first
         column, the lag 2 in the second column and so on.
         
         Parameters
-        ----------        
-        y : 1d numpy ndarray
-            Training time series.
+        ----------
+        y : numpy ndarray
+            1d numpy ndarray Training time series.
 
-        Returns 
+        Returns
         -------
-        X_data : 2d numpy ndarray, shape (samples - max(self.lags), len(self.lags))
-            2d numpy array with the lagged values (predictors).
-        
-        y_data : 1d numpy ndarray, shape (samples - max(self.lags),)
-            Values of the time series related to each row of `X_data`.
+        X_data : numpy ndarray
+            2d numpy ndarray with the lagged values (predictors). 
+            Shape: (samples - max(self.lags), len(self.lags))
+        y_data : numpy ndarray
+            2d numpy ndarray with the values of the time series related to each 
+            row of `X_data` for each step. 
+            Shape: (len(self.steps), samples - max(self.lags))
         
         """
 
         n_splits = len(y) - self.max_lag - (self.steps - 1) # rows of y_data
         if n_splits <= 0:
             raise ValueError(
                 (f"The maximum lag ({self.max_lag}) must be less than the length "
                  f"of the series minus the number of steps ({len(y)-(self.steps-1)}).")
             )
         
         X_data = np.full(shape=(n_splits, len(self.lags)), fill_value=np.nan, dtype=float)
         for i, lag in enumerate(self.lags):
             X_data[:, i] = y[self.max_lag - lag : -(lag + self.steps - 1)] 
 
-        y_data = np.full(shape=(n_splits, self.steps), fill_value=np.nan, dtype=float)
+        y_data = np.full(shape=(self.steps, n_splits), fill_value=np.nan, dtype=float)
         for step in range(self.steps):
-            y_data[:, step] = y[self.max_lag + step : self.max_lag + step + n_splits]
+            y_data[step, ] = y[self.max_lag + step : self.max_lag + step + n_splits]
             
         return X_data, y_data
 
 
     def create_train_X_y(
         self,
         y: pd.Series,
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None
-    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
+    ) -> Tuple[pd.DataFrame, dict]:
         """
         Create training matrices from univariate time series and exogenous
         variables. The resulting matrices contain the target variable and predictors
         needed to train all the regressors (one per step).
         
         Parameters
-        ----------        
+        ----------
         y : pandas Series
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `y` and their indexes must be aligned.
 
-        Returns 
+        Returns
         -------
         X_train : pandas DataFrame
-            Pandas DataFrame with the training values (predictors) for each step.
-            Shape (len(y) - self.max_lag, len(self.lags) + exog.shape[1]*steps)
-            
-        y_train : pandas DataFrame, shape (len(y) - self.max_lag, )
+            Training values (predictors) for each step. Note that the index 
+            corresponds to that of the last step. It is updated for the corresponding 
+            step in the filter_train_X_y_for_step method.
+            Shape: (len(y) - self.max_lag, len(self.lags))
+        y_train : dict
             Values (target) of the time series related to each row of `X_train` 
-            for each step.
+            for each step of the form {step: y_step_[i]}.
+            Shape of each series: (len(y) - self.max_lag, )
         
         """
 
         if len(y) < self.max_lag + self.steps:
             raise ValueError(
                 (f"Minimum length of `y` for training this forecaster is "
                  f"{self.max_lag + self.steps}. Got {len(y)}. Reduce the "
@@ -464,81 +455,81 @@
                                 exog  = exog,
                                 steps = self.steps
                             ).iloc[-X_train.shape[0]:, :]
             X_train = pd.concat((X_train, exog_to_train), axis=1)
 
         self.X_train_col_names = X_train.columns.to_list()
 
-        y_train_col_names = [f"y_step_{i+1}" for i in range(self.steps)]
-        y_train = pd.DataFrame(
-                      data    = y_train,
-                      index   = y_index[self.max_lag + (self.steps -1): ],
-                      columns = y_train_col_names,
-                  )
+        y_train = {step: pd.Series(
+                             data  = y_train[step-1], 
+                             index = y_index[self.max_lag + step-1:][:len(y_train[0])],
+                             name  = f"y_step_{step}"
+                         )
+                   for step in range(1, self.steps + 1)}
         
         return X_train, y_train
 
     
     def filter_train_X_y_for_step(
         self,
         step: int,
         X_train: pd.DataFrame,
-        y_train: pd.Series,
+        y_train: dict,
         remove_suffix: bool=False
     ) -> Tuple[pd.DataFrame, pd.Series]:
         """
         Select the columns needed to train a forecaster for a specific step.  
-        The input matrices should be created using `create_train_X_y()`. If 
-        `remove_suffix=True` the suffix "_step_i" will be removed from the 
-        column names. 
+        The input matrices should be created using `create_train_X_y` method. 
+        This method updates the index of `X_train` to the corresponding one 
+        according to `y_train`. If `remove_suffix=True` the suffix "_step_i" 
+        will be removed from the column names. 
 
         Parameters
         ----------
         step : int
             Step for which columns must be selected selected. Starts at 1.
-
         X_train : pandas DataFrame
-            Pandas DataFrame with the training values (predictors).
-            
-        y_train : pandas Series
-            Values (target) of the time series related to each row of `X_train`.
-
+            Dataframe created with the `create_train_X_y` method, first return.
+        y_train : dict
+            Dict created with the `create_train_X_y` method, second return.
         remove_suffix : bool, default `False`
             If True, suffix "_step_i" is removed from the column names.
 
-        Returns 
+        Returns
         -------
         X_train_step : pandas DataFrame
-            Pandas DataFrame with the training values (predictors) for step.
-            
-        y_train_step : pandas Series, shape (len(y) - self.max_lag)
+            Training values (predictors) for the selected step.
+        y_train_step : pandas Series
             Values (target) of the time series related to each row of `X_train`.
+            Shape: (len(y) - self.max_lag)
 
         """
 
         if (step < 1) or (step > self.steps):
             raise ValueError(
                 (f"Invalid value `step`. For this forecaster, minimum value is 1 "
                  f"and the maximum step is {self.steps}.")
             )
 
-        # Matrices X_train and y_train start at index 0.
-        y_train_step = y_train.iloc[:, step - 1] 
+        y_train_step = y_train[step]
 
+        # Matrix X_train starts at index 0.
         if not self.included_exog:
             X_train_step = X_train
         else:
             idx_columns_lags = np.arange(len(self.lags))
             n_exog = (len(self.X_train_col_names) - len(self.lags)) / self.steps
             idx_columns_exog = (
                 np.arange((step-1)*n_exog, (step)*n_exog) + idx_columns_lags[-1] + 1
             )
             idx_columns = np.hstack((idx_columns_lags, idx_columns_exog))
             X_train_step = X_train.iloc[:, idx_columns]
 
+        X_train_step.index = y_train_step.index
+
         if remove_suffix:
             X_train_step.columns = [col_name.replace(f"_step_{step}", "")
                                     for col_name in X_train_step.columns]
             y_train_step.name = y_train_step.name.replace(f"_step_{step}", "")
 
         return  X_train_step, y_train_step
 
@@ -550,16 +541,16 @@
         """
         Crate weights for each observation according to the forecaster's attribute
         `weight_func`.
 
         Parameters
         ----------
         X_train : pandas DataFrame
-           Dataframe generated with the methods `create_train_X_y` and 
-            `filter_train_X_y_for_step`, first return.
+            Dataframe created with `create_train_X_y` and filter_train_X_y_for_step`
+            methods, first return.
 
         Returns
         -------
         sample_weight : numpy ndarray
             Weights to use in `fit` method.
 
         """
@@ -594,30 +585,28 @@
         store_in_sample_residuals: bool=True
     ) -> None:
         """
         Training Forecaster.
 
         Additional arguments to be passed to the `fit` method of the regressor 
         can be added with the `fit_kwargs` argument when initializing the forecaster.
-        
+
         Parameters
-        ----------        
+        ----------
         y : pandas Series
             Training time series.
-        
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `y` and their indexes must be aligned so
             that y[i] is regressed on exog[i].
-
         store_in_sample_residuals : bool, default `True`
-            If True, in-sample residuals will be stored in the forecaster object
+            If `True`, in-sample residuals will be stored in the forecaster object
             after fitting.
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         # Reset values in case the forecaster has already been fitted.
         self.index_type          = None
@@ -635,57 +624,98 @@
         if exog is not None:
             self.included_exog = True
             self.exog_type = type(exog)
             self.exog_col_names = \
                  exog.columns.to_list() if isinstance(exog, pd.DataFrame) else exog.name
 
         X_train, y_train = self.create_train_X_y(y=y, exog=exog)
-        
-        # Train one regressor for each step 
-        for step in range(1, self.steps + 1): 
-            # self.regressors_ and self.filter_train_X_y_for_step expect
-            # first step to start at value 1
+
+        def fit_forecaster(regressor, X_train, y_train, step, store_in_sample_residuals):
+            """
+            Auxiliary function to fit each of the forecaster's regressors in parallel.
+
+            Parameters
+            ----------
+            regressor : object
+                Regressor to be fitted.
+            X_train : pandas DataFrame
+                Dataframe created with the `create_train_X_y` method, first return.
+            y_train : dict
+                Dict created with the `create_train_X_y` method, second return.
+            step : int
+                Step of the forecaster to be fitted.
+            store_in_sample_residuals : bool
+                If `True`, in-sample residuals will be stored in the forecaster object
+                after fitting.
+            
+            Returns
+            -------
+            Tuple with the step, fitted regressor and in-sample residuals.
+
+            """
+
             X_train_step, y_train_step = self.filter_train_X_y_for_step(
                                              step          = step,
                                              X_train       = X_train,
                                              y_train       = y_train,
                                              remove_suffix = True
                                          )
             sample_weight = self.create_sample_weights(X_train=X_train_step)
             if sample_weight is not None:
-                self.regressors_[step].fit(
+                regressor.fit(
                     X             = X_train_step,
                     y             = y_train_step,
                     sample_weight = sample_weight,
                     **self.fit_kwargs
                 )
             else:
-                self.regressors_[step].fit(
+                regressor.fit(
                     X = X_train_step,
                     y = y_train_step,
                     **self.fit_kwargs
                 )
 
             # This is done to save time during fit in functions such as backtesting()
             if store_in_sample_residuals:
-                
                 residuals = (
-                    (y_train_step - self.regressors_[step].predict(X_train_step))
+                    (y_train_step - regressor.predict(X_train_step))
                 ).to_numpy()
 
                 if len(residuals) > 1000:
                     # Only up to 1000 residuals are stored
                         rng = np.random.default_rng(seed=123)
                         residuals = rng.choice(
                                         a       = residuals, 
                                         size    = 1000, 
                                         replace = False
                                     )
+            else:
+                residuals = None
+
+            return step, regressor, residuals
+
+        results_fit = (
+            Parallel(n_jobs=self.n_jobs)
+            (delayed(fit_forecaster)
+            (
+                regressor=copy(self.regressor),
+                X_train=X_train,
+                y_train=y_train,
+                step=step,
+                store_in_sample_residuals=store_in_sample_residuals
+            )
+            for step in range(1, self.steps + 1))
+        )
+
+        self.regressors_ = {step: regressor 
+                            for step, regressor, _ in results_fit}
 
-                self.in_sample_residuals[step] = residuals
+        if store_in_sample_residuals:
+            self.in_sample_residuals = {step: residuals 
+                                        for step, _, residuals in results_fit}
 
         self.fitted = True
         self.fit_date = pd.Timestamp.today().strftime('%Y-%m-%d %H:%M:%S')
         self.training_range = preprocess_y(y=y, return_values=False)[1][[0, -1]]
         self.index_type = type(X_train.index)
         if isinstance(X_train.index, pd.DatetimeIndex):
             self.index_freq = X_train.index.freqstr
@@ -706,35 +736,29 @@
 
         Parameters
         ----------
         steps : int, list, None, default `None`
             Predict n steps. The value of `steps` must be less than or equal to the 
             value of steps defined when initializing the forecaster. Starts at 1.
         
-            If `int`:
-                Only steps within the range of 1 to int are predicted.
-        
-            If `list`:
-                List of ints. Only the steps contained in the list are predicted.
-
-            If `None`:
-                As many steps are predicted as were defined at initialization.
-
+                - If `int`: Only steps within the range of 1 to int are predicted.
+                - If `list`: List of ints. Only the steps contained in the list 
+                are predicted.
+                - If `None`: As many steps are predicted as were defined at 
+                initialization.
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
 
-        Returns 
+        Returns
         -------
         predictions : pandas Series
             Predicted values.
 
         """
 
         if isinstance(steps, int):
@@ -856,58 +880,50 @@
         """
         Generate multiple forecasting predictions using a bootstrapping process. 
         By sampling from a collection of past observed errors (the residuals),
         each iteration of bootstrapping generates a different set of predictions. 
         See the Notes section for more information. 
         
         Parameters
-        ----------   
+        ----------
         steps : int, list, None, default `None`
             Predict n steps. The value of `steps` must be less than or equal to the 
             value of steps defined when initializing the forecaster. Starts at 1.
         
-            If `int`:
-                Only steps within the range of 1 to int are predicted.
-        
-            If `list`:
-                List of ints. Only the steps contained in the list are predicted.
-
-            If `None`:
-                As many steps are predicted as were defined at initialization.
-
+                - If `int`: Only steps within the range of 1 to int are predicted.
+                - If `list`: List of ints. Only the steps contained in the list 
+                are predicted.
+                - If `None`: As many steps are predicted as were defined at 
+                initialization.
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-                        
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
-        boot_predictions : pandas DataFrame, shape (steps, n_boot)
+        boot_predictions : pandas DataFrame
             Predictions generated by bootstrapping.
+            Shape: (steps, n_boot)
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp3/prediction-intervals.html#prediction-intervals-from-bootstrapped-residuals
         Forecasting: Principles and Practice (3nd ed) Rob J Hyndman and George Athanasopoulos.
 
@@ -971,17 +987,17 @@
                           series            = predictions,
                           transformer       = self.transformer_y,
                           fit               = False,
                           inverse_transform = False
                       )
         boot_predictions = pd.concat([predictions] * n_boot, axis=1)
         boot_predictions.columns= [f"pred_boot_{i}" for i in range(n_boot)]
-
-        rng = np.random.default_rng(seed=random_state)
+        
         for i, step in enumerate(steps):
+            rng = np.random.default_rng(seed=random_state)
             sample_residuals = rng.choice(
                                    a       = residuals[step],
                                    size    = n_boot,
                                    replace = True
                                )
             boot_predictions.iloc[i, :] = boot_predictions.iloc[i, :] + sample_residuals
 
@@ -1008,75 +1024,65 @@
         in_sample_residuals: bool=True
     ) -> pd.DataFrame:
         """
         Bootstrapping based prediction intervals.
         Both predictions and intervals are returned.
         
         Parameters
-        ---------- 
+        ----------
         steps : int, list, None, default `None`
             Predict n steps. The value of `steps` must be less than or equal to the 
             value of steps defined when initializing the forecaster. Starts at 1.
         
-            If `int`:
-                Only steps within the range of 1 to int are predicted.
-        
-            If `list`:
-                List of ints. Only the steps contained in the list are predicted.
-
-            If `None`:
-                As many steps are predicted as were defined at initialization.
-
+                - If `int`: Only steps within the range of 1 to int are predicted.
+                - If `list`: List of ints. Only the steps contained in the list 
+                are predicted.
+                - If `None`: As many steps are predicted as were defined at 
+                initialization.
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         interval : list, default `[5, 95]`
             Confidence of the prediction interval estimated. Sequence of 
             percentiles to compute, which must be between 0 and 100 inclusive. 
             For example, interval of 95% should be as `interval = [2.5, 97.5]`.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
-            Values predicted by the forecaster and their estimated interval:
+            Values predicted by the forecaster and their estimated interval.
 
-            - pred: predictions.
-            - lower_bound: lower bound of the interval.
-            - upper_bound: upper bound interval of the interval.
+                - pred: predictions.
+                - lower_bound: lower bound of the interval.
+                - upper_bound: upper bound of the interval.
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp2/prediction-intervals.html
         Forecasting: Principles and Practice (2nd ed) Rob J Hyndman and
         George Athanasopoulos.
-            
+        
         """
 
         check_interval(interval=interval)
 
         predictions = self.predict(
                           steps       = steps,
                           last_window = last_window,
@@ -1112,58 +1118,48 @@
     ) -> pd.DataFrame:
         """
         Fit a given probability distribution for each step. After generating 
         multiple forecasting predictions through a bootstrapping process, each 
         step is fitted to the given distribution.
         
         Parameters
-        ---------- 
+        ----------
         distribution : Object
             A distribution object from scipy.stats.
-        
         steps : int, list, None, default `None`
             Predict n steps. The value of `steps` must be less than or equal to the 
             value of steps defined when initializing the forecaster. Starts at 1.
         
-            If `int`:
-                Only steps within the range of 1 to int are predicted.
-        
-            If `list`:
-                List of ints. Only the steps contained in the list are predicted.
-
-            If `None`:
-                As many steps are predicted as were defined at initialization.
-            
+                - If `int`: Only steps within the range of 1 to int are predicted.
+                - If `list`: List of ints. Only the steps contained in the list 
+                are predicted.
+                - If `None`: As many steps are predicted as were defined at 
+                initialization.
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
             Distribution parameters estimated for each step.
 
         """
         
         boot_samples = self.predict_bootstrapping(
@@ -1201,17 +1197,17 @@
         configuration of parameters and hyperparameters.
         
         Parameters
         ----------
         params : dict
             Parameters values.
 
-        Returns 
+        Returns
         -------
-        self
+        None
         
         """
         
         self.regressor = clone(self.regressor)
         self.regressor.set_params(**params)
         self.regressors_ = {step: clone(self.regressor)
                             for step in range(1, self.steps + 1)}
@@ -1226,15 +1222,15 @@
         method of the regressor.
         
         Parameters
         ----------
         fit_kwargs : dict
             Dict of the form {"argument": new_value}.
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         self.fit_kwargs = check_select_fit_kwargs(self.regressor, fit_kwargs=fit_kwargs)
 
@@ -1245,20 +1241,22 @@
     ) -> None:
         """      
         Set new value to the attribute `lags`.
         Attributes `max_lag` and `window_size` are also updated.
         
         Parameters
         ----------
-        lags : int, list, 1D np.ndarray, range
+        lags : int, list, numpy ndarray, range
             Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
-                `int`: include lags from 1 to `lags`.
-                `list` or `np.ndarray`: include only lags present in `lags`.
 
-        Returns 
+            - `int`: include lags from 1 to `lags` (included).
+            - `list`, `1d numpy ndarray` or `range`: include only lags present in 
+            `lags`, all elements must be int.
+
+        Returns
         -------
         None
         
         """
         
         self.lags = initialize_lags(type(self).__name__, lags)
         self.max_lag = max(self.lags)
@@ -1279,65 +1277,65 @@
         
         Parameters
         ----------
         residuals : dict
             Dictionary of numpy ndarrays with the residuals of each model in the
             form {step: residuals}. If len(residuals) > 1000, only a random 
             sample of 1000 values are stored.
-            
         append : bool, default `True`
             If `True`, new residuals are added to the once already stored in the
             attribute `out_sample_residuals`. Once the limit of 1000 values is
             reached, no more values are appended. If False, `out_sample_residuals`
             is overwritten with the new residuals.
-
         transform : bool, default `True`
             If `True`, new residuals are transformed using self.transformer_y.
-
         random_state : int, default `123`
             Sets a seed to the random sampling for reproducible output.
-            
-        Returns 
+
+        Returns
         -------
-        self
+        None
 
         """
 
         if not isinstance(residuals, dict) or not all(isinstance(x, np.ndarray) for x in residuals.values()):
             raise TypeError(
-                f"`residuals` argument must be a dict of numpy ndarrays in the form "
-                "`{step: residuals}`. " 
-                f"Got {type(residuals)}."
+                (f"`residuals` argument must be a dict of numpy ndarrays in the form "
+                 "`{step: residuals}`. " 
+                 f"Got {type(residuals)}.")
             )
 
         if not self.fitted:
             raise sklearn.exceptions.NotFittedError(
                 ("This forecaster is not fitted yet. Call `fit` with appropriate "
                  "arguments before using `set_out_sample_residuals()`.")
             )
         
         if self.out_sample_residuals is None:
-            self.out_sample_residuals = {step: None for step in range(1, self.steps + 1)}
+            self.out_sample_residuals = {step: None 
+                                         for step in range(1, self.steps + 1)}
         
         if not set(self.out_sample_residuals.keys()).issubset(set(residuals.keys())):
             warnings.warn(
                 f"""
                 Only residuals of models (steps) 
                 {set(self.out_sample_residuals.keys()).intersection(set(residuals.keys()))} 
                 are updated.
                 """
             )
 
-        residuals = {key: value for key, value in residuals.items() if key in self.out_sample_residuals.keys()}
+        residuals = {key: value 
+                     for key, value in residuals.items() 
+                     if key in self.out_sample_residuals.keys()}
 
         if not transform and self.transformer_y is not None:
             warnings.warn(
                 (f"Argument `transform` is set to `False` but forecaster was trained "
-                 f"using a transformer {self.transformer_y}. Ensure that the new residuals "
-                 f"are already transformed or set `transform=True`.")
+                 f"using a transformer {self.transformer_y}. Ensure that the new "
+                 f"residuals are already transformed or set `transform=True`.")
             )
 
         if transform and self.transformer_y is not None:
             warnings.warn(
                 (f"Residuals will be transformed using the same transformer used "
                  f"when training the forecaster ({self.transformer_y}). Ensure the "
                  f"new residuals are on the same scale as the original time series.")
@@ -1376,23 +1374,24 @@
         step: int
     ) -> pd.DataFrame:
         """
         Return feature importance of the model stored in the forecaster for a
         specific step. Since a separate model is created for each forecast time
         step, it is necessary to select the model from which retrieve information.
         Only valid when regressor stores internally the feature importances in
-        the attribute `feature_importances_` or `coef_`.
+        the attribute `feature_importances_` or `coef_`. Otherwise, it returns  
+        `None`.
 
         Parameters
         ----------
         step : int
             Model from which retrieve information (a separate model is created 
             for each forecast time step). First step is 1.
 
-        Returns 
+        Returns
         -------
         feature_importances : pandas DataFrame
             Feature importances associated with each predictor.
         
         """
 
         if not isinstance(step, int):
@@ -1444,43 +1443,8 @@
 
         if feature_importances is not None:
             feature_importances = pd.DataFrame({
                                       'feature': feature_names,
                                       'importance': feature_importances
                                   })
 
-        return feature_importances
-    
-
-    def get_feature_importance(
-        self, 
-        step: int
-    ) -> pd.DataFrame:
-        """
-        This method has been replaced by `get_feature_importances()`.
-
-        Return feature importance of the model stored in the forecaster for a
-        specific step. Since a separate model is created for each forecast time
-        step, it is necessary to select the model from which retrieve information.
-        Only valid when regressor stores internally the feature importances in
-        the attribute `feature_importances_` or `coef_`. Otherwise, it returns  
-        `None`.
-
-        Parameters
-        ----------
-        step : int
-            Model from which retrieve information (a separate model is created 
-            for each forecast time step). First step is 1.
-
-        Returns 
-        -------
-        feature_importances : pandas DataFrame
-            Feature importances associated with each predictor.
-        
-        """
-
-        warnings.warn(
-            ("get_feature_importance() method has been renamed to get_feature_importances()."
-             "This method will be removed in skforecast 0.9.0.")
-        )
-
-        return self.get_feature_importances(step=step)
+        return feature_importances
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/fixtures_ForecasterAutoregDirect.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/fixtures_ForecasterAutoregDirect.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_create_lags.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_create_lags.py`

 * *Files 7% similar despite different names*

```diff
@@ -12,16 +12,16 @@
     """
     Check exception is raised when n_splits in _create_lags is less than 0.
     """
     forecaster = ForecasterAutoregDirect(LinearRegression(), lags=8, steps=3)
     y = pd.Series(np.arange(10))
 
     err_msg = re.escape(
-                f'The maximum lag ({forecaster.max_lag}) must be less than the length '
-                f'of the series minus the number of steps ({len(y)-(forecaster.steps-1)}).'
+                (f"The maximum lag ({forecaster.max_lag}) must be less than the length "
+                 f"of the series minus the number of steps ({len(y)-(forecaster.steps-1)}).")
             )
     with pytest.raises(ValueError, match = err_msg):
         forecaster._create_lags(y=y)
 
   
 def test_create_lags_when_lags_is_3_steps_1_and_y_is_numpy_arange_10():
     """
@@ -33,21 +33,16 @@
     expected = (np.array([[2., 1., 0.],
                           [3., 2., 1.],
                           [4., 3., 2.],
                           [5., 4., 3.],
                           [6., 5., 4.],
                           [7., 6., 5.],
                           [8., 7., 6.]]),
-                np.array([[3.],
-                          [4.],
-                          [5.],
-                          [6.],
-                          [7.],
-                          [8.],
-                          [9.]]))
+                np.array([[3., 4., 5., 6., 7., 8., 9.]])
+                )
 
     assert (results[0] == expected[0]).all()
     assert (results[1] == expected[1]).all()
 
   
 def test_create_lags_when_lags_is_list_interspersed_lags_steps_1_and_y_is_numpy_arange_10():
     """
@@ -57,19 +52,16 @@
     forecaster = ForecasterAutoregDirect(LinearRegression(), lags=[1, 5], steps=1)
     results = forecaster._create_lags(y=np.arange(10))
     expected = (np.array([[4., 0.],
                           [5., 1.],
                           [6., 2.],
                           [7., 3.],
                           [8., 4.]]),
-                np.array([[5.],
-                          [6.],
-                          [7.],
-                          [8.],
-                          [9.]]))
+                np.array([[5., 6., 7., 8., 9.]])
+                )
 
     assert (results[0] == expected[0]).all()
     assert (results[1] == expected[1]).all()
 
 
 def test_create_lags_when_lags_is_3_steps_2_and_y_is_numpy_arange_10():
     """
@@ -80,20 +72,17 @@
     results = forecaster._create_lags(y=np.arange(10))
     expected = (np.array([[2., 1., 0.],
                           [3., 2., 1.],
                           [4., 3., 2.],
                           [5., 4., 3.],
                           [6., 5., 4.],
                           [7., 6., 5.]]),
-                np.array([[3., 4.],
-                          [4., 5.],
-                          [5., 6.],
-                          [6., 7.],
-                          [7., 8.],
-                          [8., 9.]]))
+                np.array([[3., 4., 5., 6., 7., 8.],
+                          [4., 5., 6., 7., 8., 9.]])
+                )
 
     assert (results[0] == expected[0]).all()
     assert (results[1] == expected[1]).all()
 
 
 def test_create_lags_when_lags_is_3_steps_5_and_y_is_numpy_arange_10():
     """
@@ -101,13 +90,16 @@
     np.arange(10).
     """
     forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=5)
     results = forecaster._create_lags(y=np.arange(10))
     expected = (np.array([[2., 1., 0.],
                           [3., 2., 1.],
                           [4., 3., 2.]]),
-                np.array([[3., 4., 5., 6., 7.],
-                          [4., 5., 6., 7., 8.],
-                          [5., 6., 7., 8., 9.]]))
+                np.array([[3., 4., 5.],
+                          [4., 5., 6.],
+                          [5., 6., 7.],
+                          [6., 7., 8.],
+                          [7., 8., 9.]])
+                )
 
     assert (results[0] == expected[0]).all()
     assert (results[1] == expected[1]).all()
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_create_sample_weights.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_create_sample_weights.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_create_train_X_y.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_create_train_X_y.py`

 * *Files 9% similar despite different names*

```diff
@@ -120,22 +120,29 @@
                              [5., 4., 3.],
                              [6., 5., 4.],
                              [7., 6., 5.],
                              [8., 7., 6.]], dtype=float),
             index   = pd.RangeIndex(start=3, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3']
         ),
-        pd.DataFrame(
-            data    = np.array([3., 4., 5., 6., 7., 8., 9.], dtype=float),
-            index   = pd.RangeIndex(start=3, stop=10, step=1),
-            columns = ['y_step_1'])
+        {1: pd.Series(
+                data  = np.array([3., 4., 5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=3, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
+               
 
 
 def test_create_train_X_y_output_when_interspersed_lags_steps_2_and_exog_is_None():
     """
     Test output of create_train_X_y when regressor is LinearRegression, 
     interspersed_lags and steps is 2.
     """
@@ -152,28 +159,33 @@
                              [4., 2.],
                              [5., 3.],
                              [6., 4.],
                              [7., 5.]], dtype=float),
             index   = pd.RangeIndex(start=4, stop=10, step=1),
             columns = ['lag_1', 'lag_3']
         ),
-        pd.DataFrame(
-            data = np.array([[3., 4.],
-                             [4., 5.],
-                             [5., 6.],
-                             [6., 7.],
-                             [7., 8.],
-                             [8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=4, stop=10, step=1),
-            columns = ['y_step_1', 'y_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array([3., 4., 5., 6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=3, stop=9, step=1),
+                name  = "y_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([4., 5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=4, stop=10, step=1),
+                name  = "y_step_2"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("dtype", 
                          [float, int], 
                          ids = lambda dt : f'dtype: {dt}')
 def test_create_train_X_y_output_when_y_is_series_10_steps_1_and_exog_is_series_of_float_int(dtype):
     """
@@ -193,27 +205,28 @@
                              [6., 5., 4., 3., 2., 107.],
                              [7., 6., 5., 4., 3., 108.],
                              [8., 7., 6., 5., 4., 109.]]),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 
                        'exog_step_1']
         ).astype({'exog_step_1': dtype}),
-        pd.DataFrame(
-            data = np.array([[5.],
-                             [6.],
-                             [7.],
-                             [8.],
-                             [9.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['y_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("dtype", 
                          [float, int], 
                          ids = lambda dt : f'dtype: {dt}')
 def test_create_train_X_y_output_when_y_is_series_10_steps_2_and_exog_is_series_of_float_int(dtype):
     """
@@ -230,26 +243,33 @@
                              [5., 4., 3., 2., 1., 106., 107.],
                              [6., 5., 4., 3., 2., 107., 108.],
                              [7., 6., 5., 4., 3., 108., 109.]], dtype=float),
             index   = pd.RangeIndex(start=6, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 
                        'exog_step_1', 'exog_step_2']
         ).astype({'exog_step_1': dtype, 'exog_step_2': dtype}),
-        pd.DataFrame(
-            data = np.array([[5., 6.],
-                             [6., 7.],
-                             [7., 8.],
-                             [8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=6, stop=10, step=1),
-            columns = ['y_step_1', 'y_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=9, step=1),
+                name  = "y_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=10, step=1),
+                name  = "y_step_2"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("dtype", 
                          [float, int], 
                          ids = lambda dt : f'dtype: {dt}')
 def test_create_train_X_y_output_when_y_is_series_10_steps_1_and_exog_is_dataframe_of_float_int(dtype):
     """
@@ -270,27 +290,28 @@
                              [6., 5., 4., 3., 2., 107., 1007.],
                              [7., 6., 5., 4., 3., 108., 1008.],
                              [8., 7., 6., 5., 4., 109., 1009.]], dtype=float),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 
                        'exog_1_step_1', 'exog_2_step_1']
         ).astype({'exog_1_step_1': dtype, 'exog_2_step_1': dtype}),
-        pd.DataFrame(
-            data = np.array([[5.],
-                             [6.],
-                             [7.],
-                             [8.],
-                             [9.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['y_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("dtype", 
                          [float, int], 
                          ids = lambda dt : f'dtype: {dt}')
 def test_create_train_X_y_output_when_y_is_series_10_steps_3_and_exog_is_dataframe_of_float_int(dtype):
     """
@@ -314,25 +335,38 @@
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 
                        'exog_1_step_1', 'exog_2_step_1', 
                        'exog_1_step_2', 'exog_2_step_2', 
                        'exog_1_step_3', 'exog_2_step_3']
         ).astype({'exog_1_step_1': dtype, 'exog_2_step_1': dtype, 
                   'exog_1_step_2': dtype, 'exog_2_step_2': dtype, 
                   'exog_1_step_3': dtype, 'exog_2_step_3': dtype}),
-        pd.DataFrame(
-            data = np.array([[5., 6., 7.],
-                             [6., 7., 8.],
-                             [7., 8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=7, stop=10, step=1),
-            columns = ['y_step_1', 'y_step_2', 'y_step_3']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=8, step=1),
+                name  = "y_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=9, step=1),
+                name  = "y_step_2"
+            ),
+         3: pd.Series(
+                data  = np.array([7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=7, stop=10, step=1),
+                name  = "y_step_3"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("exog_values, dtype", 
                          [([True]    , bool), 
                           (['string'], str)], 
                          ids = lambda dt : f'values, dtype: {dt}')
 def test_create_train_X_y_output_when_y_is_series_10_steps_1_and_exog_is_series_of_bool_str(exog_values, dtype):
@@ -352,27 +386,28 @@
                              [5., 4., 3., 2., 1.],
                              [6., 5., 4., 3., 2.],
                              [7., 6., 5., 4., 3.],
                              [8., 7., 6., 5., 4.]], dtype=float),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']
         ).assign(exog_step_1=exog_values*5).astype({'exog_step_1': dtype}),
-        pd.DataFrame(
-            data = np.array([[5.],
-                             [6.],
-                             [7.],
-                             [8.],
-                             [9.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['y_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("exog_values, dtype", 
                          [([True]    , bool), 
                           (['string'], str)], 
                          ids = lambda dt : f'values, dtype: {dt}')
 def test_create_train_X_y_output_when_y_is_series_10_steps_2_and_exog_is_series_of_bool_str(exog_values, dtype):
@@ -393,26 +428,33 @@
                              [6., 5., 4., 3., 2.],
                              [7., 6., 5., 4., 3.]], dtype=float),
             index   = pd.RangeIndex(start=6, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']
         ).assign(exog_step_1=exog_values*4,
                  exog_step_2=exog_values*4).astype({'exog_step_1': dtype, 
                                                     'exog_step_2': dtype}),
-        pd.DataFrame(
-            data = np.array([[5., 6.],
-                             [6., 7.],
-                             [7., 8.],
-                             [8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=6, stop=10, step=1),
-            columns = ['y_step_1', 'y_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=9, step=1),
+                name  = "y_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=10, step=1),
+                name  = "y_step_2"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("v_exog_1   , v_exog_2  , dtype", 
                          [([True]    , [False]   , bool), 
                           (['string'], ['string'], str)], 
                          ids = lambda dt : f'values, dtype: {dt}')
 def test_create_train_X_y_output_when_y_is_series_10_steps_1_and_exog_is_dataframe_of_bool_str(v_exog_1, v_exog_2, dtype):
@@ -435,27 +477,28 @@
                              [7., 6., 5., 4., 3.],
                              [8., 7., 6., 5., 4.]]),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']
         ).assign(exog_1_step_1=v_exog_1*5,
                  exog_2_step_1=v_exog_2*5).astype({'exog_1_step_1': dtype, 
                                                    'exog_2_step_1': dtype}),
-        pd.DataFrame(
-            data = np.array([[5.],
-                             [6.],
-                             [7.],
-                             [8.],
-                             [9.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['y_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("v_exog_1   , v_exog_2  , dtype", 
                          [([True]    , [False]   , bool), 
                           (['string'], ['string'], str)], 
                          ids = lambda dt : f'values, dtype: {dt}')
 def test_create_train_X_y_output_when_y_is_series_10_steps_3_and_exog_is_dataframe_of_bool_str(v_exog_1, v_exog_2, dtype):
@@ -487,25 +530,38 @@
         ).astype({'exog_1_step_1': dtype, 
                   'exog_2_step_1': dtype, 
                   'exog_1_step_2': dtype, 
                   'exog_2_step_2': dtype, 
                   'exog_1_step_3': dtype,
                   'exog_2_step_3': dtype}
         ),
-        pd.DataFrame(
-            data = np.array([[5., 6., 7.],
-                             [6., 7., 8.],
-                             [7., 8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=7, stop=10, step=1),
-            columns = ['y_step_1', 'y_step_2', 'y_step_3']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=8, step=1),
+                name  = "y_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=9, step=1),
+                name  = "y_step_2"
+            ),
+         3: pd.Series(
+                data  = np.array([7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=7, stop=10, step=1),
+                name  = "y_step_3"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
     
 
 def test_create_train_X_y_output_when_y_is_series_10_steps_1_and_exog_is_series_of_category():
     """
     Test the output of create_train_X_y when y=pd.Series(np.arange(10)), steps=1 
     and exog is a pandas Series of category.
     """
@@ -521,27 +577,28 @@
                              [5., 4., 3., 2., 1.],
                              [6., 5., 4., 3., 2.],
                              [7., 6., 5., 4., 3.],
                              [8., 7., 6., 5., 4.]]),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']
         ).assign(exog_step_1=pd.Categorical(range(5, 10), categories=range(10))),
-        pd.DataFrame(
-            data = np.array([[5.],
-                             [6.],
-                             [7.],
-                             [8.],
-                             [9.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['y_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_y_is_series_10_steps_2_and_exog_is_series_of_category():
     """
     Test the output of create_train_X_y when y=pd.Series(np.arange(10)), steps=2 
     and exog is a pandas Series of category.
     """
@@ -557,26 +614,33 @@
                              [5., 4., 3., 2., 1.],
                              [6., 5., 4., 3., 2.],
                              [7., 6., 5., 4., 3.]]),
             index   = pd.RangeIndex(start=6, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']
         ).assign(exog_step_1=pd.Categorical(range(5, 9), categories=range(10)),
                  exog_step_2=pd.Categorical(range(6, 10), categories=range(10))),
-        pd.DataFrame(
-            data = np.array([[5., 6.],
-                             [6., 7.],
-                             [7., 8.],
-                             [8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=6, stop=10, step=1),
-            columns = ['y_step_1', 'y_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=9, step=1),
+                name  = "y_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=10, step=1),
+                name  = "y_step_2"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_y_is_series_10_steps_1_and_exog_is_dataframe_of_category():
     """
     Test the output of create_train_X_y when y=pd.Series(np.arange(10)), steps=1 
     and exog is a pandas DataFrame of category.
     """
@@ -596,27 +660,28 @@
                              [8., 7., 6., 5., 4.]]),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']
         ).assign(
             exog_1_step_1=pd.Categorical(range(5, 10), categories=range(10)),
             exog_2_step_1=pd.Categorical(range(105, 110), categories=range(100, 110))
         ),
-        pd.DataFrame(
-            data = np.array([[5.],
-                             [6.],
-                             [7.],
-                             [8.],
-                             [9.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['y_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_y_is_series_10_steps_3_and_exog_is_dataframe_of_category():
     """
     Test the output of create_train_X_y when y=pd.Series(np.arange(10)), steps=3 
     and exog is a pandas DataFrame of category.
     """
@@ -639,25 +704,38 @@
             exog_1_step_1=pd.Categorical(range(5, 8), categories=range(10)),
             exog_2_step_1=pd.Categorical(range(105, 108), categories=range(100, 110)),
             exog_1_step_2=pd.Categorical(range(6, 9), categories=range(10)),
             exog_2_step_2=pd.Categorical(range(106, 109), categories=range(100, 110)),
             exog_1_step_3=pd.Categorical(range(7, 10), categories=range(10)),
             exog_2_step_3=pd.Categorical(range(107, 110), categories=range(100, 110))
         ),
-        pd.DataFrame(
-            data = np.array([[5., 6., 7.],
-                             [6., 7., 8.],
-                             [7., 8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=7, stop=10, step=1),
-            columns = ['y_step_1', 'y_step_2', 'y_step_3']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=8, step=1),
+                name  = "y_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=9, step=1),
+                name  = "y_step_2"
+            ),
+         3: pd.Series(
+                data  = np.array([7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=7, stop=10, step=1),
+                name  = "y_step_3"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_y_is_series_10_and_exog_is_dataframe_of_float_int_category_steps_1():
     """
     Test the output of create_train_X_y when y=pd.Series(np.arange(10)), steps=1 
     and exog is a pandas DataFrame of float, int and category.
     """
@@ -675,24 +753,30 @@
                              [6., 5., 4., 3., 2., 107., 1007.],
                              [7., 6., 5., 4., 3., 108., 1008.],
                              [8., 7., 6., 5., 4., 109., 1009.]]),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 
                        'exog_1_step_1', 'exog_2_step_1']
         ).astype({'exog_1_step_1': float, 
-                  'exog_2_step_1': int}).assign(exog_3_step_1=pd.Categorical(range(105, 110), categories=range(100, 110))),
-        pd.DataFrame(
-            data    = np.array([5, 6, 7, 8, 9], dtype=float),
-            index   = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['y_step_1']
-        )
+                  'exog_2_step_1': int}).assign(exog_3_step_1=pd.Categorical(range(105, 110), categories=range(100, 110))
+        ),
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_y_is_series_10_and_exog_is_dataframe_of_float_int_category_steps_3():
     """
     Test the output of create_train_X_y when y=pd.Series(np.arange(10)), steps=3 
     and exog is a pandas DataFrame of float, int and category.
     """
@@ -717,25 +801,38 @@
         ).astype({'exog_1_step_1': float, 'exog_2_step_1': int,
                   'exog_1_step_2': float, 'exog_2_step_2': int,
                   'exog_1_step_3': float, 'exog_2_step_3': int}
         ).assign(exog_3_step_1=pd.Categorical(range(105, 108), categories=range(100, 110)),
                  exog_3_step_2=pd.Categorical(range(106, 109), categories=range(100, 110)),
                  exog_3_step_3=pd.Categorical(range(107, 110), categories=range(100, 110))
         ),
-        pd.DataFrame(
-            data = np.array([[5., 6., 7.],
-                             [6., 7., 8.],
-                             [7., 8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=7, stop=10, step=1),
-            columns = ['y_step_1', 'y_step_2', 'y_step_3']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=8, step=1),
+                name  = "y_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=9, step=1),
+                name  = "y_step_2"
+            ),
+         3: pd.Series(
+                data  = np.array([7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=7, stop=10, step=1),
+                name  = "y_step_3"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_y_is_series_10_and_transformer_y_is_StandardScaler():
     """
     Test the output of create_train_X_y when exog is None and transformer_y
     is StandardScaler with steps=1.
     """
@@ -752,27 +849,29 @@
                              [0.17407766, -0.17407766, -0.52223297, -0.87038828, -1.21854359],
                              [0.52223297,  0.17407766, -0.17407766, -0.52223297, -0.87038828],
                              [0.87038828,  0.52223297,  0.17407766, -0.17407766, -0.52223297],
                              [1.21854359,  0.87038828,  0.52223297,  0.17407766, -0.17407766]]),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']
         ),
-        pd.DataFrame(
-            data  = np.array([[0.17407766], 
-                              [0.52223297], 
-                              [0.87038828], 
-                              [1.21854359], 
-                              [1.5666989]]),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns  = ['y_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([0.17407766, 0.52223297, 0.87038828, 
+                                  1.21854359, 1.5666989]), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_lags_3_steps_1_and_exog_is_None_and_transformer_exog_is_not_None():
     """
     Test output of create_train_X_y when regressor is LinearRegression, lags is 3
     and steps is 1 and transformer_exog is not None.
     """
@@ -795,22 +894,28 @@
                              [5., 4., 3.],
                              [6., 5., 4.],
                              [7., 6., 5.],
                              [8., 7., 6.]], dtype=float),
             index   = pd.RangeIndex(start=3, stop=10, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3']
         ),
-        pd.DataFrame(
-            np.array([3., 4., 5., 6., 7., 8., 9.], dtype=float),
-            index = pd.RangeIndex(start=3, stop=10, step=1),
-            columns = ['y_step_1'])
+        {1: pd.Series(
+                data  = np.array([3., 4., 5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=3, stop=10, step=1),
+                name  = "y_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_transformer_y_and_transformer_exog_steps_2():
     """
     Test the output of create_train_X_y when using transformer_y and transformer_exog 
     with steps=2.
     """
@@ -850,19 +955,26 @@
                              [0.87038828,  0.52223297,  0.17407766, -0.17407766, -0.52223297,
                               1.88177028,  1. ,  0. ,  0.13801109,  0. , 1. ]]),
             index   = pd.date_range("1990-01-07", periods=4, freq='D'),
             columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'col_1_step_1',
                        'col_2_a_step_1', 'col_2_b_step_1', 'col_1_step_2', 'col_2_a_step_2',
                        'col_2_b_step_2']
         ),
-        pd.DataFrame(
-            data  = np.array([[0.17407766, 0.52223297],
-                              [0.52223297, 0.87038828],
-                              [0.87038828, 1.21854359],
-                              [1.21854359, 1.5666989 ]]),
-            index = pd.date_range("1990-01-07", periods=4, freq='D'),
-            columns = ['y_step_1', 'y_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array([0.17407766, 0.52223297, 0.87038828, 1.21854359]), 
+                index = pd.date_range("1990-01-06", periods=4, freq='D'),
+                name  = "y_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([0.52223297, 0.87038828, 1.21854359, 1.5666989]), 
+                index = pd.date_range("1990-01-07", periods=4, freq='D'),
+                name  = "y_step_2"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key])
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_filter_train_X_y_for_step.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_filter_train_X_y_for_step.py`

 * *Files 3% similar despite different names*

```diff
@@ -41,20 +41,20 @@
         pd.DataFrame(
             data = np.array([[2., 1., 0.],
                              [3., 2., 1.],
                              [4., 3., 2.],
                              [5., 4., 3.],
                              [6., 5., 4.],
                              [7., 6., 5.]], dtype=float),
-            index   = pd.RangeIndex(start=4, stop=10, step=1),
+            index   = pd.RangeIndex(start=3, stop=9, step=1),
             columns = ['lag_1', 'lag_2', 'lag_3']
         ),
         pd.Series(
             data  = np.array([3., 4., 5., 6., 7., 8.], dtype=float),
-            index = pd.RangeIndex(start=4, stop=10, step=1),
+            index = pd.RangeIndex(start=3, stop=9, step=1),
             name  = 'y_step_1'
         )
     )  
  
     pd.testing.assert_frame_equal(results[0], expected[0])
     pd.testing.assert_series_equal(results[1], expected[1])
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_fit.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_fit.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 # Unit test fit ForecasterAutoregDirect
 # ==============================================================================
-from pytest import approx
+import re
+import pytest
 import numpy as np
 import pandas as pd
 from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect
 from sklearn.linear_model import LinearRegression
 from xgboost import XGBRegressor
 
 
@@ -32,75 +33,84 @@
     forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2)
     forecaster.fit(y=y)
     expected = y.index.step
     results = forecaster.index_freq
 
     assert results == expected
     
-    
-def test_fit_in_sample_residuals_stored():
+
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_fit_in_sample_residuals_stored(n_jobs):
     """
     Test that values of in_sample_residuals are stored after fitting.
     """
-    forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2)
+    forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2, n_jobs=n_jobs)
     forecaster.fit(y=pd.Series(np.arange(5)))
     expected = {1: np.array([0.]),
                 2: np.array([0.])}
     results = forecaster.in_sample_residuals
 
     assert isinstance(results, dict)
     assert all(isinstance(x, np.ndarray) for x in results.values())
     assert results.keys() == expected.keys()
     assert all(all(np.isclose(results[k], expected[k])) for k in expected.keys())
 
 
-def test_fit_in_sample_residuals_stored_XGBRegressor():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_fit_in_sample_residuals_stored_XGBRegressor(n_jobs):
     """
     Test that values of in_sample_residuals are stored after fitting with XGBRegressor.
     """
-    forecaster = ForecasterAutoregDirect(XGBRegressor(random_state=123), lags=3, steps=2)
+    forecaster = ForecasterAutoregDirect(XGBRegressor(random_state=123), lags=3, steps=2, n_jobs=n_jobs)
     forecaster.fit(y=pd.Series(np.arange(5)))
     expected = {1: np.array([7.15255737e-07]),
                 2: np.array([7.15255737e-07])}
     results = forecaster.in_sample_residuals
 
     assert isinstance(results, dict)
     assert all(isinstance(x, np.ndarray) for x in results.values())
     assert results.keys() == expected.keys()
     assert all(all(np.isclose(results[k], expected[k])) for k in expected.keys())
 
 
-def test_fit_same_residuals_when_residuals_greater_than_1000():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_fit_same_residuals_when_residuals_greater_than_1000(n_jobs):
     """
     Test fit return same residuals when residuals len is greater than 1000.
     Testing with two different forecaster.
     """
-    forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2)
+    forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2, n_jobs=n_jobs)
     forecaster.fit(y=pd.Series(np.arange(1200)))
     results_1 = forecaster.in_sample_residuals
-    forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2)
+
+    forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2, n_jobs=n_jobs)
     forecaster.fit(y=pd.Series(np.arange(1200)))
     results_2 = forecaster.in_sample_residuals
 
     assert isinstance(results_1, dict)
     assert all(isinstance(x, np.ndarray) for x in results_1.values())
     assert isinstance(results_2, dict)
     assert all(isinstance(x, np.ndarray) for x in results_2.values())
     assert results_1.keys() == results_2.keys()
     assert all(len(results_1[k] == 1000) for k in results_1.keys())
     assert all(len(results_2[k] == 1000) for k in results_2.keys())
     assert all(all(results_1[k] == results_2[k]) for k in results_2.keys())
 
 
-def test_fit_in_sample_residuals_not_stored():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_fit_in_sample_residuals_not_stored(n_jobs):
     """
     Test that values of in_sample_residuals are not stored after fitting
     when `store_in_sample_residuals=False`.
     """
-    forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2)
+    forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2, n_jobs=n_jobs)
     forecaster.fit(y=pd.Series(np.arange(5)), store_in_sample_residuals=False)
     expected = {1: None, 2: None}
     results = forecaster.in_sample_residuals
 
     assert isinstance(results, dict)
     assert results.keys() == expected.keys()
     assert all(results[k] == expected[k] for k in expected.keys())
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_get_feature_importances.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_get_feature_importances.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_init.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_init.py`

 * *Files 21% similar despite different names*

```diff
@@ -2,31 +2,42 @@
 # ==============================================================================
 import re
 import pytest
 import numpy as np
 import pandas as pd
 from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect
 from sklearn.linear_model import LinearRegression
-from sklearn.neighbors import KNeighborsRegressor
 
 
-def test_init_exception_when_steps_is_not_int():
+def test_init_TypeError_when_steps_is_not_int():
     """
-    Test exception is raised when steps is not an int.
+    Test TypeError is raised when steps is not an int.
     """
     steps = 'not_valid_type'
     err_msg = re.escape(
                 f"`steps` argument must be an int greater than or equal to 1. "
                 f"Got {type(steps)}."
             )
     with pytest.raises(TypeError, match = err_msg):
         ForecasterAutoregDirect(LinearRegression(), lags=2, steps=steps)
 
 
-def test_init_exception_when_steps_is_less_than_1():
+def test_init_ValueError_when_steps_is_less_than_1():
     """
-    Test exception is raised when steps is less than 1.
+    Test ValueError is raised when steps is less than 1.
     """
     steps = 0
     err_msg = re.escape(f"`steps` argument must be greater than or equal to 1. Got {steps}.")
     with pytest.raises(ValueError, match = err_msg):
-        ForecasterAutoregDirect(LinearRegression(), lags=2, steps=steps)
+        ForecasterAutoregDirect(LinearRegression(), lags=2, steps=steps)
+
+
+@pytest.mark.parametrize("n_jobs", 
+                         [1.0, 'not_int_auto'], 
+                         ids = lambda value : f'n_jobs: {value}')
+def test_init_TypeError_when_n_jobs_not_int_or_auto(n_jobs):
+    """
+    Test TypeError is raised in when n_jobs is not an integer or 'auto'.
+    """
+    err_msg = re.escape(f"`n_jobs` must be an integer or `'auto'`. Got {type(n_jobs)}.")
+    with pytest.raises(TypeError, match = err_msg):
+        ForecasterAutoregDirect(LinearRegression(), lags=2, steps=2, n_jobs=n_jobs)
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_predict.py`

 * *Files 1% similar despite different names*

```diff
@@ -134,15 +134,17 @@
                    index = pd.RangeIndex(start=20, stop=25, step=1),
                    name  = 'pred'
                )
     
     pd.testing.assert_series_equal(predictions, expected)
 
 
-def test_predict_output_when_regressor_is_LinearRegression_with_transform_y_and_transform_exog():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_predict_output_when_regressor_is_LinearRegression_with_transform_y_and_transform_exog(n_jobs):
     """
     Test predict output when using LinearRegression as regressor, StandardScaler
     as transformer_y and transformer_exog as transformer_exog.
     """
     y = pd.Series(
             np.array([-0.59,  0.02, -0.9 ,  1.09, -3.61,  0.72, -0.11, -0.4 ,  0.49,
                        0.67,  0.54, -0.17,  0.54,  1.49, -2.26, -0.41, -0.64, -0.8 ,
@@ -165,14 +167,15 @@
                        )
     forecaster = ForecasterAutoregDirect(
                      regressor = LinearRegression(),
                      lags = 5,
                      steps = 5,
                      transformer_y = transformer_y,
                      transformer_exog = transformer_exog,
+                     n_jobs = n_jobs
                  )
     forecaster.fit(y=y, exog=exog)
     predictions = forecaster.predict(steps=[1, 2, 3, 4, 5], exog=exog_predict)
     expected = pd.Series(
                    data  = np.array([1.10855119, -0.83442443, 0.9434436 , 0.6676508 , 0.58666266]),
                    index = pd.RangeIndex(start=20, stop=25, step=1),
                    name  = 'pred'
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_predict_bootstrapping.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_predict_bootstrapping.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,34 +20,34 @@
     residuals for some step.
     """
     forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2)
     forecaster.fit(y=pd.Series(np.arange(10)))
     forecaster.in_sample_residuals = {2: np.array([1, 2, 3])}
 
     err_msg = re.escape(
-                (f'Not `forecaster.in_sample_residuals` for steps: '
-                 f'{set([1, 2]) - set(forecaster.in_sample_residuals.keys())}.')
-                )
+                (f"Not `forecaster.in_sample_residuals` for steps: "
+                 f"{set([1, 2]) - set(forecaster.in_sample_residuals.keys())}.")
+              )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=None, in_sample_residuals=True)
 
 
 def test_predict_bootstrapping_ValueError_when_out_sample_residuals_is_None():
     """
     Test ValueError is raised when in_sample_residuals=False and
     forecaster.out_sample_residuals is None.
     """
     forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=2)
     forecaster.fit(y=pd.Series(np.arange(10)))
 
     err_msg = re.escape(
-                ('`forecaster.out_sample_residuals` is `None`. Use '
-                 '`in_sample_residuals=True` or method `set_out_sample_residuals()` '
-                 'before `predict_interval()`, `predict_bootstrapping()` or '
-                 '`predict_dist()`.')
+                ("`forecaster.out_sample_residuals` is `None`. Use "
+                 "`in_sample_residuals=True` or method `set_out_sample_residuals()` "
+                 "before `predict_interval()`, `predict_bootstrapping()` or "
+                 "`predict_dist()`.")
               )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=1, in_sample_residuals=False)
 
 
 def test_predict_bootstrapping_ValueError_when_not_out_sample_residuals_for_all_steps_predicted():
     """
@@ -57,17 +57,17 @@
     forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=3)
     forecaster.fit(y=pd.Series(np.arange(15)))
     residuals = {2: np.array([1, 2, 3, 4, 5]), 
                  3: np.array([1, 2, 3, 4, 5])}
     forecaster.out_sample_residuals = residuals
 
     err_msg = re.escape(
-                    (f'Not `forecaster.out_sample_residuals` for steps: '
-                     f'{set([1, 2]) - set(forecaster.out_sample_residuals.keys())}. '
-                     f'Use method `set_out_sample_residuals()`.')
+                    (f"Not `forecaster.out_sample_residuals` for steps: "
+                     f"{set([1, 2]) - set(forecaster.out_sample_residuals.keys())}. "
+                     f"Use method `set_out_sample_residuals()`.")
                 )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=[1, 2], in_sample_residuals=False)
 
 
 def test_predict_bootstrapping_ValueError_when_step_out_sample_residuals_value_is_None():
     """
@@ -77,16 +77,16 @@
     forecaster = ForecasterAutoregDirect(LinearRegression(), lags=3, steps=3)
     forecaster.fit(y=pd.Series(np.arange(15)))
     residuals = {1: np.array([1, 2, 3, 4, 5]),
                  2: np.array([1, 2, 3, 4, 5])}
     forecaster.set_out_sample_residuals(residuals = residuals)
 
     err_msg = re.escape(
-                    (f"forecaster residuals for step 3 are `None`. Check forecaster.out_sample_residuals.")
-                )
+                ("forecaster residuals for step 3 are `None`. Check forecaster.out_sample_residuals.")
+            )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=3, in_sample_residuals=False)
 
 
 def test_predict_bootstrapping_ValueError_when_step_out_sample_residuals_value_contains_None():
     """
     Test ValueError is raised when in_sample_residuals=False and
@@ -96,15 +96,15 @@
     forecaster.fit(y=pd.Series(np.arange(15)))
     residuals = {1: np.array([1, 2, 3, 4, 5]),
                  2: np.array([1, 2, 3, 4, 5]), 
                  3: np.array([1, 2, 3, 4, None])}
     forecaster.set_out_sample_residuals(residuals = residuals)
 
     err_msg = re.escape(
-                    (f"forecaster residuals for step 3 contains `None` values. Check forecaster.out_sample_residuals.")
+                    ("forecaster residuals for step 3 contains `None` values. Check forecaster.out_sample_residuals.")
                 )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=3, in_sample_residuals=False)
 
 
 @pytest.mark.parametrize("steps", [2, [1, 2], None], 
                          ids=lambda steps: f'steps: {steps}')
@@ -120,19 +120,19 @@
                      lags             = 3,
                      transformer_y    = StandardScaler(),
                      transformer_exog = StandardScaler(),
                  )
     forecaster.fit(y=y, exog=exog)
     results = forecaster.predict_bootstrapping(steps=steps, exog=exog_predict, n_boot=4, in_sample_residuals=True)
     expected = pd.DataFrame(
-                    data = np.array([[0.73195423, 0.6896871 , 0.20248689, 0.54685553],
-                                     [0.13621074, 0.29541489, 0.51606685, 0.3341628 ]]),
-                    columns = [f"pred_boot_{i}" for i in range(4)],
-                    index   = pd.RangeIndex(start=50, stop=52)
-                )
+                   data = np.array([[0.73195423, 0.6896871 , 0.20248689, 0.54685553],
+                                    [0.58019048, 0.25711887, 0.35256064, 0.82034106]]),
+                   columns = [f"pred_boot_{i}" for i in range(4)],
+                   index   = pd.RangeIndex(start=50, stop=52)
+               )
     
     pd.testing.assert_frame_equal(expected, results)
 
 
 def test_predict_bootstrapping_output_when_forecaster_is_LinearRegression_steps_is_2_in_sample_residuals_False_exog_and_transformer():
     """
     Test output of predict_bootstrapping when regressor is LinearRegression,
@@ -146,19 +146,19 @@
                      transformer_y    = StandardScaler(),
                      transformer_exog = StandardScaler(),
                  )
     forecaster.fit(y=y, exog=exog)
     forecaster.out_sample_residuals = forecaster.in_sample_residuals
     results = forecaster.predict_bootstrapping(steps=2, exog=exog_predict, n_boot=4, in_sample_residuals=False)
     expected = pd.DataFrame(
-                    data = np.array([[0.73195423, 0.6896871 , 0.20248689, 0.54685553],
-                                     [0.13621074, 0.29541489, 0.51606685, 0.3341628 ]]),
-                    columns = [f"pred_boot_{i}" for i in range(4)],
-                    index   = pd.RangeIndex(start=50, stop=52)
-                )
+                   data = np.array([[0.73195423, 0.6896871 , 0.20248689, 0.54685553],
+                                    [0.58019048, 0.25711887, 0.35256064, 0.82034106]]),
+                   columns = [f"pred_boot_{i}" for i in range(4)],
+                   index   = pd.RangeIndex(start=50, stop=52)
+               )
     
     pd.testing.assert_frame_equal(expected, results)
 
 
 def test_predict_bootstrapping_output_when_forecaster_is_LinearRegression_steps_is_2_in_sample_residuals_fixed():
     """
     Test output of predict_bootstrapping when regressor is LinearRegression,
@@ -170,14 +170,14 @@
                      lags      = 3
                  )
     forecaster.fit(y=y, exog=exog)
     forecaster.in_sample_residuals = {1: pd.Series([1, 1, 1, 1, 1, 1, 1]),
                                       2: pd.Series([5, 5, 5, 5, 5, 5, 5])}
     results = forecaster.predict_bootstrapping(steps=2, exog=exog_predict, n_boot=4, in_sample_residuals=True)
     expected = pd.DataFrame(
-                    data = np.array([[1.67523588, 1.67523588, 1.67523588, 1.67523588],
-                                     [5.38024988, 5.38024988, 5.38024988, 5.38024988]]),
-                    columns = [f"pred_boot_{i}" for i in range(4)],
-                    index   = pd.RangeIndex(start=50, stop=52)
-                )
+                   data = np.array([[1.67523588, 1.67523588, 1.67523588, 1.67523588],
+                                    [5.38024988, 5.38024988, 5.38024988, 5.38024988]]),
+                   columns = [f"pred_boot_{i}" for i in range(4)],
+                   index   = pd.RangeIndex(start=50, stop=52)
+               )
     
     pd.testing.assert_frame_equal(expected, results)
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_predict_dist.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_predict_dist.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,15 +15,14 @@
 
 def test_predict_dist_output_when_forecaster_is_LinearRegression_steps_is_2_in_sample_residuals_True_exog_and_transformer():
     """
     Test output of predict_dist when regressor is LinearRegression,
     2 steps are predicted, using in-sample residuals, exog is included and both
     inputs are transformed.
     """
-
     forecaster = ForecasterAutoregDirect(
                      regressor        = LinearRegression(),
                      steps            = 2,
                      lags             = 3,
                      transformer_y    = StandardScaler(),
                      transformer_exog = StandardScaler(),
                  )
@@ -33,29 +32,28 @@
                   exog                = exog_predict,
                   distribution        = norm,
                   n_boot              = 4,
                   in_sample_residuals = True
               )
     expected = pd.DataFrame(
                    data    = np.array([[0.54274594, 0.20807726],
-                                       [0.32046382, 0.13511556]]),
+                                       [0.50255276, 0.21780292]]),
                    columns = ['loc', 'scale'],
                    index   = pd.RangeIndex(start=50, stop=52)
                )
     
     pd.testing.assert_frame_equal(expected, results)
 
 
 def test_predict_dist_output_when_forecaster_is_LinearRegression_steps_is_2_in_sample_residuals_False_exog_and_transformer():
     """
     Test output of predict_dist when regressor is LinearRegression,
     2 steps are predicted, using out-sample residuals, exog is included and both
     inputs are transformed.
     """
-
     forecaster = ForecasterAutoregDirect(
                      regressor        = LinearRegression(),
                      steps            = 2,
                      lags             = 3,
                      transformer_y    = StandardScaler(),
                      transformer_exog = StandardScaler(),
                  )
@@ -66,13 +64,13 @@
                   exog                = exog_predict,
                   distribution        = norm,
                   n_boot              = 4,
                   in_sample_residuals = False
               )
     expected = pd.DataFrame(
                    data    = np.array([[0.54274594, 0.20807726],
-                                       [0.32046382, 0.13511556]]),
+                                       [0.50255276, 0.21780292]]),
                    columns = ['loc', 'scale'],
                    index   = pd.RangeIndex(start=50, stop=52)
                )
 
     pd.testing.assert_frame_equal(expected, results)
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_predict_interval.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_predict_interval.py`

 * *Files 7% similar despite different names*

```diff
@@ -31,15 +31,15 @@
                   steps               = 2,
                   exog                = exog_predict,
                   n_boot              = 4,
                   in_sample_residuals = True
               )
     expected = pd.DataFrame(
                    data    = np.array([[0.67523588, 0.25414219, 0.72561416],
-                                       [0.38024988, 0.16009136, 0.48878124]]),
+                                       [0.38024988, 0.27143513, 0.78431847]]),
                    columns = ['pred', 'lower_bound', 'upper_bound'],
                    index   = pd.RangeIndex(start=50, stop=52)
                )
     
     pd.testing.assert_frame_equal(expected, results)
 
 
@@ -63,13 +63,13 @@
                   steps               = 2,
                   exog                = exog_predict,
                   n_boot              = 4,
                   in_sample_residuals = False
               )
     expected = pd.DataFrame(
                    data    = np.array([[0.67523588, 0.25414219, 0.72561416],
-                                       [0.38024988, 0.16009136, 0.48878124]]),
+                                       [0.38024988, 0.27143513, 0.78431847]]),
                    columns = ['pred', 'lower_bound', 'upper_bound'],
                    index   = pd.RangeIndex(start=50, stop=52)
                )
 
     pd.testing.assert_frame_equal(expected, results)
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_set_fit_kwargs.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_set_fit_kwargs.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_set_lags.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_set_lags.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_set_out_sample_residuals.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_set_out_sample_residuals.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregDirect/tests/test_set_params.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregDirect/tests/test_set_params.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 ################################################################################
 #                        ForecasterAutoregMultiSeries                          #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
-from typing import Union, Dict, List, Tuple, Any, Optional, Callable
+from typing import Union, Tuple, Optional, Callable
 import warnings
 import logging
 import sys
 import numpy as np
 import pandas as pd
 import sklearn
 import sklearn.pipeline
@@ -20,15 +20,14 @@
 
 import skforecast
 from ..ForecasterBase import ForecasterBase
 from ..exceptions import IgnoredArgumentWarning
 from ..utils import initialize_lags
 from ..utils import initialize_weights
 from ..utils import check_select_fit_kwargs
-from ..utils import check_y
 from ..utils import check_exog
 from ..utils import get_exog_dtypes
 from ..utils import check_exog_dtypes
 from ..utils import check_interval
 from ..utils import check_predict_input
 from ..utils import preprocess_y
 from ..utils import preprocess_last_window
@@ -47,212 +46,178 @@
     This class turns any regressor compatible with the scikit-learn API into a
     recursive autoregressive (multi-step) forecaster for multiple series.
     
     Parameters
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
-        
     lags : int, list, numpy ndarray, range
-        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
-            `int`: include lags from 1 to `lags` (included).
-            `list`, `numpy ndarray` or `range`: include only lags present in `lags`,
-            all elements must be int.
-
-    transformer_series : transformer (preprocessor) or dict of transformers, default `None`
-        An instance of a transformer (preprocessor) compatible with the scikit-learn
-        preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
-        If a single transformer is passed, it is cloned and applied to all series. If a
-        dict, a different transformer can be used for each series. Transformation is
-        applied to each `series` before training the forecaster.
-        ColumnTransformers are not allowed since they do not have inverse_transform method.
+        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1. 
     
+            - `int`: include lags from 1 to `lags` (included).
+            - `list`, `1d numpy ndarray` or `range`: include only lags present in 
+            `lags`, all elements must be int.
+    transformer_series : transformer (preprocessor), dict, default `None`
+        An instance of a transformer (preprocessor) compatible with the scikit-learn
+        preprocessing API with methods: fit, transform, fit_transform and 
+        inverse_transform. Transformation is applied to each `series` before training 
+        the forecaster. ColumnTransformers are not allowed since they do not have 
+        inverse_transform method.
+
+            - If single transformer: it is cloned and applied to all series. 
+            - If `dict` of transformers: a different transformer can be used for each 
+            series.
     transformer_exog : transformer, default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
     weight_func : Callable, dict, default `None`
         Function that defines the individual weights for each sample based on the
-        index. For example, a function that assigns a lower weight to certain dates.
-        If dict {'series_column_name' : Callable} a different function can be
-        used for each series, a weight of 1 is given to all series not present
-        in `weight_func`. Ignored if `regressor` does not have the argument 
-        `sample_weight` in its `fit` method. See Notes section for more details 
-        on the use of the weights.
-        **New in version 0.6.0**
-
+        index. For example, a function that assigns a lower weight to certain dates. 
+        Ignored if `regressor` does not have the argument `sample_weight` in its 
+        `fit` method. See Notes section for more details on the use of the weights.
+
+            - If single function: it is applied to all series. 
+            - If `dict` {'series_column_name' : Callable}: a different function can be
+              used for each series, a weight of 1 is given to all series not present 
+              in `weight_func`.
     series_weights : dict, default `None`
         Weights associated with each series {'series_column_name' : float}. It is only
-        applied if the `regressor` used accepts `sample_weight` in its `fit` method.
-        If `series_weights` is provided, a weight of 1 is given to all series not present
-        in `series_weights`. If `None`, all levels have the same weight. See Notes section
-        for more details on the use of the weights.
-        **New in version 0.6.0**
+        applied if the `regressor` used accepts `sample_weight` in its `fit` method. 
+        See Notes section for more details on the use of the weights.
 
+            - If a `dict` is provided, a weight of 1 is given to all series not present
+            in `series_weights`.
+            - If `None`, all levels have the same weight.
     fit_kwargs : dict, default `None`
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
     forecaster_id : str, int, default `None`
         Name used as an identifier of the forecaster.
         **New in version 0.7.0**
 
-    
     Attributes
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
-        
     lags : numpy ndarray
         Lags used as predictors.
-
-    transformer_series : transformer (preprocessor) or dict of transformers, default `None`
+    transformer_series : transformer (preprocessor), dict
         An instance of a transformer (preprocessor) compatible with the scikit-learn
-        preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
-        If a single transformer is passed, it is cloned and applied to all series. If a
-        dict, a different transformer can be used for each series. Transformation is
-        applied to each `series` before training the forecaster.
-        ColumnTransformers are not allowed since they do not have inverse_transform method.
-        
+        preprocessing API with methods: fit, transform, fit_transform and 
+        inverse_transform. Transformation is applied to each `series` before training 
+        the forecaster. ColumnTransformers are not allowed since they do not have 
+        inverse_transform method.
+
+            - If single transformer: it is cloned and applied to all series. 
+            - If `dict` of transformers: a different transformer can be used for each 
+            series.
     transformer_series_ : dict
-        Dictionary with the transformer for each series. It is created cloning the objects
-        in `transformer_series` and is used internally to avoid overwriting.
-
-    transformer_exog : transformer (preprocessor), default `None`
+        Dictionary with the transformer for each series. It is created cloning the 
+        objects in `transformer_series` and is used internally to avoid overwriting.
+    transformer_exog : transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
-    weight_func : Callable, dict, default `None`
-        Function that defines the individual weights of each sample based on the
-        index. For example, a function that assigns a lower weight to certain dates.
-        If dict {'series_column_name': Callable} a different function can be
-        used for each series, a weight of 1 is given to all series not present
-        in `weight_func`. Ignored if `regressor` does not have the argument 
-        `sample_weight` in its `fit` method. See Notes section for more details 
-        on the use of the weights.
-        **New in version 0.6.0**
-
+    weight_func : Callable, dict
+        Function that defines the individual weights for each sample based on the
+        index. For example, a function that assigns a lower weight to certain dates. 
+        Ignored if `regressor` does not have the argument `sample_weight` in its 
+        `fit` method. See Notes section for more details on the use of the weights.
+
+            - If single function: it is applied to all series. 
+            - If `dict` {'series_column_name' : Callable}: a different function can be
+              used for each series, a weight of 1 is given to all series not present 
+              in `weight_func`.
     weight_func_ : dict
-        Dictionary with the `weight_func` for each series. It is created cloning the objects
-        in `weight_func` and is used internally to avoid overwriting.
-        **New in version 0.6.0**
-
+        Dictionary with the `weight_func` for each series. It is created cloning the 
+        objects in `weight_func` and is used internally to avoid overwriting.
     source_code_weight_func : str, dict
         Source code of the custom function(s) used to create weights.
-        **New in version 0.6.0**
-
     series_weights : dict, default `None`
-        Weights associated with each series {'series_column_name': float}. It is only
-        applied if the `regressor` used accepts `sample_weight` in its `fit` method.
-        If `series_weights` is provided, a weight of 1 is given to all series not present
-        in `series_weights`. If `None`, all levels have the same weight. See Notes section
-        for more details on the use of the weights.
-        **New in version 0.6.0**
+        Weights associated with each series {'series_column_name' : float}. It is only
+        applied if the `regressor` used accepts `sample_weight` in its `fit` method. 
+        See Notes section for more details on the use of the weights.
 
+            - If a `dict` is provided, a weight of 1 is given to all series not present
+            in `series_weights`.
+            - If `None`, all levels have the same weight.
     series_weights_ : dict
         Weights associated with each series.It is created as a clone of `series_weights`
         and is used internally to avoid overwriting.
-        **New in version 0.6.0**
-
     max_lag : int
         Maximum value of lag included in `lags`.
-        
     window_size : int
-        Size of the window needed to create the predictors. It is equal to
-        `max_lag`.
-
+        Size of the window needed to create the predictors. It is equal to `max_lag`.
     last_window : pandas Series
         Last window seen by the forecaster during training. It stores the values 
         needed to predict the next `step` immediately after the training data.
-        
     index_type : type
         Type of index of the input used in training.
-        
     index_freq : str
         Frequency of Index of the input used in training.
-
     index_values : pandas Index
         Values of Index of the input used in training.
-
     training_range: pandas Index
         First and last values of index of the data used during training.
-        
     included_exog : bool
         If the forecaster has been trained using exogenous variable/s.
-        
     exog_type : type
         Type of exogenous variable/s used in training.
-
     exog_dtypes : dict
         Type of each exogenous variable/s used in training. If `transformer_exog` 
         is used, the dtypes are calculated after the transformation.
-        
     exog_col_names : list
         Names of columns of `exog` if `exog` used in training was a pandas
         DataFrame.
-
     series_col_names : list
         Names of the series (levels) used during training.
-
     X_train_col_names : list
         Names of columns of the matrix created internally for training.
-
     fit_kwargs : dict
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-        
     in_sample_residuals : dict
         Residuals of the model when predicting training data. Only stored up to
         1000 values in the form `{level: residuals}`. If `transformer_series` 
         is not `None`, residuals are stored in the transformed scale.
-        
     out_sample_residuals : dict
         Residuals of the models when predicting non training data. Only stored
         up to 1000 values in the form `{level: residuals}`. If `transformer_series` 
         is not `None`, residuals are assumed to be in the transformed scale. Use 
         `set_out_sample_residuals()` method to set values.
-        
     fitted : bool
         Tag to identify if the regressor has been fitted (trained).
-
     creation_date : str
         Date of creation.
-
     fit_date : str
         Date of last fit.
-
     skforcast_version : str
         Version of skforecast library used to create the forecaster.
-
     python_version : str
         Version of python used to create the forecaster.
-
-    forecaster_id : str, int default `None`
+    forecaster_id : str, int
         Name used as an identifier of the forecaster.
-        **New in version 0.7.0**
-
 
     Notes
     -----
 
     The weights are used to control the influence that each observation has on the
-    training of the model. `ForecasterAutoregMultiseries` accepts two types of weights:
-
-    + series_weights : controls the relative importance of each series. If a series has
-    twice as much weight as the others, the observations of that series influence the
-    training twice as much. The higher the weight of a series relative to the others,
-    the more the model will focus on trying to learn that series.
-
-    + weight_func : controls the relative importance of each observation according to its
-    index value. For example, a function that assigns a lower weight to certain dates.
-
+    training of the model. `ForecasterAutoregMultiseries` accepts two types of weights. 
     If the two types of weights are indicated, they are multiplied to create the final
     weights. The resulting `sample_weight` cannot have negative values.
+
+    - `series_weights` : controls the relative importance of each series. If a 
+    series has twice as much weight as the others, the observations of that series 
+    influence the training twice as much. The higher the weight of a series 
+    relative to the others, the more the model will focus on trying to learn 
+    that series.
+    - `weight_func` : controls the relative importance of each observation 
+    according to its index value. For example, a function that assigns a lower 
+    weight to certain dates.
     
     """
     
     def __init__(
         self,
         regressor: object,
         lags: Union[int, np.ndarray, list],
@@ -352,44 +317,49 @@
         )
 
         return info
 
     
     def _create_lags(
         self, 
-        y: np.ndarray
+        y: np.ndarray, 
+        series_name: str
     ) -> Tuple[np.ndarray, np.ndarray]:
-        """       
+        """
         Transforms a 1d array into a 2d array (X) and a 1d array (y). Each row
         in X is associated with a value of y and it represents the lags that
         precede it.
         
         Notice that, the returned matrix X_data, contains the lag 1 in the first
         column, the lag 2 in the second column and so on.
         
         Parameters
-        ----------        
-        y : 1d numpy ndarray
-            Training time series.
+        ----------
+        y : numpy ndarray
+            1d numpy ndarray Training time series.
+        series_name : str
+            Name of the series.
 
-        Returns 
+        Returns
         -------
-        X_data : 2d numpy ndarray, shape (samples - max(self.lags), len(self.lags))
-            2d numpy array with the lagged values (predictors).
-        
-        y_data : 1d numpy ndarray, shape (samples - max(self.lags),)
-            Values of the time series related to each row of `X_data`.
+        X_data : numpy ndarray
+            2d numpy ndarray with the lagged values (predictors). 
+            Shape: (samples - max(self.lags), len(self.lags))
+        y_data : numpy ndarray
+            1d numpy ndarray with the values of the time series related to each 
+            row of `X_data`. 
+            Shape: (samples - max(self.lags), )
         
         """
           
         n_splits = len(y) - self.max_lag
         if n_splits <= 0:
             raise ValueError(
-                f"The maximum lag ({self.max_lag}) must be less than the length "
-                f"of the series ({len(y)})."
+                (f"The maximum lag ({self.max_lag}) must be less than the length "
+                 f"of the series '{series_name}', ({len(y)}).")
             )
         
         X_data = np.full(shape=(n_splits, len(self.lags)), fill_value=np.nan, dtype=float)
 
         for i, lag in enumerate(self.lags):
             X_data[:, i] = y[self.max_lag - lag: -lag]
 
@@ -404,33 +374,30 @@
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None
     ) -> Tuple[pd.DataFrame, pd.Series, pd.Index, pd.Index]:
         """
         Create training matrices from multiple time series and exogenous
         variables.
         
         Parameters
-        ----------        
+        ----------
         series : pandas DataFrame
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `series` and their indexes must be aligned.
 
-        Returns 
+        Returns
         -------
         X_train : pandas DataFrame
-            Pandas DataFrame with the training values (predictors).
-            
-        y_train : pandas Series, shape (len(series) - self.max_lag, )
+            Training values (predictors).
+        y_train : pandas Series
             Values (target) of the time series related to each row of `X_train`.
-
+            Shape: (len(series) - self.max_lag, )
         y_index : pandas Index
             Index of `series`.
-
         y_train_index: pandas Index
             Index of `y_train`.
         
         """
 
         if not isinstance(series, pd.DataFrame):
             raise TypeError(f"`series` must be a pandas DataFrame. Got {type(series)}.")
@@ -442,15 +409,16 @@
         elif not isinstance(self.transformer_series, dict):
             self.transformer_series_ = {serie: clone(self.transformer_series) 
                                         for serie in series_col_names}
         else:
             self.transformer_series_ = {serie: None for serie in series_col_names}
             # Only elements already present in transformer_series_ are updated
             self.transformer_series_.update(
-                (k, v) for k, v in deepcopy(self.transformer_series).items() if k in self.transformer_series_
+                (k, v) for k, v in deepcopy(self.transformer_series).items() 
+                if k in self.transformer_series_
             )
             series_not_in_transformer_series = set(series.columns) - set(self.transformer_series.keys())
             if series_not_in_transformer_series:
                 warnings.warn(
                     (f"{series_not_in_transformer_series} not present in `transformer_series`."
                      f" No transformation is applied to these series."),
                      IgnoredArgumentWarning
@@ -486,69 +454,88 @@
             if not (exog_index[:len(series.index)] == series.index).all():
                 raise ValueError(
                     ("Different index for `series` and `exog`. They must be equal "
                      "to ensure the correct alignment of values.")
                 )
         
         X_levels = []
+        len_series = []
         X_train_col_names = [f"lag_{lag}" for lag in self.lags]
 
         for i, serie in enumerate(series.columns):
 
             y = series[serie]
-            check_y(y=y)
+            y_values = y.to_numpy()
+
+            if np.isnan(y_values).all():
+                raise ValueError(f"All values of series '{serie}' are NaN.")
+            
+            first_no_nan_idx = np.argmax(~np.isnan(y_values))
+            y_values = y_values[first_no_nan_idx:]
+
+            if np.isnan(y_values).any():
+                raise ValueError(
+                    (f"'{serie}' Time series has missing values in between or "
+                     f"at the end of the time series. When working with series "
+                     f"of different lengths, all series must be complete after "
+                     f"the first non-null value.")
+                )
+            
             y = transform_series(
-                    series            = y,
+                    series            = y.iloc[first_no_nan_idx:],
                     transformer       = self.transformer_series_[serie],
                     fit               = True,
                     inverse_transform = False
                 )
 
-            y_values, y_index = preprocess_y(y=y)
-            X_train_values, y_train_values = self._create_lags(y=y_values)
+            y_values = y.to_numpy()
+            X_train_values, y_train_values = self._create_lags(y=y_values, series_name=serie)
 
             if i == 0:
                 X_train = X_train_values
                 y_train = y_train_values
             else:
-                X_train = np.vstack((X_train, X_train_values))
-                y_train = np.append(y_train, y_train_values)
+                X_train = np.concatenate((X_train, X_train_values), axis=0)
+                y_train = np.concatenate((y_train, y_train_values), axis=0)
 
             X_level = [serie]*len(X_train_values)
             X_levels.extend(X_level)
+            len_series.append(len(y_train_values))
         
         X_levels = pd.Series(X_levels)
         X_levels = pd.get_dummies(X_levels, dtype=float)
 
         X_train = pd.DataFrame(
                       data    = X_train,
                       columns = X_train_col_names
                   )
 
         if exog is not None:
             # The first `self.max_lag` positions have to be removed from exog
-            # since they are not in X_train. Then exog is cloned as many times
-            # as series.
-            exog_to_train = exog.iloc[self.max_lag:, ]
-            exog_to_train = pd.concat([exog_to_train]*len(series_col_names)).reset_index(drop=True)
+            # since they are not in X_train. Then Exog is cloned as many times 
+            # as there are series, taking into account the length of the series.
+            exog_to_train = [exog.iloc[-length:, ] for length in len_series]
+            exog_to_train = pd.concat(exog_to_train).reset_index(drop=True)
         else:
             exog_to_train = None
         
         X_train = pd.concat([X_train, exog_to_train, X_levels], axis=1)
         self.X_train_col_names = X_train.columns.to_list()
 
         y_train = pd.Series(
                       data = y_train,
                       name = 'y'
                   )
 
+        _, y_index = preprocess_y(y=series, return_values=False)
+
+        y_index_numpy = y_index.to_numpy()
         y_train_index = pd.Index(
-                            np.tile(
-                                y_index[self.max_lag: ].to_numpy(),
-                                reps = len(series_col_names)
+                            np.concatenate(
+                                [y_index_numpy[-length:, ] for length in len_series]
                             )
                         )
 
         return X_train, y_train, y_index, y_train_index
 
     
     def create_sample_weights(
@@ -563,17 +550,17 @@
         types of weights.
 
         Parameters
         ----------
         series : pandas DataFrame
             Time series used to create `X_train` with the method `create_train_X_y`.
         X_train : pandas DataFrame
-            Dataframe generated with the method `create_train_X_y`, first return.
+            Dataframe created with the `create_train_X_y` method, first return.
         y_train_index : pandas Index
-            Index of `y_train` generated with the method `create_train_X_y`, fourth return.
+            Index created with the `create_train_X_y` method, fourth return.
 
         Returns
         -------
         weights : numpy ndarray
             Weights to use in `fit` method.
         
         """
@@ -589,33 +576,37 @@
             if series_not_in_series_weights:
                 warnings.warn(
                     (f"{series_not_in_series_weights} not present in `series_weights`. "
                      f"A weight of 1 is given to all their samples."),
                      IgnoredArgumentWarning
                 )
             self.series_weights_ = {col: 1. for col in series.columns}
-            self.series_weights_.update((k, v) for k, v in self.series_weights.items() if k in self.series_weights_)
+            self.series_weights_.update((k, v) for k, v in self.series_weights.items() 
+                                        if k in self.series_weights_)
             weights_series = [np.repeat(self.series_weights_[serie], sum(X_train[serie])) 
                               for serie in series.columns]
             weights_series = np.concatenate(weights_series)
 
         if self.weight_func is not None:
             if isinstance(self.weight_func, Callable):
-                self.weight_func_ = {col: copy(self.weight_func) for col in series.columns}
+                self.weight_func_ = {col: copy(self.weight_func) 
+                                     for col in series.columns}
             else:
                 # Series not present in weight_func have a weight of 1 in all their samples
                 series_not_in_weight_func = set(series.columns) - set(self.weight_func.keys())
                 if series_not_in_weight_func:
                     warnings.warn(
                         (f"{series_not_in_weight_func} not present in `weight_func`. "
                          f"A weight of 1 is given to all their samples."),
                          IgnoredArgumentWarning
                     )
-                self.weight_func_ = {col: lambda x: np.ones_like(x, dtype=float) for col in series.columns}
-                self.weight_func_.update((k, v) for k, v in self.weight_func.items() if k in self.weight_func_)
+                self.weight_func_ = {col: lambda x: np.ones_like(x, dtype=float) 
+                                     for col in series.columns}
+                self.weight_func_.update((k, v) for k, v in self.weight_func.items() 
+                                         if k in self.weight_func_)
                 
             weights_samples = []
             for key in self.weight_func_.keys():
                 idx = y_train_index[X_train[X_train[key] == 1.0].index]
                 weights_samples.append(self.weight_func_[key](idx))
             weights_samples = np.concatenate(weights_samples)
 
@@ -649,30 +640,31 @@
         self,
         series: pd.DataFrame,
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
         store_in_sample_residuals: bool=True
     ) -> None:
         """
         Training Forecaster.
+
+        Additional arguments to be passed to the `fit` method of the regressor 
+        can be added with the `fit_kwargs` argument when initializing the forecaster.
         
         Parameters
-        ----------        
+        ----------
         series : pandas DataFrame
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `series` and their indexes must be aligned so
             that series[i] is regressed on exog[i].
-
         store_in_sample_residuals : bool, default `True`
-            If True, in-sample residuals will be stored in the forecaster object
+            If `True`, in-sample residuals will be stored in the forecaster object
             after fitting.
 
-        Returns 
+        Returns
         -------
         None
         
         """
         
         # Reset values in case the forecaster has already been fitted.
         self.index_type          = None
@@ -695,16 +687,16 @@
             self.included_exog = True
             self.exog_type = type(exog)
             self.exog_col_names = \
                  exog.columns.to_list() if isinstance(exog, pd.DataFrame) else [exog.name]
 
             if len(set(self.exog_col_names) - set(self.series_col_names)) != len(self.exog_col_names):
                 raise ValueError(
-                    (f"`exog` cannot contain a column named the same as one of the series"
-                     f" (column names of series).\n"
+                    (f"`exog` cannot contain a column named the same as one of the "
+                     f"series (column names of series).\n"
                      f"    `series` columns : {self.series_col_names}.\n"
                      f"    `exog`   columns : {self.exog_col_names}.")
                 )
 
         X_train, y_train, y_index, y_train_index = self.create_train_X_y(series=series, exog=exog)
         sample_weight = self.create_sample_weights(
                             series        = series,
@@ -771,26 +763,23 @@
         Predict n steps ahead. It is an iterative process in which, each prediction,
         is used as a predictor for the next step.
         
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-            
         level : str
             Time series to be predicted.
-        
         last_window : numpy ndarray
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-            
         exog : numpy ndarray, default `None`
             Exogenous variable/s included as predictor/s.
 
-        Returns 
+        Returns
         -------
         predictions : numpy ndarray
             Predicted values.
         
         """
         
         predictions = np.full(shape=steps, fill_value=np.nan)
@@ -830,27 +819,22 @@
         Predict n steps ahead. It is an recursive process in which, each prediction,
         is used as a predictor for the next step.
 
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-
         levels : str, list, default `None`
             Time series to be predicted. If `None` all levels will be predicted.
-            **New in version 0.6.0**
-
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-
             If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
 
         Returns
         -------
         predictions : pandas DataFrame
             Predicted values, one column for each level.
@@ -962,51 +946,44 @@
         """
         Generate multiple forecasting predictions using a bootstrapping process. 
         By sampling from a collection of past observed errors (the residuals),
         each iteration of bootstrapping generates a different set of predictions. 
         See the Notes section for more information. 
         
         Parameters
-        ----------   
+        ----------
         steps : int
             Number of future steps predicted.
-
         levels : str, list, default `None`
             Time series to be predicted. If `None` all levels will be predicted.
-            
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
-            Exogenous variable/s included as predictor/s.
-            
+            Exogenous variable/s included as predictor/s. 
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
-            deterministic.
-                        
+            deterministic.      
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         boot_predictions : dict
-            Predictions generated by bootstrapping for each level. 
+            Predictions generated by bootstrapping for each level.
             {level: pandas DataFrame, shape (steps, n_boot)}
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp3/prediction-intervals.html#prediction-intervals-from-bootstrapped-residuals
         Forecasting: Principles and Practice (3nd ed) Rob J Hyndman and George Athanasopoulos.
@@ -1025,36 +1002,41 @@
                      f"{set(levels) - set(self.in_sample_residuals.keys())}.")
                 )
             residuals_levels = self.in_sample_residuals
         else:
             if self.out_sample_residuals is None:
                 raise ValueError(
                     ("`forecaster.out_sample_residuals` is `None`. Use "
-                     "`in_sample_residuals=True` or method `set_out_sample_residuals()` "
-                     "before `predict_interval()`, `predict_bootstrapping()` or "
-                     "`predict_dist()`.")
+                     "`in_sample_residuals=True` or method "
+                     "`set_out_sample_residuals()` before `predict_interval()`, "
+                     "`predict_bootstrapping()` or `predict_dist()`.")
                 )
             else:
                 if not set(levels).issubset(set(self.out_sample_residuals.keys())):
                     raise ValueError(
                         (f"Not `forecaster.out_sample_residuals` for levels: "
                          f"{set(levels) - set(self.out_sample_residuals.keys())}. "
                          f"Use method `set_out_sample_residuals()`.")
                     )
             residuals_levels = self.out_sample_residuals
                 
-        check_residuals = 'forecaster.in_sample_residuals' if in_sample_residuals else 'forecaster.out_sample_residuals'
+        check_residuals = (
+            "forecaster.in_sample_residuals" if in_sample_residuals
+             else "forecaster.out_sample_residuals"
+        )
         for level in levels:
             if residuals_levels[level] is None:
                 raise ValueError(
-                    (f"forecaster residuals for level '{level}' are `None`. Check `{check_residuals}`.")
+                    (f"forecaster residuals for level '{level}' are `None`. "
+                     f"Check `{check_residuals}`.")
                 )
             elif (residuals_levels[level] == None).any():
                 raise ValueError(
-                    (f"forecaster residuals for level '{level}' contains `None` values. Check `{check_residuals}`.")
+                    (f"forecaster residuals for level '{level}' contains `None` "
+                     f"values. Check `{check_residuals}`.")
                 )
 
         if last_window is None:
             last_window = deepcopy(self.last_window)
 
         check_predict_input(
             forecaster_name  = type(self).__name__,
@@ -1184,60 +1166,52 @@
     ) -> pd.DataFrame:
         """
         Iterative process in which, each prediction, is used as a predictor
         for the next step and bootstrapping is used to estimate prediction
         intervals. Both predictions and intervals are returned.
         
         Parameters
-        ---------- 
+        ----------
         steps : int
             Number of future steps predicted.
-
         levels : str, list, default `None`
-            Time series to be predicted. If `None` all levels will be predicted.  
-            **New in version 0.6.0**  
-            
+            Time series to be predicted. If `None` all levels will be predicted.
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
-            Exogenous variable/s included as predictor/s.
-            
+            Exogenous variable/s included as predictor/s.  
         interval : list, default `[5, 95]`
             Confidence of the prediction interval estimated. Sequence of 
             percentiles to compute, which must be between 0 and 100 inclusive. 
             For example, interval of 95% should be as `interval = [2.5, 97.5]`.
-            
         n_boot : int, default `500`
-            Number of bootstrapping iterations used to estimate prediction
+            Number of bootstrapping iterations used to estimate prediction 
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
             Values predicted by the forecaster and their estimated interval.
-                level: predictions.
-                level_lower_bound: lower bound of the interval.
-                level_upper_bound: upper bound interval of the interval.
+
+                - level: predictions.
+                - level_lower_bound: lower bound of the interval.
+                - level_upper_bound: upper bound of the interval.
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp2/prediction-intervals.html
         Forecasting: Principles and Practice (2nd ed) Rob J Hyndman and
         George Athanasopoulos.
@@ -1295,52 +1269,43 @@
     ) -> pd.DataFrame:
         """
         Fit a given probability distribution for each step. After generating 
         multiple forecasting predictions through a bootstrapping process, each 
         step is fitted to the given distribution.
         
         Parameters
-        ---------- 
+        ----------
         steps : int
             Number of future steps predicted.
-
         distribution : Object
             A distribution object from scipy.stats.
-
         levels : str, list, default `None`
-            Time series to be predicted. If `None` all levels will be predicted.  
-            **New in version 0.6.0**  
-            
+            Time series to be predicted. If `None` all levels will be predicted.
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
             Distribution parameters estimated for each step and level.
 
         """
         
         if levels is None:
@@ -1387,17 +1352,17 @@
         forecaster.
         
         Parameters
         ----------
         params : dict
             Parameters values.
 
-        Returns 
+        Returns
         -------
-        self
+        None
         
         """
 
         self.regressor = clone(self.regressor)
         self.regressor.set_params(**params)
 
 
@@ -1410,15 +1375,15 @@
         method of the regressor.
         
         Parameters
         ----------
         fit_kwargs : dict
             Dict of the form {"argument": new_value}.
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         self.fit_kwargs = check_select_fit_kwargs(self.regressor, fit_kwargs=fit_kwargs)
         
@@ -1429,20 +1394,22 @@
     ) -> None:
         """      
         Set new value to the attribute `lags`.
         Attributes `max_lag` and `window_size` are also updated.
         
         Parameters
         ----------
-        lags : int, list, 1D np.array, range
+        lags : int, list, numpy ndarray, range
             Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
-                `int`: include lags from 1 to `lags`.
-                `list` or `np.array`: include only lags present in `lags`.
 
-        Returns 
+            - `int`: include lags from 1 to `lags` (included).
+            - `list`, `1d numpy ndarray` or `range`: include only lags present in 
+            `lags`, all elements must be int.
+
+        Returns
         -------
         None
         
         """
         
         self.lags = initialize_lags(type(self).__name__, lags)            
         self.max_lag  = max(self.lags)
@@ -1463,38 +1430,35 @@
         
         Parameters
         ----------
         residuals : dict
             Dictionary of numpy ndarrays with the residuals of each level in the
             form {level: residuals}. If len(residuals) > 1000, only a random 
             sample of 1000 values are stored. Keys must be the same as `levels`.
-            
         append : bool, default `True`
             If `True`, new residuals are added to the once already stored in the
             attribute `out_sample_residuals`. Once the limit of 1000 values is
             reached, no more values are appended. If False, `out_sample_residuals`
             is overwritten with the new residuals.
-
         transform : bool, default `True`
             If `True`, new residuals are transformed using self.transformer_series.
-
         random_state : int, default `123`
             Sets a seed to the random sampling for reproducible output.
         
-        Returns 
+        Returns
         -------
-        self
+        None
 
         """
 
         if not isinstance(residuals, dict) or not all(isinstance(x, np.ndarray) for x in residuals.values()):
             raise TypeError(
-                f"`residuals` argument must be a dict of numpy ndarrays in the form "
-                "`{level: residuals}`. " 
-                f"Got {type(residuals)}."
+                (f"`residuals` argument must be a dict of numpy ndarrays in the form "
+                 "`{level: residuals}`. " 
+                 f"Got {type(residuals)}.")
             )
 
         if not self.fitted:
             raise sklearn.exceptions.NotFittedError(
                 ("This forecaster is not fitted yet. Call `fit` with appropriate "
                  "arguments before using `set_out_sample_residuals()`.")
             )
@@ -1507,15 +1471,17 @@
                 (f"""
                 Only residuals of levels 
                 {set(self.out_sample_residuals.keys()).intersection(set(residuals.keys()))} 
                 are updated.
                 """), IgnoredArgumentWarning
             )
 
-        residuals = {key: value for key, value in residuals.items() if key in self.out_sample_residuals.keys()}
+        residuals = {key: value 
+                     for key, value in residuals.items() 
+                     if key in self.out_sample_residuals.keys()}
 
         for level, value in residuals.items():
 
             residuals_level = value
 
             if not transform and self.transformer_series_[level] is not None:
                 warnings.warn(
@@ -1604,37 +1570,8 @@
 
         if feature_importances is not None:
             feature_importances = pd.DataFrame({
                                       'feature': self.X_train_col_names,
                                       'importance': feature_importances
                                   })
 
-        return feature_importances
-    
-
-    def get_feature_importance(
-        self
-    ) -> pd.DataFrame:
-        """
-        This method has been replaced by `get_feature_importances()`.
-        
-        Return feature importances of the regressor stored in the
-        forecaster. Only valid when regressor stores internally the feature
-        importances in the attribute `feature_importances_` or `coef_`.
-
-        Parameters
-        ----------
-        self
-
-        Returns
-        -------
-        feature_importances : pandas DataFrame
-            Feature importances associated with each predictor.
-        
-        """
-
-        warnings.warn(
-            ("get_feature_importance() method has been renamed to get_feature_importances()."
-             "This method will be removed in skforecast 0.9.0.")
-        )
-
-        return self.get_feature_importances()
+        return feature_importances
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/fixtures_ForecasterAutoregMultiSeries.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/fixtures_ForecasterAutoregMultiSeries.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # Fixtures ForecasterAutoregMultiSeries
 # ==============================================================================
 import numpy as np
 import pandas as pd
 
-# Fixtures
+# Fixtures 
 # np.random.seed(123)
 # series_1 = np.random.rand(50)
 # series_2 = np.random.rand(50)
 # exog = np.random.rand(50)
 series = pd.DataFrame({'1': pd.Series(np.array(
                                 [0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897,
                                  0.42310646, 0.9807642 , 0.68482974, 0.4809319 , 0.39211752,
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_create_lags.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_create_lags.py`

 * *Files 6% similar despite different names*

```diff
@@ -12,27 +12,27 @@
     """
     Test exception is raised when length of y is lower than maximum lag included
     in the forecaster.
     """
     y = pd.Series(np.arange(5), name='y')
     forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=10)
     err_msg = re.escape(
-                (f'The maximum lag ({forecaster.max_lag}) must be less than the length '
-                 f'of the series ({len(y)}).')
+                (f"The maximum lag ({forecaster.max_lag}) must be less than the length "
+                 f"of the series 'y', ({len(y)}).")
               )
     with pytest.raises(ValueError, match = err_msg):
-        forecaster._create_lags(y=y)
+        forecaster._create_lags(y=y, series_name=y.name)
 
 
 def test_create_lags_output():
     """
     Test matrix of lags is created properly when langs=3 and y=np.arange(10).
     """
     forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=3)
-    results = forecaster._create_lags(y=np.arange(10))
+    results = forecaster._create_lags(y=np.arange(10), series_name='y')
     expected = (np.array([[2., 1., 0.],
                           [3., 2., 1.],
                           [4., 3., 2.],
                           [5., 4., 3.],
                           [6., 5., 4.],
                           [7., 6., 5.],
                           [8., 7., 6.]]),
@@ -43,15 +43,15 @@
 
 
 def test_create_lags_output_interspersed_lags():
     """
     Test matrix of lags is is a list with interspersed lags.
     """
     forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=[4, 7])
-    results = forecaster._create_lags(y=np.arange(10))
+    results = forecaster._create_lags(y=np.arange(10), series_name='y')
     expected = (np.array([[3., 0.],
                           [4., 1.],
                           [5., 2.]]),
                np.array([7., 8., 9.]))
 
     assert (results[0] == expected[0]).all()
     assert (results[1] == expected[1]).all()
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_create_sample_weights.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_create_sample_weights.py`

 * *Files 14% similar despite different names*

```diff
@@ -114,112 +114,176 @@
     Test `sample_weights` creation using `series_weights`.
     """
     forecaster = ForecasterAutoregMultiSeries(
                      regressor      = LinearRegression(),
                      lags           = 3,
                      series_weights = {'series_1': 1., 'series_2': 2.}
                  )
+    results = forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
 
     expected = np.array([1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2.])
-    results = forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
     
     assert np.array_equal(results, expected)
 
 
 def test_create_sample_weights_output_using_weight_func():
     """
     Test `sample_weights` creation using `weight_func`.
     """
     forecaster = ForecasterAutoregMultiSeries(
                      regressor   = LinearRegression(),
                      lags        = 3,
                      weight_func = custom_weights
                  )
+    results = forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                               y_train_index=y_train_index)
 
     expected = np.array([1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1])
-    results = forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
     
     assert np.array_equal(results, expected)
 
 
 @pytest.mark.parametrize("weight_func, expected", 
                          [({'series_1': custom_weights}, 
-                           np.array([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),                            
+                           np.array([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), 
                           ({'series_2': custom_weights_2}, 
                            np.array([1., 1., 1., 1., 1., 1., 1., 3., 3., 3., 3., 2., 2., 2.])), 
                           ({'series_1': custom_weights, 
                             'series_2': custom_weights_2}, 
                            np.array([1, 0, 0, 0, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2]))], 
-                         ids = lambda values : f'levels: {values}'
-                        )
+                         ids = lambda values : f'levels: {values}')
 def test_create_sample_weights_output_using_weight_func_dict(weight_func, expected):
     """
     Test `sample_weights` creation using `weight_func`.
     """
     forecaster = ForecasterAutoregMultiSeries(
                      regressor   = LinearRegression(),
                      lags        = 3,
                      weight_func = weight_func
                  )
+    results = forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                               y_train_index=y_train_index)
+    
+    assert np.array_equal(results, expected)
 
-    results = forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
+
+@pytest.mark.parametrize("weight_func, expected", 
+                         [({'series_1': custom_weights}, 
+                           np.array([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,])), 
+                          ({'series_2': custom_weights_2}, 
+                           np.array([1., 1., 1., 1., 1., 1., 1., 3., 2., 2., 2.])), 
+                          ({'series_1': custom_weights, 
+                            'series_2': custom_weights_2}, 
+                           np.array([1, 0, 0, 0, 1, 1, 1, 3, 2, 2, 2]))], 
+                         ids = lambda values : f'levels: {values}')
+def test_create_sample_weights_output_using_weight_func_dict_different_series_lengths(weight_func, expected):
+    """
+    Test `sample_weights` creation using `weight_func` with series of different lengths.
+    """
+    new_series = series.copy()
+    new_series['series_2'].iloc[:3] = np.nan
+    new_X_train = X_train.drop([7, 8, 9]).reset_index(drop=True)
+    new_y_train_index = pd.DatetimeIndex(
+                            ['2022-01-07', '2022-01-08', '2022-01-09', '2022-01-10',
+                             '2022-01-11', '2022-01-12', '2022-01-13',
+                             '2022-01-10', '2022-01-11', '2022-01-12', '2022-01-13'],
+                            dtype='datetime64[ns]', freq=None
+                        )
+
+    forecaster = ForecasterAutoregMultiSeries(
+                     regressor   = LinearRegression(),
+                     lags        = 3,
+                     weight_func = weight_func
+                 )
+    results = forecaster.create_sample_weights(series=new_series, X_train=new_X_train, 
+                                               y_train_index=new_y_train_index)
     
     assert np.array_equal(results, expected)
 
 
 def test_create_sample_weights_output_using_series_weights_and_weight_func():
     """
     Test `sample_weights` creation using `series_weights` and `weight_func`.
     """
     forecaster = ForecasterAutoregMultiSeries(
                      regressor      = LinearRegression(),
                      lags           = 3,
                      series_weights = {'series_1': 1., 'series_2': 2.},
                      weight_func    = custom_weights
                  )
+    results = forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                               y_train_index=y_train_index)
 
     expected = np.array([1, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 2, 2, 2], dtype=float)
-    results = forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
     
     assert np.array_equal(results, expected)
 
 
-def test_create_sample_weights_exceptions_when_weights_has_nan():
+def test_create_sample_weights_output_using_series_weights_and_weight_func_different_series_lengths():
+    """
+    Test `sample_weights` creation using `series_weights` and `weight_func` 
+    with series of different lengths.
+    """
+    new_series = series.copy()
+    new_series['series_2'].iloc[:3] = np.nan
+    new_X_train = X_train.drop([7, 8, 9]).reset_index(drop=True)
+    new_y_train_index = pd.DatetimeIndex(
+                            ['2022-01-07', '2022-01-08', '2022-01-09', '2022-01-10',
+                             '2022-01-11', '2022-01-12', '2022-01-13',
+                             '2022-01-10', '2022-01-11', '2022-01-12', '2022-01-13'],
+                            dtype='datetime64[ns]', freq=None
+                        )
+    
+    forecaster = ForecasterAutoregMultiSeries(
+                     regressor      = LinearRegression(),
+                     lags           = 3,
+                     series_weights = {'series_1': 1., 'series_2': 2.},
+                     weight_func    = custom_weights
+                 )
+    results = forecaster.create_sample_weights(series=new_series, X_train=new_X_train, 
+                                               y_train_index=new_y_train_index)
+
+    expected = np.array([1, 0, 0, 0, 1, 1, 1, 0, 2, 2, 2], dtype=float)
+    
+    assert np.array_equal(results, expected)
+
+
+def test_create_sample_weights_ValueError_when_weights_has_nan():
     """
-    Test sample_weights exception when sample_weight contains NaNs.
+    Test sample_weights ValueError when sample_weight contains NaNs.
     """
     forecaster = ForecasterAutoregMultiSeries(
                      regressor   = LinearRegression(),
                      lags        = 3,
                      weight_func = custom_weights_nan
                  )
 
     err_msg = re.escape("The resulting `weights` cannot have NaN values.")
     with pytest.raises(ValueError, match=err_msg):
         forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
 
 
-def test_create_sample_weights_exceptions_when_weights_has_negative_values():
+def test_create_sample_weights_ValueError_when_weights_has_negative_values():
     """
-    Test sample_weights exception when sample_weight contains negative values.
+    Test sample_weights ValueError when sample_weight contains negative values.
     """
     forecaster = ForecasterAutoregMultiSeries(
                      regressor   = LinearRegression(),
                      lags        = 3,
                      weight_func = custom_weights_negative
                  )
 
     err_msg = re.escape("The resulting `weights` cannot have negative values.")
     with pytest.raises(ValueError, match=err_msg):
         forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
    
 
-def test_create_sample_weights_exceptions_when_weights_all_zeros():
+def test_create_sample_weights_ValueError_when_weights_all_zeros():
     """
-    Test sample_weights exception when the sum of the weights is zero.
+    Test sample_weights ValueError when the sum of the weights is zero.
     """
     forecaster = ForecasterAutoregMultiSeries(
                      regressor      = LinearRegression(),
                      lags           = 3,
                      series_weights = {'series_1': 0, 'series_2': 0}
                  )
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_create_train_X_y.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_create_train_X_y.py`

 * *Files 9% similar despite different names*

```diff
@@ -119,14 +119,54 @@
                 ("Different index for `series` and `exog`. They must be equal "
                  "to ensure the correct alignment of values.")
               )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.fit(series=series, exog=exog)
 
 
+def test_create_train_X_y_ValueError_when_all_series_values_are_missing():
+    """
+    Test ValueError is raised when all series values are missing.
+    """
+    series = pd.DataFrame({'1': pd.Series(np.arange(7)), 
+                           '2': pd.Series([np.nan]*7)})
+    series.index = pd.date_range(start='2022-01-01', periods=7, freq='1D')
+    forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=5)
+
+    err_msg = re.escape("All values of series '2' are NaN.")
+    with pytest.raises(ValueError, match = err_msg):
+        forecaster.create_train_X_y(series=series)
+
+
+@pytest.mark.parametrize("values", 
+                         [[0, 1, 2, 3, 4, 5, np.nan], 
+                          [0, 1]+[np.nan]*5, 
+                          [np.nan, 1, 2, 3, 4, 5, np.nan],
+                          [0, 1, np.nan, 3, np.nan, 5, 6], 
+                          [np.nan, np.nan, np.nan, 3, np.nan, 5, 6]])
+def test_create_train_X_y_ValueError_when_series_values_are_missing(values):
+    """
+    Test ValueError is raised when series values are missing in different
+    locations.
+    """
+    series = pd.DataFrame({'1': pd.Series(values), 
+                           '2': pd.Series(np.arange(7))})
+    series.index = pd.date_range(start='2022-01-01', periods=7, freq='1D')
+    forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=5)
+
+    err_msg = re.escape(
+                ("'1' Time series has missing values in between or "
+                 "at the end of the time series. When working with series "
+                 "of different lengths, all series must be complete after "
+                 "the first non-null value.")
+              )
+    with pytest.raises(ValueError, match = err_msg):
+        forecaster.create_train_X_y(series=series)
+
+
 def test_create_train_X_y_output_when_series_and_exog_is_None():
     """
     Test the output of create_train_X_y when series has 2 columns and 
     exog is None.
     """
     series = pd.DataFrame({'1': pd.Series(np.arange(7, dtype=float)), 
                            '2': pd.Series(np.arange(7, dtype=float))})
@@ -666,15 +706,15 @@
         else:
             np.testing.assert_array_equal(results[i], expected[i])
 
 
 @pytest.mark.parametrize("transformer_series", 
                          [StandardScaler(),
                           {'1': StandardScaler(), '2': StandardScaler()}], 
-                         ids = lambda tr : f'transformer_series: {tr}')
+                         ids = lambda tr : f'transformer_series type: {type(tr)}')
 def test_create_train_X_y_output_when_transformer_series_and_transformer_exog(transformer_series):
     """
     Test the output of create_train_X_y when using transformer_series and 
     transformer_exog.
     """
     series = pd.DataFrame({'1': np.arange(10, dtype=float), 
                            '2': np.arange(10, dtype=float)},
@@ -736,9 +776,150 @@
     )
 
     for i in range(len(expected)):
         if isinstance(expected[i], pd.DataFrame):
             pd.testing.assert_frame_equal(results[i], expected[i])
         elif isinstance(expected[i], pd.Series):
             pd.testing.assert_series_equal(results[i], expected[i])
+        else:
+            np.testing.assert_array_equal(results[i], expected[i])
+
+
+def test_create_train_X_y_output_when_series_different_length_and_exog_is_dataframe_of_float_int_category():
+    """
+    Test the output of create_train_X_y when series has 2 columns with different 
+    lengths and exog is a pandas dataframe with two columns of float, int, category.
+    """
+    series = pd.DataFrame({'l1': pd.Series(np.arange(10, dtype=float)), 
+                           'l2': pd.Series([np.nan, np.nan, 2., 3., 4., 5., 6., 7., 8., 9.])})
+    series.index = pd.date_range("1990-01-01", periods=10, freq='D')
+    exog = pd.DataFrame({'exog_1': pd.Series(np.arange(100, 110), dtype=float),
+                         'exog_2': pd.Series(np.arange(1000, 1010), dtype=int),
+                         'exog_3': pd.Categorical(range(100, 110))})
+    exog.index = pd.date_range("1990-01-01", periods=10, freq='D')
+
+    forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=5)
+    results = forecaster.create_train_X_y(series=series, exog=exog)   
+
+    expected = (
+        pd.DataFrame(
+            data = np.array([[4., 3., 2., 1., 0., 105., 1005.],
+                             [5., 4., 3., 2., 1., 106., 1006.],
+                             [6., 5., 4., 3., 2., 107., 1007.],
+                             [7., 6., 5., 4., 3., 108., 1008.],
+                             [8., 7., 6., 5., 4., 109., 1009.],
+                             [6., 5., 4., 3., 2., 107., 1007.],
+                             [7., 6., 5., 4., 3., 108., 1008.],
+                             [8., 7., 6., 5., 4., 109., 1009.]],
+                             dtype=float),
+            index   = pd.RangeIndex(start=0, stop=8, step=1),
+            columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 
+                       'exog_1', 'exog_2']
+        ).assign(exog_3 = pd.Categorical([105, 106, 107, 108, 109, 
+                                          107, 108, 109], categories=range(100, 110)), 
+                 l1     = [1.]*5 + [0.]*3, 
+                 l2     = [0.]*5 + [1.]*3
+        ).astype({'exog_1': float, 
+                  'exog_2': int}
+        ),
+        pd.Series(
+            data  = np.array([5, 6, 7, 8, 9, 7, 8, 9]),
+            index = pd.RangeIndex(start=0, stop=8, step=1),
+            name  = 'y',
+            dtype = float
+        ),
+        pd.date_range("1990-01-01", periods=10, freq='D'),
+        pd.DatetimeIndex(['1990-01-06', '1990-01-07', '1990-01-08', '1990-01-09', '1990-01-10',
+                          '1990-01-08', '1990-01-09', '1990-01-10'],
+                         dtype='datetime64[ns]', freq=None
+        )
+    )
+
+    for i in range(len(expected)):
+        if isinstance(expected[i], pd.DataFrame):
+            pd.testing.assert_frame_equal(results[i], expected[i])
+        elif isinstance(expected[i], pd.Series):
+            pd.testing.assert_series_equal(results[i], expected[i])
+        else:
+            np.testing.assert_array_equal(results[i], expected[i])
+
+
+@pytest.mark.parametrize("transformer_series", 
+                         [StandardScaler(),
+                          {'l1': StandardScaler(), 'l2': StandardScaler(), 'l3': StandardScaler()}], 
+                         ids = lambda tr : f'transformer_series type: {type(tr)}')
+def test_create_train_X_y_output_when_transformer_series_and_transformer_exog_with_different_series_lengths(transformer_series):
+    """
+    Test the output of create_train_X_y when using transformer_series and 
+    transformer_exog with series with different lengths.
+    """
+    series = pd.DataFrame({'l1': np.arange(10, dtype=float), 
+                           'l2': pd.Series([np.nan, np.nan, 
+                                            2., 3., 4., 5., 6., 7., 8., 9.]), 
+                           'l3': pd.Series([np.nan, np.nan, np.nan, np.nan, 
+                                            4., 5., 6., 7., 8., 9.])})
+    series.index = pd.date_range("1990-01-01", periods=10, freq='D')
+    exog = pd.DataFrame({
+               'col_1': [7.5, 24.4, 60.3, 57.3, 50.7, 41.4, 24.4, 87.2, 47.4, 23.8],
+               'col_2': ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b']},
+                index = pd.date_range("1990-01-01", periods=10, freq='D'))
+
+    transformer_exog = ColumnTransformer(
+                            [('scale', StandardScaler(), ['col_1']),
+                             ('onehot', OneHotEncoder(), ['col_2'])],
+                            remainder = 'passthrough',
+                            verbose_feature_names_out = False
+                        )
+
+    forecaster = ForecasterAutoregMultiSeries(
+                     regressor          = LinearRegression(),
+                     lags               = 3,
+                     transformer_series = transformer_series,
+                     transformer_exog   = transformer_exog
+                 )
+    results = forecaster.create_train_X_y(series=series, exog=exog)
+
+    expected = (
+        pd.DataFrame(
+            data = np.array([
+                       [-0.8703882797784892,  -1.2185435916898848,  -1.5666989036012806,   0.6743197452466179,  0.0, 1.0, 1.0, 0.0, 0.0],
+                       [-0.5222329678670935,  -0.8703882797784892,  -1.2185435916898848,   0.3748237614897084,  1.0, 0.0, 1.0, 0.0, 0.0],
+                       [-0.17407765595569785, -0.5222329678670935,  -0.8703882797784892,  -0.04719330653139179, 0.0, 1.0, 1.0, 0.0, 0.0],
+                       [ 0.17407765595569785, -0.17407765595569785, -0.5222329678670935,  -0.8186223556022197,  1.0, 0.0, 1.0, 0.0, 0.0],
+                       [ 0.5222329678670935,   0.17407765595569785, -0.17407765595569785,  2.0311273080241334,  0.0, 1.0, 1.0, 0.0, 0.0],
+                       [ 0.8703882797784892,   0.5222329678670935,   0.17407765595569785,  0.2250757696112534,  1.0, 0.0, 1.0, 0.0, 0.0],
+                       [ 1.2185435916898848,   0.8703882797784892,   0.5222329678670935,  -0.8458492632164842,  0.0, 1.0, 1.0, 0.0, 0.0],
+                       [-0.6546536707079772,  -1.091089451179962,   -1.5275252316519468,  -0.04719330653139179, 0.0, 1.0, 0.0, 1.0, 0.0],
+                       [-0.2182178902359924,  -0.6546536707079772,  -1.091089451179962,   -0.8186223556022197,  1.0, 0.0, 0.0, 1.0, 0.0],
+                       [ 0.2182178902359924,  -0.2182178902359924,  -0.6546536707079772,   2.0311273080241334,  0.0, 1.0, 0.0, 1.0, 0.0],
+                       [ 0.6546536707079772,   0.2182178902359924,  -0.2182178902359924,   0.2250757696112534,  1.0, 0.0, 0.0, 1.0, 0.0],
+                       [ 1.091089451179962,    0.6546536707079772,   0.2182178902359924,  -0.8458492632164842,  0.0, 1.0, 0.0, 1.0, 0.0],
+                       [-0.29277002188455997, -0.8783100656536799,  -1.4638501094227998,   2.0311273080241334,  0.0, 1.0, 0.0, 0.0, 1.0],
+                       [ 0.29277002188455997, -0.29277002188455997, -0.8783100656536799,   0.2250757696112534,  1.0, 0.0, 0.0, 0.0, 1.0],
+                       [ 0.8783100656536799,   0.29277002188455997, -0.29277002188455997, -0.8458492632164842,  0.0, 1.0, 0.0, 0.0, 1.0]]),
+            index   = pd.RangeIndex(start=0, stop=15, step=1),
+            columns = ['lag_1', 'lag_2', 'lag_3', 'col_1',
+                       'col_2_a', 'col_2_b', 'l1', 'l2', 'l3']
+        ),
+        pd.Series(
+            data  = np.array([-0.5222329678670935, -0.17407765595569785, 0.17407765595569785, 0.5222329678670935, 0.8703882797784892, 1.2185435916898848, 1.5666989036012806, 
+                              -0.2182178902359924, 0.2182178902359924, 0.6546536707079772, 1.091089451179962, 1.5275252316519468, 
+                              0.29277002188455997, 0.8783100656536799, 1.4638501094227998]),
+            index = pd.RangeIndex(start=0, stop=15, step=1),
+            name  = 'y',
+            dtype = float
+        ),
+        pd.date_range("1990-01-01", periods=10, freq='D'),
+        pd.DatetimeIndex(['1990-01-04', '1990-01-05', '1990-01-06', '1990-01-07', '1990-01-08', '1990-01-09', '1990-01-10',
+                          '1990-01-06', '1990-01-07', '1990-01-08', '1990-01-09', '1990-01-10',
+                          '1990-01-08', '1990-01-09', '1990-01-10'],
+                         dtype='datetime64[ns]', freq=None
+        )
+    )
+
+    for i in range(len(expected)):
+        if isinstance(expected[i], pd.DataFrame):
+            pd.testing.assert_frame_equal(results[i], expected[i])
+        elif isinstance(expected[i], pd.Series):
+            pd.testing.assert_series_equal(results[i], expected[i])
         else:
             np.testing.assert_array_equal(results[i], expected[i])
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_fit.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_fit.py`

 * *Files 0% similar despite different names*

```diff
@@ -7,17 +7,17 @@
 from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries
 from sklearn.linear_model import LinearRegression
 from sklearn.preprocessing import StandardScaler
 from xgboost import XGBRegressor
 
 
 @pytest.mark.parametrize('exog', ['l1', ['l1'], ['l1', 'l2']])
-def test_fit_exception_when_exog_columns_same_as_series_col_names(exog):
+def test_fit_ValueError_when_exog_columns_same_as_series_col_names(exog):
     """
-    Test exception is raised when an exog column is named the same as
+    Test ValueError is raised when an exog column is named the same as
     the series levels.
     """
     series = pd.DataFrame({'l1': pd.Series(np.arange(10)), 
                            'l2': pd.Series(np.arange(10))})
 
     forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=3)
     series_col_names = ['l1', 'l2']
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_get_feature_importances.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_get_feature_importances.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_predict.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 # Unit test predict ForecasterAutoregMultiSeries
 # ==============================================================================
 import pytest
-from pytest import approx
 import numpy as np
 import pandas as pd
 from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries
 from sklearn.compose import ColumnTransformer
 from sklearn.preprocessing import StandardScaler
 from sklearn.preprocessing import MinMaxScaler
 from sklearn.preprocessing import OneHotEncoder
@@ -62,14 +61,15 @@
     """
     Test predict output when using LinearRegression as regressor with pytest fixture.
     This test is equivalent to the next one.
     """
     forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=5)
     forecaster.fit(series=series_2)
     predictions = forecaster.predict(steps=5, levels=expected_pandas_dataframe[0])
+
     expected = expected_pandas_dataframe[1]
 
     pd.testing.assert_frame_equal(predictions, expected)
 
 
 def test_predict_output_when_regressor_is_LinearRegression():
     """
@@ -157,14 +157,15 @@
     forecaster = ForecasterAutoregMultiSeries(
                      regressor          = LinearRegression(),
                      lags               = 5,
                      transformer_series = StandardScaler()
                  )
     forecaster.fit(series=series)
     predictions = forecaster.predict(steps=5, levels='1')
+
     expected = pd.DataFrame(
                    data    = np.array([0.52791431, 0.44509712, 0.42176045, 0.48087237, 0.48268008]),
                    index   = pd.RangeIndex(start=50, stop=55, step=1),
                    columns = ['1']
                )
     
     pd.testing.assert_frame_equal(predictions, expected)
@@ -178,51 +179,98 @@
     forecaster = ForecasterAutoregMultiSeries(
                      regressor          = LinearRegression(),
                      lags               = 5,
                      transformer_series = {'1': StandardScaler(), '2': MinMaxScaler()}
                  )
     forecaster.fit(series=series)
     predictions = forecaster.predict(steps=5, levels=['1'])
+
     expected = pd.DataFrame(
                    data    = np.array([0.59619193, 0.46282914, 0.41738496, 0.48522676, 0.47525733]),
                    index   = pd.RangeIndex(start=50, stop=55, step=1),
                    columns = ['1']
                )
     
     pd.testing.assert_frame_equal(predictions, expected)
 
 
-def test_predict_output_when_regressor_is_LinearRegression_with_transform_series_and_transform_exog():
+@pytest.mark.parametrize("transformer_series", 
+                         [StandardScaler(),
+                          {'1': StandardScaler(), '2': StandardScaler()}], 
+                         ids = lambda tr : f'transformer_series type: {type(tr)}')
+def test_predict_output_when_regressor_is_LinearRegression_with_transform_series_and_transform_exog(transformer_series):
     """
     Test predict output when using LinearRegression as regressor, StandardScaler
     as transformer_series and transformer_exog as transformer_exog.
     """
     transformer_exog = ColumnTransformer(
                            [('scale', StandardScaler(), ['col_1']),
                             ('onehot', OneHotEncoder(), ['col_2'])],
                            remainder = 'passthrough',
                            verbose_feature_names_out = False
                        )
     forecaster = ForecasterAutoregMultiSeries(
                      regressor          = LinearRegression(),
                      lags               = 5,
-                     transformer_series = StandardScaler(),
+                     transformer_series = transformer_series,
                      transformer_exog   = transformer_exog,
                  )
     forecaster.fit(series=series, exog=exog)
     predictions = forecaster.predict(steps=5, levels='1', exog=exog_predict)
+
     expected = pd.DataFrame(
                    data    = np.array([0.53267333, 0.44478046, 0.52579563, 0.57391142, 0.54633594]),
                    index   = pd.RangeIndex(start=50, stop=55, step=1),
                    columns = ['1']
                )
     
     pd.testing.assert_frame_equal(predictions, expected)
 
 
+@pytest.mark.parametrize("transformer_series", 
+                         [StandardScaler(),
+                          {'1': StandardScaler(), '2': StandardScaler()}], 
+                         ids = lambda tr : f'transformer_series type: {type(tr)}')
+def test_predict_output_when_regressor_is_LinearRegression_with_transform_series_and_transform_exog_different_length_series(transformer_series):
+    """
+    Test predict output when using LinearRegression as regressor, StandardScaler
+    as transformer_series and transformer_exog as transformer_exog with series 
+    of different lengths.
+    """
+    new_series = series.copy()
+    new_series['2'].iloc[:10] = np.nan
+
+    transformer_exog = ColumnTransformer(
+                           [('scale', StandardScaler(), ['col_1']),
+                            ('onehot', OneHotEncoder(), ['col_2'])],
+                           remainder = 'passthrough',
+                           verbose_feature_names_out = False
+                       )
+    forecaster = ForecasterAutoregMultiSeries(
+                     regressor          = LinearRegression(),
+                     lags               = 5,
+                     transformer_series = transformer_series,
+                     transformer_exog   = transformer_exog,
+                 )
+    forecaster.fit(series=series, exog=exog)
+    predictions = forecaster.predict(steps=5, exog=exog_predict)
+
+    expected = pd.DataFrame(
+                   data    = np.array([[0.53267333, 0.55496412],
+                                       [0.44478046, 0.57787982],
+                                       [0.52579563, 0.66389117],
+                                       [0.57391142, 0.65789846],
+                                       [0.54633594, 0.5841187 ]]),
+                   index   = pd.RangeIndex(start=50, stop=55, step=1),
+                   columns = ['1', '2']
+               )
+    
+    pd.testing.assert_frame_equal(predictions, expected)
+
+
 def test_predict_output_when_categorical_features_native_implementation_HistGradientBoostingRegressor():
     """
     Test predict output when using HistGradientBoostingRegressor and categorical variables.
     """
     df_exog = pd.DataFrame({'exog_1': exog['col_1'],
                             'exog_2': ['a', 'b', 'c', 'd', 'e']*10,
                             'exog_3': pd.Categorical(['F', 'G', 'H', 'I', 'J']*10)})
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_bootstrapping.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_bootstrapping.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_dist.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_dist.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_interval.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_predict_interval.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_recursive_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_recursive_predict.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_set_fit_kwargs.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_set_fit_kwargs.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_set_lags.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_set_lags.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_set_out_sample_residuals.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_set_out_sample_residuals.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeries/tests/test_set_params.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeries/tests/test_set_params.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/ForecasterAutoregMultiSeriesCustom.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/ForecasterAutoregMultiSeriesCustom.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 ################################################################################
 #                   ForecasterAutoregMultiSeriesCustom                         #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
-from typing import Union, Dict, List, Tuple, Any, Optional, Callable
+from typing import Union, Tuple, Optional, Callable
 import warnings
 import logging
 import sys
 import numpy as np
 import pandas as pd
 import sklearn
 import sklearn.pipeline
@@ -48,218 +48,190 @@
     function to create predictors.
     **New in version 0.7.0**
     
     Parameters
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
-        
     fun_predictors : Callable
         Function that receives a time series as input (numpy ndarray) and returns
         another numpy ndarray with the predictors. The same function is applied 
         to all series.
-        
     window_size : int
         Size of the window needed by `fun_predictors` to create the predictors.
-
     name_predictors : list, default `None`
         Name of the predictors returned by `fun_predictors`. If `None`, predictors are
-        named using the prefix 'custom_predictor_<i>' where `i` is the index of the position
-        the predictor has in the returned array of `fun_predictors`.
-
-    transformer_series : transformer (preprocessor) or dict of transformers, default `None`
+        named using the prefix 'custom_predictor_<i>' where `i` is the index of the 
+        position the predictor has in the returned array of `fun_predictors`.
+    transformer_series : transformer (preprocessor), dict, default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
-        preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
-        If a single transformer is passed, it is cloned and applied to all series. If a
-        dict, a different transformer can be used for each series. Transformation is
-        applied to each `series` before training the forecaster.
-        ColumnTransformers are not allowed since they do not have inverse_transform method.
-    
+        preprocessing API with methods: fit, transform, fit_transform and 
+        inverse_transform. Transformation is applied to each `series` before training 
+        the forecaster. ColumnTransformers are not allowed since they do not have 
+        inverse_transform method.
+
+            - If single transformer: it is cloned and applied to all series. 
+            - If `dict` of transformers: a different transformer can be used for each 
+            series.
     transformer_exog : transformer, default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
     weight_func : Callable, dict, default `None`
         Function that defines the individual weights for each sample based on the
-        index. For example, a function that assigns a lower weight to certain dates.
-        If dict {'series_column_name' : Callable} a different function can be
-        used for each series, a weight of 1 is given to all series not present
-        in `weight_func`. Ignored if `regressor` does not have the argument 
-        `sample_weight` in its `fit` method. See Notes section for more details 
-        on the use of the weights. 
-
+        index. For example, a function that assigns a lower weight to certain dates. 
+        Ignored if `regressor` does not have the argument `sample_weight` in its 
+        `fit` method. See Notes section for more details on the use of the weights.
+
+            - If single function: it is applied to all series. 
+            - If `dict` {'series_column_name' : Callable}: a different function can be
+              used for each series, a weight of 1 is given to all series not present 
+              in `weight_func`.
     series_weights : dict, default `None`
         Weights associated with each series {'series_column_name' : float}. It is only
-        applied if the `regressor` used accepts `sample_weight` in its `fit` method.
-        If `series_weights` is provided, a weight of 1 is given to all series not present
-        in `series_weights`. If `None`, all levels have the same weight. See Notes section
-        for more details on the use of the weights.
+        applied if the `regressor` used accepts `sample_weight` in its `fit` method. 
+        See Notes section for more details on the use of the weights.
 
+            - If a `dict` is provided, a weight of 1 is given to all series not present
+            in `series_weights`.
+            - If `None`, all levels have the same weight.
     fit_kwargs : dict, default `None`
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
     forecaster_id : str, int, default `None`
         Name used as an identifier of the forecaster.
         **New in version 0.7.0**
     
     Attributes
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
-        
     fun_predictors : Callable
         Function that receives a time series as input (numpy ndarray) and returns
         another numpy ndarray with the predictors. The same function is applied 
         to all series.
-
     source_code_fun_predictors : str
         Source code of the custom function used to create the predictors.
-        
     window_size : int
         Size of the window needed by `fun_predictors` to create the predictors.
-
-    name_predictors : list, default `None`
+    name_predictors : list
         Name of the predictors returned by `fun_predictors`. If `None`, predictors are
-        named using the prefix 'custom_predictor_<i>' where `i` is the index of the position
-        the predictor has in the returned array of `fun_predictors`.
-
-    transformer_series : transformer (preprocessor) or dict of transformers, default `None`
+        named using the prefix 'custom_predictor_<i>' where `i` is the index of the 
+        position the predictor has in the returned array of `fun_predictors`.
+    transformer_series : transformer (preprocessor), dict
         An instance of a transformer (preprocessor) compatible with the scikit-learn
-        preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
-        If a single transformer is passed, it is cloned and applied to all series. If a
-        dict, a different transformer can be used for each series. Transformation is
-        applied to each `series` before training the forecaster.
-        ColumnTransformers are not allowed since they do not have inverse_transform method.
-        
+        preprocessing API with methods: fit, transform, fit_transform and 
+        inverse_transform. Transformation is applied to each `series` before training 
+        the forecaster. ColumnTransformers are not allowed since they do not have 
+        inverse_transform method.
+
+            - If single transformer: it is cloned and applied to all series. 
+            - If `dict` of transformers: a different transformer can be used for each 
+            series.
     transformer_series_ : dict
-        Dictionary with the transformer for each series. It is created cloning the objects
-        in `transformer_series` and is used internally to avoid overwriting.
-
-    transformer_exog : transformer (preprocessor), default `None`
+        Dictionary with the transformer for each series. It is created cloning the 
+        objects in `transformer_series` and is used internally to avoid overwriting.
+    transformer_exog : transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
-    weight_func : Callable, dict, default `None`
-        Function that defines the individual weights of each sample based on the
-        index. For example, a function that assigns a lower weight to certain dates.
-        If dict {'series_column_name': Callable} a different function can be
-        used for each series, a weight of 1 is given to all series not present
-        in `weight_func`. Ignored if `regressor` does not have the argument 
-        `sample_weight` in its `fit` method. See Notes section for more details 
-        on the use of the weights.
-
+    weight_func : Callable, dict
+        Function that defines the individual weights for each sample based on the
+        index. For example, a function that assigns a lower weight to certain dates. 
+        Ignored if `regressor` does not have the argument `sample_weight` in its 
+        `fit` method. See Notes section for more details on the use of the weights.
+
+            - If single function: it is applied to all series. 
+            - If `dict` {'series_column_name' : Callable}: a different function can be
+              used for each series, a weight of 1 is given to all series not present 
+              in `weight_func`.
     weight_func_ : dict
-        Dictionary with the `weight_func` for each series. It is created cloning the objects
-        in `weight_func` and is used internally to avoid overwriting.
-
+        Dictionary with the `weight_func` for each series. It is created cloning the 
+        objects in `weight_func` and is used internally to avoid overwriting.
     source_code_weight_func : str, dict
         Source code of the custom function(s) used to create weights.
+    series_weights : dict
+        Weights associated with each series {'series_column_name' : float}. It is only
+        applied if the `regressor` used accepts `sample_weight` in its `fit` method. 
+        See Notes section for more details on the use of the weights.
 
-    series_weights : dict, default `None`
-        Weights associated with each series {'series_column_name': float}. It is only
-        applied if the `regressor` used accepts `sample_weight` in its `fit` method.
-        If `series_weights` is provided, a weight of 1 is given to all series not present
-        in `series_weights`. If `None`, all levels have the same weight. See Notes section
-        for more details on the use of the weights.
-
+            - If a `dict` is provided, a weight of 1 is given to all series not present
+            in `series_weights`.
+            - If `None`, all levels have the same weight.
     series_weights_ : dict
         Weights associated with each series.It is created as a clone of `series_weights`
         and is used internally to avoid overwriting.
-        
     window_size : int
         Size of the window needed by `fun_predictors` to create the predictors.
-
     last_window : pandas Series
         Last window seen by the forecaster during training. It stores the values 
         needed to predict the next `step` immediately after the training data.
-        
     index_type : type
         Type of index of the input used in training.
-        
     index_freq : str
         Frequency of Index of the input used in training.
-
     index_values : pandas Index
         Values of Index of the input used in training.
-
     training_range: pandas Index
         First and last values of index of the data used during training.
-        
     included_exog : bool
         If the forecaster has been trained using exogenous variable/s.
-        
     exog_type : type
         Type of exogenous variable/s used in training.
-
     exog_dtypes : dict
         Type of each exogenous variable/s used in training. If `transformer_exog` 
         is used, the dtypes are calculated after the transformation.
-        
     exog_col_names : list
         Names of columns of `exog` if `exog` used in training was a pandas
         DataFrame.
-
     series_col_names : list
         Names of the series (levels) used during training.
-
     X_train_col_names : list
         Names of columns of the matrix created internally for training.
-
     fit_kwargs : dict
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-        
     in_sample_residuals : dict
         Residuals of the model when predicting training data. Only stored up to
-        1000 values in the form `{level: residuals}`.
-        
+        1000 values in the form `{level: residuals}`. If `transformer_series` 
+        is not `None`, residuals are stored in the transformed scale.
     out_sample_residuals : dict
         Residuals of the model when predicting non-training data. Only stored
-        up to 1000 values in the form `{level: residuals}`. Use 
-        `set_out_sample_residuals` to set values.
-        
-    fitted : Bool
+        up to 1000 values in the form `{level: residuals}`. If `transformer_series` 
+        is not `None`, residuals are assumed to be in the transformed scale. Use 
+        `set_out_sample_residuals()` method to set values.
+    fitted : bool
         Tag to identify if the regressor has been fitted (trained).
-
     creation_date : str
         Date of creation.
-
     fit_date : str
         Date of last fit.
-
     skforcast_version : str
         Version of skforecast library used to create the forecaster.
-
     python_version : str
         Version of python used to create the forecaster.
-
-    forecaster_id : str, int default `None`
+    forecaster_id : str, int
         Name used as an identifier of the forecaster.
-        **New in version 0.7.0**
-
 
     Notes
     -----
 
     The weights are used to control the influence that each observation has on the
-    training of the model. `ForecasterAutoregMultiseries` accepts two types of weights:
-
-    + series_weights : controls the relative importance of each series. If a series has
-    twice as much weight as the others, the observations of that series influence the
-    training twice as much. The higher the weight of a series relative to the others,
-    the more the model will focus on trying to learn that series.
-
-    + weight_func : controls the relative importance of each observation according to its
-    index value. For example, a function that assigns a lower weight to certain dates.
-
+    training of the model. `ForecasterAutoregMultiseries` accepts two types of weights. 
     If the two types of weights are indicated, they are multiplied to create the final
     weights. The resulting `sample_weight` cannot have negative values.
+
+    - `series_weights` : controls the relative importance of each series. If a 
+    series has twice as much weight as the others, the observations of that series 
+    influence the training twice as much. The higher the weight of a series 
+    relative to the others, the more the model will focus on trying to learn 
+    that series.
+    - `weight_func` : controls the relative importance of each observation 
+    according to its index value. For example, a function that assigns a lower 
+    weight to certain dates.
     
     """
     
     def __init__(
         self,
         regressor: object,
         fun_predictors: Callable, 
@@ -381,33 +353,30 @@
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None
     ) -> Tuple[pd.DataFrame, pd.Series, pd.Index, pd.Index]:
         """
         Create training matrices from multiple time series and exogenous
         variables.
         
         Parameters
-        ----------        
+        ----------
         series : pandas DataFrame
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `series` and their indexes must be aligned.
 
-        Returns 
+        Returns
         -------
         X_train : pandas DataFrame
-            Pandas DataFrame with the training values (predictors).
-            
-        y_train : pandas Series, shape (len(series) - self.max_lag, )
+            Training values (predictors).
+        y_train : pandas Series
             Values (target) of the time series related to each row of `X_train`.
-
+            Shape: (len(series) - self.max_lag, )
         y_index : pandas Index
             Index of `series`.
-
         y_train_index: pandas Index
             Index of `y_train`.
         
         """
 
         if not isinstance(series, pd.DataFrame):
             raise TypeError(f"`series` must be a pandas DataFrame. Got {type(series)}.")
@@ -426,15 +395,16 @@
         elif not isinstance(self.transformer_series, dict):
             self.transformer_series_ = {serie: clone(self.transformer_series) 
                                         for serie in series_col_names}
         else:
             self.transformer_series_ = {serie: None for serie in series_col_names}
             # Only elements already present in transformer_series_ are updated
             self.transformer_series_.update(
-                (k, v) for k, v in deepcopy(self.transformer_series).items() if k in self.transformer_series_
+                (k, v) for k, v in deepcopy(self.transformer_series).items() 
+                if k in self.transformer_series_
             )
             series_not_in_transformer_series = set(series.columns) - set(self.transformer_series.keys())
             if series_not_in_transformer_series:
                     warnings.warn(
                         (f"{series_not_in_transformer_series} not present in `transformer_series`."
                          f" No transformation is applied to these series."),
                          IgnoredArgumentWarning
@@ -470,64 +440,82 @@
             if not (exog_index[:len(series.index)] == series.index).all():
                 raise ValueError(
                     ("Different index for `series` and `exog`. They must be equal "
                      "to ensure the correct alignment of values.")
                 )
 
         X_levels = []
+        len_series = []
         
         for i, serie in enumerate(series.columns):
 
             y = series[serie]
-            check_y(y=y)
+            y_values = y.to_numpy()
+
+            if np.isnan(y_values).all():
+                raise ValueError(f"All values of series '{serie}' are NaN.")
+            
+            first_no_nan_idx = np.argmax(~np.isnan(y_values))
+            y_values = y_values[first_no_nan_idx:]
+
+            if np.isnan(y_values).any():
+                raise ValueError(
+                    (f"'{serie}' Time series has missing values in between or "
+                     f"at the end of the time series. When working with series "
+                     f"of different lengths, all series must be complete after "
+                     f"the first non-null value.")
+                )
+            
             y = transform_series(
-                    series            = y,
+                    series            = y.iloc[first_no_nan_idx:],
                     transformer       = self.transformer_series_[serie],
                     fit               = True,
                     inverse_transform = False
                 )
 
-            y_values, y_index = preprocess_y(y=y)
+            y_values = y.to_numpy()
 
-            temp_X_train  = []
-            temp_y_train  = []
+            X_train_values  = []
+            y_train_values  = []
 
             for j in range(len(y) - self.window_size):
 
-                train_index = np.arange(j, self.window_size + j)
-                test_index  = self.window_size + j
+                temp_X_index = np.arange(j, self.window_size + j)
+                temp_y_index  = self.window_size + j
 
-                temp_X_train.append(self.fun_predictors(y=y_values[train_index]))
-                temp_y_train.append(y_values[test_index])
+                X_train_values.append(self.fun_predictors(y=y_values[temp_X_index]))
+                y_train_values.append(y_values[temp_y_index])
 
-            X_train_values = np.vstack(temp_X_train)
-            y_train_values = np.array(temp_y_train)
+            X_train_values = np.vstack(X_train_values)
+            y_train_values = np.array(y_train_values)
 
             if np.isnan(X_train_values).any():
                 raise ValueError(
-                    f"`fun_predictors()` is returning `NaN` values for series {serie}."
+                    f"`fun_predictors()` is returning `NaN` values for series '{serie}'."
                 )
 
             if i == 0:
                 X_train = X_train_values
                 y_train = y_train_values
             else:
-                X_train = np.vstack((X_train, X_train_values))
-                y_train = np.append(y_train, y_train_values)
+                X_train = np.concatenate((X_train, X_train_values), axis=0)
+                y_train = np.concatenate((y_train, y_train_values), axis=0)
 
             X_level = [serie]*len(X_train_values)
             X_levels.extend(X_level)
+            len_series.append(len(y_train_values))
 
         if self.name_predictors is None:
-            X_train_col_names = [f"custom_predictor_{i}" for i in range(X_train.shape[1])]
+            X_train_col_names = [f"custom_predictor_{i}" 
+                                 for i in range(X_train.shape[1])]
         else:
             if len(self.name_predictors) != X_train.shape[1]:
                 raise ValueError(
-                    (f"The length of provided predictors names (`name_predictors`) do not "
-                     f"match the number of columns created by `fun_predictors()`.")
+                    ("The length of provided predictors names (`name_predictors`) do "
+                     "not match the number of columns created by `fun_predictors()`.")
                 )
             X_train_col_names = self.name_predictors.copy()
 
         # y_values correspond only to the last series of `series`. Since the columns
         # of X_train are the same for all series, the check is the same.
         expected = self.fun_predictors(y_values[:-1])
         observed = X_train[-1, :]
@@ -545,33 +533,35 @@
         X_train = pd.DataFrame(
                       data    = X_train,
                       columns = X_train_col_names
                   )
 
         if exog is not None:
             # The first `self.window_size` positions have to be removed from exog
-            # since they are not in X_train. Then exog is cloned as many times
-            # as series.
-            exog_to_train = exog.iloc[self.window_size:, ]
-            exog_to_train = pd.concat([exog_to_train]*len(series_col_names)).reset_index(drop=True)
+            # since they are not in X_train. Then Exog is cloned as many times 
+            # as there are series, taking into account the length of the series.
+            exog_to_train = [exog.iloc[-length:, ] for length in len_series]
+            exog_to_train = pd.concat(exog_to_train).reset_index(drop=True)
         else:
             exog_to_train = None
 
         X_train = pd.concat([X_train, exog_to_train, X_levels], axis=1)
         self.X_train_col_names = X_train.columns.to_list()
 
         y_train = pd.Series(
                       data = y_train,
                       name = 'y'
                   )
 
+        _, y_index = preprocess_y(y=series, return_values=False)
+
+        y_index_numpy = y_index.to_numpy()
         y_train_index = pd.Index(
-                            np.tile(
-                                y_index[self.window_size: ].values,
-                                reps = len(series_col_names)
+                            np.concatenate(
+                                [y_index_numpy[-length:, ] for length in len_series]
                             )
                         )
 
         return X_train, y_train, y_index, y_train_index
 
     
     def create_sample_weights(
@@ -586,17 +576,17 @@
         types of weights.
 
         Parameters
         ----------
         series : pandas DataFrame
             Time series used to create `X_train` with the method `create_train_X_y`.
         X_train : pandas DataFrame
-            Dataframe generated with the method `create_train_X_y`, first return.
+            Dataframe created with the `create_train_X_y` method, first return.
         y_train_index : pandas Index
-            Index of `y_train` generated with the method `create_train_X_y`, fourth return.
+            Index created with the `create_train_X_y` method, fourth return.
 
         Returns
         -------
         weights : numpy ndarray
             Weights to use in `fit` method.
         
         """
@@ -612,33 +602,37 @@
             if series_not_in_series_weights:
                 warnings.warn(
                     (f"{series_not_in_series_weights} not present in `series_weights`."
                      f" A weight of 1 is given to all their samples."),
                     IgnoredArgumentWarning
                 )
             self.series_weights_ = {col: 1. for col in series.columns}
-            self.series_weights_.update((k, v) for k, v in self.series_weights.items() if k in self.series_weights_)
+            self.series_weights_.update((k, v) for k, v in self.series_weights.items() 
+                                        if k in self.series_weights_)
             weights_series = [np.repeat(self.series_weights_[serie], sum(X_train[serie])) 
                               for serie in series.columns]
             weights_series = np.concatenate(weights_series)
 
         if self.weight_func is not None:
             if isinstance(self.weight_func, Callable):
-                self.weight_func_ = {col: copy(self.weight_func) for col in series.columns}
+                self.weight_func_ = {col: copy(self.weight_func) 
+                                     for col in series.columns}
             else:
                 # Series not present in weight_func have a weight of 1 in all their samples
                 series_not_in_weight_func = set(series.columns) - set(self.weight_func.keys())
                 if series_not_in_weight_func:
                     warnings.warn(
                         (f"{series_not_in_weight_func} not present in `weight_func`."
                          f" A weight of 1 is given to all their samples."),
                         IgnoredArgumentWarning
                     )
-                self.weight_func_ = {col: lambda x: np.ones_like(x, dtype=float) for col in series.columns}
-                self.weight_func_.update((k, v) for k, v in self.weight_func.items() if k in self.weight_func_)
+                self.weight_func_ = {col: lambda x: np.ones_like(x, dtype=float) 
+                                     for col in series.columns}
+                self.weight_func_.update((k, v) for k, v in self.weight_func.items() 
+                                         if k in self.weight_func_)
                 
             weights_samples = []
             for key in self.weight_func_.keys():
                 idx = y_train_index[X_train[X_train[key] == 1.0].index]
                 weights_samples.append(self.weight_func_[key](idx))
             weights_samples = np.concatenate(weights_samples)
 
@@ -672,30 +666,31 @@
         self,
         series: pd.DataFrame,
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
         store_in_sample_residuals: bool=True
     ) -> None:
         """
         Training Forecaster.
+
+        Additional arguments to be passed to the `fit` method of the regressor 
+        can be added with the `fit_kwargs` argument when initializing the forecaster.
         
         Parameters
-        ----------        
+        ----------
         series : pandas DataFrame
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `series` and their indexes must be aligned so
             that series[i] is regressed on exog[i].
-
         store_in_sample_residuals : bool, default `True`
-            If True, in-sample residuals will be stored in the forecaster object
+            If `True`, in-sample residuals will be stored in the forecaster object
             after fitting.
 
-        Returns 
+        Returns
         -------
         None
         
         """
         
         # Reset values in case the forecaster has already been fitted.
         self.index_type          = None
@@ -718,16 +713,16 @@
             self.included_exog = True
             self.exog_type = type(exog)
             self.exog_col_names = \
                  exog.columns.to_list() if isinstance(exog, pd.DataFrame) else [exog.name]
 
             if len(set(self.exog_col_names) - set(self.series_col_names)) != len(self.exog_col_names):
                 raise ValueError(
-                    (f"`exog` cannot contain a column named the same as one of the series"
-                     f" (column names of series).\n"
+                    (f"`exog` cannot contain a column named the same as one of the "
+                     f"series (column names of series).\n"
                      f"    `series` columns : {self.series_col_names}.\n"
                      f"    `exog`   columns : {self.exog_col_names}.")
                 )
 
         X_train, y_train, y_index, y_train_index = self.create_train_X_y(series=series, exog=exog)
         sample_weight = self.create_sample_weights(
                             series        = series,
@@ -794,26 +789,23 @@
         Predict n steps ahead. It is an iterative process in which, each prediction,
         is used as a predictor for the next step.
         
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-            
         level : str
             Time series to be predicted.
-        
         last_window : numpy ndarray
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-            
         exog : numpy ndarray, default `None`
             Exogenous variable/s included as predictor/s.
 
-        Returns 
+        Returns
         -------
         predictions : numpy ndarray
             Predicted values.
         
         """
         
         predictions = np.full(shape=steps, fill_value=np.nan)
@@ -853,26 +845,22 @@
         Predict n steps ahead. It is an recursive process in which, each prediction,
         is used as a predictor for the next step.
 
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-
         levels : str, list, default `None`
             Time series to be predicted. If `None` all levels will be predicted.
-
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-
             If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
 
         Returns
         -------
         predictions : pandas DataFrame
             Predicted values, one column for each level.
@@ -984,48 +972,41 @@
         """
         Generate multiple forecasting predictions using a bootstrapping process. 
         By sampling from a collection of past observed errors (the residuals),
         each iteration of bootstrapping generates a different set of predictions. 
         See the Notes section for more information. 
         
         Parameters
-        ----------   
+        ----------
         steps : int
             Number of future steps predicted.
-
         levels : str, list, default `None`
             Time series to be predicted. If `None` all levels will be predicted.
-            
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
-            deterministic.
-                        
+            deterministic.        
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         boot_predictions : dict
             Predictions generated by bootstrapping for each level. 
             {level: pandas DataFrame, shape (steps, n_boot)}
 
         Notes
         -----
@@ -1047,36 +1028,41 @@
                      f"{set(levels) - set(self.in_sample_residuals.keys())}.")
                 )
             residuals_levels = self.in_sample_residuals
         else:
             if self.out_sample_residuals is None:
                 raise ValueError(
                     ("`forecaster.out_sample_residuals` is `None`. Use "
-                     "`in_sample_residuals=True` or method `set_out_sample_residuals()` "
-                     "before `predict_interval()`, `predict_bootstrapping()` or "
-                     "`predict_dist()`.")
+                     "`in_sample_residuals=True` or method "
+                     "`set_out_sample_residuals()` before `predict_interval()`, "
+                     "`predict_bootstrapping()` or `predict_dist()`.")
                 )
             else:
                 if not set(levels).issubset(set(self.out_sample_residuals.keys())):
                     raise ValueError(
                         (f"Not `forecaster.out_sample_residuals` for levels: "
                          f"{set(levels) - set(self.out_sample_residuals.keys())}. "
                          f"Use method `set_out_sample_residuals()`.")
                     )
             residuals_levels = self.out_sample_residuals
                 
-        check_residuals = 'forecaster.in_sample_residuals' if in_sample_residuals else 'forecaster.out_sample_residuals'
+        check_residuals = (
+            "forecaster.in_sample_residuals" if in_sample_residuals
+             else "forecaster.out_sample_residuals"
+        )
         for level in levels:
             if residuals_levels[level] is None:
                 raise ValueError(
-                    (f"forecaster residuals for level '{level}' are `None`. Check `{check_residuals}`.")
+                    (f"forecaster residuals for level '{level}' are `None`. "
+                     f"Check `{check_residuals}`.")
                 )
             elif (residuals_levels[level] == None).any():
                 raise ValueError(
-                    (f"forecaster residuals for level '{level}' contains `None` values. Check `{check_residuals}`.")
+                    (f"forecaster residuals for level '{level}' contains `None` "
+                     f"values. Check `{check_residuals}`.")
                 )
 
         if last_window is None:
             last_window = deepcopy(self.last_window)
 
         last_window = last_window.iloc[-self.window_size:, ]
 
@@ -1209,59 +1195,52 @@
     ) -> pd.DataFrame:
         """
         Iterative process in which, each prediction, is used as a predictor
         for the next step and bootstrapping is used to estimate prediction
         intervals. Both predictions and intervals are returned.
         
         Parameters
-        ---------- 
+        ----------
         steps : int
             Number of future steps predicted.
-
         levels : str, list, default `None`
             Time series to be predicted. If `None` all levels will be predicted.  
-            
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         interval : list, default `[5, 95]`
             Confidence of the prediction interval estimated. Sequence of 
             percentiles to compute, which must be between 0 and 100 inclusive. 
             For example, interval of 95% should be as `interval = [2.5, 97.5]`.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
             Values predicted by the forecaster and their estimated interval.
-                level: predictions.
-                level_lower_bound: lower bound of the interval.
-                level_upper_bound: upper bound interval of the interval.
+
+                - level: predictions.
+                - level_lower_bound: lower bound of the interval.
+                - level_upper_bound: upper bound of the interval.
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp2/prediction-intervals.html
         Forecasting: Principles and Practice (2nd ed) Rob J Hyndman and
         George Athanasopoulos.
@@ -1319,51 +1298,43 @@
     ) -> pd.DataFrame:
         """
         Fit a given probability distribution for each step. After generating 
         multiple forecasting predictions through a bootstrapping process, each 
         step is fitted to the given distribution.
         
         Parameters
-        ---------- 
+        ----------
         steps : int
             Number of future steps predicted.
-
         distribution : Object
             A distribution object from scipy.stats. For example scipy.stats.norm.
-
         levels : str, list, default `None`
             Time series to be predicted. If `None` all levels will be predicted.  
-            
         last_window : pandas DataFrame, default `None`
             Values of the series used to create the predictors needed in the first
             re of prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
             Distribution parameters estimated for each step and level.
 
         """
         
         if levels is None:
@@ -1410,17 +1381,17 @@
         forecaster.
         
         Parameters
         ----------
         params : dict
             Parameters values.
 
-        Returns 
+        Returns
         -------
-        self
+        None
         
         """
 
         self.regressor = clone(self.regressor)
         self.regressor.set_params(**params)
 
 
@@ -1433,15 +1404,15 @@
         method of the regressor.
         
         Parameters
         ----------
         fit_kwargs : dict
             Dict of the form {"argument": new_value}.
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         self.fit_kwargs = check_select_fit_kwargs(self.regressor, fit_kwargs=fit_kwargs)
         
@@ -1453,45 +1424,42 @@
         transform: bool=True,
         random_state: int=123
     )-> None:
         """
         Set new values to the attribute `out_sample_residuals`. Out of sample
         residuals are meant to be calculated using observations that did not
         participate in the training process.
-        
+
         Parameters
         ----------
         residuals : dict
             Dictionary of numpy ndarrays with the residuals of each level in the
             form {level: residuals}. If len(residuals) > 1000, only a random 
             sample of 1000 values are stored. Keys must be the same as `levels`.
-            
         append : bool, default `True`
             If `True`, new residuals are added to the once already stored in the
             attribute `out_sample_residuals`. Once the limit of 1000 values is
             reached, no more values are appended. If False, `out_sample_residuals`
             is overwritten with the new residuals.
-
         transform : bool, default `True`
             If `True`, new residuals are transformed using self.transformer_series.
-
         random_state : int, default `123`
             Sets a seed to the random sampling for reproducible output.
-        
-        Returns 
+
+        Returns
         -------
-        self
+        None
 
         """
 
         if not isinstance(residuals, dict) or not all(isinstance(x, np.ndarray) for x in residuals.values()):
             raise TypeError(
-                f"`residuals` argument must be a dict of numpy ndarrays in the form "
-                "`{level: residuals}`. " 
-                f"Got {type(residuals)}."
+                (f"`residuals` argument must be a dict of numpy ndarrays in the form "
+                 "`{level: residuals}`. " 
+                 f"Got {type(residuals)}.")
             )
 
         if not self.fitted:
             raise sklearn.exceptions.NotFittedError(
                 ("This forecaster is not fitted yet. Call `fit` with appropriate "
                  "arguments before using `set_out_sample_residuals()`.")
             )
@@ -1504,15 +1472,17 @@
                 (f"""
                 Only residuals of levels 
                 {set(self.out_sample_residuals.keys()).intersection(set(residuals.keys()))} 
                 are updated.
                 """), IgnoredArgumentWarning
             )
 
-        residuals = {key: value for key, value in residuals.items() if key in self.out_sample_residuals.keys()}
+        residuals = {key: value 
+                     for key, value in residuals.items() 
+                     if key in self.out_sample_residuals.keys()}
 
         for level, value in residuals.items():
 
             residuals_level = value
 
             if not transform and self.transformer_series_[level] is not None:
                 warnings.warn(
@@ -1601,37 +1571,8 @@
 
         if feature_importances is not None:
             feature_importances = pd.DataFrame({
                                       'feature': self.X_train_col_names,
                                       'importance': feature_importances
                                   })
 
-        return feature_importances
-    
-
-    def get_feature_importance(
-        self
-    ) -> pd.DataFrame:
-        """
-        This method has been replaced by `get_feature_importances()`.
-
-        Return feature importances of the regressor stored in the
-        forecaster. Only valid when regressor stores internally the feature
-        importances in the attribute `feature_importances_` or `coef_`.
-
-        Parameters
-        ----------
-        self
-
-        Returns
-        -------
-        feature_importances : pandas DataFrame
-            Feature importances associated with each predictor.
-        
-        """
-
-        warnings.warn(
-            ("get_feature_importance() method has been renamed to get_feature_importances()."
-             "This method will be removed in skforecast 0.9.0.")
-        )
-
-        return self.get_feature_importances()
+        return feature_importances
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/fixtures_ForecasterAutoregMultiSeriesCustom.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/fixtures_ForecasterAutoregMultiSeriesCustom.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_create_sample_weights.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_create_sample_weights.py`

 * *Files 22% similar despite different names*

```diff
@@ -126,15 +126,16 @@
                      regressor       = LinearRegression(),
                      fun_predictors  = create_predictors,
                      window_size     = 3,
                      series_weights  = {'series_1': 1., 'series_2': 2.}
                  )
 
     expected = np.array([1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2.])
-    results = forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
+    results = forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                               y_train_index=y_train_index)
     
     assert np.array_equal(results, expected)
 
 
 def test_create_sample_weights_output_using_weight_func():
     """
     Test `sample_weights` creation using `weight_func`.
@@ -143,15 +144,16 @@
                      regressor       = LinearRegression(),
                      fun_predictors  = create_predictors,
                      window_size     = 3,
                      weight_func     = custom_weights
                  )
 
     expected = np.array([1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1])
-    results = forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
+    results = forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                               y_train_index=y_train_index)
     
     assert np.array_equal(results, expected)
 
 
 @pytest.mark.parametrize("weight_func, expected", 
                          [({'series_1': custom_weights}, 
                            np.array([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),                            
@@ -169,15 +171,51 @@
     forecaster = ForecasterAutoregMultiSeriesCustom(
                      regressor       = LinearRegression(),
                      fun_predictors  = create_predictors,
                      window_size     = 3,
                      weight_func     = weight_func
                  )
 
-    results = forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
+    results = forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                               y_train_index=y_train_index)
+    
+    assert np.array_equal(results, expected)
+
+
+@pytest.mark.parametrize("weight_func, expected", 
+                         [({'series_1': custom_weights}, 
+                           np.array([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,])), 
+                          ({'series_2': custom_weights_2}, 
+                           np.array([1., 1., 1., 1., 1., 1., 1., 3., 2., 2., 2.])), 
+                          ({'series_1': custom_weights, 
+                            'series_2': custom_weights_2}, 
+                           np.array([1, 0, 0, 0, 1, 1, 1, 3, 2, 2, 2]))], 
+                         ids = lambda values : f'levels: {values}')
+def test_create_sample_weights_output_using_weight_func_dict_different_series_lengths(weight_func, expected):
+    """
+    Test `sample_weights` creation using `weight_func` with series of different lengths.
+    """
+    new_series = series.copy()
+    new_series['series_2'].iloc[:3] = np.nan
+    new_X_train = X_train.drop([7, 8, 9]).reset_index(drop=True)
+    new_y_train_index = pd.DatetimeIndex(
+                            ['2022-01-07', '2022-01-08', '2022-01-09', '2022-01-10',
+                             '2022-01-11', '2022-01-12', '2022-01-13',
+                             '2022-01-10', '2022-01-11', '2022-01-12', '2022-01-13'],
+                            dtype='datetime64[ns]', freq=None
+                        )
+    
+    forecaster = ForecasterAutoregMultiSeriesCustom(
+                     regressor       = LinearRegression(),
+                     fun_predictors  = create_predictors,
+                     window_size     = 3,
+                     weight_func     = weight_func
+                 )
+    results = forecaster.create_sample_weights(series=new_series, X_train=new_X_train, 
+                                               y_train_index=new_y_train_index)
     
     assert np.array_equal(results, expected)
 
 
 def test_create_sample_weights_output_using_series_weights_and_weight_func():
     """
     Test `sample_weights` creation using `series_weights` and `weight_func`.
@@ -187,15 +225,46 @@
                      fun_predictors  = create_predictors,
                      window_size     = 3,
                      series_weights  = {'series_1': 1., 'series_2': 2.},
                      weight_func     = custom_weights
                  )
 
     expected = np.array([1, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 2, 2, 2], dtype=float)
-    results = forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
+    results = forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                               y_train_index=y_train_index)
+    
+    assert np.array_equal(results, expected)
+
+
+def test_create_sample_weights_output_using_series_weights_and_weight_func_different_series_lengths():
+    """
+    Test `sample_weights` creation using `series_weights` and `weight_func` 
+    with series of different lengths.
+    """
+    new_series = series.copy()
+    new_series['series_2'].iloc[:3] = np.nan
+    new_X_train = X_train.drop([7, 8, 9]).reset_index(drop=True)
+    new_y_train_index = pd.DatetimeIndex(
+                            ['2022-01-07', '2022-01-08', '2022-01-09', '2022-01-10',
+                             '2022-01-11', '2022-01-12', '2022-01-13',
+                             '2022-01-10', '2022-01-11', '2022-01-12', '2022-01-13'],
+                            dtype='datetime64[ns]', freq=None
+                        )
+    
+    forecaster = ForecasterAutoregMultiSeriesCustom(
+                     regressor       = LinearRegression(),
+                     fun_predictors  = create_predictors,
+                     window_size     = 3,
+                     series_weights  = {'series_1': 1., 'series_2': 2.},
+                     weight_func     = custom_weights
+                 )
+    results = forecaster.create_sample_weights(series=new_series, X_train=new_X_train, 
+                                               y_train_index=new_y_train_index)
+
+    expected = np.array([1, 0, 0, 0, 1, 1, 1, 0, 2, 2, 2], dtype=float)
     
     assert np.array_equal(results, expected)
 
 
 def test_create_sample_weights_exceptions_when_weights_has_nan():
     """
     Test sample_weights exception when sample_weight contains NaNs.
@@ -205,15 +274,16 @@
                      fun_predictors  = create_predictors,
                      window_size     = 3,
                      weight_func     = custom_weights_nan
                  )
 
     err_msg = re.escape("The resulting `weights` cannot have NaN values.")
     with pytest.raises(ValueError, match=err_msg):
-        forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
+        forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                         y_train_index=y_train_index)
 
 
 def test_create_sample_weights_exceptions_when_weights_has_negative_values():
     """
     Test sample_weights exception when sample_weight contains negative values.
     """
     forecaster = ForecasterAutoregMultiSeriesCustom(
@@ -221,15 +291,16 @@
                      fun_predictors  = create_predictors,
                      window_size     = 3,
                      weight_func     = custom_weights_negative
                  )
 
     err_msg = re.escape("The resulting `weights` cannot have negative values.")
     with pytest.raises(ValueError, match=err_msg):
-        forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
+        forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                         y_train_index=y_train_index)
    
 
 def test_create_sample_weights_exceptions_when_weights_all_zeros():
     """
     Test sample_weights exception when the sum of the weights is zero.
     """
     forecaster = ForecasterAutoregMultiSeriesCustom(
@@ -240,8 +311,9 @@
                  )
     
     err_msg = re.escape(
                     ("The resulting `weights` cannot be normalized because "
                      "the sum of the weights is zero.")
                 )
     with pytest.raises(ValueError, match=err_msg):
-        forecaster.create_sample_weights(series=series, X_train=X_train, y_train_index=y_train_index)
+        forecaster.create_sample_weights(series=series, X_train=X_train, 
+                                         y_train_index=y_train_index)
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_create_train_X_y.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_create_train_X_y.py`

 * *Files 13% similar despite different names*

```diff
@@ -141,14 +141,64 @@
                     (f"{series_not_in_transformer_series} not present in `transformer_series`."
                      f" No transformation is applied to these series.")
                 )
     with pytest.warns(UserWarning, match = warn_msg):
         forecaster.create_train_X_y(series=series)
 
 
+def test_create_train_X_y_ValueError_when_all_series_values_are_missing():
+    """
+    Test ValueError is raised when all series values are missing.
+    """
+    series = pd.DataFrame({'1': pd.Series(np.arange(7)), 
+                           '2': pd.Series([np.nan]*7)})
+    series.index = pd.date_range(start='2022-01-01', periods=7, freq='1D')
+
+    forecaster = ForecasterAutoregMultiSeriesCustom(
+                     regressor       = LinearRegression(),
+                     fun_predictors  = create_predictors_5,
+                     window_size     = 5
+                 )
+
+    err_msg = re.escape("All values of series '2' are NaN.")
+    with pytest.raises(ValueError, match = err_msg):
+        forecaster.create_train_X_y(series=series)
+
+
+@pytest.mark.parametrize("values", 
+                         [[0, 1, 2, 3, 4, 5, np.nan], 
+                          [0, 1]+[np.nan]*5, 
+                          [np.nan, 1, 2, 3, 4, 5, np.nan],
+                          [0, 1, np.nan, 3, np.nan, 5, 6], 
+                          [np.nan, np.nan, np.nan, 3, np.nan, 5, 6]])
+def test_create_train_X_y_ValueError_when_series_values_are_missing(values):
+    """
+    Test ValueError is raised when series values are missing in different
+    locations.
+    """
+    series = pd.DataFrame({'1': pd.Series(values), 
+                           '2': pd.Series(np.arange(7))})
+    series.index = pd.date_range(start='2022-01-01', periods=7, freq='1D')
+
+    forecaster = ForecasterAutoregMultiSeriesCustom(
+                     regressor       = LinearRegression(),
+                     fun_predictors  = create_predictors_5,
+                     window_size     = 5
+                 )
+
+    err_msg = re.escape(
+                ("'1' Time series has missing values in between or "
+                 "at the end of the time series. When working with series "
+                 "of different lengths, all series must be complete after "
+                 "the first non-null value.")
+              )
+    with pytest.raises(ValueError, match = err_msg):
+        forecaster.create_train_X_y(series=series)
+
+
 def test_create_train_X_y_ValueError_when_fun_predictors_return_NaN():
     """
     Test ValueError is raised when `fun_predictors()` return NaN values.
     """
     series = pd.DataFrame({'1': pd.Series(np.arange(5)),  
                            '2': pd.Series(np.arange(5))
                            })
@@ -156,15 +206,15 @@
     forecaster = ForecasterAutoregMultiSeriesCustom(
                     regressor       = LinearRegression(),
                     fun_predictors  = create_predictors_nan,
                     name_predictors = ['lag_1', 'lag_2', 'lag_3'],
                     window_size     = 3
                  )
 
-    err_msg = re.escape(("`fun_predictors()` is returning `NaN` values for series 1."))
+    err_msg = re.escape("`fun_predictors()` is returning `NaN` values for series '1'.")
     with pytest.raises(ValueError, match = err_msg):
         forecaster.create_train_X_y(series = series)
 
 
 def test_create_train_X_y_ValueError_when_len_name_predictors_not_match_X_train_columns():
     """
     Test ValueError is raised when argument `name_predictors` has less values than the number of
@@ -944,9 +994,157 @@
     )
 
     for i in range(len(expected)):
         if isinstance(expected[i], pd.DataFrame):
             pd.testing.assert_frame_equal(results[i], expected[i])
         elif isinstance(expected[i], pd.Series):
             pd.testing.assert_series_equal(results[i], expected[i])
+        else:
+            np.testing.assert_array_equal(results[i], expected[i])
+
+
+def test_create_train_X_y_output_when_series_different_length_and_exog_is_dataframe_of_float_int_category():
+    """
+    Test the output of create_train_X_y when series has 2 columns with different 
+    lengths and exog is a pandas dataframe with two columns of float, int, category.
+    """
+    series = pd.DataFrame({'l1': pd.Series(np.arange(10, dtype=float)), 
+                           'l2': pd.Series([np.nan, np.nan, 2., 3., 4., 5., 6., 7., 8., 9.])})
+    series.index = pd.date_range("1990-01-01", periods=10, freq='D')
+    exog = pd.DataFrame({'exog_1': pd.Series(np.arange(100, 110), dtype=float),
+                         'exog_2': pd.Series(np.arange(1000, 1010), dtype=int),
+                         'exog_3': pd.Categorical(range(100, 110))})
+    exog.index = pd.date_range("1990-01-01", periods=10, freq='D')
+
+    forecaster = ForecasterAutoregMultiSeriesCustom(
+                     regressor       = LinearRegression(),
+                     fun_predictors  = create_predictors_5,
+                     name_predictors = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5'],
+                     window_size     = 5
+                 )
+    results = forecaster.create_train_X_y(series=series, exog=exog)   
+
+    expected = (
+        pd.DataFrame(
+            data = np.array([[4., 3., 2., 1., 0., 105., 1005.],
+                             [5., 4., 3., 2., 1., 106., 1006.],
+                             [6., 5., 4., 3., 2., 107., 1007.],
+                             [7., 6., 5., 4., 3., 108., 1008.],
+                             [8., 7., 6., 5., 4., 109., 1009.],
+                             [6., 5., 4., 3., 2., 107., 1007.],
+                             [7., 6., 5., 4., 3., 108., 1008.],
+                             [8., 7., 6., 5., 4., 109., 1009.]],
+                             dtype=float),
+            index   = pd.RangeIndex(start=0, stop=8, step=1),
+            columns = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 
+                       'exog_1', 'exog_2']
+        ).assign(exog_3 = pd.Categorical([105, 106, 107, 108, 109, 
+                                          107, 108, 109], categories=range(100, 110)), 
+                 l1     = [1.]*5 + [0.]*3, 
+                 l2     = [0.]*5 + [1.]*3
+        ).astype({'exog_1': float, 
+                  'exog_2': int}
+        ),
+        pd.Series(
+            data  = np.array([5, 6, 7, 8, 9, 7, 8, 9]),
+            index = pd.RangeIndex(start=0, stop=8, step=1),
+            name  = 'y',
+            dtype = float
+        ),
+        pd.date_range("1990-01-01", periods=10, freq='D'),
+        pd.DatetimeIndex(['1990-01-06', '1990-01-07', '1990-01-08', '1990-01-09', '1990-01-10',
+                          '1990-01-08', '1990-01-09', '1990-01-10'],
+                         dtype='datetime64[ns]', freq=None
+        )
+    )
+
+    for i in range(len(expected)):
+        if isinstance(expected[i], pd.DataFrame):
+            pd.testing.assert_frame_equal(results[i], expected[i])
+        elif isinstance(expected[i], pd.Series):
+            pd.testing.assert_series_equal(results[i], expected[i])
+        else:
+            np.testing.assert_array_equal(results[i], expected[i])
+
+
+@pytest.mark.parametrize("transformer_series", 
+                         [StandardScaler(),
+                          {'l1': StandardScaler(), 'l2': StandardScaler(), 'l3': StandardScaler()}], 
+                         ids = lambda tr : f'transformer_series type: {type(tr)}')
+def test_create_train_X_y_output_when_transformer_series_and_transformer_exog_with_different_series_lengths(transformer_series):
+    """
+    Test the output of create_train_X_y when using transformer_series and 
+    transformer_exog with series with different lengths.
+    """
+    series = pd.DataFrame({'l1': np.arange(10, dtype=float), 
+                           'l2': pd.Series([np.nan, np.nan, 
+                                            2., 3., 4., 5., 6., 7., 8., 9.]), 
+                           'l3': pd.Series([np.nan, np.nan, np.nan, np.nan, 
+                                            4., 5., 6., 7., 8., 9.])})
+    series.index = pd.date_range("1990-01-01", periods=10, freq='D')
+    exog = pd.DataFrame({
+               'col_1': [7.5, 24.4, 60.3, 57.3, 50.7, 41.4, 24.4, 87.2, 47.4, 23.8],
+               'col_2': ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b']},
+                index = pd.date_range("1990-01-01", periods=10, freq='D'))
+
+    transformer_exog = ColumnTransformer(
+                            [('scale', StandardScaler(), ['col_1']),
+                             ('onehot', OneHotEncoder(), ['col_2'])],
+                            remainder = 'passthrough',
+                            verbose_feature_names_out = False
+                        )
+
+    forecaster = ForecasterAutoregMultiSeriesCustom(
+                     regressor          = LinearRegression(),
+                     fun_predictors     = create_predictors_3,
+                     window_size        = 3,
+                     transformer_series = transformer_series,
+                     transformer_exog   = transformer_exog
+                 )
+
+    results = forecaster.create_train_X_y(series=series, exog=exog)
+
+    expected = (
+        pd.DataFrame(
+            data = np.array([
+                       [-0.8703882797784892,  -1.2185435916898848,  -1.5666989036012806,   0.6743197452466179,  0.0, 1.0, 1.0, 0.0, 0.0],
+                       [-0.5222329678670935,  -0.8703882797784892,  -1.2185435916898848,   0.3748237614897084,  1.0, 0.0, 1.0, 0.0, 0.0],
+                       [-0.17407765595569785, -0.5222329678670935,  -0.8703882797784892,  -0.04719330653139179, 0.0, 1.0, 1.0, 0.0, 0.0],
+                       [ 0.17407765595569785, -0.17407765595569785, -0.5222329678670935,  -0.8186223556022197,  1.0, 0.0, 1.0, 0.0, 0.0],
+                       [ 0.5222329678670935,   0.17407765595569785, -0.17407765595569785,  2.0311273080241334,  0.0, 1.0, 1.0, 0.0, 0.0],
+                       [ 0.8703882797784892,   0.5222329678670935,   0.17407765595569785,  0.2250757696112534,  1.0, 0.0, 1.0, 0.0, 0.0],
+                       [ 1.2185435916898848,   0.8703882797784892,   0.5222329678670935,  -0.8458492632164842,  0.0, 1.0, 1.0, 0.0, 0.0],
+                       [-0.6546536707079772,  -1.091089451179962,   -1.5275252316519468,  -0.04719330653139179, 0.0, 1.0, 0.0, 1.0, 0.0],
+                       [-0.2182178902359924,  -0.6546536707079772,  -1.091089451179962,   -0.8186223556022197,  1.0, 0.0, 0.0, 1.0, 0.0],
+                       [ 0.2182178902359924,  -0.2182178902359924,  -0.6546536707079772,   2.0311273080241334,  0.0, 1.0, 0.0, 1.0, 0.0],
+                       [ 0.6546536707079772,   0.2182178902359924,  -0.2182178902359924,   0.2250757696112534,  1.0, 0.0, 0.0, 1.0, 0.0],
+                       [ 1.091089451179962,    0.6546536707079772,   0.2182178902359924,  -0.8458492632164842,  0.0, 1.0, 0.0, 1.0, 0.0],
+                       [-0.29277002188455997, -0.8783100656536799,  -1.4638501094227998,   2.0311273080241334,  0.0, 1.0, 0.0, 0.0, 1.0],
+                       [ 0.29277002188455997, -0.29277002188455997, -0.8783100656536799,   0.2250757696112534,  1.0, 0.0, 0.0, 0.0, 1.0],
+                       [ 0.8783100656536799,   0.29277002188455997, -0.29277002188455997, -0.8458492632164842,  0.0, 1.0, 0.0, 0.0, 1.0]]),
+            index   = pd.RangeIndex(start=0, stop=15, step=1),
+            columns = ['custom_predictor_0', 'custom_predictor_1', 'custom_predictor_2',
+                       'col_1', 'col_2_a', 'col_2_b', 'l1', 'l2', 'l3']
+        ),
+        pd.Series(
+            data  = np.array([-0.5222329678670935, -0.17407765595569785, 0.17407765595569785, 0.5222329678670935, 0.8703882797784892, 1.2185435916898848, 1.5666989036012806, 
+                              -0.2182178902359924, 0.2182178902359924, 0.6546536707079772, 1.091089451179962, 1.5275252316519468, 
+                              0.29277002188455997, 0.8783100656536799, 1.4638501094227998]),
+            index = pd.RangeIndex(start=0, stop=15, step=1),
+            name  = 'y',
+            dtype = float
+        ),
+        pd.date_range("1990-01-01", periods=10, freq='D'),
+        pd.DatetimeIndex(['1990-01-04', '1990-01-05', '1990-01-06', '1990-01-07', '1990-01-08', '1990-01-09', '1990-01-10',
+                          '1990-01-06', '1990-01-07', '1990-01-08', '1990-01-09', '1990-01-10',
+                          '1990-01-08', '1990-01-09', '1990-01-10'],
+                         dtype='datetime64[ns]', freq=None
+        )
+    )
+
+    for i in range(len(expected)):
+        if isinstance(expected[i], pd.DataFrame):
+            pd.testing.assert_frame_equal(results[i], expected[i])
+        elif isinstance(expected[i], pd.Series):
+            pd.testing.assert_series_equal(results[i], expected[i])
         else:
             np.testing.assert_array_equal(results[i], expected[i])
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_fit.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_fit.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 # Unit test fit ForecasterAutoregMultiSeriesCustom
 # ==============================================================================
 import re
 import pytest
-from pytest import approx
 import numpy as np
 import pandas as pd
 from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom
 from sklearn.linear_model import LinearRegression
 from sklearn.preprocessing import StandardScaler
 from xgboost import XGBRegressor
 
@@ -17,17 +16,17 @@
     """
     lags = y[-1:-4:-1]
 
     return lags
 
 
 @pytest.mark.parametrize('exog', ['l1', ['l1'], ['l1', 'l2']])
-def test_fit_exception_when_exog_columns_same_as_series_col_names(exog):
+def test_fit_ValueError_when_exog_columns_same_as_series_col_names(exog):
     """
-    Test exception is raised when an exog column is named the same as
+    Test ValueError is raised when an exog column is named the same as
     the series levels.
     """
     series = pd.DataFrame({'l1': pd.Series(np.arange(10)), 
                            'l2': pd.Series(np.arange(10))})
 
     forecaster = ForecasterAutoregMultiSeriesCustom(
                      regressor       = LinearRegression(),
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_get_feature_importances.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_get_feature_importances.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_init.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_init.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 # Unit test predict ForecasterAutoregMultiSeriesCustom
 # ==============================================================================
 import pytest
-from pytest import approx
 import numpy as np
 import pandas as pd
 from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom
 from sklearn.compose import ColumnTransformer
 from sklearn.preprocessing import StandardScaler
 from sklearn.preprocessing import MinMaxScaler
 from sklearn.preprocessing import OneHotEncoder
@@ -75,14 +74,15 @@
     forecaster = ForecasterAutoregMultiSeriesCustom(
                     regressor      = LinearRegression(),
                     fun_predictors = create_predictors,
                     window_size    = 5
                 )
     forecaster.fit(series=series_2)
     predictions = forecaster.predict(steps=5, levels=expected_pandas_dataframe[0])
+    
     expected = expected_pandas_dataframe[1]
 
     pd.testing.assert_frame_equal(predictions, expected)
 
 
 def test_predict_output_when_regressor_is_LinearRegression():
     """
@@ -179,14 +179,15 @@
                      regressor      = LinearRegression(),
                      fun_predictors = create_predictors,
                      window_size    = 5,
                      transformer_series = StandardScaler()
                  )
     forecaster.fit(series=series)
     predictions = forecaster.predict(steps=5, levels='1')
+    
     expected = pd.DataFrame(
                    data    = np.array([0.52791431, 0.44509712, 0.42176045, 0.48087237, 0.48268008]),
                    index   = pd.RangeIndex(start=50, stop=55, step=1),
                    columns = ['1']
                )
     
     pd.testing.assert_frame_equal(predictions, expected)
@@ -201,52 +202,100 @@
                      regressor      = LinearRegression(),
                      fun_predictors = create_predictors,
                      window_size    = 5,
                      transformer_series = {'1': StandardScaler(), '2': MinMaxScaler()}
                  )
     forecaster.fit(series=series)
     predictions = forecaster.predict(steps=5, levels=['1'])
+    
     expected = pd.DataFrame(
                    data    = np.array([0.59619193, 0.46282914, 0.41738496, 0.48522676, 0.47525733]),
                    index   = pd.RangeIndex(start=50, stop=55, step=1),
                    columns = ['1']
                )
     
     pd.testing.assert_frame_equal(predictions, expected)
 
 
-def test_predict_output_when_regressor_is_LinearRegression_with_transform_series_and_transform_exog():
+@pytest.mark.parametrize("transformer_series", 
+                         [StandardScaler(),
+                          {'1': StandardScaler(), '2': StandardScaler()}], 
+                         ids = lambda tr : f'transformer_series type: {type(tr)}')
+def test_predict_output_when_regressor_is_LinearRegression_with_transform_series_and_transform_exog(transformer_series):
     """
     Test predict output when using LinearRegression as regressor, StandardScaler
     as transformer_series and transformer_exog as transformer_exog.
     """
     transformer_exog = ColumnTransformer(
                            [('scale', StandardScaler(), ['col_1']),
                             ('onehot', OneHotEncoder(), ['col_2'])],
                            remainder = 'passthrough',
                            verbose_feature_names_out = False
                        )
     forecaster = ForecasterAutoregMultiSeriesCustom(
                      regressor          = LinearRegression(),
                      fun_predictors     = create_predictors,
                      window_size        = 5,
-                     transformer_series = StandardScaler(),
+                     transformer_series = transformer_series,
                      transformer_exog   = transformer_exog,
                  )
     forecaster.fit(series=series, exog=exog)
     predictions = forecaster.predict(steps=5, levels='1', exog=exog_predict)
+   
     expected = pd.DataFrame(
                    data    = np.array([0.53267333, 0.44478046, 0.52579563, 0.57391142, 0.54633594]),
                    index   = pd.RangeIndex(start=50, stop=55, step=1),
                    columns = ['1']
                )
     
     pd.testing.assert_frame_equal(predictions, expected)
 
 
+@pytest.mark.parametrize("transformer_series", 
+                         [StandardScaler(),
+                          {'1': StandardScaler(), '2': StandardScaler()}], 
+                         ids = lambda tr : f'transformer_series type: {type(tr)}')
+def test_predict_output_when_regressor_is_LinearRegression_with_transform_series_and_transform_exog_different_length_series(transformer_series):
+    """
+    Test predict output when using LinearRegression as regressor, StandardScaler
+    as transformer_series and transformer_exog as transformer_exog with series 
+    of different lengths.
+    """
+    new_series = series.copy()
+    new_series['2'].iloc[:10] = np.nan
+
+    transformer_exog = ColumnTransformer(
+                           [('scale', StandardScaler(), ['col_1']),
+                            ('onehot', OneHotEncoder(), ['col_2'])],
+                           remainder = 'passthrough',
+                           verbose_feature_names_out = False
+                       )
+    forecaster = ForecasterAutoregMultiSeriesCustom(
+                     regressor          = LinearRegression(),
+                     fun_predictors     = create_predictors,
+                     window_size        = 5,
+                     transformer_series = transformer_series,
+                     transformer_exog   = transformer_exog,
+                 )
+    forecaster.fit(series=series, exog=exog)
+    predictions = forecaster.predict(steps=5, exog=exog_predict)
+
+    expected = pd.DataFrame(
+                   data    = np.array([[0.53267333, 0.55496412],
+                                       [0.44478046, 0.57787982],
+                                       [0.52579563, 0.66389117],
+                                       [0.57391142, 0.65789846],
+                                       [0.54633594, 0.5841187 ]]),
+                   index   = pd.RangeIndex(start=50, stop=55, step=1),
+                   columns = ['1', '2']
+               )
+    
+    pd.testing.assert_frame_equal(predictions, expected)
+
+
 def test_predict_output_when_categorical_features_native_implementation_HistGradientBoostingRegressor():
     """
     Test predict output when using HistGradientBoostingRegressor and categorical variables.
     """
     df_exog = pd.DataFrame({'exog_1': exog['col_1'],
                             'exog_2': ['a', 'b', 'c', 'd', 'e']*10,
                             'exog_3': pd.Categorical(['F', 'G', 'H', 'I', 'J']*10)})
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_bootstrapping.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_bootstrapping.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_dist.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_dist.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_interval.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_predict_interval.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_recursive_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_recursive_predict.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_fit_kwargs.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_fit_kwargs.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_out_sample_residuals.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_out_sample_residuals.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_params.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiSeriesCustom/tests/test_set_params.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/ForecasterAutoregMultiVariate.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/ForecasterAutoregMultiVariate.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,27 +1,28 @@
 ################################################################################
 #                        ForecasterAutoregMultiVariate                         #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
 from typing import Union, Dict, List, Tuple, Any, Optional, Callable
 import warnings
 import logging
 import sys
 import numpy as np
 import pandas as pd
 import sklearn
 import sklearn.pipeline
 from sklearn.base import clone
 import inspect
-from copy import deepcopy
+from copy import copy, deepcopy
 from itertools import chain
+from joblib import Parallel, delayed, cpu_count
 
 import skforecast
 from ..ForecasterBase import ForecasterBase
 from ..exceptions import IgnoredArgumentWarning
 from ..utils import initialize_lags
 from ..utils import initialize_weights
 from ..utils import check_select_fit_kwargs
@@ -35,212 +36,176 @@
 from ..utils import preprocess_last_window
 from ..utils import preprocess_exog
 from ..utils import exog_to_direct
 from ..utils import exog_to_direct_numpy
 from ..utils import expand_index
 from ..utils import transform_series
 from ..utils import transform_dataframe
+from ..utils import select_n_jobs_fit_forecaster
 
 logging.basicConfig(
     format = '%(name)-10s %(levelname)-5s %(message)s', 
     level  = logging.INFO,
 )
 
 class ForecasterAutoregMultiVariate(ForecasterBase):
     """
     This class turns any regressor compatible with the scikit-learn API into a
     autoregressive multivariate direct multi-step forecaster. A separate model 
     is created for each forecast time step. See documentation for more details.
-    **New in version 0.6.0**
 
     Parameters
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
-
     level : str
         Name of the time series to be predicted.
-            
     steps : int
         Maximum number of future steps the forecaster will predict when using
         method `predict()`. Since a different model is created for each step,
         this value must be defined before training.
-        
     lags : int, list, numpy ndarray, range, dict
         Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
 
-        If `int`: 
-            include lags from 1 to `lags` (included).
-            
-        If `list`, `numpy ndarray` or `range`: 
-            include only lags present in `lags`, all elements must be int.
-
-        If `dict`: 
-            create different lags for each series. {'series_column_name': lags}.
-
-    transformer_series : transformer or dict of transformers, default `None`
+            - `int`: include lags from 1 to `lags` (included).
+            - `list`, `1d numpy ndarray` or `range`: include only lags present in 
+            `lags`, all elements must be int.
+            - `dict`: create different lags for each series. 
+            {'series_column_name': lags}.
+    transformer_series : transformer (preprocessor), dict, default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
-        preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
-        If a single transformer is passed, it is cloned and applied to all series.
-        If dict, a different transformer can be used for each series {'series_column_name':
-        transformer}. Transformation is applied to each series before training the forecaster.
-        ColumnTransformers are not allowed since they do not have inverse_transform method.
-
+        preprocessing API with methods: fit, transform, fit_transform and 
+        inverse_transform. Transformation is applied to each `series` before training 
+        the forecaster. ColumnTransformers are not allowed since they do not have 
+        inverse_transform method.
+
+            - If single transformer: it is cloned and applied to all series. 
+            - If `dict` of transformers: a different transformer can be used for each 
+            series.
     transformer_exog : transformer, default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
     weight_func : Callable, default `None`
         Function that defines the individual weights for each sample based on the
         index. For example, a function that assigns a lower weight to certain dates.
-        Ignored if `regressor` does not have the argument `sample_weight` in its
-        `fit` method. The resulting `sample_weight` cannot have negative values.
-
+        Ignored if `regressor` does not have the argument `sample_weight` in its `fit`
+        method. The resulting `sample_weight` cannot have negative values.
     fit_kwargs : dict, default `None`
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_fit_forecaster.
+        **New in version 0.9.0**
     forecaster_id : str, int, default `None`
         Name used as an identifier of the forecaster.
         **New in version 0.7.0**
-        
 
     Attributes
     ----------
     regressor : regressor or pipeline compatible with the scikit-learn API
         An instance of a regressor or pipeline compatible with the scikit-learn API.
         An instance of this regressor is trained for each step. All of them 
         are stored in `self.regressors_`.
-
     regressors_ : dict
         Dictionary with regressors trained for each step. They are initialized 
         as a copy of `regressor`.
-        
     steps : int
         Number of future steps the forecaster will predict when using method
         `predict()`. Since a different model is created for each step, this value
         should be defined before training.
-        
-    lags : int, list, numpy ndarray, range, dict
-        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
-
-        If `int`: 
-            include lags from 1 to `lags` (included).
-        
-        If `list`, `numpy ndarray` or `range`: 
-            include only lags present in `lags`, all elements must be int.
-
-        If `dict`: 
-            create different lags for each series. {'series_column_name': lags}.
-
+    lags : numpy ndarray, dict
+        Lags used as predictors.
     lags_ : dict
         Dictionary containing the lags of each series. Created from `lags` and 
         used internally.
-
-    transformer_series : transformer (preprocessor) or dict of transformers, default `None`
+    transformer_series : transformer (preprocessor), dict, default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
-        preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
-        If a single transformer is passed, it is cloned and applied to all series. If a
-        dict, a different transformer can be used for each series. Transformation is
-        applied to each `series` before training the forecaster.
-        ColumnTransformers are not allowed since they do not have inverse_transform method.
-        
+        preprocessing API with methods: fit, transform, fit_transform and 
+        inverse_transform. Transformation is applied to each `series` before training 
+        the forecaster. ColumnTransformers are not allowed since they do not have 
+        inverse_transform method.
+
+            - If single transformer: it is cloned and applied to all series. 
+            - If `dict` of transformers: a different transformer can be used for each 
+            series.
     transformer_series_ : dict
-        Dictionary with the transformer for each series. It is created cloning the objects
-        in `transformer_series` and is used internally to avoid overwriting.
-
-    transformer_exog : transformer, default `None`
+        Dictionary with the transformer for each series. It is created cloning the 
+        objects in `transformer_series` and is used internally to avoid overwriting.
+    transformer_exog : transformer
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
-    weight_func : Callable, default `None`
+    weight_func : Callable
         Function that defines the individual weights for each sample based on the
         index. For example, a function that assigns a lower weight to certain dates.
         Ignored if `regressor` does not have the argument `sample_weight` in its
         `fit` method. The resulting `sample_weight` cannot have negative values.
-
     source_code_weight_func : str
         Source code of the custom function used to create weights.
-
     max_lag : int
         Maximum value of lag included in `lags`.
-        
     window_size : int
         Size of the window needed to create the predictors. It is equal to
         `max_lag`.
-
     last_window : pandas Series
         Last window seen by the forecaster during training. It stores the values 
-        needed to predict the next `step` immediately after the training data.
-        
+        needed to predict the next `step` immediately after the training data.   
     index_type : type
         Type of index of the input used in training.
-        
     index_freq : str
         Frequency of Index of the input used in training.
-
     training_range: pandas Index
         First and last values of index of the data used during training.
-        
     included_exog : bool
         If the forecaster has been trained using exogenous variable/s.
-        
     exog_type : type
         Type of exogenous variable/s used in training.
-
     exog_dtypes : dict
         Type of each exogenous variable/s used in training. If `transformer_exog` 
         is used, the dtypes are calculated after the transformation.
-        
     exog_col_names : list
         Names of columns of `exog` if `exog` used in training was a pandas
         DataFrame.
-
     series_col_names : list
         Names of the series used during training.
-
     X_train_col_names : list
         Names of columns of the matrix created internally for training.
-
     fit_kwargs : dict
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
     in_sample_residuals : dict
         Residuals of the models when predicting training data. Only stored up to
         1000 values per model in the form `{step: residuals}`. If `transformer_series` 
         is not `None`, residuals are stored in the transformed scale.
-        
     out_sample_residuals : dict
         Residuals of the models when predicting non training data. Only stored
         up to 1000 values per model in the form `{step: residuals}`. If `transformer_series` 
         is not `None`, residuals are assumed to be in the transformed scale. Use 
         `set_out_sample_residuals()` method to set values.
-        
     fitted : bool
         Tag to identify if the regressor has been fitted (trained).
-
     creation_date : str
         Date of creation.
-
     fit_date : str
         Date of last fit.
-
     skforcast_version : str
         Version of skforecast library used to create the forecaster.
-
     python_version : str
         Version of python used to create the forecaster.
-
-    forecaster_id : str, int default `None`
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the fuction
+        skforecast.utils.select_n_jobs_fit_forecaster.
+        **New in version 0.9.0**
+    forecaster_id : str, int
         Name used as an identifier of the forecaster.
 
-            
     Notes
     -----
     A separate model is created for each forecasting time step. It is important to
     note that all models share the same parameter and hyperparameter configuration.
     
     """
     
@@ -250,14 +215,15 @@
         level: str,
         steps: int,
         lags: Union[int, np.ndarray, list, dict],
         transformer_series: Optional[Union[object, dict]]=None,
         transformer_exog: Optional[object]=None,
         weight_func: Optional[Callable]=None,
         fit_kwargs: Optional[dict]=None,
+        n_jobs: Optional[Union[int, str]]='auto',
         forecaster_id: Optional[Union[str, int]]=None
     ) -> None:
         
         self.regressor               = regressor
         self.level                   = level
         self.steps                   = steps
         self.transformer_series      = transformer_series
@@ -296,14 +262,19 @@
             )
 
         if steps < 1:
             raise ValueError(
                 f"`steps` argument must be greater than or equal to 1. Got {steps}."
             )
         
+        if not isinstance(n_jobs, int) and n_jobs != 'auto':
+            raise TypeError(
+                f"`n_jobs` must be an integer or `'auto'`. Got {type(n_jobs)}."
+            )
+        
         self.regressors_ = {step: clone(self.regressor) for step in range(1, steps + 1)}
 
         if isinstance(lags, dict):
             self.lags = {}
             for key in lags:
                 self.lags[key] = initialize_lags(
                                      forecaster_name = type(self).__name__,
@@ -333,14 +304,22 @@
         self.fit_kwargs = check_select_fit_kwargs(
                               regressor  = regressor,
                               fit_kwargs = fit_kwargs
                           )
 
         self.in_sample_residuals = {step: None for step in range(1, steps + 1)}
         self.out_sample_residuals = None
+
+        if n_jobs == 'auto':
+            self.n_jobs = select_n_jobs_fit_forecaster(
+                              forecaster_name = type(self).__name__,
+                              regressor_name  = type(self.regressor).__name__,
+                          )
+        else:
+            self.n_jobs = n_jobs if n_jobs > 0 else cpu_count()
     
 
     def __repr__(
         self
     ) -> str:
         """
         Information displayed when a ForecasterAutoregMultiVariate object is printed.
@@ -385,86 +364,88 @@
 
     
     def _create_lags(
         self, 
         y: np.ndarray,
         lags: np.ndarray,
     ) -> Tuple[np.ndarray, np.ndarray]:
-        """       
-        Transforms a 1d array into a 2d array (X) and a 1d array (y). Each row
+        """
+        Transforms a 1d array into a 2d array (X) and a 2d array (y). Each row
         in X is associated with a value of y and it represents the lags that
         precede it.
         
         Notice that, the returned matrix X_data, contains the lag 1 in the first
         column, the lag 2 in the second column and so on.
         
         Parameters
         ----------
-        y : 1d numpy ndarray
-            Training time series.
-
-        lags : 1d numpy ndarray
+        y : numpy ndarray
+            1d numpy ndarray Training time series.
+        lags : numpy ndarray
             lags to create.
 
-        Returns 
+        Returns
         -------
-        X_data : 2d numpy ndarray, shape (samples - max(self.lags), len(self.lags))
-            2d numpy array with the lagged values (predictors).
-        
-        y_data : 1d numpy ndarray, shape (samples - max(self.lags),)
-            Values of the time series related to each row of `X_data`.
+        X_data : numpy ndarray
+            2d numpy ndarray with the lagged values (predictors). 
+            Shape: (samples - max(self.lags), len(self.lags))
+        y_data : numpy ndarray
+            2d numpy ndarray with the values of the time series related to each 
+            row of `X_data` for each step. 
+            Shape: (len(self.steps), samples - max(self.lags))
         
         """
           
         n_splits = len(y) - self.max_lag - (self.steps - 1) # rows of y_data
         if n_splits <= 0:
             raise ValueError(
                 (f"The maximum lag ({self.max_lag}) must be less than the length "
                  f"of the series minus the number of steps ({len(y)-(self.steps-1)}).")
             )
         
         X_data = np.full(shape=(n_splits, len(lags)), fill_value=np.nan, dtype=float)
         for i, lag in enumerate(lags):
             X_data[:, i] = y[self.max_lag - lag : -(lag + self.steps - 1)] 
 
-        y_data = np.full(shape=(n_splits, self.steps), fill_value=np.nan, dtype=float)
+        y_data = np.full(shape=(self.steps, n_splits), fill_value=np.nan, dtype=float)
         for step in range(self.steps):
-            y_data[:, step] = y[self.max_lag + step : self.max_lag + step + n_splits]
+            y_data[step, ] = y[self.max_lag + step : self.max_lag + step + n_splits]
             
         return X_data, y_data
 
 
     def create_train_X_y(
         self,
         series: pd.DataFrame,
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None
-    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
+    ) -> Tuple[pd.DataFrame, dict]:
         """
         Create training matrices from multiple time series and exogenous
         variables. The resulting matrices contain the target variable and predictors
         needed to train all the regressors (one per step).
         
         Parameters
-        ----------        
+        ----------
         series : pandas DataFrame
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `series` and their indexes must be aligned.
 
-        Returns 
+        Returns
         -------
         X_train : pandas DataFrame
-            Pandas DataFrame with the training values (predictors) for each step.
-            Shape (len(series) - self.max_lag, len(self.lags)*len(series.columns) + exog.shape[1]*steps)
-            
-        y_train : pandas DataFrame, shape (len(series) - self.max_lag, )
+            Training values (predictors) for each step. Note that the index 
+            corresponds to that of the last step. It is updated for the corresponding 
+            step in the filter_train_X_y_for_step method.
+            Shape: (len(series) - self.max_lag, len(self.lags)*len(series.columns) + exog.shape[1]*steps)
+        y_train : dict
             Values (target) of the time series related to each row of `X_train` 
-            for each step.
+            for each step of the form {step: y_step_[i]}.
+            Shape of each series: (len(y) - self.max_lag, )
         
         """
 
         if not isinstance(series, pd.DataFrame):
             raise TypeError(f"`series` must be a pandas DataFrame. Got {type(series)}.")
         
         series_col_names = list(series.columns)
@@ -562,17 +543,17 @@
                     transformer       = self.transformer_series_[serie],
                     fit               = True,
                     inverse_transform = False
                 )
 
             y_values, y_index = preprocess_y(y=y)
             X_train_values, y_train_values = self._create_lags(
-                                                y    = y_values,
-                                                lags = self.lags_[serie]
-                                            )
+                                                 y    = y_values,
+                                                 lags = self.lags_[serie]
+                                             )
             if i == 0:
                 X_train = X_train_values
             else:
                 X_train = np.hstack((X_train, X_train_values))
 
             if serie == self.level:
                 y_train = y_train_values
@@ -593,82 +574,82 @@
                                 exog  = exog,
                                 steps = self.steps
                             ).iloc[-X_train.shape[0]:, :]
             X_train = pd.concat((X_train, exog_to_train), axis=1)
         
         self.X_train_col_names = X_train.columns.to_list()
 
-        y_train_col_names = [f"{self.level}_step_{i+1}" for i in range(self.steps)]
-        y_train = pd.DataFrame(
-                      data    = y_train,
-                      index   = y_index[self.max_lag + (self.steps -1): ],
-                      columns = y_train_col_names,
-                  )
+        y_train = {step: pd.Series(
+                             data  = y_train[step-1], 
+                             index = y_index[self.max_lag + step-1:][:len(y_train[0])],
+                             name  = f"{self.level}_step_{step}"
+                         )
+                   for step in range(1, self.steps + 1)}
                         
         return X_train, y_train
 
     
     def filter_train_X_y_for_step(
         self,
         step: int,
         X_train: pd.DataFrame,
-        y_train: pd.Series,
+        y_train: dict,
         remove_suffix: bool=False
     ) -> Tuple[pd.DataFrame, pd.Series]:
         """
         Select the columns needed to train a forecaster for a specific step.  
-        The input matrices should be created using `create_train_X_y()`. If 
-        `remove_suffix=True` the suffix "_step_i" will be removed from the 
-        column names.      
+        The input matrices should be created using `create_train_X_y` method. 
+        This method updates the index of `X_train` to the corresponding one 
+        according to `y_train`. If `remove_suffix=True` the suffix "_step_i" 
+        will be removed from the column names. 
 
         Parameters
         ----------
         step : int
             step for which columns must be selected selected. Starts at 1.
-
         X_train : pandas DataFrame
-            Pandas DataFrame with the training values (predictors).
-            
-        y_train : pandas Series
-            Values (target) of the time series related to each row of `X_train`.
-
+            Dataframe created with the `create_train_X_y` method, first return.
+        y_train : dict
+            Dict created with the `create_train_X_y` method, second return.
         remove_suffix : bool, default `False`
             If True, suffix "_step_i" is removed from the column names.
 
-        Returns 
+        Returns
         -------
         X_train_step : pandas DataFrame
-            Pandas DataFrame with the training values (predictors) for step.
-            
-        y_train_step : pandas Series, shape (len(y) - self.max_lag)
+            Training values (predictors) for the selected step.
+        y_train_step : pandas Series
             Values (target) of the time series related to each row of `X_train`.
+            Shape: (len(y) - self.max_lag)
 
         """
 
         if (step < 1) or (step > self.steps):
             raise ValueError(
                 (f"Invalid value `step`. For this forecaster, minimum value is 1 "
                  f"and the maximum step is {self.steps}.")
             )
 
-        # Matrices X_train and y_train start at index 0.
-        y_train_step = y_train.iloc[:, step - 1]
+        y_train_step = y_train[step]
 
+        # Matrix X_train starts at index 0.
         if not self.included_exog:
             X_train_step = X_train
         else:
             len_columns_lags = len(list(chain(*self.lags_.values())))
             idx_columns_lags = np.arange(len_columns_lags)
             n_exog = (len(self.X_train_col_names) - len_columns_lags) / self.steps
             idx_columns_exog = (
                 np.arange((step-1)*n_exog, (step)*n_exog) + idx_columns_lags[-1] + 1 
             )
             idx_columns = np.hstack((idx_columns_lags, idx_columns_exog))
             X_train_step = X_train.iloc[:, idx_columns]
 
+        X_train_step.index = y_train_step.index
+
         if remove_suffix:
             X_train_step.columns = [col_name.replace(f"_step_{step}", "")
                                     for col_name in X_train_step.columns]
             y_train_step.name = y_train_step.name.replace(f"_step_{step}", "")
 
         return  X_train_step, y_train_step
 
@@ -680,16 +661,16 @@
         """
         Crate weights for each observation according to the forecaster's attribute
         `weight_func`. 
 
         Parameters
         ----------
         X_train : pandas DataFrame
-            Dataframe generated with the methods `create_train_X_y` and 
-            `filter_train_X_y_for_step`, first return.
+            Dataframe created with `create_train_X_y` and filter_train_X_y_for_step`
+            methods, first return.
 
         Returns
         -------
         sample_weight : numpy ndarray
             Weights to use in `fit` method.
         
         """
@@ -721,30 +702,31 @@
         self,
         series: pd.DataFrame,
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
         store_in_sample_residuals: bool=True
     ) -> None:
         """
         Training Forecaster.
-        
+
+        Additional arguments to be passed to the `fit` method of the regressor 
+        can be added with the `fit_kwargs` argument when initializing the forecaster.
+
         Parameters
-        ----------        
+        ----------
         series : pandas DataFrame
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `series` and their indexes must be aligned so
             that series[i] is regressed on exog[i].
-
         store_in_sample_residuals : bool, default `True`
-            If True, in-sample residuals will be stored in the forecaster object
+            If `True`, in-sample residuals will be stored in the forecaster object
             after fitting.
 
-        Returns 
+        Returns
         -------
         None
         
         """
         
         # Reset values in case the forecaster has already been fitted.
         self.index_type          = None
@@ -755,74 +737,116 @@
         self.exog_dtypes         = None
         self.exog_col_names      = None
         self.series_col_names    = None
         self.X_train_col_names   = None
         self.in_sample_residuals = {step: None for step in range(1, self.steps + 1)}
         self.fitted              = False
         self.training_range      = None
-        
+
         self.series_col_names = list(series.columns)
 
         if exog is not None:
             self.included_exog = True
             self.exog_type = type(exog)
             self.exog_col_names = \
                 exog.columns.to_list() if isinstance(exog, pd.DataFrame) else [exog.name]
 
             if len(set(self.exog_col_names) - set(self.series_col_names)) != len(self.exog_col_names):
                 raise ValueError(
-                    (f"`exog` cannot contain a column named the same as one of the series "
-                     f"(column names of series).\n"
+                    (f"`exog` cannot contain a column named the same as one of the "
+                     f"series (column names of series).\n"
                      f"    `series` columns : {self.series_col_names}.\n"
                      f"    `exog`   columns : {self.exog_col_names}.")
                 )
 
         X_train, y_train = self.create_train_X_y(series=series, exog=exog)
-       
-        # Train one regressor for each step
-        for step in range(1, self.steps + 1):
-            # self.regressors_ and self.filter_train_X_y_for_step expect
-            # first step to start at value 1
+
+        def fit_forecaster(regressor, X_train, y_train, step, store_in_sample_residuals):
+            """
+            Auxiliary function to fit each of the forecaster's regressors in parallel.
+
+            Parameters
+            ----------
+            regressor : object
+                Regressor to be fitted.
+            X_train : pandas DataFrame
+                Dataframe created with the `create_train_X_y` method, first return.
+            y_train : dict
+                Dict created with the `create_train_X_y` method, second return.
+            step : int
+                Step of the forecaster to be fitted.
+            store_in_sample_residuals : bool
+                If `True`, in-sample residuals will be stored in the forecaster object
+                after fitting.
+            
+            Returns
+            -------
+            Tuple with the step, fitted regressor and in-sample residuals.
+
+            """
+
             X_train_step, y_train_step = self.filter_train_X_y_for_step(
                                              step          = step,
                                              X_train       = X_train,
                                              y_train       = y_train,
                                              remove_suffix = True
                                          )
             sample_weight = self.create_sample_weights(X_train=X_train_step)
             if sample_weight is not None:
-                self.regressors_[step].fit(
+                regressor.fit(
                     X             = X_train_step,
                     y             = y_train_step,
                     sample_weight = sample_weight,
                     **self.fit_kwargs
                 )
             else:
-                self.regressors_[step].fit(
-                    X = X_train_step, 
-                    y = y_train_step, 
+                regressor.fit(
+                    X = X_train_step,
+                    y = y_train_step,
                     **self.fit_kwargs
                 )
 
             # This is done to save time during fit in functions such as backtesting()
             if store_in_sample_residuals:
                 residuals = (
-                    (y_train_step - self.regressors_[step].predict(X_train_step))
+                    (y_train_step - regressor.predict(X_train_step))
                 ).to_numpy()
 
                 if len(residuals) > 1000:
                     # Only up to 1000 residuals are stored
-                    rng = np.random.default_rng(seed=123)
-                    residuals = rng.choice(
-                                    a       = residuals, 
-                                    size    = 1000, 
-                                    replace = False
-                                )
+                        rng = np.random.default_rng(seed=123)
+                        residuals = rng.choice(
+                                        a       = residuals, 
+                                        size    = 1000, 
+                                        replace = False
+                                    )
+            else:
+                residuals = None
 
-                self.in_sample_residuals[step] = residuals
+            return step, regressor, residuals
+
+        results_fit = (
+            Parallel(n_jobs=self.n_jobs)
+            (delayed(fit_forecaster)
+            (
+                regressor=copy(self.regressor),
+                X_train=X_train,
+                y_train=y_train,
+                step=step,
+                store_in_sample_residuals=store_in_sample_residuals
+            )
+            for step in range(1, self.steps + 1))
+        )
+
+        self.regressors_ = {step: regressor 
+                            for step, regressor, _ in results_fit}
+
+        if store_in_sample_residuals:
+            self.in_sample_residuals = {step: residuals 
+                                        for step, _, residuals in results_fit}
         
         self.fitted = True
         self.fit_date = pd.Timestamp.today().strftime('%Y-%m-%d %H:%M:%S')
         self.training_range = preprocess_y(
                                 y = series[self.level],
                                 return_values = False
                               )[1][[0, -1]]
@@ -847,34 +871,27 @@
 
         Parameters
         ----------
         steps : int, list, None, default `None`
             Predict n steps. The value of `steps` must be less than or equal to the 
             value of steps defined when initializing the forecaster. Starts at 1.
         
-            If `int`:
-                Only steps within the range of 1 to int are predicted.
-        
-            If `list`:
-                List of ints. Only the steps contained in the list are predicted.
-
-            If `None`:
-                As many steps are predicted as were defined at initialization.
-
+                - If `int`: Only steps within the range of 1 to int are predicted.
+                - If `list`: List of ints. Only the steps contained in the list 
+                are predicted.
+                - If `None`: As many steps are predicted as were defined at 
+                initialization.
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-
             If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-
         levels : Ignored
             Not used, present here for API consistency by convention.
 
         Returns
         -------
         predictions : pandas DataFrame
             Predicted values.
@@ -1012,61 +1029,52 @@
         """
         Generate multiple forecasting predictions using a bootstrapping process. 
         By sampling from a collection of past observed errors (the residuals),
         each iteration of bootstrapping generates a different set of predictions. 
         See the Notes section for more information. 
         
         Parameters
-        ----------   
+        ----------
         steps : int, list, None, default `None`
             Predict n steps. The value of `steps` must be less than or equal to the 
             value of steps defined when initializing the forecaster. Starts at 1.
         
-            If `int`:
-                Only steps within the range of 1 to int are predicted.
-        
-            If `list`:
-                List of ints. Only the steps contained in the list are predicted.
-
-            If `None`:
-                As many steps are predicted as were defined at initialization.
-
+                - If `int`: Only steps within the range of 1 to int are predicted.
+                - If `list`: List of ints. Only the steps contained in the list 
+                are predicted.
+                - If `None`: As many steps are predicted as were defined at 
+                initialization.
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
-            Exogenous variable/s included as predictor/s.
-            
+            Exogenous variable/s included as predictor/s.     
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
-            deterministic.
-                        
+            deterministic.               
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
-
         levels : Ignored
             Not used, present here for API consistency by convention.
 
-        Returns 
+        Returns
         -------
-        boot_predictions : pandas DataFrame, shape (steps, n_boot)
+        boot_predictions : pandas DataFrame
             Predictions generated by bootstrapping.
+            Shape: (steps, n_boot)
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp3/prediction-intervals.html#prediction-intervals-from-bootstrapped-residuals
         Forecasting: Principles and Practice (3nd ed) Rob J Hyndman and George Athanasopoulos.
 
@@ -1131,16 +1139,16 @@
                           transformer       = self.transformer_series_[self.level],
                           fit               = False,
                           inverse_transform = False
                       )
         boot_predictions = pd.concat([predictions] * n_boot, axis=1)
         boot_predictions.columns= [f"pred_boot_{i}" for i in range(n_boot)]
 
-        rng = np.random.default_rng(seed=random_state)
         for i, step in enumerate(steps):
+            rng = np.random.default_rng(seed=random_state)
             sample_residuals = rng.choice(
                                    a       = residuals[step],
                                    size    = n_boot,
                                    replace = True
                                )
             boot_predictions.iloc[i, :] = boot_predictions.iloc[i, :] + sample_residuals
 
@@ -1168,78 +1176,67 @@
         levels: Any=None
     ) -> pd.DataFrame:
         """
         Bootstrapping based prediction intervals.
         Both predictions and intervals are returned.
         
         Parameters
-        ---------- 
+        ----------
         steps : int, list, None, default `None`
             Predict n steps. The value of `steps` must be less than or equal to the 
             value of steps defined when initializing the forecaster. Starts at 1.
         
-            If `int`:
-                Only steps within the range of 1 to int are predicted.
-        
-            If `list`:
-                List of ints. Only the steps contained in the list are predicted.
-
-            If `None`:
-                As many steps are predicted as were defined at initialization.
-
+                - If `int`: Only steps within the range of 1 to int are predicted.
+                - If `list`: List of ints. Only the steps contained in the list 
+                are predicted.
+                - If `None`: As many steps are predicted as were defined at 
+                initialization.
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         interval : list, default `[5, 95]`
             Confidence of the prediction interval estimated. Sequence of 
             percentiles to compute, which must be between 0 and 100 inclusive. 
             For example, interval of 95% should be as `interval = [2.5, 97.5]`.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
-
         levels : Ignored
             Not used, present here for API consistency by convention.
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
-            Values predicted by the forecaster and their estimated interval:
+            Values predicted by the forecaster and their estimated interval.
 
-            - pred: predictions.
-            - lower_bound: lower bound of the interval.
-            - upper_bound: upper bound interval of the interval.
+                - pred: predictions.
+                - lower_bound: lower bound of the interval.
+                - upper_bound: upper bound of the interval.
 
         Notes
         -----
         More information about prediction intervals in forecasting:
         https://otexts.com/fpp2/prediction-intervals.html
         Forecasting: Principles and Practice (2nd ed) Rob J Hyndman and
         George Athanasopoulos.
-            
+        
         """
 
         check_interval(interval=interval)
 
         predictions = self.predict(
                           steps       = steps,
                           last_window = last_window,
@@ -1276,61 +1273,50 @@
     ) -> pd.DataFrame:
         """
         Fit a given probability distribution for each step. After generating 
         multiple forecasting predictions through a bootstrapping process, each 
         step is fitted to the given distribution.
         
         Parameters
-        ---------- 
+        ----------
         distribution : Object
             A distribution object from scipy.stats.
-        
         steps : int, list, None, default `None`
             Predict n steps. The value of `steps` must be less than or equal to the 
             value of steps defined when initializing the forecaster. Starts at 1.
         
-            If `int`:
-                Only steps within the range of 1 to int are predicted.
-        
-            If `list`:
-                List of ints. Only the steps contained in the list are predicted.
-
-            If `None`:
-                As many steps are predicted as were defined at initialization.
-            
+                - If `int`: Only steps within the range of 1 to int are predicted.
+                - If `list`: List of ints. Only the steps contained in the list 
+                are predicted.
+                - If `None`: As many steps are predicted as were defined at 
+                initialization.
         last_window : pandas DataFrame, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
             If `last_window = None`, the values stored in` self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         n_boot : int, default `500`
             Number of bootstrapping iterations used to estimate prediction
             intervals.
-
         random_state : int, default `123`
             Sets a seed to the random generator, so that boot intervals are always 
             deterministic.
-            
         in_sample_residuals : bool, default `True`
             If `True`, residuals from the training data are used as proxy of
             prediction error to create prediction intervals. If `False`, out of
             sample residuals are used. In the latter case, the user should have
             calculated and stored the residuals within the forecaster (see
             `set_out_sample_residuals()`).
-
         levels : Ignored
             Not used, present here for API consistency by convention.
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
             Distribution parameters estimated for each step.
 
         """
         
         boot_samples = self.predict_bootstrapping(
@@ -1368,17 +1354,17 @@
         configuration of parameters and hyperparameters.
         
         Parameters
         ----------
         params : dict
             Parameters values.
 
-        Returns 
+        Returns
         -------
-        self
+        None
         
         """
 
         self.regressor = clone(self.regressor)
         self.regressor.set_params(**params)
         self.regressors_ = {step: clone(self.regressor)
                             for step in range(1, self.steps + 1)}
@@ -1393,15 +1379,15 @@
         method of the regressor.
         
         Parameters
         ----------
         fit_kwargs : dict
             Dict of the form {"argument": new_value}.
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         self.fit_kwargs = check_select_fit_kwargs(self.regressor, fit_kwargs=fit_kwargs)
         
@@ -1412,27 +1398,24 @@
     ) -> None:
         """      
         Set new value to the attribute `lags`.
         Attributes `max_lag` and `window_size` are also updated.
         
         Parameters
         ----------
-        lags : int, list, 1d numpy ndarray, range, dict
+        lags : int, list, numpy ndarray, range, dict
             Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
 
-            If `int`: 
-                include lags from 1 to `lags` (included).
-            
-            If `list`, `numpy ndarray` or `range`: 
-                include only lags present in `lags`, all elements must be int.
-
-            If `dict`: 
-                create different lags for each series. {'series_column_name': lags}.
+                - `int`: include lags from 1 to `lags` (included).
+                - `list`, `1d numpy ndarray` or `range`: include only lags present in 
+                `lags`, all elements must be int.
+                - `dict`: create different lags for each series. 
+                {'series_column_name': lags}.
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         if isinstance(lags, dict):
             self.lags = {}
@@ -1469,48 +1452,46 @@
         
         Parameters
         ----------
         residuals : dict
             Dictionary of numpy ndarrays with the residuals of each model in the
             form {step: residuals}. If len(residuals) > 1000, only a random 
             sample of 1000 values are stored.
-            
         append : bool, default `True`
             If `True`, new residuals are added to the once already stored in the
             attribute `out_sample_residuals`. Once the limit of 1000 values is
             reached, no more values are appended. If False, `out_sample_residuals`
             is overwritten with the new residuals.
-
         transform : bool, default `True`
             If `True`, new residuals are transformed using self.transformer_y.
-
         random_state : int, default `123`
             Sets a seed to the random sampling for reproducible output.
-            
-        Returns 
+
+        Returns
         -------
-        self
+        None
 
         """
 
         if not isinstance(residuals, dict) or not all(isinstance(x, np.ndarray) for x in residuals.values()):
             raise TypeError(
-                f"`residuals` argument must be a dict of numpy ndarrays in the form "
-                "`{step: residuals}`. " 
-                f"Got {type(residuals)}."
+                (f"`residuals` argument must be a dict of numpy ndarrays in the form "
+                 "`{step: residuals}`. " 
+                 f"Got {type(residuals)}.")
             )
 
         if not self.fitted:
             raise sklearn.exceptions.NotFittedError(
                 ("This forecaster is not fitted yet. Call `fit` with appropriate "
                  "arguments before using `set_out_sample_residuals()`.")
             )
         
         if self.out_sample_residuals is None:
-            self.out_sample_residuals = {step: None for step in range(1, self.steps + 1)}
+            self.out_sample_residuals = {step: None 
+                                         for step in range(1, self.steps + 1)}
         
         if not set(self.out_sample_residuals.keys()).issubset(set(residuals.keys())):
             warnings.warn(
                 (f"""
                 Only residuals of models (steps) 
                 {set(self.out_sample_residuals.keys()).intersection(set(residuals.keys()))} 
                 are updated.
@@ -1638,42 +1619,8 @@
 
         if feature_importances is not None:
             feature_importances = pd.DataFrame({
                                       'feature': feature_names,
                                       'importance': feature_importances
                                   })
 
-        return feature_importances
-
-
-    def get_feature_importance(
-        self,
-        step: int
-    ) -> pd.DataFrame:
-        """
-        This method has been replaced by `get_feature_importances()`.
-
-        Return impurity-based feature importance of the model stored in
-        the forecaster for a specific step. Since a separate model is created for
-        each forecast time step, it is necessary to select the model from which
-        retrieve information. Only valid when regressor stores internally the 
-        feature importances in the attribute `feature_importances_` or `coef_`.
-
-        Parameters
-        ----------
-        step : int
-            Model from which retrieve information (a separate model is created 
-            for each forecast time step). First step is 1.
-
-        Returns
-        -------
-        feature_importances : pandas DataFrame
-            Feature importances associated with each predictor.
-        
-        """
-
-        warnings.warn(
-            ("get_feature_importance() method has been renamed to get_feature_importances()."
-             "This method will be removed in skforecast 0.9.0.")
-        )
-
-        return self.get_feature_importances(step=step)
+        return feature_importances
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/fixtures_ForecasterAutoregMultiVariate.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/fixtures_ForecasterAutoregMultiVariate.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_create_lags.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_create_lags.py`

 * *Files 7% similar despite different names*

```diff
@@ -35,21 +35,16 @@
     expected = (np.array([[2., 1., 0.],
                           [3., 2., 1.],
                           [4., 3., 2.],
                           [5., 4., 3.],
                           [6., 5., 4.],
                           [7., 6., 5.],
                           [8., 7., 6.]]),
-                np.array([[3.],
-                          [4.],
-                          [5.],
-                          [6.],
-                          [7.],
-                          [8.],
-                          [9.]]))
+                np.array([[3., 4., 5., 6., 7., 8., 9.]])
+                )
 
     assert (results[0] == expected[0]).all()
     assert (results[1] == expected[1]).all()
 
   
 def test_create_lags_when_lags_is_list_interspersed_lags_steps_1_and_y_is_numpy_arange_10():
     """
@@ -60,19 +55,16 @@
                                                lags=[1, 5], steps=1)
     results = forecaster._create_lags(y=np.arange(10), lags=np.array([1, 5]))
     expected = (np.array([[4., 0.],
                           [5., 1.],
                           [6., 2.],
                           [7., 3.],
                           [8., 4.]]),
-                np.array([[5.],
-                          [6.],
-                          [7.],
-                          [8.],
-                          [9.]]))
+                np.array([[5., 6., 7., 8., 9.]])
+                )
 
     assert (results[0] == expected[0]).all()
     assert (results[1] == expected[1]).all()
 
 
 def test_create_lags_when_lags_is_3_steps_2_and_y_is_numpy_arange_10():
     """
@@ -84,20 +76,17 @@
     results = forecaster._create_lags(y=np.arange(10), lags=np.array([1, 2, 3]))
     expected = (np.array([[2., 1., 0.],
                           [3., 2., 1.],
                           [4., 3., 2.],
                           [5., 4., 3.],
                           [6., 5., 4.],
                           [7., 6., 5.]]),
-                np.array([[3., 4.],
-                          [4., 5.],
-                          [5., 6.],
-                          [6., 7.],
-                          [7., 8.],
-                          [8., 9.]]))
+                np.array([[3., 4., 5., 6., 7., 8.],
+                          [4., 5., 6., 7., 8., 9.]])
+                )
 
     assert (results[0] == expected[0]).all()
     assert (results[1] == expected[1]).all()
 
 
 def test_create_lags_when_lags_is_3_steps_5_and_y_is_numpy_arange_10():
     """
@@ -106,13 +95,16 @@
     """
     forecaster = ForecasterAutoregMultiVariate(LinearRegression(), level= 'l1', 
                                                lags=3, steps=5)
     results = forecaster._create_lags(y=np.arange(10), lags=np.array([1, 2, 3]))
     expected = (np.array([[2., 1., 0.],
                           [3., 2., 1.],
                           [4., 3., 2.]]),
-                np.array([[3., 4., 5., 6., 7.],
-                          [4., 5., 6., 7., 8.],
-                          [5., 6., 7., 8., 9.]]))
+                np.array([[3., 4., 5.],
+                          [4., 5., 6.],
+                          [5., 6., 7.],
+                          [6., 7., 8.],
+                          [7., 8., 9.]])
+                )
 
     assert (results[0] == expected[0]).all()
     assert (results[1] == expected[1]).all()
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_create_sample_weights.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_create_sample_weights.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_create_train_X_y.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_create_train_X_y.py`

 * *Files 9% similar despite different names*

```diff
@@ -212,28 +212,35 @@
                              [6., 5., 4., 106., 105., 104.],
                              [7., 6., 5., 107., 106., 105.],
                              [8., 7., 6., 108., 107., 106.]], dtype=float),
             index   = pd.RangeIndex(start=3, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3',
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3']
         ),
-        pd.DataFrame(
-            data    = np.array(expected_y_values, dtype=float),
-            index   = pd.RangeIndex(start=3, stop=10, step=1),
-            columns = [f'{level}_step_1'])
+        {1: pd.Series(
+                data  = np.array(expected_y_values, dtype=float), 
+                index = pd.RangeIndex(start=3, stop=10, step=1),
+                name  = f'{level}_step_1'
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("level, expected_y_values", 
-                         [('l1', [[3., 4.], [4., 5.], [5., 6.], [6., 7.], [7., 8.], [8., 9.]]), 
-                          ('l2', [[103., 104.], [104., 105.], [105., 106.], 
-                                  [106., 107.], [107., 108.], [108., 109.]])])
+                         [('l1', ([3., 4., 5., 6., 7., 8.], 
+                                  [4., 5., 6., 7., 8., 9.])), 
+                          ('l2', ([103., 104., 105., 106., 107., 108.], 
+                                  [104., 105., 106., 107., 108., 109.]))])
 def test_create_train_X_y_output_when_interspersed_lags_steps_2_and_exog_is_None(level, expected_y_values):
     """
     Test output of create_train_X_y when regressor is LinearRegression, 
     interspersed lags and steps is 2.
     """
     series = pd.DataFrame({'l1': pd.Series(np.arange(10), dtype=float), 
                            'l2': pd.Series(np.arange(100, 110), dtype=float)})
@@ -251,28 +258,40 @@
                              [5., 3., 105., 103.],
                              [6., 4., 106., 104.],
                              [7., 5., 107., 105.]], dtype=float),
             index   = pd.RangeIndex(start=4, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_3',
                        'l2_lag_1', 'l2_lag_3']
         ),
-        pd.DataFrame(
-            data    = np.array(expected_y_values, dtype=float),
-            index   = pd.RangeIndex(start=4, stop=10, step=1),
-            columns = [f'{level}_step_1', f'{level}_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array(expected_y_values[0], dtype=float), 
+                index = pd.RangeIndex(start=3, stop=9, step=1),
+                name  = f'{level}_step_1'
+            ),
+         2: pd.Series(
+                data  = np.array(expected_y_values[1], dtype=float), 
+                index = pd.RangeIndex(start=4, stop=10, step=1),
+                name  = f'{level}_step_2'
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("level, expected_y_values", 
-                         [('l1', [[5., 6.], [6., 7.], [7., 8.], [8., 9.]]), 
-                          ('l2', [[105., 106.], [106., 107.], [107., 108.], [108., 109.]])])
+                         [('l1', ([5., 6., 7., 8.], 
+                                  [6., 7., 8., 9.])), 
+                          ('l2', ([105., 106., 107., 108.], 
+                                  [106., 107., 108., 109.]))])
 def test_create_train_X_y_output_when_different_lags_steps_2_and_exog_is_None(level, expected_y_values):
     """
     Test output of create_train_X_y when regressor is LinearRegression, 
     different lags and steps is 2.
     """
     series = pd.DataFrame({'l1': pd.Series(np.arange(10)), 
                            'l2': pd.Series(np.arange(100, 110))})
@@ -289,23 +308,33 @@
                              [5., 4., 3., 105., 101.],
                              [6., 5., 4., 106., 102.],
                              [7., 6., 5., 107., 103.]], dtype=float),
             index   = pd.RangeIndex(start=6, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3',
                        'l2_lag_1', 'l2_lag_5']
         ),
-        pd.DataFrame(
-            data    = np.array(expected_y_values, dtype=float),
-            index   = pd.RangeIndex(start=6, stop=10, step=1),
-            columns = [f'{level}_step_1', f'{level}_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array(expected_y_values[0], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=9, step=1),
+                name  = f'{level}_step_1'
+            ),
+         2: pd.Series(
+                data  = np.array(expected_y_values[1], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=10, step=1),
+                name  = f'{level}_step_2'
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("dtype", 
                          [float, int], 
                          ids = lambda dt : f'dtype: {dt}')
 def test_create_train_X_y_output_when_lags_5_steps_1_and_exog_is_series_of_float_int(dtype):
     """
@@ -329,27 +358,28 @@
                              [8., 7., 6., 5., 4., 58., 57., 56., 55., 54., 109.]], 
                              dtype=float),
             index = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5',
                        'exog_step_1']
         ).astype({'exog_step_1': dtype}),
-        pd.DataFrame(
-            data = np.array([[5.],
-                             [6.],
-                             [7.],
-                             [8.],
-                             [9.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['l1_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "l1_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("dtype", 
                          [float, int], 
                          ids = lambda dt : f'dtype: {dt}')
 def test_create_train_X_y_output_when_lags_5_steps_2_and_exog_is_series_of_float_int(dtype):
     """
@@ -372,26 +402,33 @@
                              [7., 6., 5., 4., 3., 57., 56., 55., 54., 53., 108., 109.]], 
                              dtype=float),
             index = pd.RangeIndex(start=6, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5',
                        'exog_step_1', 'exog_step_2']
         ).astype({'exog_step_1': dtype, 'exog_step_2': dtype}),
-        pd.DataFrame(
-            data = np.array([[5., 6.],
-                             [6., 7.],
-                             [7., 8.],
-                             [8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=6, stop=10, step=1),
-            columns = ['l1_step_1', 'l1_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=9, step=1),
+                name  = "l1_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=10, step=1),
+                name  = "l1_step_2"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("dtype", 
                          [float, int], 
                          ids = lambda dt : f'dtype: {dt}')
 def test_create_train_X_y_output_when_lags_5_steps_1_and_exog_is_dataframe_of_float_int(dtype):
     """
@@ -416,27 +453,28 @@
                              [8., 7., 6., 5., 4., 58., 57., 56., 55., 54., 109., 1009.]], 
                              dtype=float),
             index = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5',
                        'exog_1_step_1', 'exog_2_step_1']
         ).astype({'exog_1_step_1': dtype, 'exog_2_step_1': dtype}),
-        pd.DataFrame(
-            data = np.array([[55.],
-                             [56.],
-                             [57.],
-                             [58.],
-                             [59.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['l2_step_1']
-        )      
+        {1: pd.Series(
+                data  = np.array([55., 56., 57., 58., 59.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "l2_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("dtype", 
                          [float, int], 
                          ids = lambda dt : f'dtype: {dt}')
 def test_create_train_X_y_output_when_lags_5_steps_3_and_exog_is_dataframe_of_float_int(dtype):
     """
@@ -463,25 +501,38 @@
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5',
                        'exog_1_step_1', 'exog_2_step_1', 
                        'exog_1_step_2', 'exog_2_step_2', 
                        'exog_1_step_3', 'exog_2_step_3']
         ).astype({'exog_1_step_1': dtype, 'exog_2_step_1': dtype, 
                   'exog_1_step_2': dtype, 'exog_2_step_2': dtype, 
                   'exog_1_step_3': dtype, 'exog_2_step_3': dtype}),
-        pd.DataFrame(
-            data = np.array([[55., 56., 57.],
-                             [56., 57., 58.],
-                             [57., 58., 59.]], dtype=float),
-            index = pd.RangeIndex(start=7, stop=10, step=1),
-            columns = ['l2_step_1', 'l2_step_2', 'l2_step_3']
-        )
+        {1: pd.Series(
+                data  = np.array([55., 56., 57.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=8, step=1),
+                name  = "l2_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([56., 57., 58.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=9, step=1),
+                name  = "l2_step_2"
+            ),
+         3: pd.Series(
+                data  = np.array([57., 58., 59.], dtype=float), 
+                index = pd.RangeIndex(start=7, stop=10, step=1),
+                name  = "l2_step_3"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("exog_values, dtype", 
                          [([True]    , bool), 
                           (['string'], str)], 
                          ids = lambda dt : f'values, dtype: {dt}')
 def test_create_train_X_y_output_when_lags_5_steps_1_and_exog_is_series_of_bool_str(exog_values, dtype):
@@ -505,27 +556,28 @@
                              [7., 6., 5., 4., 3., 57., 56., 55., 54., 53.],
                              [8., 7., 6., 5., 4., 58., 57., 56., 55., 54.]], 
                              dtype=float),
             index = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5']
         ).assign(exog_step_1=exog_values*5).astype({'exog_step_1': dtype}),
-        pd.DataFrame(
-            data = np.array([[5.],
-                             [6.],
-                             [7.],
-                             [8.],
-                             [9.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['l1_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "l1_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("exog_values, dtype", 
                          [([True]    , bool), 
                           (['string'], str)], 
                          ids = lambda dt : f'values, dtype: {dt}')
 def test_create_train_X_y_output_when_lags_5_steps_2_and_exog_is_series_of_bool_str(exog_values, dtype):
@@ -550,26 +602,33 @@
                              dtype=float),
             index = pd.RangeIndex(start=6, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5']
         ).assign(exog_step_1=exog_values*4,
                  exog_step_2=exog_values*4).astype({'exog_step_1': dtype, 
                                                     'exog_step_2': dtype}),
-        pd.DataFrame(
-            data = np.array([[5., 6.],
-                             [6., 7.],
-                             [7., 8.],
-                             [8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=6, stop=10, step=1),
-            columns = ['l1_step_1', 'l1_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=9, step=1),
+                name  = "l1_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=10, step=1),
+                name  = "l1_step_2"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("v_exog_1   , v_exog_2  , dtype", 
                          [([True]    , [False]   , bool), 
                           (['string'], ['string'], str)], 
                          ids = lambda dt : f'values, dtype: {dt}')
 def test_create_train_X_y_output_when_lags_5_steps_1_and_exog_is_dataframe_of_bool_str(v_exog_1, v_exog_2, dtype):
@@ -596,27 +655,28 @@
                              dtype=float),
             index = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5']
         ).assign(exog_1_step_1=v_exog_1*5,
                  exog_2_step_1=v_exog_2*5).astype({'exog_1_step_1': dtype, 
                                                    'exog_2_step_1': dtype}),
-        pd.DataFrame(
-            data = np.array([[55.],
-                             [56.],
-                             [57.],
-                             [58.],
-                             [59.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['l2_step_1']
-        )      
+        {1: pd.Series(
+                data  = np.array([55., 56., 57., 58., 59.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "l2_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("v_exog_1   , v_exog_2  , dtype", 
                          [([True]    , [False]   , bool), 
                           (['string'], ['string'], str)], 
                          ids = lambda dt : f'values, dtype: {dt}')
 def test_create_train_X_y_output_when_lags_5_steps_3_and_exog_is_dataframe_of_bool_str(v_exog_1, v_exog_2, dtype):
@@ -648,25 +708,38 @@
                  exog_2_step_2=v_exog_2*3,
                  exog_1_step_3=v_exog_1*3,
                  exog_2_step_3=v_exog_2*3
         ).astype({'exog_1_step_1': dtype, 'exog_2_step_1': dtype, 
                   'exog_1_step_2': dtype, 'exog_2_step_2': dtype, 
                   'exog_1_step_3': dtype, 'exog_2_step_3': dtype}
         ),
-        pd.DataFrame(
-            data = np.array([[55., 56., 57.],
-                             [56., 57., 58.],
-                             [57., 58., 59.]], dtype=float),
-            index = pd.RangeIndex(start=7, stop=10, step=1),
-            columns = ['l2_step_1', 'l2_step_2', 'l2_step_3']
-        )
+        {1: pd.Series(
+                data  = np.array([55., 56., 57.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=8, step=1),
+                name  = "l2_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([56., 57., 58.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=9, step=1),
+                name  = "l2_step_2"
+            ),
+         3: pd.Series(
+                data  = np.array([57., 58., 59.], dtype=float), 
+                index = pd.RangeIndex(start=7, stop=10, step=1),
+                name  = "l2_step_3"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_lags_5_steps_1_and_exog_is_series_of_category():
     """
     Test output of create_train_X_y when regressor is LinearRegression, 
     lags is 5, steps is 1 and exog is pandas Series of category.
     """
@@ -686,27 +759,28 @@
                              [7., 6., 5., 4., 3., 57., 56., 55., 54., 53.],
                              [8., 7., 6., 5., 4., 58., 57., 56., 55., 54.]], 
                              dtype=float),
             index = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5']
         ).assign(exog_step_1=pd.Categorical(range(5, 10), categories=range(10))),
-        pd.DataFrame(
-            data = np.array([[5.],
-                             [6.],
-                             [7.],
-                             [8.],
-                             [9.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['l1_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "l1_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_lags_5_steps_2_and_exog_is_series_of_category():
     """
     Test output of create_train_X_y when regressor is LinearRegression, 
     lags is 5, steps is 2 and exog is pandas Series of category.
     """
@@ -726,26 +800,33 @@
                              [7., 6., 5., 4., 3., 57., 56., 55., 54., 53.]], 
                              dtype=float),
             index = pd.RangeIndex(start=6, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5']
         ).assign(exog_step_1=pd.Categorical(range(5, 9), categories=range(10)),
                  exog_step_2=pd.Categorical(range(6, 10), categories=range(10))),
-        pd.DataFrame(
-            data = np.array([[5., 6.],
-                             [6., 7.],
-                             [7., 8.],
-                             [8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=6, stop=10, step=1),
-            columns = ['l1_step_1', 'l1_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=9, step=1),
+                name  = "l1_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=10, step=1),
+                name  = "l1_step_2"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_lags_5_steps_1_and_exog_is_dataframe_of_category():
     """
     Test output of create_train_X_y when regressor is LinearRegression, 
     lags is 5, steps is 1 and exog is pandas DataFrame of category.
     """
@@ -769,27 +850,28 @@
             index = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5']
         ).assign(
             exog_1_step_1=pd.Categorical(range(5, 10), categories=range(10)),
             exog_2_step_1=pd.Categorical(range(105, 110), categories=range(100, 110))
         ),
-        pd.DataFrame(
-            data = np.array([[55.],
-                             [56.],
-                             [57.],
-                             [58.],
-                             [59.]], dtype=float),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['l2_step_1']
-        )      
+        {1: pd.Series(
+                data  = np.array([55., 56., 57., 58., 59.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "l2_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_lags_5_steps_3_and_exog_is_dataframe_of_category():
     """
     Test output of create_train_X_y when regressor is LinearRegression, 
     lags is 5, steps is 3 and exog is pandas DataFrame of category.
     """
@@ -815,25 +897,38 @@
             exog_1_step_1=pd.Categorical(range(5, 8), categories=range(10)),
             exog_2_step_1=pd.Categorical(range(105, 108), categories=range(100, 110)),
             exog_1_step_2=pd.Categorical(range(6, 9), categories=range(10)),
             exog_2_step_2=pd.Categorical(range(106, 109), categories=range(100, 110)),
             exog_1_step_3=pd.Categorical(range(7, 10), categories=range(10)),
             exog_2_step_3=pd.Categorical(range(107, 110), categories=range(100, 110))
         ),
-        pd.DataFrame(
-            data = np.array([[55., 56., 57.],
-                             [56., 57., 58.],
-                             [57., 58., 59.]], dtype=float),
-            index = pd.RangeIndex(start=7, stop=10, step=1),
-            columns = ['l2_step_1', 'l2_step_2', 'l2_step_3']
-        )
+        {1: pd.Series(
+                data  = np.array([55., 56., 57.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=8, step=1),
+                name  = "l2_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([56., 57., 58.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=9, step=1),
+                name  = "l2_step_2"
+            ),
+         3: pd.Series(
+                data  = np.array([57., 58., 59.], dtype=float), 
+                index = pd.RangeIndex(start=7, stop=10, step=1),
+                name  = "l2_step_3"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_y_is_series_10_and_exog_is_dataframe_of_float_int_category_steps_1():
     """
     Test output of create_train_X_y when regressor is LinearRegression, 
     lags is 5, steps is 1 and exog is pandas DataFrame of float, int and category.
     """
@@ -855,24 +950,30 @@
                              [8., 7., 6., 5., 4., 58., 57., 56., 55., 54., 109., 1009.]], 
                              dtype=float),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5',
                        'exog_1_step_1', 'exog_2_step_1']
         ).astype({'exog_1_step_1': float, 
-                  'exog_2_step_1': int}).assign(exog_3_step_1=pd.Categorical(range(105, 110), categories=range(100, 110))),
-        pd.DataFrame(
-            data    = np.array([5, 6, 7, 8, 9], dtype=float),
-            index   = pd.RangeIndex(start=5, stop=10, step=1),
-            columns = ['l1_step_1']
-        )
+                  'exog_2_step_1': int}).assign(exog_3_step_1=pd.Categorical(range(105, 110), categories=range(100, 110))
+        ),
+        {1: pd.Series(
+                data  = np.array([5., 6., 7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "l1_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 def test_create_train_X_y_output_when_y_is_series_10_and_exog_is_dataframe_of_float_int_category_steps_3():
     """
     Test output of create_train_X_y when regressor is LinearRegression, 
     lags is 5, steps is 3 and exog is pandas DataFrame of float, int and category.
     """
@@ -900,25 +1001,38 @@
         ).astype({'exog_1_step_1': float, 'exog_2_step_1': int,
                   'exog_1_step_2': float, 'exog_2_step_2': int,
                   'exog_1_step_3': float, 'exog_2_step_3': int}
         ).assign(exog_3_step_1=pd.Categorical(range(105, 108), categories=range(100, 110)),
                  exog_3_step_2=pd.Categorical(range(106, 109), categories=range(100, 110)),
                  exog_3_step_3=pd.Categorical(range(107, 110), categories=range(100, 110))
         ),
-        pd.DataFrame(
-            data = np.array([[5., 6., 7.],
-                             [6., 7., 8.],
-                             [7., 8., 9.]], dtype=float),
-            index = pd.RangeIndex(start=7, stop=10, step=1),
-            columns = ['l1_step_1', 'l1_step_2', 'l1_step_3']
-        )
+        {1: pd.Series(
+                data  = np.array([5., 6., 7.], dtype=float), 
+                index = pd.RangeIndex(start=5, stop=8, step=1),
+                name  = "l1_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([6., 7., 8.], dtype=float), 
+                index = pd.RangeIndex(start=6, stop=9, step=1),
+                name  = "l1_step_2"
+            ),
+         3: pd.Series(
+                data  = np.array([7., 8., 9.], dtype=float), 
+                index = pd.RangeIndex(start=7, stop=10, step=1),
+                name  = "l1_step_3"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("transformer_series", 
                          [StandardScaler(),
                           {'l1': StandardScaler(), 'l2': StandardScaler()}], 
                          ids = lambda tr : f'transformer_series: {tr}')
 def test_create_train_X_y_output_when_lags_5_steps_1_and_transformer_series_StandardScaler(transformer_series):
@@ -950,27 +1064,29 @@
                                0.87038828,  0.52223297,  0.17407766, -0.17407766, -0.52223297],
                              [ 1.21854359,  0.87038828,  0.52223297,  0.17407766, -0.17407766,
                                1.21854359,  0.87038828,  0.52223297,  0.17407766, -0.17407766]]),
             index   = pd.RangeIndex(start=5, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5']
         ),
-        pd.DataFrame(
-            data  = np.array([[0.17407766],
-                              [0.52223297],
-                              [0.87038828],
-                              [1.21854359],
-                              [1.5666989 ]]),
-            index = pd.RangeIndex(start=5, stop=10, step=1),
-            columns  = ['l1_step_1']
-        )
+        {1: pd.Series(
+                data  = np.array([0.17407766, 0.52223297, 0.87038828, 
+                                  1.21854359, 1.5666989]), 
+                index = pd.RangeIndex(start=5, stop=10, step=1),
+                name  = "l1_step_1"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("level, expected_y_values", 
                          [('l1', [3., 4., 5., 6., 7., 8., 9.]), 
                           ('l2', [103., 104., 105., 106., 107., 108., 109.])])
 def test_create_train_X_y_output_when_lags_3_steps_1_and_exog_is_None_and_transformer_exog_is_not_None(level, expected_y_values):
     """
@@ -994,22 +1110,28 @@
                              [6., 5., 4., 106., 105., 104.],
                              [7., 6., 5., 107., 106., 105.],
                              [8., 7., 6., 108., 107., 106.]], dtype=float),
             index   = pd.RangeIndex(start=3, stop=10, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3',
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3']
         ),
-        pd.DataFrame(
-            data    = np.array(expected_y_values, dtype=float),
-            index   = pd.RangeIndex(start=3, stop=10, step=1),
-            columns = [f'{level}_step_1'])
+        {1: pd.Series(
+                data  = np.array(expected_y_values, dtype=float), 
+                index = pd.RangeIndex(start=3, stop=10, step=1),
+                name  = f'{level}_step_1'
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key]) 
 
 
 @pytest.mark.parametrize("transformer_series", 
                          [StandardScaler(),
                           {'l1': StandardScaler(), 'l2': StandardScaler()}], 
                          ids = lambda tr : f'transformer_series: {tr}')
 def test_create_train_X_y_output_when_transformer_series_and_transformer_exog_steps_2(transformer_series):
@@ -1062,19 +1184,26 @@
                                1.        ]]),
             index   = pd.date_range("1990-01-07", periods=4, freq='D'),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5', 
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3', 'l2_lag_4', 'l2_lag_5', 
                        'col_1_step_1', 'col_2_a_step_1', 'col_2_b_step_1',
                        'col_1_step_2', 'col_2_a_step_2', 'col_2_b_step_2']
         ),
-        pd.DataFrame(
-            data  = np.array([[0.17407766, 0.52223297],
-                              [0.52223297, 0.87038828],
-                              [0.87038828, 1.21854359],
-                              [1.21854359, 1.5666989 ]]),
-            index = pd.date_range("1990-01-07", periods=4, freq='D'),
-            columns = ['l1_step_1', 'l1_step_2']
-        )
+        {1: pd.Series(
+                data  = np.array([0.17407766, 0.52223297, 0.87038828, 1.21854359]), 
+                index = pd.date_range("1990-01-06", periods=4, freq='D'),
+                name  = "l1_step_1"
+            ),
+         2: pd.Series(
+                data  = np.array([0.52223297, 0.87038828, 1.21854359, 1.5666989]), 
+                index = pd.date_range("1990-01-07", periods=4, freq='D'),
+                name  = "l1_step_2"
+            )
+        }
     )
 
     pd.testing.assert_frame_equal(results[0], expected[0])
-    pd.testing.assert_frame_equal(results[1], expected[1])
+    assert isinstance(results[1], dict)
+    assert all(isinstance(x, pd.Series) for x in results[1].values())
+    assert results[1].keys() == expected[1].keys()
+    for key in expected[1]: 
+        pd.testing.assert_series_equal(results[1][key], expected[1][key])
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_filter_train_X_y_for_step.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_filter_train_X_y_for_step.py`

 * *Files 4% similar despite different names*

```diff
@@ -45,21 +45,21 @@
         pd.DataFrame(
             data = np.array([[2., 1., 0., 102., 101., 100.],
                              [3., 2., 1., 103., 102., 101.],
                              [4., 3., 2., 104., 103., 102.],
                              [5., 4., 3., 105., 104., 103.],
                              [6., 5., 4., 106., 105., 104.],
                              [7., 6., 5., 107., 106., 105.]], dtype=float),
-            index   = pd.RangeIndex(start=4, stop=10, step=1),
+            index   = pd.RangeIndex(start=3, stop=9, step=1),
             columns = ['l1_lag_1', 'l1_lag_2', 'l1_lag_3',
                        'l2_lag_1', 'l2_lag_2', 'l2_lag_3']
         ),
         pd.Series(
             data  = np.array([3., 4., 5., 6., 7., 8.], dtype=float),
-            index = pd.RangeIndex(start=4, stop=10, step=1),
+            index = pd.RangeIndex(start=3, stop=9, step=1),
             name  = 'l1_step_1'
         )
     )
  
     pd.testing.assert_frame_equal(results[0], expected[0])
     pd.testing.assert_series_equal(results[1], expected[1])
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_fit.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_fit.py`

 * *Files 14% similar despite different names*

```diff
@@ -91,70 +91,77 @@
                                                level='l1', lags=3, steps=2)
     forecaster.fit(series=series)
     expected = series.index.step
     results = forecaster.index_freq
 
     assert results == expected
     
-    
-def test_fit_in_sample_residuals_stored():
+
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_fit_in_sample_residuals_stored(n_jobs):
     """
     Test that values of in_sample_residuals are stored after fitting.
     """
     series = pd.DataFrame({'l1': pd.Series(np.arange(10)), 
                            'l2': pd.Series(np.arange(10))})
     
-    forecaster = ForecasterAutoregMultiVariate(LinearRegression(), 
-                                               level='l1', lags=3, steps=2)
+    forecaster = ForecasterAutoregMultiVariate(LinearRegression(), level='l1', 
+                                               lags=3, steps=2, n_jobs=n_jobs)
     forecaster.fit(series=series)
     expected = {1: np.array([0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 
                              0.0000000e+00, 0.0000000e+00, 8.8817842e-16]),
                 2: np.array([0., 0., 0., 0., 0., 0.])}
     results = forecaster.in_sample_residuals
 
     assert isinstance(results, dict)
     assert all(isinstance(x, np.ndarray) for x in results.values())
     assert results.keys() == expected.keys()
     assert all(all(np.isclose(results[k], expected[k])) for k in expected.keys())
 
 
-def test_fit_in_sample_residuals_stored_XGBRegressor():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_fit_in_sample_residuals_stored_XGBRegressor(n_jobs):
     """
     Test that values of in_sample_residuals are stored after fitting with XGBRegressor.
     """
     series = pd.DataFrame({'l1': pd.Series(np.arange(10)), 
                            'l2': pd.Series(np.arange(10))})
     
     forecaster = ForecasterAutoregMultiVariate(XGBRegressor(random_state=123),  
-                                               level='l2', lags=3, steps=2)
+                                               level='l2', lags=3, steps=2, n_jobs=n_jobs)
     forecaster.fit(series=series)
     expected = {1: np.array([-7.98702240e-05, -7.86781311e-05, -9.74178314e-04, 
                               1.15251541e-03, -1.14297867e-03,  1.12581253e-03]),
                 2: np.array([-0.00083256,  0.00097084, -0.00123358,  
                               0.00103426, -0.00101185, 0.00107765])}
     results = forecaster.in_sample_residuals
 
     assert isinstance(results, dict)
     assert all(isinstance(x, np.ndarray) for x in results.values())
     assert results.keys() == expected.keys()
     assert all(all(np.isclose(results[k], expected[k])) for k in expected.keys())
 
 
-def test_fit_same_residuals_when_residuals_greater_than_1000():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_fit_same_residuals_when_residuals_greater_than_1000(n_jobs):
     """
     Test fit return same residuals when residuals len is greater than 1000.
     Testing with two different forecaster.
     """
     series = pd.DataFrame({'l1': pd.Series(np.arange(1200)), 
                            'l2': pd.Series(np.arange(1200))})
     
-    forecaster = ForecasterAutoregMultiVariate(LinearRegression(),  
-                                               level='l1', lags=3, steps=2)
+    forecaster = ForecasterAutoregMultiVariate(LinearRegression(), level='l1', 
+                                               lags=3, steps=2, n_jobs=n_jobs)
     forecaster.fit(series=series)
     results_1 = forecaster.in_sample_residuals
+
     forecaster = ForecasterAutoregMultiVariate(LinearRegression(),  
                                                level='l1', lags=3, steps=2)
     forecaster.fit(series=series)
     results_2 = forecaster.in_sample_residuals
 
     assert isinstance(results_1, dict)
     assert all(isinstance(x, np.ndarray) for x in results_1.values())
@@ -162,24 +169,26 @@
     assert all(isinstance(x, np.ndarray) for x in results_2.values())
     assert results_1.keys() == results_2.keys()
     assert all(len(results_1[k] == 1000) for k in results_1.keys())
     assert all(len(results_2[k] == 1000) for k in results_2.keys())
     assert all(all(results_1[k] == results_2[k]) for k in results_2.keys())
 
 
-def test_fit_in_sample_residuals_not_stored():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_fit_in_sample_residuals_not_stored(n_jobs):
     """
     Test that values of in_sample_residuals are not stored after fitting
     when `store_in_sample_residuals=False`.
     """
     series = pd.DataFrame({'l1': pd.Series(np.arange(5)), 
                            'l2': pd.Series(np.arange(5))})
 
-    forecaster = ForecasterAutoregMultiVariate(LinearRegression(),  
-                                               level='l1', lags=3, steps=2)
+    forecaster = ForecasterAutoregMultiVariate(LinearRegression(), level='l1', 
+                                               lags=3, steps=2, n_jobs=n_jobs)
     forecaster.fit(series=series, store_in_sample_residuals=False)
     expected = {1: None, 2: None}
     results = forecaster.in_sample_residuals
 
     assert isinstance(results, dict)
     assert results.keys() == expected.keys()
     assert all(results[k] == expected[k] for k in expected.keys())
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_get_feature_importances.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_get_feature_importances.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_predict.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_predict.py`

 * *Files 2% similar despite different names*

```diff
@@ -187,26 +187,29 @@
                    index   = pd.RangeIndex(start=50, stop=55, step=1),
                    columns = ['l2']
                )
     
     pd.testing.assert_frame_equal(results, expected)
 
 
-def test_predict_output_when_regressor_is_LinearRegression_with_transform_series_and_transform_exog():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'], 
+                         ids=lambda n_jobs: f'n_jobs: {n_jobs}')
+def test_predict_output_when_regressor_is_LinearRegression_with_transform_series_and_transform_exog(n_jobs):
     """
     Test predict output when using LinearRegression as regressor, StandardScaler
     as transformer_series and transformer_exog as transformer_exog.
     """
     forecaster = ForecasterAutoregMultiVariate(
                      regressor          = LinearRegression(),
                      level              = 'l1',
                      lags               = 5,
                      steps              = 5,
                      transformer_series = StandardScaler(),
-                     transformer_exog   = transformer_exog
+                     transformer_exog   = transformer_exog,
+                     n_jobs             = n_jobs
                  )
     forecaster.fit(series=series, exog=exog)
     results = forecaster.predict(steps=[1, 2, 3, 4, 5], exog=exog_predict)
     expected = pd.DataFrame(
                    data    = np.array([0.61043227, 0.46658137, 0.54994519, 0.52561227, 0.46596527]),
                    index   = pd.RangeIndex(start=50, stop=55, step=1),
                    columns = ['l1']
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_bootstrapping.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_bootstrapping.py`

 * *Files 2% similar despite different names*

```diff
@@ -30,16 +30,16 @@
     """
     forecaster = ForecasterAutoregMultiVariate(LinearRegression(), level='l1',
                                                lags=3, steps=2)
     forecaster.fit(series=series)
     forecaster.in_sample_residuals = {2: np.array([1, 2, 3])}
 
     err_msg = re.escape(
-                (f'Not `forecaster.in_sample_residuals` for steps: '
-                 f'{set([1, 2]) - set(forecaster.in_sample_residuals.keys())}.')
+                (f"Not `forecaster.in_sample_residuals` for steps: "
+                 f"{set([1, 2]) - set(forecaster.in_sample_residuals.keys())}.")
                 )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=None, in_sample_residuals=True)
 
 
 def test_predict_bootstrapping_ValueError_when_out_sample_residuals_is_None():
     """
@@ -47,18 +47,18 @@
     forecaster.out_sample_residuals is None.
     """
     forecaster = ForecasterAutoregMultiVariate(LinearRegression(), level='l1',
                                                lags=3, steps=2)
     forecaster.fit(series=series)
 
     err_msg = re.escape(
-                ('`forecaster.out_sample_residuals` is `None`. Use '
-                 '`in_sample_residuals=True` or method `set_out_sample_residuals()` '
-                 'before `predict_interval()`, `predict_bootstrapping()` or '
-                 '`predict_dist()`.')
+                ("`forecaster.out_sample_residuals` is `None`. Use "
+                 "`in_sample_residuals=True` or method `set_out_sample_residuals()` "
+                 "before `predict_interval()`, `predict_bootstrapping()` or "
+                 "`predict_dist()`.")
               )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=1, in_sample_residuals=False)
 
 
 def test_predict_bootstrapping_ValueError_when_not_out_sample_residuals_for_all_steps_predicted():
     """
@@ -69,17 +69,17 @@
                                                lags=3, steps=3)
     forecaster.fit(series=series)
     residuals = {2: np.array([1, 2, 3, 4, 5]), 
                  3: np.array([1, 2, 3, 4, 5])}
     forecaster.out_sample_residuals = residuals
 
     err_msg = re.escape(
-                    (f'Not `forecaster.out_sample_residuals` for steps: '
-                     f'{set([1, 2]) - set(forecaster.out_sample_residuals.keys())}. '
-                     f'Use method `set_out_sample_residuals()`.')
+                    (f"Not `forecaster.out_sample_residuals` for steps: "
+                     f"{set([1, 2]) - set(forecaster.out_sample_residuals.keys())}. "
+                     f"Use method `set_out_sample_residuals()`.")
                 )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=[1, 2], in_sample_residuals=False)
 
 
 def test_predict_bootstrapping_ValueError_when_step_out_sample_residuals_value_is_None():
     """
@@ -90,15 +90,15 @@
                                                lags=3, steps=3)
     forecaster.fit(series=series)
     residuals = {1: np.array([1, 2, 3, 4, 5]),
                  2: np.array([1, 2, 3, 4, 5])}
     forecaster.set_out_sample_residuals(residuals = residuals)
 
     err_msg = re.escape(
-                    (f"forecaster residuals for step 3 are `None`. Check forecaster.out_sample_residuals.")
+                    ("forecaster residuals for step 3 are `None`. Check forecaster.out_sample_residuals.")
                 )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=3, in_sample_residuals=False)
 
 
 def test_predict_bootstrapping_ValueError_when_step_out_sample_residuals_value_contains_None():
     """
@@ -110,15 +110,15 @@
     forecaster.fit(series=series)
     residuals = {1: np.array([1, 2, 3, 4, 5]),
                  2: np.array([1, 2, 3, 4, 5]), 
                  3: np.array([1, 2, 3, 4, None])}
     forecaster.set_out_sample_residuals(residuals = residuals)
 
     err_msg = re.escape(
-                    (f"forecaster residuals for step 3 contains `None` values. Check forecaster.out_sample_residuals.")
+                    ("forecaster residuals for step 3 contains `None` values. Check forecaster.out_sample_residuals.")
                 )
     with pytest.raises(ValueError, match = err_msg):
         forecaster.predict_bootstrapping(steps=3, in_sample_residuals=False)
 
 
 @pytest.mark.parametrize("steps", [2, [1, 2], None], 
                          ids=lambda steps: f'steps: {steps}')
@@ -137,15 +137,15 @@
                      transformer_exog   = transformer_exog
                  )
     forecaster.fit(series=series, exog=exog)
     results = forecaster.predict_bootstrapping(steps=steps, exog=exog_predict, 
                                                n_boot=4, in_sample_residuals=True)
     expected = pd.DataFrame(
                     data = np.array([[0.68370403, 0.61428329, 0.38628787, 0.46804785],
-                                     [0.23010355, 0.19812106, 0.62028743, 0.25357764]]),
+                                     [0.53932503, 0.13843292, 0.39752999, 0.86694953]]),
                     columns = [f"pred_boot_{i}" for i in range(4)],
                     index   = pd.RangeIndex(start=50, stop=52)
                 )
     
     pd.testing.assert_frame_equal(expected, results)
 
 
@@ -165,15 +165,15 @@
                  )
     forecaster.fit(series=series, exog=exog)
     forecaster.out_sample_residuals = forecaster.in_sample_residuals
     results = forecaster.predict_bootstrapping(steps=2, exog=exog_predict, 
                                                n_boot=4, in_sample_residuals=False)
     expected = pd.DataFrame(
                     data = np.array([[0.68370403, 0.61428329, 0.38628787, 0.46804785],
-                                     [0.23010355, 0.19812106, 0.62028743, 0.25357764]]),
+                                     [0.53932503, 0.13843292, 0.39752999, 0.86694953]]),
                     columns = [f"pred_boot_{i}" for i in range(4)],
                     index   = pd.RangeIndex(start=50, stop=52)
                 )
     
     pd.testing.assert_frame_equal(expected, results)
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_dist.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_dist.py`

 * *Files 4% similar despite different names*

```diff
@@ -42,15 +42,15 @@
                   exog                = exog_predict,
                   distribution        = norm,
                   n_boot              = 4,
                   in_sample_residuals = True
               )
     expected = pd.DataFrame(
                    data    = np.array([[0.53808076, 0.11721631],
-                                       [0.32552242, 0.1713172 ]]),
+                                       [0.48555937, 0.26296157]]),
                    columns = ['loc', 'scale'],
                    index   = pd.RangeIndex(start=50, stop=52)
                )
     
     pd.testing.assert_frame_equal(expected, results)
 
 
@@ -75,13 +75,13 @@
                   exog                = exog_predict,
                   distribution        = norm,
                   n_boot              = 4,
                   in_sample_residuals = False
               )
     expected = pd.DataFrame(
                    data    = np.array([[0.53808076, 0.11721631],
-                                       [0.32552242, 0.1713172 ]]),
+                                       [0.48555937, 0.26296157]]),
                    columns = ['loc', 'scale'],
                    index   = pd.RangeIndex(start=50, stop=52)
                )
 
     pd.testing.assert_frame_equal(expected, results)
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_interval.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_predict_interval.py`

 * *Files 7% similar despite different names*

```diff
@@ -40,15 +40,15 @@
                   steps               = 2,
                   exog                = exog_predict,
                   n_boot              = 4,
                   in_sample_residuals = True
               )
     expected = pd.DataFrame(
                    data    = np.array([[0.61820497, 0.39855187, 0.67329092],
-                                       [0.41314101, 0.20291844, 0.56528096]]),
+                                       [0.41314101, 0.17729748, 0.81780586]]),
                    columns = ['l1', 'lower_bound', 'upper_bound'],
                    index   = pd.RangeIndex(start=50, stop=52)
                )
     
     pd.testing.assert_frame_equal(expected, results)
 
 
@@ -72,13 +72,13 @@
                   steps               = 2,
                   exog                = exog_predict,
                   n_boot              = 4,
                   in_sample_residuals = False
               )
     expected = pd.DataFrame(
                    data    = np.array([[0.61820497, 0.39855187, 0.67329092],
-                                       [0.41314101, 0.20291844, 0.56528096]]),
+                                       [0.41314101, 0.17729748, 0.81780586]]),
                    columns = ['l1', 'lower_bound', 'upper_bound'],
                    index   = pd.RangeIndex(start=50, stop=52)
                )
 
     pd.testing.assert_frame_equal(expected, results)
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_set_fit_kwargs.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_set_fit_kwargs.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_set_lags.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_set_lags.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_set_out_sample_residuals.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_set_out_sample_residuals.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterAutoregMultiVariate/tests/test_set_params.py` & `skforecast-0.9.0/skforecast/ForecasterAutoregMultiVariate/tests/test_set_params.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterBase/ForecasterBase.py` & `skforecast-0.9.0/skforecast/ForecasterBase/ForecasterBase.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 ################################################################################
 #                                ForecasterBase                                #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
 from abc import ABC, abstractmethod
 from typing import Union, Dict, List, Tuple, Any, Optional
 import logging
 import pandas as pd
@@ -28,31 +28,31 @@
         self,
         y: pd.Series,
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None
     ) -> Tuple[pd.DataFrame, pd.Series]:
         """
         Create training matrices from univariate time series and exogenous
         variables.
-        
+
         Parameters
-        ----------        
+        ----------
         y : pandas Series
-            Time series.
-            
+            Training time series.
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `y` and their indexes must be aligned.
 
-        Returns 
+        Returns
         -------
-        X_train : pandas DataFrame, shape (len(y) - self.max_lag, len(self.lags))
-            Pandas DataFrame with the training values (predictors).
-            
-        y_train : pandas Series, shape (len(y) - self.max_lag, )
+        X_train : pandas DataFrame
+            Training values (predictors).
+            Shape: (len(y) - self.max_lag, len(self.lags))
+        y_train : pandas Series
             Values (target) of the time series related to each row of `X_train`.
+            Shape: (len(y) - self.max_lag, )
         
         """
         
         pass
 
 
     @abstractmethod
@@ -61,25 +61,23 @@
         y: pd.Series,
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None
     ) -> None:
         """
         Training Forecaster.
         
         Parameters
-        ----------        
+        ----------
         y : pandas Series
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `y` and their indexes must be aligned so
             that y[i] is regressed on exog[i].
 
-
-        Returns 
+        Returns
         -------
         None
         
         """
         
         pass
 
@@ -94,76 +92,84 @@
         """
         Predict n steps ahead.
         
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors (lags) needed in the 
             first iteration of the prediction (t + 1).
-    
-            If `last_window = None`, the values stored in` self.last_window` are
+            If `last_window = None`, the values stored in `self.last_window` are
             used to calculate the initial predictors, and the predictions start
             right after training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
 
-        Returns 
+        Returns
         -------
         predictions : pandas Series
             Predicted values.
-            
+        
         """
 
         pass
         
 
     @abstractmethod
     def set_params(self, params: dict) -> None:
         """
         Set new values to the parameters of the scikit learn model stored in the
-        ForecasterAutoreg.
+        forecaster.
         
         Parameters
         ----------
         params : dict
             Parameters values.
 
-        Returns 
+        Returns
         -------
-        self
+        None
         
         """
         
         pass
         
    
     def set_lags(self, lags: int) -> None:
-        """      
+        """
         Set new value to the attribute `lags`.
         Attributes `max_lag` and `window_size` are also updated.
         
         Parameters
         ----------
-        lags : int, list, 1D np.array, range
-        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
-            `int`: include lags from 1 to `lags`.
-            `list` or `np.array`: include only lags present in `lags`.
+        lags : int, list, numpy ndarray, range
+            Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
+
+            - `int`: include lags from 1 to `lags` (included).
+            - `list`, `1d numpy ndarray` or `range`: include only lags present in 
+            `lags`, all elements must be int.
 
-        Returns 
+        Returns
         -------
-        self
+        None
         
         """
         
         pass
 
 
     def summary(self) -> None:
-        """      
+        """
         Show forecaster information.
+        
+        Parameters
+        ----------
+        self
+
+        Returns
+        -------
+        None
+        
         """
         
         print(self)
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterSarimax/ForecasterSarimax.py` & `skforecast-0.9.0/skforecast/ForecasterSarimax/ForecasterSarimax.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 ################################################################################
 #                            ForecasterSarimax                                 #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
 from typing import Union, Dict, List, Tuple, Any, Optional
 import warnings
 import logging
 import sys
@@ -39,110 +39,87 @@
     **New in version 0.7.0**
     
     Parameters
     ----------
     regressor : pmdarima.arima.ARIMA
         An instance of an ARIMA from pmdarima library. This model internally wraps the
         statsmodels SARIMAX class.
-
     transformer_y : object transformer (preprocessor), default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
         ColumnTransformers are not allowed since they do not have inverse_transform method.
         The transformation is applied to `y` before training the forecaster. 
-
     transformer_exog : object transformer (preprocessor), default `None`
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-
     fit_kwargs : dict, default `None`
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
     forecaster_id : str, int default `None`
         Name used as an identifier of the forecaster.
+        **New in version 0.7.0**
     
     Attributes
     ----------
     regressor : pmdarima.arima.ARIMA
         An instance of an ARIMA from pmdarima library. The model internally wraps the
         statsmodels SARIMAX class
-
     params: dict
         Parameters of the sarimax model.
-        
-    transformer_y : object transformer (preprocessor), default `None`
+    transformer_y : object transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
         ColumnTransformers are not allowed since they do not have inverse_transform method.
         The transformation is applied to `y` before training the forecaster.
-
-    transformer_exog : object transformer (preprocessor), default `None`
+    transformer_exog : object transformer (preprocessor)
         An instance of a transformer (preprocessor) compatible with the scikit-learn
         preprocessing API. The transformation is applied to `exog` before training the
         forecaster. `inverse_transform` is not available when using ColumnTransformers.
-   
-    window_size : int, `1` 
+    window_size : int
         Not used, present here for API consistency by convention.
-
     last_window : pandas Series
         Last window the forecaster has seen during training. It stores the
         values needed to predict the next `step` immediately after the training data.
-
     extended_index : pandas Index
         When predicting using `last_window` and `last_window_exog`, the internal
         statsmodels SARIMAX will be updated using its append method. To do this,
         `last_window` data must start at the end of the index seen by the 
         forecaster, this is stored in forecaster.extended_index.
-
         Check https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMAResults.append.html
         to know more about statsmodels append method.
-        
-    fitted : Bool
+    fitted : bool
         Tag to identify if the regressor has been fitted (trained).
-        
     index_type : type
         Type of index of the input used in training.
-        
     index_freq : str
         Frequency of Index of the input used in training.
-        
     training_range : pandas Index
         First and last values of index of the data used during training.
-        
     included_exog : bool
         If the forecaster has been trained using exogenous variable/s.
-        
     exog_type : type
         Type of exogenous variable/s used in training.
-        
     exog_col_names : list
         Names of columns of `exog` if `exog` used in training was a pandas
         DataFrame.
-
     fit_kwargs : dict
         Additional arguments to be passed to the `fit` method of the regressor.
         **New in version 0.8.0**
-
     creation_date : str
         Date of creation.
-
     fit_date : str
         Date of last fit.
-
     skforcast_version : str
         Version of skforecast library used to create the forecaster.
-
     python_version : str
         Version of python used to create the forecaster.
-
-    forecaster_id : str, int default `None`
+    forecaster_id : str, int
         Name used as an identifier of the forecaster.
-     
+    
     """
     
     def __init__(
         self,
         regressor: ARIMA,
         transformer_y: Optional[object]=None,
         transformer_exog: Optional[object]=None,
@@ -220,26 +197,28 @@
     def fit(
         self,
         y: pd.Series,
         exog: Optional[Union[pd.Series, pd.DataFrame]]=None
     ) -> None:
         """
         Training Forecaster.
+
+        Additional arguments to be passed to the `fit` method of the regressor 
+        can be added with the `fit_kwargs` argument when initializing the forecaster.
         
         Parameters
-        ----------        
+        ----------
         y : pandas Series
             Training time series.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s. Must have the same
             number of observations as `y` and their indexes must be aligned so
             that y[i] is regressed on exog[i].
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         check_y(y=y)
         if exog is not None:
@@ -325,35 +304,32 @@
         Check https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMAResults.append.html
         to know more about statsmodels append method.
         
         Parameters
         ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors needed in the 
             predictions. Used to make predictions unrelated to the original data. 
             Values have to start at the end of the training data.
-
         last_window_exog : pandas Series, pandas DataFrame, default `None`
             Values of the exogenous variables aligned with `last_window`. Only
             needed when `last_window` is not None and the forecaster has been
             trained including exogenous variables. Used to make predictions 
             unrelated to the original data. Values have to start at the end 
             of the training data.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Value of the exogenous variable/s for the next steps.
 
-        Returns 
+        Returns
         -------
         predictions : pandas Series
             Predicted values.
-            
+        
         """
 
         # Needs to be a new variable to avoid arima_res_.append if not needed
         last_window_check = last_window.copy() if last_window is not None else self.last_window.copy()
 
         check_predict_input(
             forecaster_name  = type(self).__name__,
@@ -493,60 +469,55 @@
     ) -> pd.DataFrame:
         """
         Forecast future values and their confidence intervals
 
         Generate predictions (forecasts) n steps in the future with confidence
         intervals. Note that if exogenous variables were used in the model fit, 
         they will be expected for the predict procedure and will fail otherwise.
-        
+
         When predicting using `last_window` and `last_window_exog`, the internal
         statsmodels SARIMAX will be updated using its append method. To do this,
         `last_window` data must start at the end of the index seen by the 
         forecaster, this is stored in forecaster.extended_index.
 
         Check https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMAResults.append.html
         to know more about statsmodels append method.
 
         Parameters
-        ---------- 
+        ----------
         steps : int
             Number of future steps predicted.
-            
         last_window : pandas Series, default `None`
             Series values used to create the predictors needed in the 
             predictions. Used to make predictions unrelated to the original data. 
             Values have to start at the end of the training data.
-
         last_window_exog : pandas Series, pandas DataFrame, default `None`
             Values of the exogenous variables aligned with `last_window`. Only
             need when `last_window` is not None and the forecaster has been
             trained including exogenous variables.
-            
         exog : pandas Series, pandas DataFrame, default `None`
             Exogenous variable/s included as predictor/s.
-            
         alpha : float, default `0.05`
             The confidence intervals for the forecasts are (1 - alpha) %.
             If both, `alpha` and `interval` are provided, `alpha` will be used.
-            
         interval : list, default `None`
             Confidence of the prediction interval estimated. The values must be
             symmetric. Sequence of percentiles to compute, which must be between 
             0 and 100 inclusive. For example, interval of 95% should be as 
             `interval = [2.5, 97.5]`. If both, `alpha` and `interval` are 
             provided, `alpha` will be used.
 
-        Returns 
+        Returns
         -------
         predictions : pandas DataFrame
-            Values predicted by the forecaster and their estimated interval:
+            Values predicted by the forecaster and their estimated interval.
 
-            - pred: predictions.
-            - lower_bound: lower bound of the interval.
-            - upper_bound: upper bound interval of the interval.
+                - pred: predictions.
+                - lower_bound: lower bound of the interval.
+                - upper_bound: upper bound of the interval.
 
         """
 
         # Needs to be a new variable to avoid arima_res_.append if not needed
         last_window_check = last_window.copy() if last_window is not None else self.last_window.copy()
 
         check_predict_input(
@@ -701,17 +672,17 @@
         Set new values to the parameters of the model stored in the forecaster.
         
         Parameters
         ----------
         params : dict
             Parameters values.
 
-        Returns 
+        Returns
         -------
-        self
+        None
         
         """
 
         self.regressor = clone(self.regressor)
         self.regressor.set_params(**params)
         self.params = self.regressor.get_params(deep=True)
 
@@ -725,29 +696,28 @@
         method of the regressor.
         
         Parameters
         ----------
         fit_kwargs : dict
             Dict of the form {"argument": new_value}.
 
-        Returns 
+        Returns
         -------
         None
         
         """
 
         self.fit_kwargs = check_select_fit_kwargs(self.regressor, fit_kwargs=fit_kwargs)
 
 
     def get_feature_importances(
         self
     ) -> pd.DataFrame:
         """
-        Return feature importances of the regressor stored in the
-        forecaster.
+        Return feature importances of the regressor stored in the forecaster.
 
         Parameters
         ----------
         self
 
         Returns
         -------
@@ -761,36 +731,8 @@
                 ("This forecaster is not fitted yet. Call `fit` with appropriate "
                  "arguments before using `get_feature_importances()`.")
             )
 
         feature_importances = self.regressor.params().to_frame().reset_index()
         feature_importances.columns = ['feature', 'importance']
 
-        return feature_importances
-
-
-    def get_feature_importance(
-        self
-    ) -> pd.DataFrame:
-        """
-        This method has been replaced by `get_feature_importances()`.
-
-        Return feature importance of the regressor stored in the
-        forecaster.
-
-        Parameters
-        ----------
-        self
-
-        Returns
-        -------
-        feature_importances : pandas DataFrame
-            Feature importances associated with each predictor.
-
-        """
-
-        warnings.warn(
-            ("get_feature_importance() method has been renamed to get_feature_importances()."
-             "This method will be removed in skforecast 0.9.0.")
-        )
-
-        return self.get_feature_importances()
+        return feature_importances
```

### Comparing `skforecast-0.8.1/skforecast/ForecasterSarimax/tests/fixtures_ForecasterSarimax.py` & `skforecast-0.9.0/skforecast/ForecasterSarimax/tests/fixtures_ForecasterSarimax.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_fit.py` & `skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_fit.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_get_feature_importances.py` & `skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_get_feature_importances.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_init.py` & `skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_init.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_predict.py` & `skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_predict.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_predict_interval.py` & `skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_predict_interval.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_set_fit_kwargs.py` & `skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_set_fit_kwargs.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/ForecasterSarimax/tests/test_set_params.py` & `skforecast-0.9.0/skforecast/ForecasterSarimax/tests/test_set_params.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/exceptions/exceptions.py` & `skforecast-0.9.0/skforecast/exceptions/exceptions.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 ################################################################################
 #                            skforecast.exceptions                             #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
 """
 The skforecast.exceptions module contains all the custom warnings and error 
 classes used across skforecast.
 """
```

### Comparing `skforecast-0.8.1/skforecast/model_selection/model_selection.py` & `skforecast-0.9.0/skforecast/model_selection_multiseries/model_selection_multiseries.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,1755 +1,1356 @@
 ################################################################################
-#                        skforecast.model_selection                            #
+#                  skforecast.model_selection_multiseries                      #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
-from typing import Union, Tuple, Optional, Any, Callable
+from typing import Union, Tuple, Optional, Callable
 import numpy as np
 import pandas as pd
 import warnings
 import logging
 from copy import deepcopy
+from joblib import Parallel, delayed, cpu_count
 from tqdm.auto import tqdm
-from sklearn.metrics import mean_squared_error 
-from sklearn.metrics import mean_absolute_error
-from sklearn.metrics import mean_absolute_percentage_error
-from sklearn.metrics import mean_squared_log_error
+import sklearn.pipeline
 from sklearn.model_selection import ParameterGrid
 from sklearn.model_selection import ParameterSampler
-import optuna
-from optuna.samplers import TPESampler, RandomSampler
 
 from ..exceptions import LongTrainingWarning
 from ..exceptions import IgnoredArgumentWarning
+from ..model_selection.model_selection import _get_metric
+from ..model_selection.model_selection import _create_backtesting_folds
 from ..utils import check_backtesting_input
-
-optuna.logging.set_verbosity(optuna.logging.WARNING) # disable optuna logs
+from ..utils import select_n_jobs_backtesting
 
 logging.basicConfig(
     format = '%(name)-10s %(levelname)-5s %(message)s', 
     level  = logging.INFO,
 )
 
 
-def _backtesting_forecaster_verbose(
-    index_values: pd.Index,
-    steps: int,
-    initial_train_size: int,
-    folds: int,
-    remainder: int,
-    refit: bool=False,
-    fixed_train_size: bool=True
-) -> None:
-    """
-    Verbose for backtesting_forecaster functions.
-    
-    Parameters
-    ----------        
-    index_values : pandas Index
-        Values of the index of the series.
-    
-    steps : int
-        Number of steps to predict.
-
-    initial_train_size : int
-        Number of samples in the initial train split. The backtest forecaster is
-        trained using the first `initial_train_size` observations.
-        
-    folds : int
-        Number of backtesting stages.
-
-    remainder : int
-        Number of observations in the last backtesting stage. 
-
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration.
-
-    fixed_train_size : bool, default `True`
-        If True, train size doesn't increase but moves by `steps` in each iteration.
-    
-    """
-
-    print(f"Information of backtesting process")
-    print(f"----------------------------------")
-    print(f"Number of observations used for initial training: {initial_train_size}")
-    print(f"Number of observations used for backtesting: {len(index_values) - initial_train_size}")
-    print(f"    Number of folds: {folds}")
-    print(f"    Number of steps per fold: {steps}")
-    if remainder != 0:
-        print(f"    Last fold only includes {remainder} observations.")
-    print("")
-    for i in range(folds):
-        if refit:
-            # if fixed_train_size the train size doesn't increase but moves by `steps` in each iteration.
-            # if false the train size increases by `steps` in each iteration.
-            train_idx_start = i * steps if fixed_train_size else 0
-            train_idx_end = initial_train_size + i * steps
-        else:
-            # The train size doesn't increase and doesn't move
-            train_idx_start = 0
-            train_idx_end = initial_train_size
-        last_window_end = initial_train_size + i * steps
-        print(f"Data partition in fold: {i}")
-        if i < folds - 1:
-            print(f"    Training:   {index_values[train_idx_start]} -- {index_values[train_idx_end - 1]}  (n={len(index_values[train_idx_start:train_idx_end])})")
-            print(f"    Validation: {index_values[last_window_end]} -- {index_values[last_window_end + steps - 1]}  (n={len(index_values[last_window_end:last_window_end + steps])})")
-        else:
-            print(f"    Training:   {index_values[train_idx_start]} -- {index_values[train_idx_end - 1]}  (n={len(index_values[train_idx_start:train_idx_end])})")
-            print(f"    Validation: {index_values[last_window_end]} -- {index_values[-1]}  (n={len(index_values[last_window_end:])})")
-    print("")
-
-    return
-
-
-def _create_backtesting_folds(
-    data: Union[pd.Series, pd.DataFrame],
-    initial_train_size: Union[int, None],
-    test_size: int,
-    externally_fitted: bool=False,
-    refit: bool=False,
-    fixed_train_size: bool=True,
-    gap: int=0,
-    allow_incomplete_fold: bool=True,
-    return_all_indexes: bool=False,
-    verbose: bool=True
-) -> list:
-    """
-    This function is designed to work after passing the `check_backtesting_input` 
-    function from `skforecast.utils`.
-
-    Provides train/test indices (position) to split time series data samples that
-    are observed at fixed time intervals, in train/test sets. In each split, test
-    indices must be higher than before.
-
-    Three arrays are returned for each fold with the position of train, test
-    including the gap, and test excluding the gap. The gap is the number of
-    samples to exclude from the end of each train set before the test set. The
-    test excluding the gap is the one that must be used to make evaluate the
-    model. The test including the gap is provided for convenience.
-
-    Returned indexes are not the indexes of the original time series, but the
-    positional indexes of the samples in the time series. For example, if the   
-    original time series is `y = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]`, the
-    returned indexes for the first fold if  `test_size = 4`, `gap = 1` and 
-    `initial_train_size = 2` are: `[[0, 1], [2, 3, 4, 5], [3, 4, 5]]]`. This means
-    that the first fold is using the samples with positional indexes 0 and 1 in
-    the time series as training set, and the samples with positional indexes 2,
-    3, 4 and 5 as test set, but only the samples with positional indexes 3, 4 and
-    5 should be used to evaluate the model since `gap = 1`. The second fold would
-    be `[[0, 1, 2, 3], [4, 5, 6, 7], [5, 6, 7]]`, and so on.
-    
-    Parameters
-    ----------        
-    data : pandas Series, pandas DataFrame
-        Time series values.
-    
-    initial_train_size : int, None
-        Size of the training set in the first fold. If `None` or 0, the initial
-        fold does not include a training set.
-        
-    test_size : int
-        Size of the test set in each fold.
-
-    externally_fitted : bool, default `False`
-        Flag indicating whether the forecaster is already trained. Only used when 
-        `initial_train_size` is None and `refit` is False.
-
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration.
-
-    fixed_train_size : bool, default `True`
-        If True, train size doesn't increase but moves by `steps` in each iteration.
-
-    gap : int, default `0`
-        Number of samples to be excluded after the end of each training set and 
-        before the test set.
-        
-    allow_incomplete_fold : bool, default `True`
-        Last fold is allowed to have a smaller number of samples than the 
-        `test_size`. If `False`, the last fold is excluded.
-
-    return_all_indexes : bool, default `False`
-        If `True`, return all the indexes included in each fold. If `False`, return
-        only the first and last index of each partition in each fold.
-        
-    verbose : bool, default `True`
-        Print information if the folds created.
-
-    Returns
-    ------
-    folds : list
-        List containing the indices (position) of `y` for training, test including
-        the gap, and test excluding the gap for each fold.
-    
-    """
-    
-    idx = range(len(data))
-    folds = []
-    i = 0
-    last_fold_excluded = False
-
-    while initial_train_size + (i * test_size) + gap < len(data):
-
-        if refit:
-            # If fixed_train_size the train size doesn't increase but moves by 
-            # `test_size` positions in each iteration. If False, the train size
-            # increases by `test_size` in each iteration.
-            train_idx_start = i * (test_size) if fixed_train_size else 0
-            train_idx_end = initial_train_size + i * (test_size)
-            test_idx_start = train_idx_end
-        else:
-            # The train size doesn't increase and doesn't move.
-            train_idx_start = 0
-            train_idx_end = initial_train_size
-            test_idx_start = initial_train_size + i * (test_size)
-
-        test_idx_end = test_idx_start + gap + test_size
-    
-        partitions = [
-            idx[train_idx_start : train_idx_end],
-            idx[test_idx_start : test_idx_end],
-            idx[test_idx_start + gap : test_idx_end]
-        ]
-        folds.append(partitions)
-        i += 1
-
-    if not allow_incomplete_fold:
-        if len(folds[-1][2]) < test_size:
-            folds = folds[:-1]
-            last_fold_excluded = True
-
-    # Replace partitions inside folds with length 0 with None
-    folds = [[partition if len(partition) > 0 else None 
-              for partition in fold] 
-             for fold in folds]
-    
-    if verbose:
-        print("Information of backtesting process")
-        print("----------------------------------")
-        if externally_fitted:
-            print(f"An already trained forecaster is to be used. Window size: {initial_train_size}")
-        else:
-            print(f"Number of observations used for initial training: {initial_train_size}")
-        print(f"Number of observations used for backtesting: {len(data) - initial_train_size}")
-        print(f"    Number of folds: {len(folds)}")
-        print(f"    Number of steps per fold: {test_size}")
-        print(f"    Number of steps to exclude from the end of each train set before test (gap): {gap}")
-        if last_fold_excluded:
-            print("    Last fold has been excluded because it was incomplete.")
-        if len(folds[-1][2]) < test_size:
-            print(f"    Last fold only includes {len(folds[-1][2])} observations.")
-        print("")
-
-        for i, fold in enumerate(folds):
-            training_start    = data.index[fold[0][0]] if fold[0] is not None else None
-            training_end      = data.index[fold[0][-1]] if fold[0] is not None else None
-            training_length   = len(fold[0]) if fold[0] is not None else 0
-            validation_start  = data.index[fold[2][0]]
-            validation_end    = data.index[fold[2][-1]]
-            validation_length = len(fold[2])
-            print(f"Fold: {i}")
-            if not externally_fitted:
-                print(
-                    f"    Training:   {training_start} -- {training_end}  (n={training_length})"
-                )
-            print(
-                f"    Validation: {validation_start} -- {validation_end}  (n={validation_length})"
-            )
-        print("")
-
-    if not return_all_indexes:
-        # +1 to prevent iloc pandas from deleting the last observation
-        folds = [
-            [[fold[0][0], fold[0][-1]+1], 
-             [fold[1][0], fold[1][-1]+1], 
-             [fold[2][0], fold[2][-1]+1]] 
-            for fold in folds
-        ]
-
-    return folds
-        
-        
-def _get_metric(
-    metric: str
-) -> Callable:
-    """
-    Get the corresponding scikit-learn function to calculate the metric.
-    
-    Parameters
-    ----------
-    metric : str
-        Metric used to quantify the goodness of fit of the model. Available metrics: 
-        {'mean_squared_error', 'mean_absolute_error', 
-         'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-    Returns 
-    -------
-    metric : Callable
-        scikit-learn function to calculate the desired metric.
-    
-    """
-    
-    if metric not in ['mean_squared_error', 'mean_absolute_error',
-                      'mean_absolute_percentage_error', 'mean_squared_log_error']:
-        raise ValueError(
-            (f"Allowed metrics are: 'mean_squared_error', 'mean_absolute_error', "
-             f"'mean_absolute_percentage_error' and 'mean_squared_log_error'. Got {metric}.")
-        )
-    
-    metrics = {
-        'mean_squared_error': mean_squared_error,
-        'mean_absolute_error': mean_absolute_error,
-        'mean_absolute_percentage_error': mean_absolute_percentage_error,
-        'mean_squared_log_error': mean_squared_log_error
-    }
-    
-    metric = metrics[metric]
-    
-    return metric
-
-
-def _backtesting_forecaster_refit(
+def _backtesting_forecaster_multiseries(
     forecaster,
-    y: pd.Series,
-    steps: int,
-    metric: Union[str, Callable, list],
-    initial_train_size: int,
-    fixed_train_size: bool=True,
-    gap: int=0,
-    allow_incomplete_fold: bool=True,
-    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
-    interval: Optional[list]=None,
-    n_boot: int=500,
-    random_state: int=123,
-    in_sample_residuals: bool=True,
-    verbose: bool=False,
-    show_progress: bool=True
-) -> Tuple[Union[float, list], pd.DataFrame]:
-    """
-    Backtesting of forecaster model with a re-fitting strategy. A copy of the  
-    original forecaster is created so it is not modified during the process.
-    
-    In each iteration:
-        - Fit forecaster with the training set.
-        - A number of `steps` ahead are predicted.
-        - The training set increases with `steps` observations.
-        - The model is re-fitted using the new training set.
-
-    In order to apply backtesting with refit, an initial training set must be
-    available, otherwise it would not be possible to increase the training set 
-    after each iteration. `initial_train_size` must be provided.
-    
-    Parameters
-    ----------
-    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect
-        Forecaster model.
-        
-    y : pandas Series
-        Training time series.
-        
-    steps : int
-        Number of steps to predict.
-        
-    metric : str, Callable, list
-        Metric used to quantify the goodness of fit of the model.
-        
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
-             'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-    
-    initial_train_size : int
-        Number of samples in the initial train split. The backtest forecaster is
-        trained using the first `initial_train_size` observations.
-        
-    fixed_train_size : bool, default `True`
-        If True, train size doesn't increase but moves by `steps` in each iteration.
-
-    gap : int, default `0`
-        Number of samples to be excluded after the end of each training set and 
-        before the test set.
-        
-    allow_incomplete_fold : bool, default `True`
-        Last fold is allowed to have a smaller number of samples than the 
-        `test_size`. If `False`, the last fold is excluded.
-        
-    exog : pandas Series, pandas DataFrame, default `None`
-        Exogenous variable/s included as predictor/s. Must have the same
-        number of observations as `y` and should be aligned so that y[i] is
-        regressed on exog[i].
-
-    interval : list, default `None`
-        Confidence of the prediction interval estimated. Sequence of percentiles
-        to compute, which must be between 0 and 100 inclusive. For example, 
-        interval of 95% should be as `interval = [2.5, 97.5]`. If `None`, no
-        intervals are estimated. Only available for forecaster of type 
-        ForecasterAutoreg and ForecasterAutoregCustom.
-    
-    n_boot : int, default `500`
-        Number of bootstrapping iterations used to estimate prediction
-        intervals.
-
-    random_state : int, default `123`
-        Sets a seed to the random generator, so that boot intervals are always 
-        deterministic.
-
-    in_sample_residuals : bool, default `True`
-        If `True`, residuals from the training data are used as proxy of
-        prediction error to create prediction intervals. If `False`, out_sample_residuals
-        are used if they are already stored inside the forecaster.
-            
-    verbose : bool, default `False`
-        Print number of folds and index of training and validation sets used for backtesting.
-
-    show_progress: bool, default `True`
-        Whether to show a progress bar. Defaults to True.
-
-    Returns 
-    -------
-    metrics_value : float, list
-        Value(s) of the metric(s).
-
-    backtest_predictions : pandas Dataframe
-        Value of predictions and their estimated interval if `interval` is not `None`.
-            column pred = predictions.
-            column lower_bound = lower bound of the interval.
-            column upper_bound = upper bound interval of the interval.
-    
-    """
-
-    forecaster = deepcopy(forecaster)
-
-    if not isinstance(metric, list):
-        metrics = [_get_metric(metric=metric) if isinstance(metric, str) else metric]
-    else:
-        metrics = [_get_metric(metric=m) if isinstance(m, str) else m for m in metric]
-
-    folds = _create_backtesting_folds(
-                data                  = y,
-                test_size             = steps,
-                initial_train_size    = initial_train_size,
-                gap                   = gap,
-                refit                 = True,
-                fixed_train_size      = fixed_train_size,
-                allow_incomplete_fold = allow_incomplete_fold,
-                return_all_indexes    = False,
-                verbose               = verbose  
-            )
-        
-    if type(forecaster).__name__ != 'ForecasterAutoregDirect' and len(folds) > 50:
-        warnings.warn(
-            (f"The forecaster will be fit {len(folds)} times. This can take substantial "
-             f"amounts of time. If not feasible, try with `refit = False`.\n"),
-            LongTrainingWarning
-        )
-    elif type(forecaster).__name__ == 'ForecasterAutoregDirect' and len(folds)*forecaster.steps > 50:
-        warnings.warn(
-            (f"The forecaster will be fit {len(folds)*forecaster.steps} times "
-             f"({len(folds)} folds * {forecaster.steps} regressors). This can take "
-             f"substantial amounts of time. If not feasible, try with `refit = False`.\n"),
-             LongTrainingWarning
-        )
-
-    backtest_predictions = []
-    store_in_sample_residuals = False if interval is None else True
-
-    for fold in tqdm(folds) if show_progress else folds:
-        # In each iteration the model is fitted before making predictions. 
-        # if fixed_train_size the train size doesn't increase but moves by `steps` 
-        # in each iteration. if False the train size increases by `steps` in each 
-        # iteration.
-        train_idx_start = fold[0][0]
-        train_idx_end   = fold[0][1]
-        test_idx_start  = fold[1][0]
-        test_idx_end    = fold[1][1]
-        
-        y_train = y.iloc[train_idx_start:train_idx_end, ]
-        exog_train = exog.iloc[train_idx_start:train_idx_end, ] if exog is not None else None
-        next_window_exog = exog.iloc[test_idx_start:test_idx_end, ] if exog is not None else None
-
-        forecaster.fit(
-            y                         = y_train, 
-            exog                      = exog_train, 
-            store_in_sample_residuals = store_in_sample_residuals
-        )
-        steps = len(range(test_idx_start, test_idx_end))
-        if interval is None:
-            pred = forecaster.predict(steps=steps, exog=next_window_exog)
-        else:
-            pred = forecaster.predict_interval(
-                       steps               = steps,
-                       exog                = next_window_exog,
-                       interval            = interval,
-                       n_boot              = n_boot,
-                       random_state        = random_state,
-                       in_sample_residuals = in_sample_residuals
-                   )
-
-        pred = pred.iloc[gap:, ]
-        backtest_predictions.append(pred)
-    
-    backtest_predictions = pd.concat(backtest_predictions)
-    if isinstance(backtest_predictions, pd.Series):
-        backtest_predictions = pd.DataFrame(backtest_predictions)
-
-    metrics_values = [m(
-                        y_true = y.loc[backtest_predictions.index],
-                        y_pred = backtest_predictions['pred']
-                      ) for m in metrics
-                     ]
-    
-    if not isinstance(metric, list):
-        metrics_values = metrics_values[0]
-
-    return metrics_values, backtest_predictions
-
-
-def _backtesting_forecaster_no_refit(
-    forecaster,
-    y: pd.Series,
+    series: pd.DataFrame,
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: Optional[int]=None,
+    fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
+    levels: Optional[Union[str, list]]=None,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
+    refit: Optional[Union[bool, int]]=False,
     interval: Optional[list]=None,
     n_boot: int=500,
     random_state: int=123,
     in_sample_residuals: bool=True,
+    n_jobs: Optional[Union[int, str]]='auto',
     verbose: bool=False,
     show_progress: bool=True
-) -> Tuple[Union[float, list], pd.DataFrame]:
+) -> Tuple[pd.DataFrame, pd.DataFrame]:
     """
-    Backtesting of forecaster without iterative re-fitting. In each iteration,
-    a number of `steps` are predicted. A copy of the original forecaster is
-    created so it is not modified during the process.
+    Backtesting for multi-series and multivariate forecasters.
 
-    If `forecaster` is already trained and `initial_train_size` is `None`,
-    no initial train is done and all data is used to evaluate the model.
+    - If `refit` is `False`, the model will be trained only once using the 
+    `initial_train_size` first observations. 
+    - If `refit` is `True`, the model is trained on each iteration, increasing
+    the training set. 
+    - If `refit` is an `integer`, the model will be trained every that number 
+    of iterations.
+    - If `forecaster` is already trained and `initial_train_size` is `None`,
+    no initial train will be done and all data will be used to evaluate the model.
     However, the first `len(forecaster.last_window)` observations are needed
     to create the initial predictors, so no predictions are calculated for them.
     
+    A copy of the original forecaster is created so that it is not modified during 
+    the process.
+    
     Parameters
     ----------
-    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect
+    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom,
+    ForecasterAutoregMultiVariate
         Forecaster model.
-        
-    y : pandas Series
+    series : pandas DataFrame
         Training time series.
-        
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-    
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int, default `None`
-        Number of samples in the initial train split. If `None` and `forecaster` is already
-        trained, no initial train is done and all data is used to evaluate the model. However, 
-        the first `len(forecaster.last_window)` observations are needed to create the 
-        initial predictors, so no predictions are calculated for them. This useful
-        to backtest the model on the same data used to train it.
-
+        Number of samples in the initial train split. If `None` and `forecaster` is 
+        already trained, no initial train is done and all data is used to evaluate the 
+        model. However, the first `len(forecaster.last_window)` observations are needed 
+        to create the initial predictors, so no predictions are calculated for them. 
+        This useful to backtest the model on the same data used to train it.
         `None` is only allowed when `refit` is `False` and `forecaster` is already
         trained.
-
+    fixed_train_size : bool, default `True`
+        If True, train size doesn't increase but moves by `steps` in each iteration.
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-        
+    levels : str, list, default `None`
+        Time series to be predicted. If `None` all levels will be predicted.
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     interval : list, default `None`
         Confidence of the prediction interval estimated. Sequence of percentiles
-        to compute, which must be between 0 and 100 inclusive. For example, 
-        interval of 95% should be as `interval = [2.5, 97.5]`. If `None`, no
-        intervals are estimated. Only available for forecaster of type 
-        ForecasterAutoreg and ForecasterAutoregCustom.
-            
+        to compute, which must be between 0 and 100 inclusive. If `None`, no
+        intervals are estimated.
     n_boot : int, default `500`
         Number of bootstrapping iterations used to estimate prediction
         intervals.
-
     random_state : int, default `123`
         Sets a seed to the random generator, so that boot intervals are always 
         deterministic.
-
     in_sample_residuals : bool, default `True`
-        If `True`, residuals from the training data are used as proxy of
-        prediction error to create prediction intervals.  If `False`, out_sample_residuals
+        If `True`, residuals from the training data are used as proxy of prediction
+        error to create prediction intervals. If `False`, out_sample_residuals 
         are used if they are already stored inside the forecaster.
-            
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `False`
-        Print number of folds and index of training and validation sets used for backtesting.
-
+        Print number of folds and index of training and validation sets used 
+        for backtesting.
     show_progress: bool, default `True`
-        Whether to show a progress bar. Defaults to True.
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
-    metrics_value : float, list
-        Value(s) of the metric(s).
+    metrics_levels : pandas DataFrame
+        Value(s) of the metric(s). Index are the levels and columns the metrics.
+    backtest_predictions : pandas Dataframe
+        Value of predictions and their estimated interval if `interval` is not `None`. 
+        If there is more than one level, this structure will be repeated for each of them.
 
-    backtest_predictions : pandas DataFrame
-        Value of predictions and their estimated interval if `interval` is not `None`.
-            column pred = predictions.
-            column lower_bound = lower bound of the interval.
-            column upper_bound = upper bound interval of the interval.
+            - column pred: predictions.
+            - column lower_bound: lower bound of the interval.
+            - column upper_bound: upper bound of the interval.
     
     """
 
     forecaster = deepcopy(forecaster)
+    if n_jobs == 'auto':
+        if isinstance(forecaster.regressor, sklearn.pipeline.Pipeline):
+            regressor_name = type(forecaster.regressor[-1]).__name__
+        else:
+            regressor_name = type(forecaster.regressor).__name__
+        
+        n_jobs = select_n_jobs_backtesting(
+                     forecaster_name = type(forecaster).__name__,
+                     regressor_name  = regressor_name,
+                     refit           = refit
+                 )
+    else:
+        n_jobs = n_jobs if n_jobs > 0 else cpu_count()
+
+    if type(forecaster).__name__ == 'ForecasterAutoregMultiVariate':
+        levels = [forecaster.level]
+    else:
+        if levels is None:
+            # Forecaster can be not fitted, so cannot use self.series_col_names
+            levels = list(series.columns) 
+        elif isinstance(levels, str):
+            levels = [levels]
 
     if not isinstance(metric, list):
         metrics = [_get_metric(metric=metric) if isinstance(metric, str) else metric]
     else:
         metrics = [_get_metric(metric=m) if isinstance(m, str) else m for m in metric]
 
-    # Initial model training
+    store_in_sample_residuals = False if interval is None else True
+
     if initial_train_size is not None:
+        # First model training, this is done to allow parallelization when `refit` 
+        # is `False`. The initial Forecaster fit is outside the auxiliary function.
         exog_train = exog.iloc[:initial_train_size, ] if exog is not None else None
-        store_in_sample_residuals = False if interval is None else True
         forecaster.fit(
-            y                         = y.iloc[:initial_train_size], 
+            series                    = series.iloc[:initial_train_size, ],
             exog                      = exog_train,
             store_in_sample_residuals = store_in_sample_residuals
         )
         window_size = forecaster.window_size
         externally_fitted = False
     else:
         # Although not used for training, first observations are needed to create
         # the initial predictors
         window_size = forecaster.window_size
         initial_train_size = window_size
         externally_fitted = True
-    
+
     folds = _create_backtesting_folds(
-                data                  = y,
+                data                  = series,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = steps,
                 externally_fitted     = externally_fitted,
-                refit                 = False,
+                refit                 = refit,
+                fixed_train_size      = fixed_train_size,
                 gap                   = gap,
                 allow_incomplete_fold = allow_incomplete_fold,
                 return_all_indexes    = False,
                 verbose               = verbose  
             )
 
-    backtest_predictions = []
-    
-    for fold in tqdm(folds) if show_progress else folds:
-        # Since the model is only fitted with the initial_train_size, last_window
-        # and next_window_exog must be updated to include the data needed to make
-        # predictions.
-        test_idx_start = fold[1][0]
-        test_idx_end   = fold[1][1]
-
-        last_window_end   = test_idx_start
-        last_window_start = last_window_end - window_size 
-        last_window_y     = y.iloc[last_window_start:last_window_end]
+    if refit:
+        n_of_fits = int(len(folds)/refit)
+        if type(forecaster).__name__ != 'ForecasterAutoregMultiVariate' and n_of_fits > 50:
+            warnings.warn(
+                (f"The forecaster will be fit {n_of_fits} times. This can take substantial "
+                 f"amounts of time. If not feasible, try with `refit = False`.\n"),
+                LongTrainingWarning
+            )
+        elif type(forecaster).__name__ == 'ForecasterAutoregMultiVariate' and n_of_fits*forecaster.steps > 50:
+            warnings.warn(
+                (f"The forecaster will be fit {n_of_fits*forecaster.steps} times "
+                 f"({n_of_fits} folds * {forecaster.steps} regressors). This can take "
+                 f"substantial amounts of time. If not feasible, try with `refit = False`.\n"),
+                LongTrainingWarning
+            )
+
+    if show_progress:
+        folds = tqdm(folds)
+
+    def _fit_predict_forecaster(series, exog, forecaster, interval, fold):
+        """
+        Fit the forecaster and predict `steps` ahead. This is an auxiliary 
+        function used to parallelize the backtesting_forecaster_multiseries
+        function.
+        """
+
+        train_idx_start   = fold[0][0]
+        train_idx_end     = fold[0][1]
+        last_window_start = fold[1][0]
+        last_window_end   = fold[1][1]
+        test_idx_start    = fold[2][0]
+        test_idx_end      = fold[2][1]
+
+        if fold[4] is False:
+            # When the model is not fitted, last_window must be updated to include 
+            # the data needed to make predictions.
+            last_window_series = series.iloc[last_window_start:last_window_end, ]
+        else:
+            # The model is fitted before making predictions. If `fixed_train_size`  
+            # the train size doesn't increase but moves by `steps` in each iteration. 
+            # If `False` the train size increases by `steps` in each  iteration.
+            series_train = series.iloc[train_idx_start:train_idx_end, ]
+            exog_train = exog.iloc[train_idx_start:train_idx_end, ] if exog is not None else None
+            last_window_series = None
+            forecaster.fit(
+                series                    = series_train, 
+                exog                      = exog_train,
+                store_in_sample_residuals = store_in_sample_residuals
+            )
         
         next_window_exog = exog.iloc[test_idx_start:test_idx_end, ] if exog is not None else None
+
         steps = len(range(test_idx_start, test_idx_end))
+        if type(forecaster).__name__ == 'ForecasterAutoregMultiVariate' and gap > 0:
+            # Select only the steps that need to be predicted if gap > 0
+            test_idx_start = fold[3][0]
+            test_idx_end   = fold[3][1]
+            steps = list(np.arange(len(range(test_idx_start, test_idx_end))) + gap + 1)
+        
         if interval is None:
             pred = forecaster.predict(
-                       steps       = steps,
-                       last_window = last_window_y,
+                       steps       = steps, 
+                       levels      = levels, 
+                       last_window = last_window_series,
                        exog        = next_window_exog
                    )
         else:
             pred = forecaster.predict_interval(
                        steps               = steps,
-                       last_window         = last_window_y,
+                       levels              = levels, 
+                       last_window         = last_window_series,
                        exog                = next_window_exog,
                        interval            = interval,
                        n_boot              = n_boot,
                        random_state        = random_state,
                        in_sample_residuals = in_sample_residuals
                    )
+
+        if type(forecaster).__name__ != 'ForecasterAutoregMultiVariate' and gap > 0:
+            pred = pred.iloc[gap:, ]
         
-        pred = pred.iloc[gap:, ]
-        backtest_predictions.append(pred)
+        return pred
+    
+    backtest_predictions = (
+        Parallel(n_jobs=n_jobs)
+        (delayed(_fit_predict_forecaster)
+        (series=series, exog=exog, forecaster=forecaster, interval=interval, fold=fold)
+         for fold in folds)
+    )
 
     backtest_predictions = pd.concat(backtest_predictions)
-    if isinstance(backtest_predictions, pd.Series):
-        backtest_predictions = pd.DataFrame(backtest_predictions)
 
-    metrics_values = [m(
-                        y_true = y.loc[backtest_predictions.index],
-                        y_pred = backtest_predictions['pred']
-                      ) for m in metrics
-                     ]
-    
-    if not isinstance(metric, list):
-        metrics_values = metrics_values[0]
+    metrics_levels = [[m(
+                         y_true = series[level].loc[backtest_predictions.index],
+                         y_pred = backtest_predictions[level]
+                        ) for m in metrics
+                      ] for level in levels]
+
+    metrics_levels = pd.concat(
+                         [pd.DataFrame({'levels': levels}), 
+                          pd.DataFrame(
+                              data    = metrics_levels,
+                              columns = [m if isinstance(m, str) else m.__name__ 
+                                         for m in metrics]
+                          )],
+                         axis=1
+                     )
 
-    return metrics_values, backtest_predictions
+    return metrics_levels, backtest_predictions
 
 
-def backtesting_forecaster(
+def backtesting_forecaster_multiseries(
     forecaster,
-    y: pd.Series,
+    series: pd.DataFrame,
     steps: int,
     metric: Union[str, Callable, list],
-    initial_train_size: Optional[int]=None,
+    initial_train_size: Optional[int],
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
+    levels: Optional[Union[str, list]]=None,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
-    refit: bool=False,
+    refit: Optional[Union[bool, int]]=False,
     interval: Optional[list]=None,
     n_boot: int=500,
     random_state: int=123,
     in_sample_residuals: bool=True,
+    n_jobs: Optional[Union[int, str]]='auto',
     verbose: bool=False,
     show_progress: bool=True
-) -> Tuple[Union[float, list], pd.DataFrame]:
+) -> Tuple[pd.DataFrame, pd.DataFrame]:
     """
-    Backtesting of forecaster model.
+    Backtesting for multi-series and multivariate forecasters.
 
-    If `refit` is False, the model is trained only once using the `initial_train_size`
-    first observations. If `refit` is True, the model is trained in each iteration
-    increasing the training set. A copy of the original forecaster is created so 
-    it is not modified during the process.
+    - If `refit` is `False`, the model will be trained only once using the 
+    `initial_train_size` first observations. 
+    - If `refit` is `True`, the model is trained on each iteration, increasing
+    the training set. 
+    - If `refit` is an `integer`, the model will be trained every that number 
+    of iterations.
+    - If `forecaster` is already trained and `initial_train_size` is `None`,
+    no initial train will be done and all data will be used to evaluate the model.
+    However, the first `len(forecaster.last_window)` observations are needed
+    to create the initial predictors, so no predictions are calculated for them.
+    
+    A copy of the original forecaster is created so that it is not modified during 
+    the process.
 
     Parameters
     ----------
-    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect
+    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom,
+    ForecasterAutoregMultiVariate
         Forecaster model.
-        
-    y : pandas Series
+    series : pandas DataFrame
         Training time series.
-    
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-    
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int, default `None`
-        Number of samples in the initial train split. If `None` and `forecaster` is already 
-        trained, no initial train is done and all data is used to evaluate the model. However, 
-        the first `len(forecaster.last_window)` observations are needed to create the 
-        initial predictors, so no predictions are calculated for them. This useful
-        to backtest the model on the same data used to train it.
-
-        `None` is only allowed when `refit` is `False` and `forecaster` is already trained.
-    
+        Number of samples in the initial train split. If `None` and `forecaster` is 
+        already trained, no initial train is done and all data is used to evaluate the 
+        model. However, the first `len(forecaster.last_window)` observations are needed 
+        to create the initial predictors, so no predictions are calculated for them. 
+        This useful to backtest the model on the same data used to train it.
+        `None` is only allowed when `refit` is `False` and `forecaster` is already
+        trained.
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-        
+    levels : str, list, default `None`
+        Time series to be predicted. If `None` all levels will be predicted.
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration.
-
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     interval : list, default `None`
         Confidence of the prediction interval estimated. Sequence of percentiles
-        to compute, which must be between 0 and 100 inclusive. For example, 
-        interval of 95% should be as `interval = [2.5, 97.5]`. If `None`, no
-        intervals are estimated. Only available for forecaster of type 
-        ForecasterAutoreg and ForecasterAutoregCustom.
-            
+        to compute, which must be between 0 and 100 inclusive. If `None`, no
+        intervals are estimated.
     n_boot : int, default `500`
         Number of bootstrapping iterations used to estimate prediction
         intervals.
-
     random_state : int, default `123`
         Sets a seed to the random generator, so that boot intervals are always 
         deterministic.
-
     in_sample_residuals : bool, default `True`
-        If `True`, residuals from the training data are used as proxy of
-        prediction error to create prediction intervals.  If `False`, out_sample_residuals
+        If `True`, residuals from the training data are used as proxy of prediction 
+        error to create prediction intervals.  If `False`, out_sample_residuals 
         are used if they are already stored inside the forecaster.
-                  
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `False`
         Print number of folds and index of training and validation sets used 
         for backtesting.
-
     show_progress: bool, default `True`
-        Whether to show a progress bar. Defaults to True.
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
-    metrics_value : float, list
-        Value(s) of the metric(s).
-
+    metrics_levels : pandas DataFrame
+        Value(s) of the metric(s). Index are the levels and columns the metrics.
     backtest_predictions : pandas DataFrame
         Value of predictions and their estimated interval if `interval` is not `None`.
-            column pred = predictions.
-            column lower_bound = lower bound of the interval.
-            column upper_bound = upper bound interval of the interval.
+        If there is more than one level, this structure will be repeated for each of them.
+
+            - column pred: predictions.
+            - column lower_bound: lower bound of the interval.
+            - column upper_bound: upper bound of the interval.
     
     """
-    
-    if type(forecaster).__name__ not in ['ForecasterAutoreg', 
-                                         'ForecasterAutoregCustom', 
-                                         'ForecasterAutoregDirect']:
+
+    if type(forecaster).__name__ not in ['ForecasterAutoregMultiSeries', 
+                                         'ForecasterAutoregMultiSeriesCustom', 
+                                         'ForecasterAutoregMultiVariate']:
         raise TypeError(
-            ("`forecaster` must be of type `ForecasterAutoreg`, `ForecasterAutoregCustom` "
-             "or `ForecasterAutoregDirect`, for all other types of forecasters "
-             "use the functions available in the other `model_selection` modules.")
+            ("`forecaster` must be of type `ForecasterAutoregMultiSeries`, "
+             "`ForecasterAutoregMultiSeriesCustom` or `ForecasterAutoregMultiVariate`, "
+             "for all other types of forecasters use the functions available in "
+             f"the `model_selection` module. Got {type(forecaster).__name__}")
         )
     
     check_backtesting_input(
         forecaster            = forecaster,
         steps                 = steps,
         metric                = metric,
-        y                     = y,
+        series                = series,
         initial_train_size    = initial_train_size,
         fixed_train_size      = fixed_train_size,
         gap                   = gap,
         allow_incomplete_fold = allow_incomplete_fold,
         refit                 = refit,
         interval              = interval,
         n_boot                = n_boot,
         random_state          = random_state,
         in_sample_residuals   = in_sample_residuals,
+        n_jobs                = n_jobs,
         verbose               = verbose,
         show_progress         = show_progress
     )
-    
-    if type(forecaster).__name__ == 'ForecasterAutoregDirect' and \
-       forecaster.steps < steps + gap:
-        raise ValueError(
-            ("When using a ForecasterAutoregDirect, the combination of steps "
-             f"+ gap ({steps+gap}) cannot be greater than the `steps` parameter "
-             f"declared when the forecaster is initialized ({forecaster.steps}).")
+
+    if type(forecaster).__name__ in ['ForecasterAutoregMultiSeries', 
+                                     'ForecasterAutoregMultiSeriesCustom'] \
+        and levels is not None and not isinstance(levels, (str, list)):
+        raise TypeError(
+            ("`levels` must be a `list` of column names, a `str` of a column name "
+             "or `None` when using a `ForecasterAutoregMultiSeries` or "
+             "`ForecasterAutoregMultiSeriesCustom`. If the forecaster is of type "
+             "`ForecasterAutoregMultiVariate`, this argument is ignored.")
         )
-    
-    if refit:
-        metrics_values, backtest_predictions = _backtesting_forecaster_refit(
-            forecaster            = forecaster,
-            y                     = y,
-            steps                 = steps,
-            metric                = metric,
-            initial_train_size    = initial_train_size,
-            fixed_train_size      = fixed_train_size,
-            gap                   = gap,
-            allow_incomplete_fold = allow_incomplete_fold,
-            exog                  = exog,
-            interval              = interval,
-            n_boot                = n_boot,
-            random_state          = random_state,
-            in_sample_residuals   = in_sample_residuals,
-            verbose               = verbose,
-            show_progress         = show_progress
+
+    if type(forecaster).__name__ == 'ForecasterAutoregMultiVariate' \
+        and levels and levels != forecaster.level and levels != [forecaster.level]:
+        warnings.warn(
+            (f"`levels` argument have no use when the forecaster is of type "
+             f"`ForecasterAutoregMultiVariate`. The level of this forecaster is "
+             f"'{forecaster.level}', to predict another level, change the `level` "
+             f"argument when initializing the forecaster."),
+             IgnoredArgumentWarning
         )
-    else:
-        metrics_values, backtest_predictions = _backtesting_forecaster_no_refit(
-            forecaster            = forecaster,
-            y                     = y,
-            steps                 = steps,
-            metric                = metric,
-            initial_train_size    = initial_train_size,
-            gap                   = gap,
-            allow_incomplete_fold = allow_incomplete_fold,
-            exog                  = exog,
-            interval              = interval,
-            n_boot                = n_boot,
-            random_state          = random_state,
-            in_sample_residuals   = in_sample_residuals,
-            verbose               = verbose,
-            show_progress         = show_progress
-        )  
 
-    return metrics_values, backtest_predictions
+    metrics_levels, backtest_predictions = _backtesting_forecaster_multiseries(
+        forecaster            = forecaster,
+        series                = series,
+        steps                 = steps,
+        levels                = levels,
+        metric                = metric,
+        initial_train_size    = initial_train_size,
+        fixed_train_size      = fixed_train_size,
+        gap                   = gap,
+        allow_incomplete_fold = allow_incomplete_fold,
+        exog                  = exog,
+        refit                 = refit,
+        interval              = interval,
+        n_boot                = n_boot,
+        random_state          = random_state,
+        in_sample_residuals   = in_sample_residuals,
+        n_jobs                = n_jobs,
+        verbose               = verbose,
+        show_progress         = show_progress
+    )
+
+    return metrics_levels, backtest_predictions
 
 
-def grid_search_forecaster(
+def grid_search_forecaster_multiseries(
     forecaster,
-    y: pd.Series,
+    series: pd.DataFrame,
     param_grid: dict,
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
+    levels: Optional[Union[str, list]]=None,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
     lags_grid: Optional[list]=None,
-    refit: bool=False,
+    refit: Optional[Union[bool, int]]=False,
     return_best: bool=True,
-    verbose: bool=True
+    n_jobs: Optional[Union[int, str]]='auto',
+    verbose: bool=True,
+    show_progress: bool=True
 ) -> pd.DataFrame:
     """
     Exhaustive search over specified parameter values for a Forecaster object.
-    Validation is done using time series backtesting.
+    Validation is done using multi-series backtesting.
     
     Parameters
     ----------
-    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect
+    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom,
+    ForecasterAutoregMultiVariate
         Forcaster model.
-        
-    y : pandas Series
-        Training time series values. 
-        
+    series : pandas DataFrame
+        Training time series.
     param_grid : dict
         Dictionary with parameters names (`str`) as keys and lists of parameter
         settings to try as values.
-
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int 
         Number of samples in the initial train split.
- 
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
+    levels : str, list, default `None`
+        level (`str`) or levels (`list`) at which the forecaster is optimized. 
+        If `None`, all levels are taken into account. The resulting metric will be
+        the average of the optimization of all levels.
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-           
-    lags_grid : list of int, lists, numpy ndarray or range, default `None`
+    lags_grid : list of int, lists, np.narray or range, default `None`
         Lists of `lags` to try. Only used if forecaster is an instance of 
-        `ForecasterAutoreg` or `ForecasterAutoregDirect`.
-        
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration of backtesting.
-        
+        `ForecasterAutoregMultiSeries` or `ForecasterAutoregMultiVariate`.
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     return_best : bool, default `True`
         Refit the `forecaster` using the best found parameters on the whole data.
-        
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `True`
         Print number of folds used for cv or backtesting.
+    show_progress: bool, default `True`
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
     results : pandas DataFrame
         Results for each combination of parameters.
-            column lags = predictions.
-            column params = lower bound of the interval.
-            column metric = metric value estimated for the combination of parameters.
-            additional n columns with param = value.
+
+            - column levels: levels configuration for each iteration.
+            - column lags: lags configuration for each iteration.
+            - column params: parameters configuration for each iteration.
+            - column metric: metric value estimated for each iteration. The resulting 
+            metric will be the average of the optimization of all levels.
+            - additional n columns with param = value.
     
     """
 
     param_grid = list(ParameterGrid(param_grid))
 
-    results = _evaluate_grid_hyperparameters(
-        forecaster            = forecaster,
-        y                     = y,
-        param_grid            = param_grid,
-        steps                 = steps,
-        metric                = metric,
-        initial_train_size    = initial_train_size,
-        fixed_train_size      = fixed_train_size,
-        gap                   = gap,
-        allow_incomplete_fold = allow_incomplete_fold,
-        exog                  = exog,
-        lags_grid             = lags_grid,
-        refit                 = refit,
-        return_best           = return_best,
-        verbose               = verbose
-    )
+    results = _evaluate_grid_hyperparameters_multiseries(
+                  forecaster            = forecaster,
+                  series                = series,
+                  param_grid            = param_grid,
+                  steps                 = steps,
+                  metric                = metric,
+                  initial_train_size    = initial_train_size,
+                  fixed_train_size      = fixed_train_size,
+                  gap                   = gap,
+                  allow_incomplete_fold = allow_incomplete_fold,
+                  levels                = levels,
+                  exog                  = exog,
+                  lags_grid             = lags_grid,
+                  refit                 = refit,
+                  n_jobs                = n_jobs,
+                  return_best           = return_best,
+                  verbose               = verbose,
+                  show_progress         = show_progress
+              )
 
     return results
 
 
-def random_search_forecaster(
+def random_search_forecaster_multiseries(
     forecaster,
-    y: pd.Series,
+    series: pd.DataFrame,
     param_distributions: dict,
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
+    levels: Optional[Union[str, list]]=None,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
     lags_grid: Optional[list]=None,
-    refit: bool=False,
+    refit: Optional[Union[bool, int]]=False,
     n_iter: int=10,
     random_state: int=123,
     return_best: bool=True,
-    verbose: bool=True
+    n_jobs: Optional[Union[int, str]]='auto',
+    verbose: bool=True,
+    show_progress: bool=True
 ) -> pd.DataFrame:
     """
-    Random search over specified parameter values or distributions for a Forecaster object.
-    Validation is done using time series backtesting.
+    Random search over specified parameter values or distributions for a Forecaster 
+    object. Validation is done using multi-series backtesting.
     
     Parameters
     ----------
-    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect
+    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom, 
+    ForecasterAutoregMultiVariate
         Forcaster model.
-        
-    y : pandas Series
-        Training time series. 
-        
+    series : pandas DataFrame
+        Training time series.
     param_distributions : dict
-        Dictionary with parameters names (`str`) as keys and 
-        distributions or lists of parameters to try.
-
+        Dictionary with parameters names (`str`) as keys and distributions or 
+        lists of parameters to try.
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int 
         Number of samples in the initial train split.
- 
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
+    levels : str, list, default `None`
+        level (`str`) or levels (`list`) at which the forecaster is optimized. 
+        If `None`, all levels are taken into account. The resulting metric will be
+        the average of the optimization of all levels.
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-           
-    lags_grid : list of int, lists, numpy ndarray or range, default `None`
+    lags_grid : list of int, lists, np.narray or range, default `None`
         Lists of `lags` to try. Only used if forecaster is an instance of 
-        `ForecasterAutoreg` or `ForecasterAutoregDirect`.
-        
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration of backtesting.
-
+        `ForecasterAutoregMultiSeries` or `ForecasterAutoregMultiVariate`.
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     n_iter : int, default `10`
         Number of parameter settings that are sampled per lags configuration. 
         n_iter trades off runtime vs quality of the solution.
-
     random_state : int, default `123`
         Sets a seed to the random sampling for reproducible output.
-
     return_best : bool, default `True`
         Refit the `forecaster` using the best found parameters on the whole data.
-        
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `True`
         Print number of folds used for cv or backtesting.
+    show_progress: bool, default `True`
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
     results : pandas DataFrame
         Results for each combination of parameters.
-            column lags = predictions.
-            column params = lower bound of the interval.
-            column metric = metric value estimated for the combination of parameters.
-            additional n columns with param = value.
+
+            - column levels: levels configuration for each iteration.
+            - column lags: lags configuration for each iteration.
+            - column params: parameters configuration for each iteration.
+            - column metric: metric value estimated for each iteration. The resulting 
+            metric will be the average of the optimization of all levels.
+            - additional n columns with param = value.
     
     """
 
-    param_grid = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=random_state))
-
-    results = _evaluate_grid_hyperparameters(
-        forecaster            = forecaster,
-        y                     = y,
-        param_grid            = param_grid,
-        steps                 = steps,
-        metric                = metric,
-        initial_train_size    = initial_train_size,
-        fixed_train_size      = fixed_train_size,
-        gap                   = gap,
-        allow_incomplete_fold = allow_incomplete_fold,
-        exog                  = exog,
-        lags_grid             = lags_grid,
-        refit                 = refit,
-        return_best           = return_best,
-        verbose               = verbose
-    )
+    param_grid = list(ParameterSampler(param_distributions, n_iter=n_iter, 
+                                       random_state=random_state))
+
+    results = _evaluate_grid_hyperparameters_multiseries(
+                  forecaster            = forecaster,
+                  series                = series,
+                  param_grid            = param_grid,
+                  steps                 = steps,
+                  metric                = metric,
+                  initial_train_size    = initial_train_size,
+                  fixed_train_size      = fixed_train_size,
+                  gap                   = gap,
+                  allow_incomplete_fold = allow_incomplete_fold,
+                  levels                = levels,
+                  exog                  = exog,
+                  lags_grid             = lags_grid,
+                  refit                 = refit,
+                  return_best           = return_best,
+                  n_jobs                = n_jobs,
+                  verbose               = verbose,
+                  show_progress         = show_progress
+              )
 
     return results
 
 
-def _evaluate_grid_hyperparameters(
+def _evaluate_grid_hyperparameters_multiseries(
     forecaster,
-    y: pd.Series,
+    series: pd.DataFrame,
     param_grid: dict,
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
+    levels: Optional[Union[str, list]]=None,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
     lags_grid: Optional[list]=None,
-    refit: bool=False,
+    refit: Optional[Union[bool, int]]=False,
     return_best: bool=True,
-    verbose: bool=True
+    n_jobs: Optional[Union[int, str]]='auto',
+    verbose: bool=True,
+    show_progress: bool=True
 ) -> pd.DataFrame:
     """
-    Evaluate parameter values for a Forecaster object using time series backtesting.
+    Evaluate parameter values for a Forecaster object using multi-series backtesting.
     
     Parameters
     ----------
-    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect
+    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom,
+    ForecasterAutoregMultiVariate
         Forcaster model.
-        
-    y : pandas Series
-        Training time series values. 
-        
+    series : pandas DataFrame
+        Training time series.
     param_grid : dict
         Dictionary with parameters names (`str`) as keys and lists of parameter
         settings to try as values.
-
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int 
         Number of samples in the initial train split.
- 
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
+    levels : str, list, default `None`
+        level (`str`) or levels (`list`) at which the forecaster is optimized. 
+        If `None`, all levels are taken into account. The resulting metric will be
+        the average of the optimization of all levels.
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-           
-    lags_grid : list of int, lists, numpy ndarray or range, default `None`
+    lags_grid : list of int, lists, np.narray or range, default `None`
         Lists of `lags` to try. Only used if forecaster is an instance of 
-        `ForecasterAutoreg` or `ForecasterAutoregDirect`.
-        
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration of backtesting.
-        
+        `ForecasterAutoregMultiSeries` or `ForecasterAutoregMultiVariate`.
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     return_best : bool, default `True`
         Refit the `forecaster` using the best found parameters on the whole data.
-        
     verbose : bool, default `True`
         Print number of folds used for cv or backtesting.
 
-    Returns 
+    Returns
     -------
     results : pandas DataFrame
         Results for each combination of parameters.
-            column lags = predictions.
-            column params = lower bound of the interval.
-            column metric = metric value estimated for the combination of parameters.
-            additional n columns with param = value.
 
+            - column levels: levels configuration for each iteration.
+            - column lags: lags configuration for each iteration.
+            - column params: parameters configuration for each iteration.
+            - column metric: metric value estimated for each iteration. The resulting 
+            metric will be the average of the optimization of all levels.
+            - additional n columns with param = value.
+    
     """
 
-    if return_best and exog is not None and (len(exog) != len(y)):
+    if return_best and exog is not None and (len(exog) != len(series)):
         raise ValueError(
-            (f"`exog` must have same number of samples as `y`. "
-             f"length `exog`: ({len(exog)}), length `y`: ({len(y)})")
+            (f"`exog` must have same number of samples as `series`. "
+             f"length `exog`: ({len(exog)}), length `series`: ({len(series)})")
         )
 
-    if type(forecaster).__name__ == 'ForecasterAutoregCustom':
+    if type(forecaster).__name__ in ['ForecasterAutoregMultiSeries', 
+                                     'ForecasterAutoregMultiSeriesCustom']  \
+        and levels is not None and not isinstance(levels, (str, list)):
+        raise TypeError(
+            ("`levels` must be a `list` of column names, a `str` of a column "
+             "name or `None`.")
+        )
+
+    if type(forecaster).__name__ == 'ForecasterAutoregMultiVariate':
+        if levels and levels != forecaster.level and levels != [forecaster.level]:
+            warnings.warn(
+                (f"`levels` argument have no use when the forecaster is of type "
+                 f"ForecasterAutoregMultiVariate. The level of this forecaster "
+                 f"is {forecaster.level}, to predict another level, change "
+                 f"the `level` argument when initializing the forecaster. \n"),
+                 IgnoredArgumentWarning
+            )
+        levels = [forecaster.level]
+    else:
+        if levels is None:
+            # Forecaster can be not fitted, so cannot use self.series_col_names
+            levels = list(series.columns) 
+        elif isinstance(levels, str):
+            levels = [levels]
+
+    if type(forecaster).__name__ == 'ForecasterAutoregMultiSeriesCustom':
         if lags_grid is not None:
             warnings.warn(
-                "`lags_grid` ignored if forecaster is an instance of `ForecasterAutoregCustom`.",
-                IgnoredArgumentWarning
+                ("`lags_grid` ignored if forecaster is an instance of "
+                 "`ForecasterAutoregMultiSeriesCustom`."),
+                 IgnoredArgumentWarning
             )
         lags_grid = ['custom predictors']
-        
     elif lags_grid is None:
         lags_grid = [forecaster.lags]
    
     lags_list = []
     params_list = []
     if not isinstance(metric, list):
         metric = [metric] 
     metric_dict = {(m if isinstance(m, str) else m.__name__): [] for m in metric}
     
     if len(metric_dict) != len(metric):
         raise ValueError(
             "When `metric` is a `list`, each metric name must be unique."
         )
 
-    print(f"Number of models compared: {len(param_grid)*len(lags_grid)}.")
+    print(
+        f'{len(param_grid)*len(lags_grid)} models compared for {len(levels)} level(s). '
+        f'Number of iterations: {len(param_grid)*len(lags_grid)}.'
+    )
+
+    if show_progress:
+        lags_grid = tqdm(lags_grid, desc='lags grid', position=0) #ncols=90
+        param_grid = tqdm(param_grid, desc='params grid', position=1, leave=False)
 
-    for lags in tqdm(lags_grid, desc='lags grid', position=0): #ncols=90
-        
-        if type(forecaster).__name__ in ['ForecasterAutoreg', 'ForecasterAutoregDirect']:
+    for lags in lags_grid:
+
+        if type(forecaster).__name__ in ['ForecasterAutoregMultiSeries', 
+                                         'ForecasterAutoregMultiVariate']:
             forecaster.set_lags(lags)
             lags = forecaster.lags.copy()
         
-        for params in tqdm(param_grid, desc='params grid', position=1, leave=False): #ncols=90
+        for params in param_grid:
 
             forecaster.set_params(params)
-            metrics_values = backtesting_forecaster(
+            metrics_levels = backtesting_forecaster_multiseries(
                                  forecaster            = forecaster,
-                                 y                     = y,
+                                 series                = series,
                                  steps                 = steps,
+                                 levels                = levels,
                                  metric                = metric,
                                  initial_train_size    = initial_train_size,
                                  fixed_train_size      = fixed_train_size,
                                  gap                   = gap,
                                  allow_incomplete_fold = allow_incomplete_fold,
                                  exog                  = exog,
                                  refit                 = refit,
                                  interval              = None,
                                  verbose               = verbose,
+                                 n_jobs                = n_jobs,
                                  show_progress         = False
                              )[0]
-            warnings.filterwarnings('ignore', category=RuntimeWarning, message= "The forecaster will be fit.*")
+            warnings.filterwarnings(
+                'ignore', category=RuntimeWarning, message= "The forecaster will be fit.*"
+            )
             lags_list.append(lags)
             params_list.append(params)
-            for m, m_value in zip(metric, metrics_values):
+            for m in metric:
                 m_name = m if isinstance(m, str) else m.__name__
-                metric_dict[m_name].append(m_value)
+                metric_dict[m_name].append(metrics_levels[m_name].mean())
 
     results = pd.DataFrame({
-                 'lags'  : lags_list,
-                 'params': params_list,
-                 **metric_dict
+                  'levels': [levels]*len(lags_list),
+                  'lags'  : lags_list,
+                  'params': params_list,
+                  **metric_dict
               })
     
     results = results.sort_values(by=list(metric_dict.keys())[0], ascending=True)
     results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)
     
     if return_best:
         
         best_lags = results['lags'].iloc[0]
         best_params = results['params'].iloc[0]
         best_metric = results[list(metric_dict.keys())[0]].iloc[0]
         
-        if type(forecaster).__name__ in ['ForecasterAutoreg', 'ForecasterAutoregDirect']:
+        if type(forecaster).__name__ != 'ForecasterAutoregMultiSeriesCustom':
             forecaster.set_lags(best_lags)
         forecaster.set_params(best_params)
-        forecaster.fit(y=y, exog=exog)
+        forecaster.fit(series=series, exog=exog, store_in_sample_residuals=True)
         
         print(
             f"`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n"
-            f"  Lags: {best_lags} \n"
+            f"  Lags: {best_lags}\n"
             f"  Parameters: {best_params}\n"
             f"  Backtesting metric: {best_metric}\n"
+            f"  Levels: {results['levels'].iloc[0]}\n"
         )
             
     return results
 
 
-def bayesian_search_forecaster(
+# Alias MultiVariate
+# ==============================================================================
+def backtesting_forecaster_multivariate(
     forecaster,
-    y: pd.Series,
-    search_space: Union[Callable, dict],
+    series: pd.DataFrame,
+    steps: int,
+    metric: Union[str, Callable, list],
+    initial_train_size: Optional[int],
+    fixed_train_size: bool=True,
+    gap: int=0,
+    allow_incomplete_fold: bool=True,
+    levels: Optional[Union[str, list]]=None,
+    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
+    refit: Optional[Union[bool, int]]=False,
+    interval: Optional[list]=None,
+    n_boot: int=500,
+    random_state: int=123,
+    in_sample_residuals: bool=True,
+    n_jobs: Optional[Union[int, str]]='auto',
+    verbose: bool=False,
+    show_progress: bool=True
+) -> Tuple[pd.DataFrame, pd.DataFrame]:
+    """
+    This function is an alias of backtesting_forecaster_multiseries.
+
+    Backtesting for multi-series and multivariate forecasters.
+
+    If `refit` is False, the model is trained only once using the `initial_train_size`
+    first observations. If `refit` is True, the model is trained in each iteration
+    increasing the training set. A copy of the original forecaster is created so 
+    it is not modified during the process.
+
+    Parameters
+    ----------
+    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom, 
+    ForecasterAutoregMultiVariate
+        Forecaster model.
+    series : pandas DataFrame
+        Training time series.
+    steps : int
+        Number of steps to predict.
+    metric : str, Callable, list
+        Metric used to quantify the goodness of fit of the model.
+        
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
+             'mean_absolute_percentage_error', 'mean_squared_log_error'}
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
+    initial_train_size : int, default `None`
+        Number of samples in the initial train split. If `None` and `forecaster` is 
+        already trained, no initial train is done and all data is used to evaluate the 
+        model. However, the first `len(forecaster.last_window)` observations are needed 
+        to create the initial predictors, so no predictions are calculated for them. 
+        This useful to backtest the model on the same data used to train it.
+        `None` is only allowed when `refit` is `False` and `forecaster` is already
+        trained.
+    fixed_train_size : bool, default `True`
+        If True, train size doesn't increase but moves by `steps` in each iteration.
+    gap : int, default `0`
+        Number of samples to be excluded after the end of each training set and 
+        before the test set.
+    allow_incomplete_fold : bool, default `True`
+        Last fold is allowed to have a smaller number of samples than the 
+        `test_size`. If `False`, the last fold is excluded.
+    levels : str, list, default `None`
+        Time series to be predicted. If `None` all levels will be predicted.
+    exog : pandas Series, pandas DataFrame, default `None`
+        Exogenous variable/s included as predictor/s. Must have the same
+        number of observations as `y` and should be aligned so that y[i] is
+        regressed on exog[i].
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
+    interval : list, default `None`
+        Confidence of the prediction interval estimated. Sequence of percentiles
+        to compute, which must be between 0 and 100 inclusive. If `None`, no
+        intervals are estimated.
+    n_boot : int, default `500`
+        Number of bootstrapping iterations used to estimate prediction
+        intervals.
+    random_state : int, default `123`
+        Sets a seed to the random generator, so that boot intervals are always 
+        deterministic.
+    in_sample_residuals : bool, default `True`
+        If `True`, residuals from the training data are used as proxy of prediction 
+        error to create prediction intervals.  If `False`, out_sample_residuals 
+        are used if they are already stored inside the forecaster.
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0** 
+    verbose : bool, default `False`
+        Print number of folds and index of training and validation sets used 
+        for backtesting.
+    show_progress: bool, default `True`
+        Whether to show a progress bar.
+
+    Returns
+    -------
+    metrics_levels : pandas DataFrame
+        Value(s) of the metric(s). Index are the levels and columns the metrics.
+    backtest_predictions : pandas DataFrame
+        Value of predictions and their estimated interval if `interval` is not `None`.
+        If there is more than one level, this structure will be repeated for each of them.
+
+            - column pred: predictions.
+            - column lower_bound: lower bound of the interval.
+            - column upper_bound: upper bound of the interval.
+    
+    """
+
+    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(
+        forecaster            = forecaster,
+        series                = series,
+        steps                 = steps,
+        metric                = metric,
+        initial_train_size    = initial_train_size,
+        fixed_train_size      = fixed_train_size,
+        gap                   = gap,
+        allow_incomplete_fold = allow_incomplete_fold,
+        levels                = levels,
+        exog                  = exog,
+        refit                 = refit,
+        interval              = interval,
+        n_boot                = n_boot,
+        random_state          = random_state,
+        in_sample_residuals   = in_sample_residuals,
+        n_jobs                = n_jobs,
+        verbose               = verbose,
+        show_progress         = show_progress
+        
+    )
+
+    return metrics_levels, backtest_predictions
+
+
+def grid_search_forecaster_multivariate(
+    forecaster,
+    series: pd.DataFrame,
+    param_grid: dict,
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
+    levels: Optional[Union[str, list]]=None,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
     lags_grid: Optional[list]=None,
-    refit: bool=False,
-    n_trials: int=10,
-    random_state: int=123,
+    refit: Optional[Union[bool, int]]=False,
     return_best: bool=True,
+    n_jobs: Optional[Union[int, str]]='auto',
     verbose: bool=True,
-    engine: str='optuna',
-    kwargs_create_study: dict={},
-    kwargs_study_optimize: dict={},
-    kwargs_gp_minimize: Any='deprecated'
-) -> Tuple[pd.DataFrame, object]:
+    show_progress: bool=True
+) -> pd.DataFrame:
     """
-    Bayesian optimization for a Forecaster object using time series backtesting and 
-    optuna library.
+    This function is an alias of grid_search_forecaster_multiseries.
+
+    Exhaustive search over specified parameter values for a Forecaster object.
+    Validation is done using multi-series backtesting.
     
     Parameters
     ----------
-    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect
+    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom, 
+    ForecasterAutoregMultiVariate
         Forcaster model.
-        
-    y : pandas Series
-        Training time series. 
-        
-    search_space : Callable (optuna), dict (skopt)
-        If optuna engine: Callable
-            Function with argument `trial` which returns a dictionary with parameters names 
-            (`str`) as keys and Trial object from optuna (trial.suggest_float, 
-            trial.suggest_int, trial.suggest_categorical) as values.
-
-        If skopt engine: dict
-            Dictionary with parameters names (`str`) as keys and Space object from skopt 
-            (Real, Integer, Categorical) as values.
-            **Deprecated in version 0.7.0**
-
+    series : pandas DataFrame
+        Training time series.
+    param_grid : dict
+        Dictionary with parameters names (`str`) as keys and lists of parameter
+        settings to try as values.
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int 
         Number of samples in the initial train split.
- 
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
+    levels : str, list, default `None`
+        level (`str`) or levels (`list`) at which the forecaster is optimized. 
+        If `None`, all levels are taken into account. The resulting metric will be
+        the average of the optimization of all levels.
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-           
-    lags_grid : list of int, lists, numpy ndarray or range, default `None`
+    lags_grid : list of int, lists, np.narray or range, default `None`
         Lists of `lags` to try. Only used if forecaster is an instance of 
-        `ForecasterAutoreg` or `ForecasterAutoregDirect`.
-        
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration of backtesting.
-        
-    n_trials : int, default `10`
-        Number of parameter settings that are sampled in each lag configuration.
-        When using engine "skopt", the minimum value is 10.
-
-    random_state : int, default `123`
-        Sets a seed to the sampling for reproducible output.
-
+        `ForecasterAutoregMultiSeries` or `ForecasterAutoregMultiVariate`.
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     return_best : bool, default `True`
         Refit the `forecaster` using the best found parameters on the whole data.
-        
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `True`
         Print number of folds used for cv or backtesting.
+    show_progress: bool, default `True`
+        Whether to show a progress bar.
 
-    engine : str, default `'optuna'`
-        If 'optuna':
-            Bayesian optimization runs through the optuna library.
-
-        If 'skopt':
-            Bayesian optimization runs through the skopt library.
-            **Deprecated in version 0.7.0**
-
-    kwargs_create_study : dict, default `{'direction':'minimize', 'sampler':TPESampler(seed=123)}`
-        Only applies to engine='optuna'.
-            Keyword arguments (key, value mappings) to pass to optuna.create_study.
-
-    kwargs_study_optimize : dict, default `{}`
-        Only applies to engine='optuna'.
-            Other keyword arguments (key, value mappings) to pass to study.optimize().
-
-    kwargs_gp_minimize : dict, default `{}`
-        Only applies to engine='skopt'.
-            Other keyword arguments (key, value mappings) to pass to skopt.gp_minimize().
-            **Deprecated in version 0.7.0**
-
-    Returns 
+    Returns
     -------
     results : pandas DataFrame
         Results for each combination of parameters.
-            column lags = predictions.
-            column params = lower bound of the interval.
-            column metric = metric value estimated for the combination of parameters.
-            additional n columns with param = value.
-
-    results_opt_best : optuna object (optuna), scipy object (skopt)   
-        If optuna engine:
-            The best optimization result returned as a FrozenTrial optuna object.
-
-        If skopt engine:
-            The best optimization result returned as a OptimizeResult object.
-            **Deprecated in version 0.7.0**
-    
-    """
 
-    if return_best and exog is not None and (len(exog) != len(y)):
-        raise ValueError(
-            f'`exog` must have same number of samples as `y`. '
-            f'length `exog`: ({len(exog)}), length `y`: ({len(y)})'
-        )
+            - column levels: levels configuration for each iteration.
+            - column lags: lags configuration for each iteration.
+            - column params: parameters configuration for each iteration.
+            - column metric: metric value estimated for each iteration. The resulting 
+            metric will be the average of the optimization of all levels.
+            - additional n columns with param = value.
     
-    if engine == 'skopt':
-        warnings.warn(
-            ("The engine 'skopt' for `bayesian_search_forecaster` is deprecated "
-             "in favor of 'optuna' engine. To continue using it, use skforecast "
-             "0.6.0. The optimization will be performed using the 'optuna' engine.")
-        )
-        engine = 'optuna'
-
-    if engine not in ['optuna']:
-        raise ValueError(
-            f"""`engine` only allows 'optuna', got {engine}."""
-        )
+    """
 
-    results, results_opt_best = _bayesian_search_optuna(
-                                    forecaster            = forecaster,
-                                    y                     = y,
-                                    exog                  = exog,
-                                    lags_grid             = lags_grid,
-                                    search_space          = search_space,
-                                    steps                 = steps,
-                                    metric                = metric,
-                                    refit                 = refit,
-                                    initial_train_size    = initial_train_size,
-                                    fixed_train_size      = fixed_train_size,
-                                    gap                   = gap,
-                                    allow_incomplete_fold = allow_incomplete_fold,
-                                    n_trials              = n_trials,
-                                    random_state          = random_state,
-                                    return_best           = return_best,
-                                    verbose               = verbose,
-                                    kwargs_create_study   = kwargs_create_study,
-                                    kwargs_study_optimize = kwargs_study_optimize
-                                )
+    results = grid_search_forecaster_multiseries(
+        forecaster            = forecaster,
+        series                = series,
+        param_grid            = param_grid,
+        steps                 = steps,
+        metric                = metric,
+        initial_train_size    = initial_train_size,
+        fixed_train_size      = fixed_train_size,
+        gap                   = gap,
+        allow_incomplete_fold = allow_incomplete_fold,
+        levels                = levels,
+        exog                  = exog,
+        lags_grid             = lags_grid,
+        refit                 = refit,
+        return_best           = return_best,
+        n_jobs                = n_jobs,
+        verbose               = verbose,
+        show_progress         = show_progress
+    )
 
-    return results, results_opt_best
+    return results
 
 
-def _bayesian_search_optuna(
+def random_search_forecaster_multivariate(
     forecaster,
-    y: pd.Series,
-    search_space: Callable,
+    series: pd.DataFrame,
+    param_distributions: dict,
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
+    levels: Optional[Union[str, list]]=None,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
     lags_grid: Optional[list]=None,
-    refit: bool=False,
-    n_trials: int=10,
+    refit: Optional[Union[bool, int]]=False,
+    n_iter: int=10,
     random_state: int=123,
     return_best: bool=True,
+    n_jobs: Optional[Union[int, str]]='auto',
     verbose: bool=True,
-    kwargs_create_study: dict={},
-    kwargs_study_optimize: dict={}
-) -> Tuple[pd.DataFrame, object]:
+    show_progress: bool=True
+) -> pd.DataFrame:
     """
-    Bayesian optimization for a Forecaster object using time series backtesting 
-    and optuna library.
-    
+    This function is an alias of random_search_forecaster_multiseries.
+
+    Random search over specified parameter values or distributions for a Forecaster 
+    object. Validation is done using multi-series backtesting.
+
     Parameters
     ----------
-    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect
+    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom,
+    ForecasterAutoregMultiVariate
         Forcaster model.
-        
-    y : pandas Series
-        Training time series. 
-        
-    search_space : Callable
-        Function with argument `trial` which returns a dictionary with parameters names 
-        (`str`) as keys and Trial object from optuna (trial.suggest_float, 
-        trial.suggest_int, trial.suggest_categorical) as values.
-
+    series : pandas DataFrame
+        Training time series.
+    param_distributions : dict
+        Dictionary with parameters names (`str`) as keys and distributions or 
+        lists of parameters to try.
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int 
         Number of samples in the initial train split.
- 
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
+    levels : str, list, default `None`
+        level (`str`) or levels (`list`) at which the forecaster is optimized. 
+        If `None`, all levels are taken into account. The resulting metric will be
+        the average of the optimization of all levels.
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-           
-    lags_grid : list of int, lists, numpy ndarray or range, default `None`
+    lags_grid : list of int, lists, np.narray or range, default `None`
         Lists of `lags` to try. Only used if forecaster is an instance of 
-        `ForecasterAutoreg` or `ForecasterAutoregDirect`.
-        
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration of backtesting.
-        
-    n_trials : int, default `10`
-        Number of parameter settings that are sampled in each lag configuration.
-
+        `ForecasterAutoregMultiSeries` or `ForecasterAutoregMultiVariate`.
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
+    n_iter : int, default `10`
+        Number of parameter settings that are sampled per lags configuration. 
+        n_iter trades off runtime vs quality of the solution.
     random_state : int, default `123`
-        Sets a seed to the sampling for reproducible output.
-
+        Sets a seed to the random sampling for reproducible output.
     return_best : bool, default `True`
         Refit the `forecaster` using the best found parameters on the whole data.
-        
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `True`
         Print number of folds used for cv or backtesting.
+    show_progress: bool, default `True`
+        Whether to show a progress bar.
 
-    kwargs_create_study : dict, default `{'direction':'minimize', 'sampler':TPESampler(seed=123)}`
-        Keyword arguments (key, value mappings) to pass to optuna.create_study.
-
-    kwargs_study_optimize : dict, default `{}`
-        Other keyword arguments (key, value mappings) to pass to study.optimize().
-
-    Returns 
+    Returns
     -------
     results : pandas DataFrame
         Results for each combination of parameters.
-            column lags = predictions.
-            column params = lower bound of the interval.
-            column metric = metric value estimated for the combination of parameters.
-            additional n columns with param = value.
 
-    results_opt_best : optuna object
-        The best optimization result returned as a FrozenTrial optuna object.
+            - column levels: levels configuration for each iteration.
+            - column lags: lags configuration for each iteration.
+            - column params: parameters configuration for each iteration.
+            - column metric: metric value estimated for each iteration. The resulting 
+            metric will be the average of the optimization of all levels.
+            - additional n columns with param = value.
 
     """
 
-    if type(forecaster).__name__ == 'ForecasterAutoregCustom':
-        if lags_grid is not None:
-            warnings.warn(
-                "`lags_grid` ignored if forecaster is an instance of `ForecasterAutoregCustom`.",
-                IgnoredArgumentWarning
-            )
-        lags_grid = ['custom predictors']
-        
-    elif lags_grid is None:
-        lags_grid = [forecaster.lags]
-   
-    lags_list = []
-    params_list = []
-    results_opt_best = None
-    if not isinstance(metric, list):
-        metric = [metric] 
-    metric_dict = {(m if isinstance(m, str) else m.__name__): [] for m in metric}
-    
-    if len(metric_dict) != len(metric):
-        raise ValueError(
-            "When `metric` is a `list`, each metric name must be unique."
-        )
-
-    # Objective function using backtesting_forecaster
-    def _objective(
-        trial,
+    results = random_search_forecaster_multiseries(
         forecaster            = forecaster,
-        y                     = y,
-        exog                  = exog,
+        series                = series,
+        param_distributions   = param_distributions,
+        steps                 = steps,
+        metric                = metric,
         initial_train_size    = initial_train_size,
         fixed_train_size      = fixed_train_size,
         gap                   = gap,
         allow_incomplete_fold = allow_incomplete_fold,
-        steps                 = steps,
-        metric                = metric,
+        levels                = levels,
+        exog                  = exog,
+        lags_grid             = lags_grid,
         refit                 = refit,
+        n_iter                = n_iter,
+        random_state          = random_state,
+        return_best           = return_best,
+        n_jobs                = n_jobs,
         verbose               = verbose,
-        search_space          = search_space,
-    ) -> float:
-        
-        forecaster.set_params(search_space(trial))
-        
-        metrics, _ = backtesting_forecaster(
-                         forecaster            = forecaster,
-                         y                     = y,
-                         exog                  = exog,
-                         steps                 = steps,
-                         metric                = metric,
-                         initial_train_size    = initial_train_size,
-                         fixed_train_size      = fixed_train_size,
-                         gap                   = gap,
-                         allow_incomplete_fold = allow_incomplete_fold,
-                         refit                 = refit,
-                         verbose               = verbose,
-                         show_progress         = False
-                     )
-        # Store metrics in the variable metric_values defined outside _objective.
-        nonlocal metric_values
-        metric_values.append(metrics)
-
-        return abs(metrics[0])
-
-    print(
-        f"""Number of models compared: {n_trials*len(lags_grid)},
-         {n_trials} bayesian search in each lag configuration."""
-    )
-
-    for lags in tqdm(lags_grid, desc='lags grid', position=0): #ncols=90
-                
-        metric_values = [] # This variable will be modified inside _objective function. 
-        # It is a trick to extract multiple values from _objective function since
-        # only the optimized value can be returned.
-
-        if type(forecaster).__name__ in ['ForecasterAutoreg', 'ForecasterAutoregDirect']:
-            forecaster.set_lags(lags)
-            lags = forecaster.lags.copy()
-        
-        if 'sampler' in kwargs_create_study.keys():
-            kwargs_create_study['sampler']._rng = np.random.RandomState(random_state)
-            kwargs_create_study['sampler']._random_sampler = RandomSampler(seed=random_state)
-
-        study = optuna.create_study(**kwargs_create_study)
-
-        if 'sampler' not in kwargs_create_study.keys():
-            study.sampler = TPESampler(seed=random_state)
-
-        study.optimize(_objective, n_trials=n_trials, **kwargs_study_optimize)
-
-        best_trial = study.best_trial
-
-        if search_space(best_trial).keys() != best_trial.params.keys():
-            raise ValueError(
-                f"""Some of the key values do not match the search_space key names.
-                Dict keys     : {list(search_space(best_trial).keys())}
-                Trial objects : {list(best_trial.params.keys())}."""
-            )
-        
-        for i, trial in enumerate(study.get_trials()):
-            params_list.append(trial.params)
-            lags_list.append(lags)
-
-            for m, m_values in zip(metric, metric_values[i]):
-                m_name = m if isinstance(m, str) else m.__name__
-                metric_dict[m_name].append(m_values)
-        
-        if results_opt_best is None:
-            results_opt_best = best_trial
-        else:
-            if best_trial.value < results_opt_best.value:
-                results_opt_best = best_trial
-        
-    results = pd.DataFrame(
-                  {'lags'  : lags_list,
-                   'params': params_list,
-                   **metric_dict}
-              )
+        show_progress         = show_progress
+    ) 
 
-    results = results.sort_values(by=list(metric_dict.keys())[0], ascending=True)
-    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)
-    
-    if return_best:
-        
-        best_lags = results['lags'].iloc[0]
-        best_params = results['params'].iloc[0]
-        best_metric = results[list(metric_dict.keys())[0]].iloc[0]
-        
-        if type(forecaster).__name__ in ['ForecasterAutoreg', 'ForecasterAutoregDirect']:
-            forecaster.set_lags(best_lags)
-        forecaster.set_params(best_params)
-        forecaster.fit(y=y, exog=exog)
-        
-        print(
-            f"`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n"
-            f"  Lags: {best_lags} \n"
-            f"  Parameters: {best_params}\n"
-            f"  Backtesting metric: {best_metric}\n"
-        )
-            
-    return results, results_opt_best
+    return results
```

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/fixtures_model_selection.py` & `skforecast-0.9.0/skforecast/model_selection/tests/fixtures_model_selection.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_backtesting_forecaster.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_backtesting_forecaster.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,22 @@
 # Unit test backtesting_forecaster
 # ==============================================================================
 import re
 import pytest
 import numpy as np
 import pandas as pd
 from sklearn.linear_model import Ridge
+from skforecast.ForecasterAutoreg import ForecasterAutoreg
 from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect
 from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries
 from skforecast.model_selection import backtesting_forecaster
 
 # Fixtures
 from .fixtures_model_selection import y
+from .fixtures_model_selection import exog
 
 
 def test_backtesting_forecaster_TypeError_when_forecaster_not_supported_types():
     """
     Test TypeError is raised in backtesting_forecaster if Forecaster is not one 
     of the types supported by the function.
     """
```

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_backtesting_forecaster_no_refit.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_backtesting_forecaster_no_refit.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,59 +1,66 @@
-# Unit test _backtesting_forecaster_no_refit
+# Unit test _backtesting_forecaster No refit
 # ==============================================================================
+import pytest
 import numpy as np
 import pandas as pd
 from pytest import approx
 from sklearn.linear_model import LinearRegression
 from sklearn.metrics import mean_squared_error
 from skforecast.ForecasterAutoreg import ForecasterAutoreg
 from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom
 from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect
-from skforecast.model_selection.model_selection import _backtesting_forecaster_no_refit
+from skforecast.model_selection.model_selection import _backtesting_forecaster
 
 # Fixtures
 from .fixtures_model_selection import y
 from .fixtures_model_selection import exog
 from .fixtures_model_selection import out_sample_residuals
 
 
 # ******************************************************************************
-# * Test _backtesting_forecaster_no_refit No Interval                             *
+# * Test _backtesting_forecaster No Interval                                   *
 # ******************************************************************************
 
-def test_output_backtesting_forecaster_no_refit_no_exog_no_remainder_ForecasterAutoreg_with_mocked():
+@pytest.mark.parametrize("n_jobs", [-1, 1, 'auto'],
+                         ids=lambda n: f'n_jobs: {n}')
+def test_output_backtesting_forecaster_no_exog_no_remainder_ForecasterAutoreg_with_mocked(n_jobs):
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     ForecasterAutoreg.
     """
     expected_metric = 0.0646438286283131
     expected_predictions = pd.DataFrame({
-    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.39585199, 0.55935949,
-                     0.45263533, 0.4578669 , 0.36988237, 0.57912951, 0.48686057, 0.45709952])
-                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))
+        'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 
+                         0.39585199, 0.55935949, 0.45263533, 0.4578669 , 
+                         0.36988237, 0.57912951, 0.48686057, 0.45709952])}, 
+        index=pd.RangeIndex(start=38, stop=50, step=1)
+    )
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
-                                        forecaster          = forecaster,
-                                        y                   = y,
-                                        exog                = None,
-                                        initial_train_size  = len(y_train),
-                                        steps               = 4,
-                                        metric              = 'mean_squared_error',
-                                        interval            = None,
-                                        n_boot              = 500,
-                                        random_state        = 123,
-                                        in_sample_residuals = True,
-                                        verbose             = False
+    metric, backtest_predictions = _backtesting_forecaster(
+                                       forecaster          = forecaster,
+                                       y                   = y,
+                                       exog                = None,
+                                       refit               = False,
+                                       initial_train_size  = len(y_train),
+                                       steps               = 4,
+                                       metric              = 'mean_squared_error',
+                                       interval            = None,
+                                       n_boot              = 500,
+                                       random_state        = 123,
+                                       in_sample_residuals = True,
+                                       n_jobs              = n_jobs,
+                                       verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
 def create_predictors(y): # pragma: no cover
@@ -62,17 +69,19 @@
     """
     
     lags = y[-1:-4:-1]
     
     return lags 
 
 
-def test_output_backtesting_forecaster_no_refit_no_exog_no_remainder_ForecasterAutoregCustom_with_mocked():
+@pytest.mark.parametrize("refit", [False, 0],
+                         ids=lambda n: f'refit: {n}')
+def test_output_backtesting_forecaster_no_exog_no_remainder_ForecasterAutoregCustom_with_mocked(refit):
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     ForecasterAutoregCustom.
     """
     expected_metric = 0.06464382862831312
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.39585199, 0.55935949, 
@@ -84,35 +93,36 @@
                      fun_predictors = create_predictors,
                      window_size    = 3
                  )
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = refit,
                                         initial_train_size  = len(y_train),
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_no_refit_no_exog_no_remainder_ForecasterAutoregDirect_with_mocked():
+def test_output_backtesting_forecaster_no_exog_no_remainder_ForecasterAutoregDirect_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     ForecasterAutoregDirect.
     """
     expected_metric = 0.06999891546733726
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.5468482 , 0.44670961, 0.57651222, 0.52511275, 0.39745044, 0.53365885, 
@@ -124,162 +134,170 @@
                      lags      = 3,
                      steps     = 4
                  )
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_no_refit_no_exog_no_initial_train_size_with_mocked():
+def test_output_backtesting_forecaster_no_exog_no_initial_train_size_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     no initial_train_size, steps=1, ForecasterAutoreg.
     """
     expected_metric = 0.05194702533929101
     expected_predictions = pd.DataFrame({
         'pred':np.array([0.50394528, 0.53092847, 0.51638165, 0.47382814, 0.61996956,
                          0.47685471, 0.52565717, 0.50842469, 0.4925563 , 0.55717972,
                          0.45707228, 0.45990822, 0.53762873, 0.5230163 , 0.41661072,
                          0.51097738, 0.52448483, 0.48179537, 0.5307759 , 0.55580453,
                          0.51780297, 0.53189442, 0.55356883, 0.46142853, 0.52517734,
                          0.46241276, 0.49292214, 0.53169102, 0.40448875, 0.55686226,
                          0.46860633, 0.5098154 , 0.49041677, 0.48435035, 0.51152271,
                          0.56870534, 0.53226143, 0.49091506, 0.56878395, 0.42767269,
                          0.53335856, 0.48167273, 0.5658333 , 0.41464667, 0.56733702,
-                         0.5724869 , 0.45299923])}, index=pd.RangeIndex(start=3, stop=50, step=1))
+                         0.5724869 , 0.45299923])
+        }, 
+        index=pd.RangeIndex(start=3, stop=50, step=1)
+    )
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
     forecaster.fit(y=y)
 
     initial_train_size = None
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = False,
                                         initial_train_size  = initial_train_size,
                                         steps               = 1,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_no_refit_no_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_no_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'
     """
     expected_metric = 0.07085869503962372
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.54252612, 
                      0.46139434, 0.44730047, 0.50031862, 0.49831103, 0.55613172, 0.42970914])
                                                                  }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_no_refit_yes_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_yes_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     """
     expected_metric = 0.05585411566592716
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.41316188, 0.51416101, 
                      0.42705363, 0.4384041 , 0.42611891, 0.59547291, 0.5170294 , 0.4982889 ])
                                                                  }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
                                         verbose             = False
                                    )
 
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_no_refit_yes_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_yes_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'
     """
     expected_metric = 0.06313056651237414
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.49157332, 
                      0.43327346, 0.42420804, 0.53389427, 0.51693094, 0.60207937, 0.48227974])
                                                                  }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
@@ -287,20 +305,20 @@
                                    )
     
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
 # ******************************************************************************
-# * Test _backtesting_forecaster_no_refit Interval                                *
+# * Test _backtesting_forecaster Interval                                      *
 # ******************************************************************************
 
-def test_output_backtesting_forecaster_no_refit_interval_no_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_no_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval yes.
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.0646438286283131
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.39585199, 0.55935949, 
@@ -312,35 +330,36 @@
                                                                          }, index=pd.RangeIndex(start=38, stop=50, step=1))
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
                                         verbose             = False
                                    ) 
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_no_refit_interval_no_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_no_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval yes. 
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes. 
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.07085869503962372
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.54252612, 
@@ -352,35 +371,36 @@
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
     
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
                                         verbose             = False
                                    )
     
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_no_refit_interval_yes_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_yes_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval yes.
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes.
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.05585411566592716
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.41316188, 0.51416101, 
@@ -392,35 +412,36 @@
                                                                          }, index=pd.RangeIndex(start=38, stop=50, step=1))
     
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
                                         verbose             = False
                                    )
     
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_no_refit_interval_yes_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_yes_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval yes. 
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes. 
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.06313056651237414
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.49157332, 
@@ -432,18 +453,19 @@
                                                                          }, index=pd.RangeIndex(start=38, stop=50, step=1))
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
@@ -454,17 +476,17 @@
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
 # ******************************************************************************
 # * Out sample residuals                                                       *
 # ******************************************************************************
 
-def test_output_backtesting_forecaster_no_refit_interval_out_sample_residuals_no_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_out_sample_residuals_no_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval yes.
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',
     'in_sample_residuals = False'
     """
     expected_metric = 0.0646438286283131
     expected_predictions = pd.DataFrame({
         'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.39585199, 0.55935949, 
@@ -477,18 +499,19 @@
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
     forecaster.set_out_sample_residuals(residuals=out_sample_residuals, append=False)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = False,
@@ -507,69 +530,71 @@
     """
     Callable metric
     """
     metric = ((y_true - y_pred)/len(y_true)).mean()
     
     return metric
 
-def test_callable_metric_backtesting_forecaster_no_refit_no_exog_no_remainder_with_mocked():
+def test_callable_metric_backtesting_forecaster_no_exog_no_remainder_with_mocked():
     """
-    Test callable metric in _backtesting_forecaster_no_refit with backtesting mocked, interval no. 
+    Test callable metric in _backtesting_forecaster with backtesting mocked, interval no. 
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     """
     expected_metric = 0.005603130564222017
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.39585199, 0.55935949, 
                      0.45263533, 0.4578669 , 0.36988237, 0.57912951, 0.48686057, 0.45709952])
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 4,
                                         metric              = my_metric,
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
                                         verbose             = False
                                    )
 
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_list_metrics_backtesting_forecaster_no_refit_no_exog_no_remainder_with_mocked():
+def test_list_metrics_backtesting_forecaster_no_exog_no_remainder_with_mocked():
     """
-    Test list of metrics in _backtesting_forecaster_no_refit with backtesting mocked, interval no. 
+    Test list of metrics in _backtesting_forecaster with backtesting mocked, interval no. 
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     """
     expected_metrics = [0.0646438286283131, 0.0646438286283131]
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.39585199, 0.55935949, 
                      0.45263533, 0.4578669 , 0.36988237, 0.57912951, 0.48686057, 0.45709952])
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metrics, backtest_predictions = _backtesting_forecaster_no_refit(
+    metrics, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = False,
                                         initial_train_size  = len(y_train),
                                         steps               = 4,
                                         metric              = ['mean_squared_error', mean_squared_error],
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
@@ -581,57 +606,58 @@
 
 
 # ******************************************************************************
 # * Gap                                                                        *
 # ******************************************************************************
 
 
-def test_output_backtesting_forecaster_no_refit_interval_yes_exog_yes_remainder_gap_with_mocked():
+def test_output_backtesting_forecaster_interval_yes_exog_yes_remainder_gap_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval yes. 
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes. 
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     20 observations to backtest, steps=5 and gap=3, metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.07965887934114284
     expected_predictions = pd.DataFrame(
-        data = np.array([[ 0.65022999,  0.24880098,  1.06503914],
+        data = np.array([[ 0.65022999,  0.27183154,  1.06503914],
                          [ 0.52364637,  0.19453326,  0.923044  ],
-                         [ 0.46809256,  0.12440678,  0.8859392 ],
-                         [ 0.48759732,  0.24079549,  0.86300276],
-                         [ 0.47172445,  0.13894447,  0.74697552],
-                         [ 0.57585845,  0.17442943,  0.99066759],
+                         [ 0.46809256,  0.12440678,  0.75395058],
+                         [ 0.48759732,  0.12107577,  0.83145059],
+                         [ 0.47172445,  0.14533367,  0.74697552],
+                         [ 0.57585845,  0.19746   ,  0.99066759],
                          [ 0.53592933,  0.20681622,  0.93532696],
-                         [ 0.48995122,  0.14626544,  0.90779787],
-                         [ 0.45271317,  0.20591135,  0.82811861],
-                         [ 0.49519413,  0.16241415,  0.7704452 ],
-                         [ 0.27167824, -0.12975077,  0.68648739],
+                         [ 0.48995122,  0.14626544,  0.77580924],
+                         [ 0.45271317,  0.08619163,  0.79656645],
+                         [ 0.49519413,  0.16880335,  0.7704452 ],
+                         [ 0.27167824, -0.10672021,  0.68648739],
                          [ 0.27813822, -0.05097489,  0.67753585],
-                         [ 0.31569424, -0.02799154,  0.73354088],
-                         [ 0.3983224 ,  0.15152057,  0.77372784],
-                         [ 0.34822681,  0.01544683,  0.62347788],
-                         [ 0.62098686,  0.21955784,  1.035796  ],
+                         [ 0.31569424, -0.02799154,  0.60155226],
+                         [ 0.3983224 ,  0.03180086,  0.74217568],
+                         [ 0.34822681,  0.02183603,  0.62347788],
+                         [ 0.62098686,  0.24258841,  1.035796  ],
                          [ 0.47190757,  0.14279445,  0.87130519]]),
         columns = ['pred', 'lower_bound', 'upper_bound'],
         index = pd.RangeIndex(start=33, stop=50, step=1)
     )
 
     forecaster = ForecasterAutoregDirect(
                      regressor = LinearRegression(), 
                      lags      = 3,
                      steps     = 8
                  )
 
     n_backtest = 20
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster            = forecaster,
                                         y                     = y,
                                         exog                  = exog,
+                                        refit                 = False,
                                         initial_train_size    = len(y_train),
                                         gap                   = 3,
                                         allow_incomplete_fold = True,
                                         steps                 = 5,
                                         metric                = 'mean_squared_error',
                                         interval              = [5, 95],
                                         n_boot                = 500,
@@ -640,57 +666,58 @@
                                         verbose               = False
                                    )
 
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_no_refit_interval_yes_exog_not_allow_remainder_gap_with_mocked():
+def test_output_backtesting_forecaster_interval_yes_exog_not_allow_remainder_gap_with_mocked():
     """
-    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval yes. 
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes. 
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     20 observations to backtest, steps=5 and gap=3, metric='mean_squared_error',
     'in_sample_residuals = True', allow_incomplete_fold = False
     """
     y_with_index = y.copy()
     y_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
     exog_with_index = exog.copy()
     exog_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
 
     expected_metric = 0.08826806818628832
     expected_predictions = pd.DataFrame(
-        data = np.array([[ 0.65022999,  0.24880098,  1.06503914],
+        data = np.array([[ 0.65022999,  0.27183154,  1.06503914],
                          [ 0.52364637,  0.19453326,  0.923044  ],
-                         [ 0.46809256,  0.12440678,  0.8859392 ],
-                         [ 0.48759732,  0.24079549,  0.86300276],
-                         [ 0.47172445,  0.13894447,  0.74697552],
-                         [ 0.57585845,  0.17442943,  0.99066759],
+                         [ 0.46809256,  0.12440678,  0.75395058],
+                         [ 0.48759732,  0.12107577,  0.83145059],
+                         [ 0.47172445,  0.14533367,  0.74697552],
+                         [ 0.57585845,  0.19746   ,  0.99066759],
                          [ 0.53592933,  0.20681622,  0.93532696],
-                         [ 0.48995122,  0.14626544,  0.90779787],
-                         [ 0.45271317,  0.20591135,  0.82811861],
-                         [ 0.49519413,  0.16241415,  0.7704452 ],
-                         [ 0.27167824, -0.12975077,  0.68648739],
+                         [ 0.48995122,  0.14626544,  0.77580924],
+                         [ 0.45271317,  0.08619163,  0.79656645],
+                         [ 0.49519413,  0.16880335,  0.7704452 ],
+                         [ 0.27167824, -0.10672021,  0.68648739],
                          [ 0.27813822, -0.05097489,  0.67753585],
-                         [ 0.31569424, -0.02799154,  0.73354088],
-                         [ 0.3983224 ,  0.15152057,  0.77372784],
-                         [ 0.34822681,  0.01544683,  0.62347788]]),
+                         [ 0.31569424, -0.02799154,  0.60155226],
+                         [ 0.3983224 ,  0.03180086,  0.74217568],
+                         [ 0.34822681,  0.02183603,  0.62347788]]),
         columns = ['pred', 'lower_bound', 'upper_bound'],
         index = pd.date_range(start='2022-02-03', periods=15, freq='D')
     )
 
     forecaster = ForecasterAutoregDirect(
                      regressor = LinearRegression(), 
                      lags      = 3,
                      steps     = 8
                  )
 
-    metric, backtest_predictions = _backtesting_forecaster_no_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster            = forecaster,
                                         y                     = y_with_index,
                                         exog                  = exog_with_index,
+                                        refit                 = False,
                                         initial_train_size    = len(y_with_index) - 20,
                                         gap                   = 3,
                                         allow_incomplete_fold = False,
                                         steps                 = 5,
                                         metric                = 'mean_squared_error',
                                         interval              = [5, 95],
                                         n_boot                = 500,
```

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_backtesting_forecaster_refit.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_backtesting_forecaster_refit.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,59 +1,67 @@
-# Unit test _backtesting_forecaster_refit
+# Unit test _backtesting_forecaster Refit
 # ==============================================================================
+import pytest
 import numpy as np
 import pandas as pd
 from pytest import approx
 from sklearn.linear_model import LinearRegression
+from sklearn.linear_model import Ridge
 from sklearn.metrics import mean_squared_error
 from skforecast.ForecasterAutoreg import ForecasterAutoreg
 from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom
 from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect
-from skforecast.model_selection.model_selection import _backtesting_forecaster_refit
+from skforecast.model_selection.model_selection import _backtesting_forecaster
 
 # Fixtures
 from .fixtures_model_selection import y
 from .fixtures_model_selection import exog
 from .fixtures_model_selection import out_sample_residuals
 
 
 # ******************************************************************************
-# * Test _backtesting_forecaster_refit No Interval                             *
+# * Test _backtesting_forecaster No Interval                                   *
 # ******************************************************************************
 
-def test_output_backtesting_forecaster_refit_no_exog_no_remainder_ForecasterAutoreg_with_mocked():
+@pytest.mark.parametrize("n_jobs", [-1, 1, 'auto'],
+                         ids=lambda n: f'n_jobs: {n}')
+def test_output_backtesting_forecaster_no_exog_no_remainder_ForecasterAutoreg_with_mocked(n_jobs):
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     ForecasterAutoreg.
     """
     expected_metric = 0.06598802629306816
     expected_predictions = pd.DataFrame({
-    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,
-                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])
-                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))
+        'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 
+                         0.38969292, 0.52778339, 0.49152015, 0.4841678 , 
+                         0.4076433 , 0.50904672, 0.50249462, 0.49232817])}, 
+        index=pd.RangeIndex(start=38, stop=50, step=1)
+    )
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
                                         in_sample_residuals = True,
+                                        n_jobs              = n_jobs,
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
@@ -63,17 +71,19 @@
     """
     
     lags = y[-1:-4:-1]
     
     return lags 
 
 
-def test_output_backtesting_forecaster_refit_no_exog_no_remainder_ForecasterAutoregCustom_with_mocked():
+@pytest.mark.parametrize("refit", [True, 1],
+                         ids=lambda n: f'refit: {n}')
+def test_output_backtesting_forecaster_no_exog_no_remainder_ForecasterAutoregCustom_with_mocked(refit):
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     ForecasterAutoregCustom.
     """
     expected_metric = 0.06598802629306816
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,
@@ -85,18 +95,19 @@
                      fun_predictors = create_predictors,
                      window_size    = 3
                  )
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = refit,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -104,40 +115,41 @@
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_no_exog_no_remainder_ForecasterAutoregDirect_with_mocked():
+def test_output_backtesting_forecaster_no_exog_no_remainder_ForecasterAutoregDirect_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     ForecasterAutoregDirect.
     """
-    expected_metric = 0.07076203468824618
+    expected_metric = 0.07076203468824617
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.5468482 , 0.44670961, 0.57651222, 0.52511275, 0.3686309 , 0.56234835, 
                      0.44276032, 0.52260065, 0.37665741, 0.5382938 , 0.48755548, 0.44534071])
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
 
     forecaster = ForecasterAutoregDirect(
                      regressor = LinearRegression(), 
                      lags      = 3,
                      steps     = 4
                  )
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -145,34 +157,35 @@
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_no_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_no_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'
     """
     expected_metric = 0.06916732087926723
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.5096801 ,
                      0.49519677, 0.47997916, 0.49177914, 0.495797  , 0.57738724, 0.44370472])
                                                                  }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -180,34 +193,35 @@
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_yes_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_yes_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     """
     expected_metric = 0.05663345135204598
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.42295275, 0.46286083,
                      0.43618422, 0.43552906, 0.48687517, 0.55455072, 0.55577332, 0.53943402])
                                                                  }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -215,34 +229,35 @@
                                         verbose             = False
                                    )
 
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_yes_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_yes_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'
     """
     expected_metric = 0.061723961096013524
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.43595809,
                      0.4349167 , 0.42381237, 0.55165332, 0.53442833, 0.65361802, 0.51297419])
                                                                  }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -251,20 +266,20 @@
                                    )
     
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
 # ******************************************************************************
-# * Test _backtesting_forecaster_refit Interval                                *
+# * Test _backtesting_forecaster Interval                                      *
 # ******************************************************************************
 
-def test_output_backtesting_forecaster_refit_interval_no_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_no_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes.
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.06598802629306816
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339, 
@@ -276,18 +291,19 @@
                                                                          }, index=pd.RangeIndex(start=38, stop=50, step=1))
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -295,17 +311,17 @@
                                         verbose             = False
                                    ) 
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_interval_no_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_no_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes. 
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes. 
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.06916732087926723
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.5096801 , 
@@ -317,18 +333,19 @@
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
     
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -336,17 +353,17 @@
                                         verbose             = False
                                    )
     
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_interval_yes_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_yes_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes.
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes.
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.05663345135204598
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.42295275, 0.46286083,
@@ -358,18 +375,19 @@
                                                                          }, index=pd.RangeIndex(start=38, stop=50, step=1))
     
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -377,17 +395,17 @@
                                         verbose             = False
                                    )
     
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_interval_yes_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_yes_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes. 
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes. 
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.061723961096013524
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.43595809,
@@ -399,18 +417,19 @@
                                                                          }, index=pd.RangeIndex(start=38, stop=50, step=1))
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -422,17 +441,17 @@
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
 # ******************************************************************************
 # * Out sample residuals                                                       *
 # ******************************************************************************
 
-def test_output_backtesting_forecaster_refit_interval_out_sample_residuals_no_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_interval_out_sample_residuals_no_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes.
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',
     'in_sample_residuals = False'
     """
     expected_metric = 0.06598802629306816
     expected_predictions = pd.DataFrame({
         'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339, 
@@ -445,18 +464,19 @@
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
     forecaster.set_out_sample_residuals(residuals=out_sample_residuals, append=False)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = [5, 95],
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -465,45 +485,46 @@
                                    )
 
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
 # ******************************************************************************
-# * Callable metric                                                           *
+# * Callable metric                                                            *
 # ******************************************************************************
 
 def my_metric(y_true, y_pred): # pragma: no cover
     """
     Callable metric
     """
     metric = ((y_true - y_pred)/len(y_true)).mean()
     
     return metric
 
-def test_callable_metric_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked():
+def test_callable_metric_backtesting_forecaster_no_exog_no_remainder_with_mocked():
     """
-    Test callable metric in _backtesting_forecaster_refit with backtesting mocked, interval no. 
+    Test callable metric in _backtesting_forecaster with backtesting mocked, interval no. 
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     """
     expected_metric = 0.005283745900436151
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,
                      0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 4,
                                         metric              = my_metric,
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -511,35 +532,36 @@
                                         verbose             = False
                                    )
 
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_list_metrics_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked():
+def test_list_metrics_backtesting_forecaster_no_exog_no_remainder_with_mocked():
     """
-    Test list of metrics in _backtesting_forecaster_refit with backtesting mocked, interval no. 
+    Test list of metrics in _backtesting_forecaster with backtesting mocked, interval no. 
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'
     """
     expected_metrics = [0.06598802629306816, 0.06598802629306816]
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,
                      0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metrics, backtest_predictions = _backtesting_forecaster_refit(
+    metrics, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = False,
                                         steps               = 4,
                                         metric              = ['mean_squared_error', mean_squared_error],
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -551,17 +573,17 @@
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
 # ******************************************************************************
 # * fixed_train_size = True                                                    *
 # ******************************************************************************
 
-def test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_fixed_train_size_no_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',
     fixed_train_size=True
     """
     expected_metric = 0.06720844584333846
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.34597367, 0.50223873,
@@ -569,18 +591,19 @@
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
 
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = True,
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -588,35 +611,36 @@
                                         verbose             = False
                                    )
     
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_fixed_train_size_no_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, no exog, 
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',
     fixed_train_size=True
     """
     expected_metric = 0.07217085374372428
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.4909399 , 
                      0.47942107, 0.46025344, 0.46649132, 0.47061725, 0.57603136, 0.41480551])
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = None,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = True,
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -624,35 +648,36 @@
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_no_remainder_with_mocked():
+def test_output_backtesting_forecaster_fixed_train_size_yes_exog_no_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked,
     12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',
     fixed_train_size=True
     """
     expected_metric = 0.05758244401484334
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.37689967, 0.44267729, 
                      0.42642836, 0.41604275, 0.45047245, 0.53784704, 0.53726274, 0.51516772])
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = True,
                                         steps               = 4,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -660,35 +685,36 @@
                                         verbose             = False
                                    )
                                    
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_yes_remainder_with_mocked():
+def test_output_backtesting_forecaster_fixed_train_size_yes_exog_yes_remainder_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.
+    Test output of _backtesting_forecaster with backtesting mocked, interval no.
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked,
     12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',
     fixed_train_size=True
     """
     expected_metric = 0.06425019123005545
     expected_predictions = pd.DataFrame({
     'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.41975558, 
                      0.4256614 , 0.41176005, 0.52357817, 0.509974  , 0.65354628, 0.48210726])
                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))
     forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)
 
     n_backtest = 12
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster          = forecaster,
                                         y                   = y,
                                         exog                = exog,
+                                        refit               = True,
                                         initial_train_size  = len(y_train),
                                         fixed_train_size    = True,
                                         steps               = 5,
                                         metric              = 'mean_squared_error',
                                         interval            = None,
                                         n_boot              = 500,
                                         random_state        = 123,
@@ -701,57 +727,58 @@
 
 
 # ******************************************************************************
 # * Gap                                                                        *
 # ******************************************************************************
 
 
-def test_output_backtesting_forecaster_refit_interval_yes_exog_yes_remainder_gap_with_mocked():
+def test_output_backtesting_forecaster_interval_yes_exog_yes_remainder_gap_with_mocked():
     """
-    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes. 
+    Test output of _backtesting_forecaster with backtesting mocked, interval yes. 
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     20 observations to backtest, steps=5 and gap=3, metric='mean_squared_error',
     'in_sample_residuals = True'
     """
     expected_metric = 0.0839045861490063
     expected_predictions = pd.DataFrame(
-        data = np.array([[ 0.65022999,  0.24880098,  1.06503914],
+        data = np.array([[ 0.65022999,  0.27183154,  1.06503914],
                          [ 0.52364637,  0.19453326,  0.923044  ],
-                         [ 0.46809256,  0.12440678,  0.8859392 ],
-                         [ 0.48759732,  0.24079549,  0.86300276],
-                         [ 0.47172445,  0.13894447,  0.74697552],
-                         [ 0.54075007,  0.15420011,  0.89637884],
+                         [ 0.46809256,  0.12440678,  0.75395058],
+                         [ 0.48759732,  0.12107577,  0.83145059],
+                         [ 0.47172445,  0.14533367,  0.74697552],
+                         [ 0.54075007,  0.15924753,  1.01588603],
                          [ 0.50283999,  0.19115121,  0.85076388],
                          [ 0.49737535,  0.22956778,  0.7939908 ],
-                         [ 0.49185456,  0.22055651,  0.84145859],
-                         [ 0.48906044,  0.17652033,  0.80063491],
+                         [ 0.49185456,  0.22055651,  0.85300844],
+                         [ 0.48906044,  0.17652033,  0.80604025],
                          [ 0.27751064, -0.07159784,  0.70858646],
                          [ 0.25859617, -0.03545793,  0.57770947],
-                         [ 0.32853669,  0.03467979,  0.64259882],
+                         [ 0.32853669,  0.03467979,  0.81698814],
                          [ 0.43751884,  0.13949436,  0.82693778],
-                         [ 0.33016371, -0.04785842,  0.64473596],
-                         [ 0.58126262,  0.24794122,  0.97074189],
-                         [ 0.52955296,  0.19886586,  0.86943174]]),
+                         [ 0.33016371,  0.03065767,  0.64473596],
+                         [ 0.58126262,  0.22355106,  1.01410171],
+                         [ 0.52955296,  0.21810115,  0.93120556]]),
         columns = ['pred', 'lower_bound', 'upper_bound'],
         index = pd.RangeIndex(start=33, stop=50, step=1)
     )
 
     forecaster = ForecasterAutoregDirect(
                      regressor = LinearRegression(), 
                      lags      = 3,
                      steps     = 8
                  )
 
     n_backtest = 20
     y_train = y[:-n_backtest]
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster            = forecaster,
                                         y                     = y,
                                         exog                  = exog,
+                                        refit                 = True,
                                         initial_train_size    = len(y_train),
                                         fixed_train_size      = False,
                                         gap                   = 3,
                                         allow_incomplete_fold = True,
                                         steps                 = 5,
                                         metric                = 'mean_squared_error',
                                         interval              = [5, 95],
@@ -761,57 +788,58 @@
                                         verbose               = False
                                    )
 
     assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_refit_interval_yes_exog_not_allow_remainder_gap_with_mocked():
+def test_output_backtesting_forecaster_interval_yes_exog_not_allow_remainder_gap_with_mocked():
     """
     Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval yes. 
     Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
     20 observations to backtest, steps=5 and gap=3, metric='mean_squared_error',
     'in_sample_residuals = True', allow_incomplete_fold = False
     """
     y_with_index = y.copy()
     y_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
     exog_with_index = exog.copy()
     exog_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
 
     expected_metric = 0.09133694038363274
     expected_predictions = pd.DataFrame(
-        data = np.array([[ 0.65022999,  0.24880098,  1.06503914],
+        data = np.array([[ 0.65022999,  0.27183154,  1.06503914],
                          [ 0.52364637,  0.19453326,  0.923044  ],
-                         [ 0.46809256,  0.12440678,  0.8859392 ],
-                         [ 0.48759732,  0.24079549,  0.86300276],
-                         [ 0.47172445,  0.13894447,  0.74697552],
-                         [ 0.50952084,  0.17343609,  0.96199755],
-                         [ 0.52131987,  0.17725791,  0.88095373],
-                         [ 0.50289964,  0.13703358,  0.89080844],
-                         [ 0.54941988,  0.19541499,  0.81990615],
-                         [ 0.51121195,  0.23007235,  0.7944829 ],
-                         [ 0.25123452, -0.05173225,  0.55943282],
-                         [ 0.2791409 ,  0.05693818,  0.67369153],
-                         [ 0.28390161,  0.00743721,  0.64748321],
+                         [ 0.46809256,  0.12440678,  0.75395058],
+                         [ 0.48759732,  0.12107577,  0.83145059],
+                         [ 0.47172445,  0.14533367,  0.74697552],
+                         [ 0.50952084,  0.17367515,  0.96199755],
+                         [ 0.52131987,  0.19133495,  0.77700048],
+                         [ 0.50289964,  0.261816  ,  0.89080844],
+                         [ 0.54941988,  0.2254731 ,  0.81990615],
+                         [ 0.51121195,  0.23007235,  0.76212766],
+                         [ 0.25123452, -0.02303138,  0.68451499],
+                         [ 0.2791409 ,  0.05980179,  0.67369153],
+                         [ 0.28390161,  0.0752468 ,  0.58609101],
                          [ 0.38317935,  0.0929118 ,  0.70099806],
-                         [ 0.42183128,  0.08731419,  0.80993652]]),
+                         [ 0.42183128,  0.10993796,  0.69111769]]),
         columns = ['pred', 'lower_bound', 'upper_bound'],
         index = pd.date_range(start='2022-02-03', periods=15, freq='D')
     )
 
     forecaster = ForecasterAutoregDirect(
                      regressor = LinearRegression(), 
                      lags      = 3,
                      steps     = 8
                  )
 
-    metric, backtest_predictions = _backtesting_forecaster_refit(
+    metric, backtest_predictions = _backtesting_forecaster(
                                         forecaster            = forecaster,
                                         y                     = y_with_index,
                                         exog                  = exog_with_index,
+                                        refit                 = True,
                                         initial_train_size    = len(y_with_index) - 20,
                                         fixed_train_size      = True,
                                         gap                   = 3,
                                         allow_incomplete_fold = False,
                                         steps                 = 5,
                                         metric                = 'mean_squared_error',
                                         interval              = [5, 95],
@@ -819,8 +847,138 @@
                                         random_state          = 123,
                                         in_sample_residuals   = True,
                                         verbose               = False
                                    )
     backtest_predictions = backtest_predictions.asfreq('D')
 
     assert expected_metric == approx(metric)
+    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
+
+
+# ******************************************************************************
+# * Refit int                                                                  *
+# ******************************************************************************
+        
+
+def test_output_backtesting_forecaster_refit_int_interval_yes_exog_yes_remainder_with_mocked():
+    """
+    Test output of backtesting_forecaster refit with backtesting mocked, interval yes. 
+    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
+    20 observations to backtest, steps=5 and gap=0, metric='mean_squared_error',
+    'in_sample_residuals = True'. Refit int.
+    """
+    expected_metric = 0.06099110404144631
+    expected_predictions = pd.DataFrame(
+        data = np.array([[0.55616986, 0.15288789, 0.89198752],
+                         [0.48751797, 0.05863911, 0.83169303],
+                         [0.57764391, 0.17436194, 0.91346157],
+                         [0.51298667, 0.08410781, 0.85716173],
+                         [0.47430051, 0.0796644 , 0.82587748],
+                         [0.49192271, 0.15006787, 0.84017409],
+                         [0.52213783, 0.12750172, 0.8737148 ],
+                         [0.54492575, 0.20307092, 0.89317713],
+                         [0.52501537, 0.13641764, 0.86685356],
+                         [0.4680474 , 0.08515461, 0.81080044],
+                         [0.51059498, 0.12199725, 0.85243317],
+                         [0.53067132, 0.14777853, 0.87342436],
+                         [0.4430938 , 0.0509291 , 0.69854202],
+                         [0.49911716, 0.1231365 , 0.8711497 ],
+                         [0.44546347, 0.05329877, 0.70091169],
+                         [0.46530749, 0.08932683, 0.83734003],
+                         [0.46901878, 0.08173407, 0.82098555],
+                         [0.55371362, 0.14618224, 0.98199137],
+                         [0.60759064, 0.22030593, 0.9595574 ],
+                         [0.50415336, 0.09662198, 0.93243111]]),
+        columns = ['pred', 'lower_bound', 'upper_bound'],
+        index = pd.RangeIndex(start=30, stop=50, step=1)
+    )
+
+    forecaster = ForecasterAutoregDirect(
+                     regressor = Ridge(random_state=123), 
+                     lags      = 3,
+                     steps     = 8
+                 )
+
+    n_backtest = 20
+    y_train = y[:-n_backtest]
+
+    metric, backtest_predictions = _backtesting_forecaster(
+                                       forecaster            = forecaster,
+                                       y                     = y,
+                                       exog                  = exog,
+                                       refit                 = 2,
+                                       initial_train_size    = len(y_train),
+                                       fixed_train_size      = False,
+                                       gap                   = 0,
+                                       allow_incomplete_fold = True,
+                                       steps                 = 2,
+                                       metric                = 'mean_squared_error',
+                                       interval              = [5, 95],
+                                       n_boot                = 500,
+                                       random_state          = 123,
+                                       in_sample_residuals   = True,
+                                       verbose               = False,
+                                       n_jobs                = 1
+                                   )
+
+    assert expected_metric == approx(metric)
+    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
+
+
+def test_output_backtesting_forecaster_refit_int_interval_yes_exog_not_allow_remainder_gap_with_mocked():
+    """
+    Test output of _backtesting_forecaster_no_refit with backtesting mocked, interval yes. 
+    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, 
+    20 observations to backtest, steps=5 and gap=3, metric='mean_squared_error',
+    'in_sample_residuals = True', allow_incomplete_fold = False. Refit int.
+    """
+    y_with_index = y.copy()
+    y_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
+    exog_with_index = exog.copy()
+    exog_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
+
+    expected_metric = 0.060991643719298785
+    expected_predictions = pd.DataFrame(
+        data = np.array([[0.51878642, 0.17324039, 0.87771447],
+                         [0.49269791, 0.15223278, 0.86847335],
+                         [0.49380441, 0.14003517, 0.81226679],
+                         [0.51467463, 0.18225936, 0.91506854],
+                         [0.52690045, 0.18135443, 0.8858285 ],
+                         [0.51731996, 0.17685482, 0.8930954 ],
+                         [0.51290311, 0.15913388, 0.83136549],
+                         [0.50334306, 0.17092779, 0.90373697],
+                         [0.50171526, 0.15616923, 0.86064331],
+                         [0.50946908, 0.16900395, 0.88524452],
+                         [0.50200357, 0.14823433, 0.82046595],
+                         [0.50436041, 0.17194514, 0.90475432],
+                         [0.4534189 , 0.09320851, 0.83561058],
+                         [0.52621695, 0.17305963, 0.91133042],
+                         [0.50477802, 0.10690002, 0.88750077],
+                         [0.52235258, 0.1700762 , 0.91128311]]),
+        columns = ['pred', 'lower_bound', 'upper_bound'],
+        index = pd.date_range(start='2022-02-03', periods=16, freq='D')
+    )
+
+    forecaster = ForecasterAutoreg(regressor=Ridge(random_state=123), lags=3)
+
+    metric, backtest_predictions = _backtesting_forecaster(
+                                       forecaster            = forecaster,
+                                       y                     = y_with_index,
+                                       exog                  = exog_with_index,
+                                       refit                 = 3,
+                                       initial_train_size    = len(y_with_index) - 20,
+                                       fixed_train_size      = True,
+                                       gap                   = 3,
+                                       allow_incomplete_fold = False,
+                                       steps                 = 4,
+                                       metric                = 'mean_squared_error',
+                                       interval              = [5, 95],
+                                       n_boot                = 500,
+                                       random_state          = 123,
+                                       in_sample_residuals   = True,
+                                       verbose               = False,
+                                       n_jobs                = 1
+                                   )
+    backtest_predictions = backtest_predictions.asfreq('D')
+
+    assert expected_metric == approx(metric)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
```

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_bayesian_search_forecaster.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_bayesian_search_forecaster.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_bayesian_search_optuna.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_bayesian_search_optuna.py`

 * *Files 1% similar despite different names*

```diff
@@ -305,14 +305,15 @@
                     steps                 = steps,
                     metric                = 'mean_absolute_error',
                     refit                 = True,
                     initial_train_size    = len(y_train),
                     fixed_train_size      = True,
                     n_trials              = 10,
                     random_state          = 123,
+                    n_jobs                = 1,
                     return_best           = False,
                     verbose               = False,
                     kwargs_study_optimize = {'timeout': timeout}
               )[0].reset_index(drop=True)
     
     expected_results = pd.DataFrame({
             'lags'  :[[1, 2], [1, 2], [1, 2], [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]],
```

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_bayesian_search_skopt.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_bayesian_search_skopt.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_create_backtesting_folds.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_create_backtesting_folds.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,37 +1,38 @@
 # Unit test _create_backtesting_folds
 # ==============================================================================
-import re
 import pytest
 import numpy as np
 import pandas as pd
 from skforecast.model_selection.model_selection import _create_backtesting_folds
 
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 70), range(70, 80), range(70, 80)],
-                                  [range(0, 70), range(80, 90), range(80, 90)],
-                                  [range(0, 70), range(90, 100), range(90, 100)]]),
-                          (False, [[[0, 70], [70, 80], [70, 80]],
-                                   [[0, 70], [80, 90], [80, 90]],
-                                   [[0, 70], [90, 100], [90, 100]]])], 
+                         [(True, [[range(0, 70), range(67, 70), range(70, 80), range(70, 80), False],
+                                  [range(0, 70), range(77, 80), range(80, 90), range(80, 90), False],
+                                  [range(0, 70), range(87, 90), range(90, 100), range(90, 100), False]]),
+                          (False, [[[0, 70], [67, 70], [70, 80], [70, 80], False],
+                                   [[0, 70], [77, 80], [80, 90], [80, 90], False],
+                                   [[0, 70], [87, 90], [90, 100], [90, 100], False]])], 
                          ids = lambda argument : f'{argument}' )
 def test_create_backtesting_folds_no_refit_no_gap_no_remainder(capfd, return_all_indexes, expected):
     """
     Test _create_backtesting_folds output when refit is False, gap=0 and not 
     remainder.
     """
     y = pd.Series(np.arange(100))
     y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 3
     initial_train_size = 70
     test_size = 10
     refit = False
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = False,
                 refit                 = refit,
                 fixed_train_size      = False,
                 gap                   = 0,
                 allow_incomplete_fold = True,
@@ -60,35 +61,37 @@
     )
 
     assert out == expected_out
     assert folds == expected
     
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 65), range(65, 75), range(65, 75)],
-                                  [range(0, 65), range(75, 85), range(75, 85)],
-                                  [range(0, 65), range(85, 95), range(85, 95)]]),
-                          (False, [[[0, 65], [65, 75], [65, 75]],
-                                   [[0, 65], [75, 85], [75, 85]],
-                                   [[0, 65], [85, 95], [85, 95]]])], 
+                         [(True, [[range(0, 65), range(61, 65), range(65, 75), range(65, 75), False],
+                                  [range(0, 65), range(71, 75), range(75, 85), range(75, 85), False],
+                                  [range(0, 65), range(81, 85), range(85, 95), range(85, 95), False]]),
+                          (False, [[[0, 65], [61, 65], [65, 75], [65, 75], False],
+                                   [[0, 65], [71, 75], [75, 85], [75, 85], False],
+                                   [[0, 65], [81, 85], [85, 95], [85, 95], False]])], 
                          ids = lambda argument : f'{argument}' )
 def test_create_backtesting_folds_no_refit_no_gap_allow_incomplete_fold_False(capfd, return_all_indexes, expected):
     """
-    Test _create_backtesting_folds output when refit is False, gap=0, 
+    Test _create_backtesting_folds output when refit is 0 (False), gap=0, 
     remainder and allow_incomplete_fold=False.
     """
     y = pd.Series(np.arange(100))
     y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 4
     initial_train_size = 65
     test_size = 10
-    refit = False
+    refit = 0
     allow_incomplete_fold = False
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = False,
                 refit                 = refit,
                 fixed_train_size      = False,
                 gap                   = 0,
                 allow_incomplete_fold = allow_incomplete_fold,
@@ -118,38 +121,40 @@
     )
 
     assert out == expected_out
     assert folds == expected
     
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 70), range(70, 82), range(75, 82)],
-                                  [range(0, 70), range(77, 89), range(82, 89)],
-                                  [range(0, 70), range(84, 96), range(89, 96)],
-                                  [range(0, 70), range(91, 100), range(96, 100)]]),
-                          (False, [[[0, 70], [70, 82], [75, 82]],
-                                   [[0, 70], [77, 89], [82, 89]],
-                                   [[0, 70], [84, 96], [89, 96]],
-                                   [[0, 70], [91, 100], [96, 100]]])], 
+                         [(True, [[range(0, 70), range(65, 70), range(70, 82), range(75, 82), False],
+                                  [range(0, 70), range(72, 77), range(77, 89), range(82, 89), False],
+                                  [range(0, 70), range(79, 84), range(84, 96), range(89, 96), False],
+                                  [range(0, 70), range(86, 91), range(91, 100), range(96, 100), False]]),
+                          (False, [[[0, 70], [65, 70], [70, 82], [75, 82], False],
+                                   [[0, 70], [72, 77], [77, 89], [82, 89], False],
+                                   [[0, 70], [79, 84], [84, 96], [89, 96], False],
+                                   [[0, 70], [86, 91], [91, 100], [96, 100], False]])], 
                          ids = lambda argument : f'{argument}' )
 def test_create_backtesting_folds_no_refit_gap_allow_incomplete_fold_True(capfd, return_all_indexes, expected):
     """
     Test _create_backtesting_folds output when refit is False, gap=5, 
     remainder, allow_incomplete_fold=True.
     """
     y = pd.Series(np.arange(100))
     y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 5
     initial_train_size = 70
     gap = 5
     test_size = 7
     refit = False
     allow_incomplete_fold = True
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = False,
                 refit                 = refit,
                 fixed_train_size      = False,
                 gap                   = gap,
                 allow_incomplete_fold = allow_incomplete_fold,
@@ -182,45 +187,47 @@
     )
 
     assert out == expected_out
     assert folds == expected
     
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 15), range(15, 30), range(20, 30)],
-                                  [range(0, 15), range(25, 40), range(30, 40)],
-                                  [range(0, 15), range(35, 50), range(40, 50)],
-                                  [range(0, 15), range(45, 60), range(50, 60)],
-                                  [range(0, 15), range(55, 70), range(60, 70)],
-                                  [range(0, 15), range(65, 80), range(70, 80)],
-                                  [range(0, 15), range(75, 90), range(80, 90)],
-                                  [range(0, 15), range(85, 100), range(90, 100)]]),
-                          (False, [[[0, 15], [15, 30], [20, 30]],
-                                   [[0, 15], [25, 40], [30, 40]],
-                                   [[0, 15], [35, 50], [40, 50]],
-                                   [[0, 15], [45, 60], [50, 60]],
-                                   [[0, 15], [55, 70], [60, 70]],
-                                   [[0, 15], [65, 80], [70, 80]],
-                                   [[0, 15], [75, 90], [80, 90]],
-                                   [[0, 15], [85, 100], [90, 100]]])], 
+                         [(True, [[range(0, 15), range(0, 15), range(15, 30), range(20, 30), False],
+                                  [range(0, 15), range(10, 25), range(25, 40), range(30, 40), False],
+                                  [range(0, 15), range(20, 35), range(35, 50), range(40, 50), False],
+                                  [range(0, 15), range(30, 45), range(45, 60), range(50, 60), False],
+                                  [range(0, 15), range(40, 55), range(55, 70), range(60, 70), False],
+                                  [range(0, 15), range(50, 65), range(65, 80), range(70, 80), False],
+                                  [range(0, 15), range(60, 75), range(75, 90), range(80, 90), False],
+                                  [range(0, 15), range(70, 85), range(85, 100), range(90, 100), False]]),
+                          (False, [[[0, 15], [0, 15], [15, 30], [20, 30], False],
+                                   [[0, 15], [10, 25], [25, 40], [30, 40], False],
+                                   [[0, 15], [20, 35], [35, 50], [40, 50], False],
+                                   [[0, 15], [30, 45], [45, 60], [50, 60], False],
+                                   [[0, 15], [40, 55], [55, 70], [60, 70], False],
+                                   [[0, 15], [50, 65], [65, 80], [70, 80], False],
+                                   [[0, 15], [60, 75], [75, 90], [80, 90], False],
+                                   [[0, 15], [70, 85], [85, 100], [90, 100], False]])], 
                          ids = lambda argument : f'{argument}' )
-def test_create_backtesting_folds_no_refit_no_initial_train_size(capfd, return_all_indexes, expected):
+def test_create_backtesting_folds_no_refit_no_initial_train_size_gap(capfd, return_all_indexes, expected):
     """
     Test _create_backtesting_folds output when refit is False, gap=5, 
     already trained, no remainder, allow_incomplete_fold=True.
     """
     y = pd.Series(np.arange(100))
     initial_train_size = 15 # window_size
+    window_size = 15
     gap = 5
     test_size = 10
     refit = False
     externally_fitted = True
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = externally_fitted,
                 refit                 = refit,
                 fixed_train_size      = False,
                 gap                   = gap,
                 allow_incomplete_fold = True,
@@ -256,35 +263,37 @@
     )
 
     assert out == expected_out
     assert folds == expected
 
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 70), range(70, 80), range(70, 80)],
-                                  [range(0, 80), range(80, 90), range(80, 90)],
-                                  [range(0, 90), range(90, 100), range(90, 100)]]),
-                          (False, [[[0, 70], [70, 80], [70, 80]],
-                                   [[0, 80], [80, 90], [80, 90]],
-                                   [[0, 90], [90, 100], [90, 100]]])], 
+                         [(True, [[range(0, 70), range(68, 70), range(70, 80), range(70, 80), False],
+                                  [range(0, 80), range(78, 80), range(80, 90), range(80, 90), True],
+                                  [range(0, 90), range(88, 90), range(90, 100), range(90, 100), True]]),
+                          (False, [[[0, 70], [68, 70], [70, 80], [70, 80], False],
+                                   [[0, 80], [78, 80], [80, 90], [80, 90], True],
+                                   [[0, 90], [88, 90], [90, 100], [90, 100], True]])], 
                          ids = lambda argument : f'{argument}' )
 def test_create_backtesting_folds_refit_no_fixed_no_gap_no_remainder(capfd, return_all_indexes, expected):
     """
     Test _create_backtesting_folds output when refit is True, fixed_train_size is 
     False, gap=0 and not remainder.
     """
     y = pd.Series(np.arange(100))
     y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 2
     initial_train_size = 70
     test_size = 10
     refit = True
     fixed_train_size = False
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = False,
                 refit                 = refit,
                 fixed_train_size      = fixed_train_size,
                 gap                   = 0,
                 allow_incomplete_fold = True,
@@ -313,35 +322,37 @@
     )
 
     assert out == expected_out
     assert folds == expected
 
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 70), range(70, 80), range(70, 80)],
-                                  [range(10, 80), range(80, 90), range(80, 90)],
-                                  [range(20, 90), range(90, 100), range(90, 100)]]),
-                          (False, [[[0, 70], [70, 80], [70, 80]],
-                                   [[10, 80], [80, 90], [80, 90]],
-                                   [[20, 90], [90, 100], [90, 100]]])], 
+                         [(True, [[range(0, 70), range(64, 70), range(70, 80), range(70, 80), False],
+                                  [range(10, 80), range(74, 80), range(80, 90), range(80, 90), True],
+                                  [range(20, 90), range(84, 90), range(90, 100), range(90, 100), True]]),
+                          (False, [[[0, 70], [64, 70], [70, 80], [70, 80], False],
+                                   [[10, 80], [74, 80], [80, 90], [80, 90], True],
+                                   [[20, 90], [84, 90], [90, 100], [90, 100], True]])], 
                          ids = lambda argument : f'{argument}' )
 def test_create_backtesting_folds_refit_fixed_train_size_no_gap_no_remainder(capfd, return_all_indexes, expected):
     """
-    Test _create_backtesting_folds output when refit is True, fixed_train_size is 
-    True, gap=0 and not remainder.
+    Test _create_backtesting_folds output when refit is 1 (True), fixed_train_size 
+    is True, gap=0 and not remainder.
     """
     y = pd.Series(np.arange(100))
     y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 6
     initial_train_size = 70
     test_size = 10
-    refit = True
+    refit = 1
     fixed_train_size = True
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = False,
                 refit                 = refit,
                 fixed_train_size      = fixed_train_size,
                 gap                   = 0,
                 allow_incomplete_fold = True,
@@ -370,39 +381,41 @@
     )
 
     assert out == expected_out
     assert folds == expected
     
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 70), range(70, 82), range(75, 82)],
-                                  [range(0, 77), range(77, 89), range(82, 89)],
-                                  [range(0, 84), range(84, 96), range(89, 96)],
-                                  [range(0, 91), range(91, 100), range(96, 100)]]),
-                          (False, [[[0, 70], [70, 82], [75, 82]],
-                                   [[0, 77], [77, 89], [82, 89]],
-                                   [[0, 84], [84, 96], [89, 96]],
-                                   [[0, 91], [91, 100], [96, 100]]])], 
+                         [(True, [[range(0, 70), range(67, 70), range(70, 82), range(75, 82), False],
+                                  [range(0, 77), range(74, 77), range(77, 89), range(82, 89), True],
+                                  [range(0, 84), range(81, 84), range(84, 96), range(89, 96), True],
+                                  [range(0, 91), range(88, 91), range(91, 100), range(96, 100), True]]),
+                          (False, [[[0, 70], [67, 70], [70, 82], [75, 82], False],
+                                   [[0, 77], [74, 77], [77, 89], [82, 89], True],
+                                   [[0, 84], [81, 84], [84, 96], [89, 96], True],
+                                   [[0, 91], [88, 91], [91, 100], [96, 100], True]])], 
                          ids = lambda argument : f'{argument}' )
 def test_create_backtesting_folds_refit_no_fixed_gap_allow_incomplete_fold_True(capfd, return_all_indexes, expected):
     """
     Test _create_backtesting_folds output when refit is True, fixed_train_size is 
     False, gap=5, remainder, allow_incomplete_fold=True.
     """
     y = pd.Series(np.arange(100))
     y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 3
     initial_train_size = 70
     gap = 5
     test_size = 7
     refit = True
     fixed_train_size = False
     allow_incomplete_fold = True
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = False,
                 refit                 = refit,
                 fixed_train_size      = fixed_train_size,
                 gap                   = gap,
                 allow_incomplete_fold = allow_incomplete_fold,
@@ -435,38 +448,40 @@
     )
 
     assert out == expected_out
     assert folds == expected
     
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 70), range(70, 82), range(75, 82)],
-                                  [range(7, 77), range(77, 89), range(82, 89)],
-                                  [range(14, 84), range(84, 96), range(89, 96)],
-                                  [range(21, 91), range(91, 100), range(96, 100)]]),
-                          (False, [[[0, 70], [70, 82], [75, 82]],
-                                   [[7, 77], [77, 89], [82, 89]],
-                                   [[14, 84], [84, 96], [89, 96]],
-                                   [[21, 91], [91, 100], [96, 100]]])], 
+                         [(True, [[range(0, 70), range(65, 70), range(70, 82), range(75, 82), False],
+                                  [range(7, 77), range(72, 77), range(77, 89), range(82, 89), True],
+                                  [range(14, 84), range(79, 84), range(84, 96), range(89, 96), True],
+                                  [range(21, 91), range(86, 91), range(91, 100), range(96, 100), True]]),
+                          (False, [[[0, 70], [65, 70], [70, 82], [75, 82], False],
+                                   [[7, 77], [72, 77], [77, 89], [82, 89], True],
+                                   [[14, 84], [79, 84], [84, 96], [89, 96], True],
+                                   [[21, 91], [86, 91], [91, 100], [96, 100], True]])], 
                          ids = lambda argument : f'{argument}' )
 def test_create_backtesting_folds_refit_fixed_train_size_gap_allow_incomplete_fold_True(capfd, return_all_indexes, expected):
     """
     Test _create_backtesting_folds output when refit is True, fixed_train_size is 
     True, gap=5, remainder, allow_incomplete_fold=True.
     """
     y = pd.Series(np.arange(100))
+    window_size = 5
     initial_train_size = 70
     gap = 5
     test_size = 7
     refit = True
     fixed_train_size = True
     allow_incomplete_fold = True
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = False,
                 refit                 = refit,
                 fixed_train_size      = fixed_train_size,
                 gap                   = gap,
                 allow_incomplete_fold = allow_incomplete_fold,
@@ -499,37 +514,39 @@
     )
 
     assert out == expected_out
     assert folds == expected
     
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 70), range(70, 82), range(75, 82)],
-                                  [range(0, 77), range(77, 89), range(82, 89)],
-                                  [range(0, 84), range(84, 96), range(89, 96)]]),
-                          (False, [[[0, 70], [70, 82], [75, 82]],
-                                   [[0, 77], [77, 89], [82, 89]],
-                                   [[0, 84], [84, 96], [89, 96]]])], 
+                         [(True, [[range(0, 70), range(67, 70), range(70, 82), range(75, 82), False],
+                                  [range(0, 77), range(74, 77), range(77, 89), range(82, 89), True],
+                                  [range(0, 84), range(81, 84), range(84, 96), range(89, 96), True]]),
+                          (False, [[[0, 70], [67, 70], [70, 82], [75, 82], False],
+                                   [[0, 77], [74, 77], [77, 89], [82, 89], True],
+                                   [[0, 84], [81, 84], [84, 96], [89, 96], True]])], 
                          ids = lambda argument : f'{argument}' )
 def test_create_backtesting_folds_refit_no_fixed_gap_allow_incomplete_fold_False(capfd, return_all_indexes, expected):
     """
     Test _create_backtesting_folds output when refit is True, fixed_train_size is 
     False, gap=5, remainder, allow_incomplete_fold=False.
     """
     y = pd.Series(np.arange(100))
     y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 3
     initial_train_size = 70
     gap = 5
     test_size = 7
     refit = True
     fixed_train_size = False
     allow_incomplete_fold = False
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = False,
                 refit                 = refit,
                 fixed_train_size      = fixed_train_size,
                 gap                   = gap,
                 allow_incomplete_fold = allow_incomplete_fold,
@@ -559,36 +576,38 @@
     )
 
     assert out == expected_out
     assert folds == expected
     
 
 @pytest.mark.parametrize("return_all_indexes, expected",
-                         [(True, [[range(0, 70), range(70, 82), range(75, 82)],
-                                  [range(7, 77), range(77, 89), range(82, 89)],
-                                  [range(14, 84), range(84, 96), range(89, 96)]]),
-                          (False, [[[0, 70], [70, 82], [75, 82]],
-                                   [[7, 77], [77, 89], [82, 89]],
-                                   [[14, 84], [84, 96], [89, 96]]])], 
+                         [(True, [[range(0, 70), range(66, 70), range(70, 82), range(75, 82), False],
+                                  [range(7, 77), range(73, 77), range(77, 89), range(82, 89), True],
+                                  [range(14, 84), range(80, 84), range(84, 96), range(89, 96), True]]),
+                          (False, [[[0, 70], [66, 70], [70, 82], [75, 82], False],
+                                   [[7, 77], [73, 77], [77, 89], [82, 89], True],
+                                   [[14, 84], [80, 84], [84, 96], [89, 96], True]])], 
                          ids = lambda argument : f'{argument}' )
 def test_create_backtesting_folds_refit_fixed_train_size_gap_allow_incomplete_fold_False(capfd, return_all_indexes, expected):
     """
     Test _create_backtesting_folds output when refit is True, fixed_train_size is 
     True, gap=5, remainder, allow_incomplete_fold=False.
     """
     y = pd.Series(np.arange(100))
+    window_size = 4
     initial_train_size = 70
     gap = 5
     test_size = 7
     refit = True
     fixed_train_size = True
     allow_incomplete_fold = False
 
     folds = _create_backtesting_folds(
                 data                  = y,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
                 test_size             = test_size,
                 externally_fitted     = False,
                 refit                 = refit,
                 fixed_train_size      = fixed_train_size,
                 gap                   = gap,
                 allow_incomplete_fold = allow_incomplete_fold,
@@ -614,8 +633,392 @@
         "    Validation: 82 -- 88  (n=7)\n"
         "Fold: 2\n"
         "    Training:   14 -- 83  (n=70)\n"
         "    Validation: 89 -- 95  (n=7)\n\n"
     )
 
     assert out == expected_out
+    assert folds == expected
+
+
+@pytest.mark.parametrize("return_all_indexes, expected",
+                         [(True, [[range(0, 60), range(56, 60), range(60, 70), range(60, 70), False],
+                                  [range(0, 60), range(66, 70), range(70, 80), range(70, 80), False],
+                                  [range(0, 80), range(76, 80), range(80, 90), range(80, 90), True],
+                                  [range(0, 80), range(86, 90), range(90, 100), range(90, 100), False]]),
+                          (False, [[[0, 60], [56, 60], [60, 70], [60, 70], False],
+                                   [[0, 60], [66, 70], [70, 80], [70, 80], False],
+                                   [[0, 80], [76, 80], [80, 90], [80, 90], True],
+                                   [[0, 80], [86, 90], [90, 100], [90, 100], False]])], 
+                         ids = lambda argument : f'{argument}' )
+def test_create_backtesting_folds_refit_int_no_fixed_no_gap_no_remainder(capfd, return_all_indexes, expected):
+    """
+    Test _create_backtesting_folds output when refit is 2, fixed_train_size is 
+    False, gap=0 and not remainder.
+    """
+    y = pd.Series(np.arange(100))
+    y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 4
+    initial_train_size = 60
+    test_size = 10
+    refit = 2
+    fixed_train_size = False
+
+    folds = _create_backtesting_folds(
+                data                  = y,
+                window_size           = window_size,
+                initial_train_size    = initial_train_size,
+                test_size             = test_size,
+                externally_fitted     = False,
+                refit                 = refit,
+                fixed_train_size      = fixed_train_size,
+                gap                   = 0,
+                allow_incomplete_fold = True,
+                return_all_indexes    = return_all_indexes,
+                verbose               = True
+            )
+    
+    out, _ = capfd.readouterr()
+    expected_out = (
+        "Information of backtesting process\n"
+        "----------------------------------\n"
+        "Number of observations used for initial training: 60\n"
+        "Number of observations used for backtesting: 40\n"
+        "    Number of folds: 4\n"
+        "    Number of steps per fold: 10\n"
+        "    Number of steps to exclude from the end of each train set before test (gap): 0\n\n"
+        "Fold: 0\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-01 00:00:00  (n=60)\n"
+        "    Validation: 2022-03-02 00:00:00 -- 2022-03-11 00:00:00  (n=10)\n"
+        "Fold: 1\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-01 00:00:00  (n=60)\n"
+        "    Validation: 2022-03-12 00:00:00 -- 2022-03-21 00:00:00  (n=10)\n"
+        "Fold: 2\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-21 00:00:00  (n=80)\n"
+        "    Validation: 2022-03-22 00:00:00 -- 2022-03-31 00:00:00  (n=10)\n"
+        "Fold: 3\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-21 00:00:00  (n=80)\n"
+        "    Validation: 2022-04-01 00:00:00 -- 2022-04-10 00:00:00  (n=10)\n\n"
+    )
+
+    assert out == expected_out
+    assert folds == expected
+
+
+@pytest.mark.parametrize("return_all_indexes, expected",
+                         [(True, [[range(0, 60), range(58, 60), range(60, 70), range(60, 70), False],
+                                  [range(0, 60), range(68, 70), range(70, 80), range(70, 80), False],
+                                  [range(0, 60), range(78, 80), range(80, 90), range(80, 90), False],
+                                  [range(30, 90), range(88, 90), range(90, 100), range(90, 100), True]]),
+                          (False, [[[0, 60], [58, 60], [60, 70], [60, 70], False],
+                                   [[0, 60], [68, 70], [70, 80], [70, 80], False],
+                                   [[0, 60], [78, 80], [80, 90], [80, 90], False],
+                                   [[30, 90], [88, 90], [90, 100], [90, 100], True]])], 
+                         ids = lambda argument : f'{argument}' )
+def test_create_backtesting_folds_refit_int_fixed_train_size_no_gap_no_remainder(capfd, return_all_indexes, expected):
+    """
+    Test _create_backtesting_folds output when refit is 3, fixed_train_size is 
+    True, gap=0 and not remainder.
+    """
+    y = pd.Series(np.arange(100))
+    y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 2
+    initial_train_size = 60
+    test_size = 10
+    refit = 3
+    fixed_train_size = True
+
+    folds = _create_backtesting_folds(
+                data                  = y,
+                window_size           = window_size,
+                initial_train_size    = initial_train_size,
+                test_size             = test_size,
+                externally_fitted     = False,
+                refit                 = refit,
+                fixed_train_size      = fixed_train_size,
+                gap                   = 0,
+                allow_incomplete_fold = True,
+                return_all_indexes    = return_all_indexes,
+                verbose               = True
+            )
+    
+    out, _ = capfd.readouterr()
+    expected_out = (
+        "Information of backtesting process\n"
+        "----------------------------------\n"
+        "Number of observations used for initial training: 60\n"
+        "Number of observations used for backtesting: 40\n"
+        "    Number of folds: 4\n"
+        "    Number of steps per fold: 10\n"
+        "    Number of steps to exclude from the end of each train set before test (gap): 0\n\n"
+        "Fold: 0\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-01 00:00:00  (n=60)\n"
+        "    Validation: 2022-03-02 00:00:00 -- 2022-03-11 00:00:00  (n=10)\n"
+        "Fold: 1\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-01 00:00:00  (n=60)\n"
+        "    Validation: 2022-03-12 00:00:00 -- 2022-03-21 00:00:00  (n=10)\n"
+        "Fold: 2\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-01 00:00:00  (n=60)\n"
+        "    Validation: 2022-03-22 00:00:00 -- 2022-03-31 00:00:00  (n=10)\n"
+        "Fold: 3\n"
+        "    Training:   2022-01-31 00:00:00 -- 2022-03-31 00:00:00  (n=60)\n"
+        "    Validation: 2022-04-01 00:00:00 -- 2022-04-10 00:00:00  (n=10)\n\n"
+    )
+
+    assert out == expected_out
+    assert folds == expected
+    
+
+@pytest.mark.parametrize("return_all_indexes, expected",
+                         [(True, [[range(0, 70), range(60, 70), range(70, 82), range(75, 82), False],
+                                  [range(0, 70), range(67, 77), range(77, 89), range(82, 89), False],
+                                  [range(0, 84), range(74, 84), range(84, 96), range(89, 96), True],
+                                  [range(0, 84), range(81, 91), range(91, 100), range(96, 100), False]]),
+                          (False, [[[0, 70], [60, 70], [70, 82], [75, 82], False],
+                                   [[0, 70], [67, 77], [77, 89], [82, 89], False],
+                                   [[0, 84], [74, 84], [84, 96], [89, 96], True],
+                                   [[0, 84], [81, 91], [91, 100], [96, 100], False]])], 
+                         ids = lambda argument : f'{argument}' )
+def test_create_backtesting_folds_refit_int_no_fixed_gap_allow_incomplete_fold_True(capfd, return_all_indexes, expected):
+    """
+    Test _create_backtesting_folds output when refit is 2, fixed_train_size is 
+    False, gap=5, remainder, allow_incomplete_fold=True.
+    """
+    y = pd.Series(np.arange(100))
+    y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 10
+    initial_train_size = 70
+    gap = 5
+    test_size = 7
+    refit = 2
+    fixed_train_size = False
+    allow_incomplete_fold = True
+
+    folds = _create_backtesting_folds(
+                data                  = y,
+                window_size           = window_size,
+                initial_train_size    = initial_train_size,
+                test_size             = test_size,
+                externally_fitted     = False,
+                refit                 = refit,
+                fixed_train_size      = fixed_train_size,
+                gap                   = gap,
+                allow_incomplete_fold = allow_incomplete_fold,
+                return_all_indexes    = return_all_indexes,
+                verbose               = True
+            )
+                    
+    out, _ = capfd.readouterr()
+    expected_out = (
+        "Information of backtesting process\n"
+        "----------------------------------\n"
+        "Number of observations used for initial training: 70\n"
+        "Number of observations used for backtesting: 30\n"
+        "    Number of folds: 4\n"
+        "    Number of steps per fold: 7\n"
+        "    Number of steps to exclude from the end of each train set before test (gap): 5\n"
+        "    Last fold only includes 4 observations.\n\n"
+        "Fold: 0\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-11 00:00:00  (n=70)\n"
+        "    Validation: 2022-03-17 00:00:00 -- 2022-03-23 00:00:00  (n=7)\n"
+        "Fold: 1\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-11 00:00:00  (n=70)\n"
+        "    Validation: 2022-03-24 00:00:00 -- 2022-03-30 00:00:00  (n=7)\n"
+        "Fold: 2\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-25 00:00:00  (n=84)\n"
+        "    Validation: 2022-03-31 00:00:00 -- 2022-04-06 00:00:00  (n=7)\n"
+        "Fold: 3\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-25 00:00:00  (n=84)\n"
+        "    Validation: 2022-04-07 00:00:00 -- 2022-04-10 00:00:00  (n=4)\n\n"
+    )
+
+    assert out == expected_out
+    assert folds == expected
+    
+
+@pytest.mark.parametrize("return_all_indexes, expected",
+                         [(True, [[range(0, 70), range(55, 70), range(70, 82), range(75, 82), False],
+                                  [range(0, 70), range(62, 77), range(77, 89), range(82, 89), False],
+                                  [range(0, 70), range(69, 84), range(84, 96), range(89, 96), False],
+                                  [range(21, 91), range(76, 91), range(91, 100), range(96, 100), True]]),
+                          (False, [[[0, 70], [55, 70], [70, 82], [75, 82], False],
+                                   [[0, 70], [62, 77], [77, 89], [82, 89], False],
+                                   [[0, 70], [69, 84], [84, 96], [89, 96], False],
+                                   [[21, 91], [76, 91], [91, 100], [96, 100], True]])], 
+                         ids = lambda argument : f'{argument}' )
+def test_create_backtesting_folds_refit_int_fixed_train_size_gap_allow_incomplete_fold_True(capfd, return_all_indexes, expected):
+    """
+    Test _create_backtesting_folds output when refit is 3, fixed_train_size is 
+    True, gap=5, remainder, allow_incomplete_fold=True.
+    """
+    y = pd.Series(np.arange(100))
+    window_size = 15
+    initial_train_size = 70
+    gap = 5
+    test_size = 7
+    refit = 3
+    fixed_train_size = True
+    allow_incomplete_fold = True
+
+    folds = _create_backtesting_folds(
+                data                  = y,
+                window_size           = window_size,
+                initial_train_size    = initial_train_size,
+                test_size             = test_size,
+                externally_fitted     = False,
+                refit                 = refit,
+                fixed_train_size      = fixed_train_size,
+                gap                   = gap,
+                allow_incomplete_fold = allow_incomplete_fold,
+                return_all_indexes    = return_all_indexes,
+                verbose               = True
+            )
+                    
+    out, _ = capfd.readouterr()
+    expected_out = (
+        "Information of backtesting process\n"
+        "----------------------------------\n"
+        "Number of observations used for initial training: 70\n"
+        "Number of observations used for backtesting: 30\n"
+        "    Number of folds: 4\n"
+        "    Number of steps per fold: 7\n"
+        "    Number of steps to exclude from the end of each train set before test (gap): 5\n"
+        "    Last fold only includes 4 observations.\n\n"
+        "Fold: 0\n"
+        "    Training:   0 -- 69  (n=70)\n"
+        "    Validation: 75 -- 81  (n=7)\n"
+        "Fold: 1\n"
+        "    Training:   0 -- 69  (n=70)\n"
+        "    Validation: 82 -- 88  (n=7)\n"
+        "Fold: 2\n"
+        "    Training:   0 -- 69  (n=70)\n"
+        "    Validation: 89 -- 95  (n=7)\n"
+        "Fold: 3\n"
+        "    Training:   21 -- 90  (n=70)\n"
+        "    Validation: 96 -- 99  (n=4)\n\n"
+    )
+
+    assert out == expected_out
+    assert folds == expected
+    
+
+@pytest.mark.parametrize("return_all_indexes, expected",
+                         [(True, [[range(0, 70), range(50, 70), range(70, 82), range(75, 82), False],
+                                  [range(0, 70), range(57, 77), range(77, 89), range(82, 89), False],
+                                  [range(0, 70), range(64, 84), range(84, 96), range(89, 96), False]]),
+                          (False, [[[0, 70], [50, 70], [70, 82], [75, 82], False],
+                                   [[0, 70], [57, 77], [77, 89], [82, 89], False],
+                                   [[0, 70], [64, 84], [84, 96], [89, 96], False]])], 
+                         ids = lambda argument : f'{argument}' )
+def test_create_backtesting_folds_refit_int_no_fixed_gap_allow_incomplete_fold_False(capfd, return_all_indexes, expected):
+    """
+    Test _create_backtesting_folds output when refit is 3, fixed_train_size is 
+    False, gap=5, remainder, allow_incomplete_fold=False.
+    """
+    y = pd.Series(np.arange(100))
+    y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')
+    window_size = 20
+    initial_train_size = 70
+    gap = 5
+    test_size = 7
+    refit = 3
+    fixed_train_size = False
+    allow_incomplete_fold = False
+
+    folds = _create_backtesting_folds(
+                data                  = y,
+                window_size           = window_size,
+                initial_train_size    = initial_train_size,
+                test_size             = test_size,
+                externally_fitted     = False,
+                refit                 = refit,
+                fixed_train_size      = fixed_train_size,
+                gap                   = gap,
+                allow_incomplete_fold = allow_incomplete_fold,
+                return_all_indexes    = return_all_indexes,
+                verbose               = True
+            )
+                    
+    out, _ = capfd.readouterr()
+    expected_out = (
+        "Information of backtesting process\n"
+        "----------------------------------\n"
+        "Number of observations used for initial training: 70\n"
+        "Number of observations used for backtesting: 30\n"
+        "    Number of folds: 3\n"
+        "    Number of steps per fold: 7\n"
+        "    Number of steps to exclude from the end of each train set before test (gap): 5\n"
+        "    Last fold has been excluded because it was incomplete.\n\n"
+        "Fold: 0\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-11 00:00:00  (n=70)\n"
+        "    Validation: 2022-03-17 00:00:00 -- 2022-03-23 00:00:00  (n=7)\n"
+        "Fold: 1\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-11 00:00:00  (n=70)\n"
+        "    Validation: 2022-03-24 00:00:00 -- 2022-03-30 00:00:00  (n=7)\n"
+        "Fold: 2\n"
+        "    Training:   2022-01-01 00:00:00 -- 2022-03-11 00:00:00  (n=70)\n"
+        "    Validation: 2022-03-31 00:00:00 -- 2022-04-06 00:00:00  (n=7)\n\n"
+    )
+
+    assert out == expected_out
+    assert folds == expected
+    
+
+@pytest.mark.parametrize("return_all_indexes, expected",
+                         [(True, [[range(0, 70), range(60, 70), range(70, 82), range(75, 82), False],
+                                  [range(0, 70), range(67, 77), range(77, 89), range(82, 89), False],
+                                  [range(14, 84), range(74, 84), range(84, 96), range(89, 96), True]]),
+                          (False, [[[0, 70], [60, 70], [70, 82], [75, 82], False],
+                                   [[0, 70], [67, 77], [77, 89], [82, 89], False],
+                                   [[14, 84], [74, 84], [84, 96], [89, 96], True]])], 
+                         ids = lambda argument : f'{argument}' )
+def test_create_backtesting_folds_refit_int_fixed_train_size_gap_allow_incomplete_fold_False(capfd, return_all_indexes, expected):
+    """
+    Test _create_backtesting_folds output when refit is True, fixed_train_size is 
+    True, gap=5, remainder, allow_incomplete_fold=False.
+    """
+    y = pd.Series(np.arange(100))
+    window_size = 10
+    initial_train_size = 70
+    gap = 5
+    test_size = 7
+    refit = 2
+    fixed_train_size = True
+    allow_incomplete_fold = False
+
+    folds = _create_backtesting_folds(
+                data                  = y,
+                window_size           = window_size,
+                initial_train_size    = initial_train_size,
+                test_size             = test_size,
+                externally_fitted     = False,
+                refit                 = refit,
+                fixed_train_size      = fixed_train_size,
+                gap                   = gap,
+                allow_incomplete_fold = allow_incomplete_fold,
+                return_all_indexes    = return_all_indexes,
+                verbose               = True
+            )
+                    
+    out, _ = capfd.readouterr()
+    expected_out = (
+        "Information of backtesting process\n"
+        "----------------------------------\n"
+        "Number of observations used for initial training: 70\n"
+        "Number of observations used for backtesting: 30\n"
+        "    Number of folds: 3\n"
+        "    Number of steps per fold: 7\n"
+        "    Number of steps to exclude from the end of each train set before test (gap): 5\n"
+        "    Last fold has been excluded because it was incomplete.\n\n"
+        "Fold: 0\n"
+        "    Training:   0 -- 69  (n=70)\n"
+        "    Validation: 75 -- 81  (n=7)\n"
+        "Fold: 1\n"
+        "    Training:   0 -- 69  (n=70)\n"
+        "    Validation: 82 -- 88  (n=7)\n"
+        "Fold: 2\n"
+        "    Training:   14 -- 83  (n=70)\n"
+        "    Validation: 89 -- 95  (n=7)\n\n"
+    )
+
+    assert out == expected_out
     assert folds == expected
```

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_evaluate_grid_hyperparameters.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_evaluate_grid_hyperparameters.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_get_metric.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_get_metric.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_grid_search_forecaster.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_grid_search_forecaster.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection/tests/test_random_search_forecaster.py` & `skforecast-0.9.0/skforecast/model_selection/tests/test_random_search_forecaster.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection_multiseries/tests/fixtures_model_selection_multiseries.py` & `skforecast-0.9.0/skforecast/model_selection_multiseries/tests/fixtures_model_selection_multiseries.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection_multiseries/tests/test_backtesting_forecaster_multiseries.py` & `skforecast-0.9.0/skforecast/model_selection_multiseries/tests/test_backtesting_forecaster_multiseries.py`

 * *Files 14% similar despite different names*

```diff
@@ -12,14 +12,16 @@
 from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom
 from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate
 from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries
 from skforecast.model_selection_multiseries import backtesting_forecaster_multivariate
 
 # Fixtures
 from .fixtures_model_selection_multiseries import series
+series_with_nans = series.copy()
+series_with_nans['l2'].iloc[:10] = np.nan
 
 def create_predictors(y): # pragma: no cover
     """
     Create first 2 lags of a time series.
     """
     lags = y[-1:-3:-1]
 
@@ -110,18 +112,18 @@
                      regressor = Ridge(random_state=123),
                      level     = 'l1',
                      lags      = 2,
                      steps     = 3
                  )
     
     warn_msg = re.escape(
-                (f"`levels` argument have no use when the forecaster is of type "
-                 f"`ForecasterAutoregMultiVariate`. The level of this forecaster is "
-                 f"{forecaster.level}, to predict another level, change the `level` "
-                 f"argument when initializing the forecaster.")
+                ("`levels` argument have no use when the forecaster is of type "
+                 "`ForecasterAutoregMultiVariate`. The level of this forecaster is "
+                 "'l1', to predict another level, change the `level` "
+                 "argument when initializing the forecaster.")
             )
     with pytest.warns(IgnoredArgumentWarning, match = warn_msg):
         backtesting_forecaster_multiseries(
             forecaster          = forecaster,
             series              = series,
             steps               = 3,
             levels              = 'not_forecaster.level',
@@ -130,28 +132,39 @@
             refit               = True,
             fixed_train_size    = False,
             exog                = None,
             interval            = None,
             n_boot              = 500,
             random_state        = 123,
             in_sample_residuals = True,
-            verbose             = False
+            verbose             = False,
+            n_jobs              = 1
         )
 
 
 # ForecasterAutoregMultiSeries and ForecasterAutoregMultiSeriesCustom
 # ======================================================================================================================
-@pytest.mark.parametrize("forecaster", 
-                         [ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
-                                                       lags=2), 
-                          ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
-                                                             fun_predictors=create_predictors, 
-                                                             window_size=2)], 
-                         ids=lambda fc: f'forecaster: {type(fc).__name__}')
-def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_not_refit_with_mocked(forecaster):
+@pytest.mark.parametrize("forecaster, n_jobs", 
+                         [(ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                        lags=2), -1),
+                          (ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                        lags=2), 1),
+                          (ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                        lags=2), 'auto'),
+                          (ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                              fun_predictors=create_predictors, 
+                                                              window_size=2), -1),
+                          (ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                              fun_predictors=create_predictors, 
+                                                              window_size=2), 1),
+                          (ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                              fun_predictors=create_predictors, 
+                                                              window_size=2), 'auto')], 
+                         ids=lambda fc: f'forecaster, n_jobs: {fc}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_not_refit_with_mocked(forecaster, n_jobs):
     """
     Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiSeries 
     and ForecasterAutoregMultiSeriesCustom without refit with mocked 
     (mocked done in Skforecast v0.5.0).
     """
     steps = 3
     n_validation = 12
@@ -166,15 +179,16 @@
                                                refit               = False,
                                                fixed_train_size    = False,
                                                exog                = None,
                                                interval            = None,
                                                n_boot              = 500,
                                                random_state        = 123,
                                                in_sample_residuals = True,
-                                               verbose             = True
+                                               verbose             = True,
+                                               n_jobs              = n_jobs
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'],
                                     'mean_absolute_error': [0.20754847190853098]})
     expected_predictions = pd.DataFrame({
                                'l1':np.array([0.4978839 , 0.46288427, 0.48433446, 
                                               0.48767779, 0.477799  , 0.48523814, 
@@ -239,22 +253,32 @@
         index=pd.RangeIndex(start=2, stop=50, step=1)
     )
                                    
     pd.testing.assert_frame_equal(expected_metric, metrics_levels)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-@pytest.mark.parametrize("forecaster", 
-                         [ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
-                                                       lags=2), 
-                          ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
-                                                             fun_predictors=create_predictors, 
-                                                             window_size=2)], 
-                         ids=lambda forecaster: f'forecaster: {type(forecaster).__name__}')
-def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_refit_fixed_train_size_with_mocked(forecaster):
+@pytest.mark.parametrize("forecaster, n_jobs", 
+                         [(ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                        lags=2), -1),
+                          (ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                        lags=2), 1),
+                          (ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                        lags=2), 'auto'),
+                          (ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                              fun_predictors=create_predictors, 
+                                                              window_size=2), -1),
+                          (ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                              fun_predictors=create_predictors, 
+                                                              window_size=2), 1),
+                          (ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                              fun_predictors=create_predictors, 
+                                                              window_size=2), 'auto')], 
+                         ids=lambda fc: f'forecaster, n_jobs: {fc}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_refit_fixed_train_size_with_mocked(forecaster, n_jobs):
     """
     Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiSeries 
     and ForecasterAutoregMultiSeriesCustom with refit, fixed_train_size and 
     custom metric with mocked (mocked done in Skforecast v0.5.0).
     """
 
     steps = 3
@@ -277,15 +301,16 @@
                                                refit               = True,
                                                fixed_train_size    = True, 
                                                exog                = None,
                                                interval            = None,
                                                n_boot              = 500,
                                                random_state        = 123,
                                                in_sample_residuals = True,
-                                               verbose             = True
+                                               verbose             = True,
+                                               n_jobs              = n_jobs
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'],
                                     'custom_metric': [0.21651617115803679]})
     expected_predictions = pd.DataFrame({
                                'l1':np.array([0.4978839 , 0.46288427, 0.48433446, 
                                               0.50853803, 0.50006415, 0.50105623,
@@ -294,22 +319,32 @@
                                index=pd.RangeIndex(start=38, stop=50, step=1)
                            )
                                    
     pd.testing.assert_frame_equal(expected_metric, metrics_levels)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-@pytest.mark.parametrize("forecaster", 
-                         [ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
-                                                       lags=2), 
-                          ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
-                                                             fun_predictors=create_predictors, 
-                                                             window_size=2)], 
-                         ids=lambda forecaster: f'forecaster: {type(forecaster).__name__}')
-def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_refit_with_mocked(forecaster):
+@pytest.mark.parametrize("forecaster, n_jobs", 
+                         [(ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                        lags=2), -1),
+                          (ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                        lags=2), 1),
+                          (ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                        lags=2), 'auto'),
+                          (ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                              fun_predictors=create_predictors, 
+                                                              window_size=2), -1),
+                          (ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                              fun_predictors=create_predictors, 
+                                                              window_size=2), 1),
+                          (ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                              fun_predictors=create_predictors, 
+                                                              window_size=2), 'auto')], 
+                         ids=lambda fc: f'forecaster, n_jobs: {fc}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_refit_with_mocked(forecaster, n_jobs):
     """
     Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiSeries 
     and ForecasterAutoregMultiSeriesCustom with refit with mocked 
     (mocked done in Skforecast v0.5.0).
     """
 
     steps = 3
@@ -325,15 +360,16 @@
                                                refit               = True,
                                                fixed_train_size    = False,
                                                exog                = None,
                                                interval            = None,
                                                n_boot              = 500,
                                                random_state        = 123,
                                                in_sample_residuals = True,
-                                               verbose             = False
+                                               verbose             = False,
+                                               n_jobs              = n_jobs
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'], 
                                     'mean_absolute_error': [0.2124129141233719]})
     expected_predictions = pd.DataFrame({
         'l1':np.array([0.4978838984103099, 0.46288426670127997, 0.48433446479429937, 
                        0.510664891759972, 0.49734477162307983, 0.5009680695304023,
@@ -803,17 +839,371 @@
         index = pd.date_range(start='2022-02-05', periods=15, freq='D')
     )
                                    
     pd.testing.assert_frame_equal(expected_metric, metrics_levels)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
+@pytest.mark.parametrize("forecaster", 
+                         [ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                       lags=2), 
+                          ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                             fun_predictors=create_predictors, 
+                                                             window_size=2)], 
+                         ids=lambda forecaster: f'forecaster: {type(forecaster).__name__}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_no_refit_different_lengths_with_mocked(forecaster):
+    """
+    Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiSeries 
+    and ForecasterAutoregMultiSeriesCustom with no refit and gap with 
+    mocked using exog and intervals and series with different lengths 
+    (mocked done in Skforecast v0.5.0).
+    """
+    n_validation = 20
+    steps = 5
+    gap = 3
+
+    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(
+                                               forecaster            = forecaster,
+                                               series                = series_with_nans,
+                                               steps                 = steps,
+                                               levels                = 'l1',
+                                               metric                = 'mean_absolute_error',
+                                               initial_train_size    = len(series_with_nans) - n_validation,
+                                               gap                   = gap,
+                                               allow_incomplete_fold = True,
+                                               refit                 = False,
+                                               fixed_train_size      = False,
+                                               exog                  = series_with_nans['l1'].rename('exog_1'),
+                                               interval              = [5, 95],
+                                               n_boot                = 150,
+                                               random_state          = 123,
+                                               in_sample_residuals   = True,
+                                               verbose               = False
+                                           )
+    
+    expected_metric = pd.DataFrame({'levels': ['l1'], 
+                                    'mean_absolute_error': [0.11243765852459384]})
+    expected_predictions = pd.DataFrame(
+                               data = np.array([[0.49746847, 0.24620019, 0.74208308],
+                                                [0.46715961, 0.27280913, 0.69897019],
+                                                [0.42170236, 0.21384761, 0.6338432 ],
+                                                [0.47242371, 0.23550111, 0.68264162],
+                                                [0.66450589, 0.4128072 , 0.87549193],
+                                                [0.67311291, 0.42184464, 0.91772752],
+                                                [0.48788629, 0.29353581, 0.71969688],
+                                                [0.55141437, 0.34355962, 0.76355521],
+                                                [0.33369285, 0.09677024, 0.54391075],
+                                                [0.43287852, 0.18117983, 0.64386456],
+                                                [0.46643379, 0.21516552, 0.7110484 ],
+                                                [0.6535986 , 0.45924812, 0.88540919],
+                                                [0.38328273, 0.17542798, 0.59542356],
+                                                [0.49931045, 0.26238785, 0.70952835],
+                                                [0.70119564, 0.44949695, 0.91218168],
+                                                [0.49290276, 0.24163448, 0.73751736],
+                                                [0.54653561, 0.35218513, 0.7783462 ]]),
+                               columns = ['l1', 'l1_lower_bound', 'l1_upper_bound'],
+                               index = pd.RangeIndex(start=33, stop=50, step=1)
+                           )
+                                   
+    pd.testing.assert_frame_equal(expected_metric, metrics_levels)
+    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
+
+
+@pytest.mark.parametrize("forecaster", 
+                         [ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                       lags=2), 
+                          ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                             fun_predictors=create_predictors, 
+                                                             window_size=2)], 
+                         ids=lambda forecaster: f'forecaster: {type(forecaster).__name__}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_refit_different_lengths_with_mocked(forecaster):
+    """
+    Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiSeries 
+    and ForecasterAutoregMultiSeriesCustom with refit, gap, allow_incomplete_fold 
+    False with mocked using exog and intervals (mocked done in Skforecast v0.5.0).
+    """
+    n_validation = 20
+    steps = 5
+    gap = 3
+
+    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(
+                                               forecaster            = forecaster,
+                                               series                = series_with_nans,
+                                               steps                 = steps,
+                                               levels                = 'l1',
+                                               metric                = 'mean_absolute_error',
+                                               initial_train_size    = len(series_with_nans) - n_validation,
+                                               gap                   = gap,
+                                               allow_incomplete_fold = False,
+                                               refit                 = True,
+                                               fixed_train_size      = False,
+                                               exog                  = series_with_nans['l1'].rename('exog_1'),
+                                               interval              = [5, 95],
+                                               n_boot                = 150,
+                                               random_state          = 123,
+                                               in_sample_residuals   = True,
+                                               verbose               = False
+                                           )
+    
+    expected_metric = pd.DataFrame({'levels': ['l1'], 
+                                    'mean_absolute_error': [0.12472922864372042]})
+    expected_predictions = pd.DataFrame(
+                               data = np.array([[0.49746847, 0.24620019, 0.74208308],
+                                                [0.46715961, 0.27280913, 0.69897019],
+                                                [0.42170236, 0.21384761, 0.6338432 ],
+                                                [0.47242371, 0.23550111, 0.68264162],
+                                                [0.66450589, 0.4128072 , 0.87549193],
+                                                [0.66852682, 0.46973936, 0.89016477],
+                                                [0.47796299, 0.2686537 , 0.69760042],
+                                                [0.5477168 , 0.35928395, 0.75677995],
+                                                [0.31418572, 0.10972171, 0.51376307],
+                                                [0.42390085, 0.22962754, 0.65199941],
+                                                [0.46927962, 0.25401323, 0.72621914],
+                                                [0.63294789, 0.39385723, 0.89726095],
+                                                [0.41355599, 0.20713645, 0.62092038],
+                                                [0.48437311, 0.24174172, 0.73198965],
+                                                [0.67731074, 0.46831444, 0.9265058 ]]),
+                               columns = ['l1', 'l1_lower_bound', 'l1_upper_bound'],
+                               index = pd.RangeIndex(start=33, stop=48, step=1)
+                           )
+                                   
+    pd.testing.assert_frame_equal(expected_metric, metrics_levels)
+    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
+
+
+@pytest.mark.parametrize("forecaster", 
+                         [ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                       lags=2), 
+                          ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                             fun_predictors=create_predictors, 
+                                                             window_size=2)], 
+                         ids=lambda forecaster: f'forecaster: {type(forecaster).__name__}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_refit_fixed_train_size_different_lengths_with_mocked(forecaster):
+    """
+    Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiSeries 
+    and ForecasterAutoregMultiSeriesCustom with refit, fixed_train_size, gap, 
+    with mocked using exog and intervals (mocked done in Skforecast v0.5.0).
+    """
+    series_with_nans_datetime = series_with_nans.copy()
+    series_with_nans_datetime.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
+
+    n_validation = 20
+    steps = 5
+    gap = 5
+
+    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(
+                                               forecaster            = forecaster,
+                                               series                = series_with_nans_datetime,
+                                               steps                 = steps,
+                                               levels                = 'l1',
+                                               metric                = 'mean_absolute_error',
+                                               initial_train_size    = len(series_with_nans_datetime) - n_validation,
+                                               gap                   = gap,
+                                               allow_incomplete_fold = False,
+                                               refit                 = True,
+                                               fixed_train_size      = True,
+                                               exog                  = series_with_nans_datetime['l1'].rename('exog_1'),
+                                               interval              = [5, 95],
+                                               n_boot                = 150,
+                                               random_state          = 123,
+                                               in_sample_residuals   = True,
+                                               verbose               = False
+                                           )
+    
+    expected_metric = pd.DataFrame({'levels': ['l1'], 
+                                    'mean_absolute_error': [0.1355099897175138]})
+    expected_predictions = pd.DataFrame(
+        data = np.array([[0.42170236, 0.21384761, 0.6338432 ],
+                         [0.47242371, 0.23550111, 0.68264162],
+                         [0.66450589, 0.4128072 , 0.87549193],
+                         [0.67311586, 0.46534536, 0.89662809],
+                         [0.487886  , 0.27487735, 0.65050566],
+                         [0.52759202, 0.30254031, 0.7316064 ],
+                         [0.33021382, 0.11679102, 0.52056867],
+                         [0.4226274 , 0.16874895, 0.61548288],
+                         [0.44647715, 0.22033296, 0.65301466],
+                         [0.61435678, 0.37793909, 0.81285962],
+                         [0.41671844, 0.13568381, 0.67943385],
+                         [0.47385345, 0.19025177, 0.76849597],
+                         [0.62360146, 0.39888165, 0.85075261],
+                         [0.49407875, 0.24011478, 0.78855477],
+                         [0.51234652, 0.26828928, 0.81339595]]),
+        columns = ['l1', 'l1_lower_bound', 'l1_upper_bound'],
+        index = pd.date_range(start='2022-02-05', periods=15, freq='D')
+    )
+                                   
+    pd.testing.assert_frame_equal(expected_metric, metrics_levels)
+    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
+
+
+@pytest.mark.parametrize("forecaster", 
+                         [ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                       lags=2), 
+                          ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                             fun_predictors=create_predictors, 
+                                                             window_size=2)], 
+                         ids=lambda forecaster: f'forecaster: {type(forecaster).__name__}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_refit_int_interval_yes_exog_yes_remainder_with_mocked(forecaster):
+    """
+    Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiSeries 
+    and ForecasterAutoregMultiSeriesCustom with refit int, interval, gap, 
+    with mocked using exog and intervals (mocked done in Skforecast v0.9.0).
+    """
+    refit = 2
+    n_validation = 20
+    steps = 2
+
+    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(
+                                               forecaster            = forecaster,
+                                               series                = series,
+                                               steps                 = steps,
+                                               levels                = None,
+                                               metric                = 'mean_absolute_error',
+                                               initial_train_size    = len(series) - n_validation,
+                                               gap                   = 0,
+                                               allow_incomplete_fold = False,
+                                               refit                 = refit,
+                                               fixed_train_size      = True,
+                                               exog                  = series['l1'].rename('exog_1'),
+                                               interval              = [5, 95],
+                                               n_boot                = 150,
+                                               random_state          = 123,
+                                               in_sample_residuals   = True,
+                                               verbose               = False
+                                           )
+    
+    expected_metric = pd.DataFrame(
+        {'levels': ['l1', 'l2'], 
+         'mean_absolute_error': [0.13341641696298234, 0.2532943228025243]}
+    )
+    expected_predictions = pd.DataFrame(
+        data = np.array([[ 3.62121311e-01,  1.50820320e-01,  5.93493644e-01,
+                             3.65807102e-01, -1.66846896e-01,  7.41872674e-01],
+                         [ 4.75603912e-01,  2.64338068e-01,  7.55477618e-01,
+                             4.77660870e-01, -2.09016888e-02,  8.50640767e-01],
+                         [ 4.78856340e-01,  2.67555349e-01,  7.10228673e-01,
+                             4.79828611e-01, -5.28253867e-02,  8.55894183e-01],
+                         [ 4.97626059e-01,  2.86360215e-01,  7.77499764e-01,
+                             4.98181879e-01, -3.80679351e-04,  8.71161776e-01],
+                         [ 4.57502853e-01,  2.34854548e-01,  6.90295515e-01,
+                             4.93394245e-01, -8.59476649e-02,  8.26877562e-01],
+                         [ 4.19762089e-01,  1.89123646e-01,  5.98698797e-01,
+                             4.37345761e-01, -2.47590943e-02,  8.09946951e-01],
+                         [ 4.64704145e-01,  2.42055840e-01,  6.97496807e-01,
+                             4.95977483e-01, -8.33644270e-02,  8.29460800e-01],
+                         [ 6.27792451e-01,  3.97154009e-01,  8.06729160e-01,
+                             6.80737238e-01,  2.18632382e-01,  1.05333843e+00],
+                         [ 5.87334375e-01,  3.26921031e-01,  8.69376004e-01,
+                             6.65280778e-01,  1.23472110e-01,  1.05838353e+00],
+                         [ 4.53164888e-01,  1.98770357e-01,  7.31112253e-01,
+                             5.17357914e-01, -3.46981422e-02,  9.17114685e-01],
+                         [ 4.91347698e-01,  2.30934354e-01,  7.73389327e-01,
+                             5.56066550e-01,  1.42578818e-02,  9.49169307e-01],
+                         [ 3.58133021e-01,  1.03738489e-01,  6.36080385e-01,
+                             3.94861192e-01, -1.57194865e-01,  7.94617962e-01],
+                         [ 4.23074894e-01,  1.46402575e-01,  6.85243368e-01,
+                             4.56570627e-01, -8.44076809e-02,  9.13597456e-01],
+                         [ 4.77639455e-01,  2.00288697e-01,  7.45269910e-01,
+                             4.52788025e-01, -6.08964382e-02,  9.16193940e-01],
+                         [ 5.90866263e-01,  3.14193944e-01,  8.53034737e-01,
+                             6.06068550e-01,  6.50902424e-02,  1.06309538e+00],
+                         [ 4.29943139e-01,  1.52592381e-01,  6.97573594e-01,
+                             4.22379461e-01, -9.13050017e-02,  8.85785376e-01],
+                         [ 4.71297777e-01,  1.92467142e-01,  7.32960612e-01,
+                             5.16307783e-01, -5.04225194e-02,  9.64821047e-01],
+                         [ 6.45316619e-01,  4.47497018e-01,  9.25177996e-01,
+                             6.51701762e-01,  1.69673821e-01,  1.01740457e+00],
+                         [ 5.42727946e-01,  2.63897311e-01,  8.04390781e-01,
+                             5.10069712e-01, -5.66605897e-02,  9.58582976e-01],
+                         [ 5.30915933e-01,  3.33096333e-01,  8.10777311e-01,
+                             5.43494604e-01,  6.14666630e-02,  9.09197415e-01]]),
+        columns = ['l1', 'l1_lower_bound', 'l1_upper_bound', 'l2', 'l2_lower_bound', 'l2_upper_bound'],
+        index = pd.RangeIndex(start=30, stop=50, step=1)
+    )
+                                   
+    pd.testing.assert_frame_equal(expected_metric, metrics_levels)
+    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
+
+
+@pytest.mark.parametrize("forecaster", 
+                         [ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), 
+                                                       lags=2), 
+                          ForecasterAutoregMultiSeriesCustom(regressor=Ridge(random_state=123), 
+                                                             fun_predictors=create_predictors, 
+                                                             window_size=2)], 
+                         ids=lambda forecaster: f'forecaster: {type(forecaster).__name__}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_refit_int_interval_yes_exog_not_allow_remainder_gap_with_mocked(forecaster):
+    """
+    Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiSeries 
+    and ForecasterAutoregMultiSeriesCustom with refit int, interval, gap, 
+    with mocked using exog and intervals (mocked done in Skforecast v0.9.0).
+    """
+    series_with_index = series.copy()
+    series_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
+    exog_with_index = series['l1'].rename('exog_1').copy()
+    exog_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
+
+    refit = 3
+    n_validation = 20
+    steps = 4
+    gap = 3
+
+    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(
+                                               forecaster            = forecaster,
+                                               series                = series_with_index,
+                                               steps                 = steps,
+                                               levels                = ['l2'],
+                                               metric                = 'mean_absolute_error',
+                                               initial_train_size    = len(series_with_index) - n_validation,
+                                               gap                   = gap,
+                                               allow_incomplete_fold = False,
+                                               refit                 = refit,
+                                               fixed_train_size      = False,
+                                               exog                  = exog_with_index,
+                                               interval              = [5, 95],
+                                               n_boot                = 100,
+                                               random_state          = 123,
+                                               in_sample_residuals   = True,
+                                               verbose               = False
+                                           )
+    
+    expected_metric = pd.DataFrame(
+        {'levels': ['l2'], 
+         'mean_absolute_error': [0.2791832310123065]}
+    )
+    expected_predictions = pd.DataFrame(
+        data = np.array([[ 0.49984026,  0.00509982,  0.82464616],
+                         [ 0.4767447 , -0.0798953 ,  0.80487146],
+                         [ 0.43791384, -0.12045877,  0.81344287],
+                         [ 0.47690063, -0.01831127,  0.85480226],
+                         [ 0.63619086,  0.14145042,  0.96099675],
+                         [ 0.65328344,  0.09664345,  0.98141021],
+                         [ 0.50150406, -0.05686855,  0.8770331 ],
+                         [ 0.54283634,  0.04762444,  0.92073797],
+                         [ 0.37097633, -0.1237641 ,  0.69578223],
+                         [ 0.43922059, -0.11741941,  0.76734736],
+                         [ 0.47379722, -0.08457539,  0.84932626],
+                         [ 0.62696782,  0.13175592,  1.00486945],
+                         [ 0.45263688, -0.09848725,  0.84471127],
+                         [ 0.5005012 , -0.02743982,  0.95029956],
+                         [ 0.66342359,  0.10579924,  1.20771224],
+                         [ 0.53547991,  0.02357046,  0.89862351]]),
+        columns = ['l2', 'l2_lower_bound', 'l2_upper_bound'],
+        index = pd.date_range(start='2022-02-03', periods=16, freq='D')
+    )
+                                   
+    pd.testing.assert_frame_equal(expected_metric, metrics_levels)
+    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
+
+
 # ForecasterAutoregMultiVariate
 # ======================================================================================================================
-def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiVariate_not_refit_with_mocked():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'],
+                         ids=lambda n: f'n_jobs: {n}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiVariate_not_refit_with_mocked(n_jobs):
     """
     Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiVariate without refit
     with mocked (mocked done in Skforecast v0.6.0).
     """
 
     forecaster = ForecasterAutoregMultiVariate(
                      regressor = Ridge(random_state=123),
@@ -835,14 +1225,15 @@
                                                refit               = False,
                                                fixed_train_size    = False,
                                                exog                = None,
                                                interval            = None,
                                                n_boot              = 500,
                                                random_state        = 123,
                                                in_sample_residuals = True,
+                                               n_jobs              = n_jobs,
                                                verbose             = True
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'],
                                     'mean_absolute_error': [0.2056686186667702]})
     expected_predictions = pd.DataFrame({
                                'l1':np.array([0.55397908, 0.48026456, 0.52368724,
@@ -907,15 +1298,17 @@
         index=pd.RangeIndex(start=2, stop=50, step=1)
     )
                                    
     pd.testing.assert_frame_equal(expected_metric, metrics_levels)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiVariate_refit_fixed_train_size_with_mocked():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'],
+                         ids=lambda n: f'n_jobs: {n}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiVariate_refit_fixed_train_size_with_mocked(n_jobs):
     """
     Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiVariate with refit,
     fixed_train_size and custom metric with mocked (mocked done in Skforecast v0.6.0).
     """
 
     forecaster = ForecasterAutoregMultiVariate(
                      regressor = Ridge(random_state=123),
@@ -944,14 +1337,15 @@
                                                refit               = True,
                                                fixed_train_size    = True, 
                                                exog                = None,
                                                interval            = None,
                                                n_boot              = 500,
                                                random_state        = 123,
                                                in_sample_residuals = True,
+                                               n_jobs              = n_jobs,
                                                verbose             = True
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l2'],
                                     'custom_metric': [0.2326510995879597]})
     expected_predictions = pd.DataFrame({
                                'l2':np.array([0.58478895, 0.56729494, 0.54469663,
@@ -961,15 +1355,17 @@
                                index=pd.RangeIndex(start=38, stop=50, step=1)
                            )
                                    
     pd.testing.assert_frame_equal(expected_metric, metrics_levels)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
 
-def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiVariate_refit_with_mocked():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'],
+                         ids=lambda n: f'n_jobs: {n}')
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiVariate_refit_with_mocked(n_jobs):
     """
     Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiVariate 
     with refit with mocked (mocked done in Skforecast v0.6.0).
     """
 
     forecaster = ForecasterAutoregMultiVariate(
                      regressor = Ridge(random_state=123),
@@ -991,14 +1387,15 @@
                                                refit               = True,
                                                fixed_train_size    = False,
                                                exog                = None,
                                                interval            = None,
                                                n_boot              = 500,
                                                random_state        = 123,
                                                in_sample_residuals = True,
+                                               n_jobs              = n_jobs,
                                                verbose             = False
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'], 
                                     'mean_absolute_error': [0.20733067815663564]})
     expected_predictions = pd.DataFrame({
                                'l1':np.array([0.55397908, 0.48026456, 0.52368724, 
@@ -1093,28 +1490,28 @@
                                                n_boot              = 500,
                                                random_state        = 123,
                                                in_sample_residuals = True,
                                                verbose             = False
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'], 
-                                    'mean_absolute_error': [0.080981301131163]})
+                                    'mean_absolute_error': [0.08098130113116303]})
     expected_predictions = pd.DataFrame(
                                data = np.array([[0.79017158, 0.65165001, 0.92309077],
-                                                [0.49318335, 0.37085985, 0.6403262 ],
-                                                [0.58563228, 0.46560056, 0.72877519],
+                                                [0.49318335, 0.33877981, 0.59549335],
+                                                [0.58563228, 0.45036051, 0.72877519],
                                                 [0.26135924, 0.12283767, 0.39427843],
-                                                [0.37825777, 0.25593427, 0.52540062],
-                                                [0.45697738, 0.33694566, 0.60012028],
+                                                [0.37825777, 0.22385422, 0.48056776],
+                                                [0.45697738, 0.3217056 , 0.60012028],
                                                 [0.70804671, 0.56952514, 0.8409659 ],
-                                                [0.33222686, 0.20990336, 0.47936971],
-                                                [0.49603977, 0.37600804, 0.63918267],
+                                                [0.33222686, 0.17782331, 0.43453685],
+                                                [0.49603977, 0.36076799, 0.63918267],
                                                 [0.79614494, 0.65762337, 0.92906413],
-                                                [0.50007531, 0.37775181, 0.64721816],
-                                                [0.55280975, 0.43277803, 0.69595266]]),
+                                                [0.50007531, 0.34567176, 0.60238531],
+                                                [0.55280975, 0.41753798, 0.69595266]]),
                                columns = ['l1', 'lower_bound', 'upper_bound'],
                                index = pd.RangeIndex(start=38, stop=50, step=1)
                            )
                                    
     pd.testing.assert_frame_equal(expected_metric, metrics_levels)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
@@ -1153,21 +1550,21 @@
                                                verbose             = False
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'], 
                                     'mean_absolute_error': [0.07705832858897509]})
     expected_predictions = pd.DataFrame(
                                data = np.array([[0.79017158, 0.65165001, 0.92309077],
-                                                [0.49318335, 0.37085985, 0.6403262 ],
-                                                [0.58563228, 0.46560056, 0.72877519],
+                                                [0.49318335, 0.33877981, 0.59549335],
+                                                [0.58563228, 0.45036051, 0.72877519],
                                                 [0.25636363, 0.10743222, 0.37710866],
                                                 [0.37604542, 0.24241796, 0.52792491],
-                                                [0.45439247, 0.32888843, 0.59559781],
+                                                [0.45439247, 0.31741445, 0.6007327 ],
                                                 [0.70488052, 0.5596997 , 0.84559181],
-                                                [0.32693583, 0.20085419, 0.47910327],
+                                                [0.32693583, 0.19870532, 0.47910327],
                                                 [0.49099895, 0.35617576, 0.63524443],
                                                 [0.82066806, 0.67917812, 0.95193044],
                                                 [0.51109877, 0.39178411, 0.66186064],
                                                 [0.54738032, 0.42195622, 0.69395717]]),
                                columns = ['l1', 'lower_bound', 'upper_bound'],
                                index = pd.RangeIndex(start=38, stop=50, step=1)
                            )
@@ -1211,31 +1608,31 @@
                                                in_sample_residuals   = True,
                                                verbose               = False
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'], 
                                     'mean_absolute_error': [0.10867753185751189]})
     expected_predictions = pd.DataFrame(
-                               data = np.array([[0.5137416 , 0.34426563, 0.73028006],
-                                                [0.51578881, 0.33968421, 0.71123006],
-                                                [0.38569703, 0.20685029, 0.57366884],
-                                                [0.41784889, 0.24557264, 0.5874939 ],
+                               data = np.array([[0.5137416 , 0.28565005, 0.64960534],
+                                                [0.51578881, 0.36235612, 0.71123006],
+                                                [0.38569703, 0.20965762, 0.51379331],
+                                                [0.41784889, 0.23241384, 0.58140101],
                                                 [0.69352545, 0.51075098, 0.88011232],
-                                                [0.7137808 , 0.54430484, 0.93031927],
-                                                [0.52155299, 0.34544839, 0.71699424],
-                                                [0.51871169, 0.33986495, 0.7066835 ],
-                                                [0.31342947, 0.14115321, 0.48307448],
+                                                [0.7137808 , 0.48568926, 0.84964454],
+                                                [0.52155299, 0.3681203 , 0.71699424],
+                                                [0.51871169, 0.34267227, 0.64680796],
+                                                [0.31342947, 0.12799441, 0.47698158],
                                                 [0.4337246 , 0.25095013, 0.62031147],
-                                                [0.44486807, 0.2753921 , 0.66140653],
-                                                [0.67773806, 0.50163345, 0.87317931],
-                                                [0.3732339 , 0.19438716, 0.56120571],
-                                                [0.44959589, 0.27731963, 0.6192409 ],
+                                                [0.44486807, 0.21677652, 0.58073181],
+                                                [0.67773806, 0.52430536, 0.87317931],
+                                                [0.3732339 , 0.19719449, 0.50133018],
+                                                [0.44959589, 0.26416083, 0.613148  ],
                                                 [0.69181652, 0.50904205, 0.87840338],
-                                                [0.51679906, 0.34732309, 0.73333753],
-                                                [0.49803962, 0.32193501, 0.69348087]]),
+                                                [0.51679906, 0.28870751, 0.6526628 ],
+                                                [0.49803962, 0.34460692, 0.69348087]]),
                                columns = ['l1', 'lower_bound', 'upper_bound'],
                                index = pd.RangeIndex(start=33, stop=50, step=1)
                            )
                                    
     pd.testing.assert_frame_equal(expected_metric, metrics_levels)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
@@ -1275,29 +1672,29 @@
                                                in_sample_residuals   = True,
                                                verbose               = False
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'], 
                                     'mean_absolute_error': [0.09906557188440204]})
     expected_predictions = pd.DataFrame(
-                               data = np.array([[0.5137416 , 0.34426563, 0.73028006],
-                                                [0.51578881, 0.33968421, 0.71123006],
-                                                [0.38569703, 0.20685029, 0.57366884],
-                                                [0.41784889, 0.24557264, 0.5874939 ],
+                               data = np.array([[0.5137416 , 0.28565005, 0.64960534],
+                                                [0.51578881, 0.36235612, 0.71123006],
+                                                [0.38569703, 0.20965762, 0.51379331],
+                                                [0.41784889, 0.23241384, 0.58140101],
                                                 [0.69352545, 0.51075098, 0.88011232],
-                                                [0.73709708, 0.58168569, 0.87889663],
-                                                [0.49379408, 0.290055  , 0.70108827],
-                                                [0.54129634, 0.38342955, 0.66728576],
-                                                [0.2889167 , 0.12235121, 0.43445229],
-                                                [0.41762991, 0.26652975, 0.56954018],
+                                                [0.73709708, 0.60256116, 0.87889663],
+                                                [0.49379408, 0.34235281, 0.70108827],
+                                                [0.54129634, 0.38342955, 0.66423569],
+                                                [0.2889167 , 0.13545924, 0.45541277],
+                                                [0.41762991, 0.26652975, 0.58517659],
                                                 [0.4281944 , 0.26680135, 0.56842703],
                                                 [0.6800295 , 0.53425961, 0.86349246],
-                                                [0.3198172 , 0.19262494, 0.44498576],
-                                                [0.45269985, 0.30700229, 0.63937102],
-                                                [0.76214215, 0.62904194, 0.89487036]]),
+                                                [0.3198172 , 0.18545173, 0.44111693],
+                                                [0.45269985, 0.29948117, 0.57043644],
+                                                [0.76214215, 0.63320969, 0.90810797]]),
                                columns = ['l1', 'lower_bound', 'upper_bound'],
                                index = pd.RangeIndex(start=33, stop=48, step=1)
                            )
                                    
     pd.testing.assert_frame_equal(expected_metric, metrics_levels)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
 
@@ -1340,29 +1737,178 @@
                                                in_sample_residuals   = True,
                                                verbose               = False
                                            )
     
     expected_metric = pd.DataFrame({'levels': ['l1'], 
                                     'mean_absolute_error': [0.12073089072357064]})
     expected_predictions = pd.DataFrame(
-        data = np.array([[0.40010139, 0.2013807 , 0.55634946],
-                         [0.42717215, 0.23434534, 0.57988887],
-                         [0.68150611, 0.48700348, 0.82602514],
-                         [0.66167269, 0.49643682, 0.87762411],
-                         [0.48946946, 0.27161248, 0.69919005],
-                         [0.52955424, 0.36121274, 0.67655883],
-                         [0.30621348, 0.11465701, 0.46321967],
-                         [0.44140106, 0.27062974, 0.59142153],
-                         [0.41294246, 0.25357362, 0.64296396],
-                         [0.66798745, 0.51402456, 0.89221746],
-                         [0.35206832, 0.15233485, 0.50524599],
-                         [0.41828203, 0.28154037, 0.5840278 ],
-                         [0.6605119 , 0.44992937, 0.83942143],
-                         [0.49225437, 0.33605182, 0.7232556 ],
-                         [0.52528842, 0.35971141, 0.7220394 ]]),
+        data = np.array([[0.40010139, 0.21491844, 0.52790634],
+                         [0.42717215, 0.23067944, 0.57988887],
+                         [0.68150611, 0.48700348, 0.81952219],
+                         [0.66167269, 0.46929506, 0.87762411],
+                         [0.48946946, 0.36803878, 0.69919005],
+                         [0.52955424, 0.36121274, 0.7342489 ],
+                         [0.30621348, 0.11465701, 0.46702924],
+                         [0.44140106, 0.27497225, 0.62523765],
+                         [0.41294246, 0.26739719, 0.58273245],
+                         [0.66798745, 0.51402456, 0.82567436],
+                         [0.35206832, 0.19485472, 0.6001923 ],
+                         [0.41828203, 0.28154037, 0.58081107],
+                         [0.6605119 , 0.44992937, 0.79751069],
+                         [0.49225437, 0.31367508, 0.67624609],
+                         [0.52528842, 0.33700505, 0.74482225]]),
         columns = ['l1', 'lower_bound', 'upper_bound'],
         index = pd.date_range(start='2022-02-05', periods=15, freq='D')
     )
     backtest_predictions = backtest_predictions.asfreq('D')
                                    
     pd.testing.assert_frame_equal(expected_metric, metrics_levels)
+    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
+
+
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiVariate_refit_int_interval_yes_exog_yes_remainder_with_mocked():
+    """
+    Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiVariate 
+    with refit int, interval, gap, with mocked using exog and intervals 
+    (mocked done in Skforecast v0.9.0).
+    """
+    forecaster = ForecasterAutoregMultiVariate(
+                     regressor = Ridge(random_state=123),
+                     level     = 'l1',
+                     lags      = 2,
+                     steps     = 2
+                 )
+    
+    refit = 2
+    n_validation = 20
+    steps = 2
+
+    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(
+                                               forecaster            = forecaster,
+                                               series                = series,
+                                               steps                 = steps,
+                                               levels                = 'l1',
+                                               metric                = 'mean_absolute_error',
+                                               initial_train_size    = len(series) - n_validation,
+                                               gap                   = 0,
+                                               allow_incomplete_fold = False,
+                                               refit                 = refit,
+                                               fixed_train_size      = True,
+                                               exog                  = series['l1'].rename('exog_1'),
+                                               interval              = [5, 95],
+                                               n_boot                = 100,
+                                               random_state          = 123,
+                                               in_sample_residuals   = True,
+                                               verbose               = False
+                                           )
+    
+    expected_metric = pd.DataFrame(
+        {'levels': ['l1'], 
+         'mean_absolute_error': [0.09237017311770493]}
+    )
+    expected_predictions = pd.DataFrame(
+        data = np.array([[0.2983264 , 0.14814112, 0.52611729],
+                         [0.45367569, 0.3061465 , 0.56042116],
+                         [0.4802857 , 0.33010042, 0.70807659],
+                         [0.48384823, 0.33631904, 0.59059371],
+                         [0.44991269, 0.27452568, 0.6567239 ],
+                         [0.38062305, 0.20946396, 0.50828437],
+                         [0.42817363, 0.25278662, 0.63498485],
+                         [0.68209515, 0.51093605, 0.80975646],
+                         [0.72786565, 0.58843297, 0.8652939 ],
+                         [0.45147711, 0.32772617, 0.57845425],
+                         [0.52904599, 0.38961331, 0.66647424],
+                         [0.28657426, 0.16282332, 0.4135514 ],
+                         [0.36296117, 0.24577117, 0.52321437],
+                         [0.46902166, 0.37455162, 0.62846802],
+                         [0.68519422, 0.56800422, 0.84544742],
+                         [0.35197602, 0.25750597, 0.51142238],
+                         [0.47338638, 0.29477692, 0.61652158],
+                         [0.74059646, 0.6075235 , 0.88275308],
+                         [0.55112717, 0.37251772, 0.69426237],
+                         [0.55778417, 0.4247112 , 0.69994079]]),
+        columns = ['l1', 'lower_bound', 'upper_bound'],
+        index = pd.RangeIndex(start=30, stop=50, step=1)
+    )
+                                   
+    pd.testing.assert_frame_equal(expected_metric, metrics_levels)
+    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
+
+
+def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiVariate_refit_int_interval_yes_exog_not_allow_remainder_gap_with_mocked():
+    """
+    Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiVariate 
+    with refit int, interval, gap, with mocked using exog and intervals 
+    (mocked done in Skforecast v0.9.0).
+    """
+    series_with_index = series.copy()
+    series_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
+    exog_with_index = series['l1'].rename('exog_1').copy()
+    exog_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')
+
+    forecaster = ForecasterAutoregMultiVariate(
+                     regressor = Ridge(random_state=123),
+                     level     = 'l1',
+                     lags      = 2,
+                     steps     = 7
+                 )
+
+    refit = 3
+    n_validation = 30
+    steps = 4
+    gap = 3
+
+    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(
+                                               forecaster            = forecaster,
+                                               series                = series_with_index,
+                                               steps                 = steps,
+                                               levels                = ['l1'],
+                                               metric                = 'mean_absolute_error',
+                                               initial_train_size    = len(series_with_index) - n_validation,
+                                               gap                   = gap,
+                                               allow_incomplete_fold = False,
+                                               refit                 = refit,
+                                               fixed_train_size      = False,
+                                               exog                  = exog_with_index,
+                                               interval              = [5, 95],
+                                               n_boot                = 100,
+                                               random_state          = 123,
+                                               in_sample_residuals   = True,
+                                               verbose               = False
+                                           )
+    
+    expected_metric = pd.DataFrame(
+        {'levels': ['l1'], 
+         'mean_absolute_error': [0.10066454067329249]}
+    )
+    expected_predictions = pd.DataFrame(
+        data = np.array([[0.53203113, 0.27318916, 0.69931226],
+                         [0.62129188, 0.46220068, 0.85870486],
+                         [0.40145922, 0.17189084, 0.59797159],
+                         [0.38821275, 0.17098498, 0.61456487],
+                         [0.37636995, 0.11752798, 0.54365108],
+                         [0.36599243, 0.20690123, 0.60340541],
+                         [0.47654862, 0.24698023, 0.67306099],
+                         [0.33725755, 0.12002978, 0.56360967],
+                         [0.46122163, 0.20237966, 0.62850276],
+                         [0.47541934, 0.31632814, 0.71283232],
+                         [0.50601999, 0.27645161, 0.70253236],
+                         [0.39293452, 0.17570675, 0.61928664],
+                         [0.43793405, 0.27695885, 0.5990429 ],
+                         [0.52600886, 0.38167775, 0.72224797],
+                         [0.70882239, 0.55319058, 0.83377003],
+                         [0.70063755, 0.51962777, 0.85415566],
+                         [0.48631217, 0.32533698, 0.64742102],
+                         [0.52248417, 0.37815306, 0.71872328],
+                         [0.30010035, 0.14446853, 0.42504798],
+                         [0.43342987, 0.25242008, 0.58694797],
+                         [0.42479569, 0.2638205 , 0.58590454],
+                         [0.68566159, 0.54133048, 0.8819007 ],
+                         [0.34632377, 0.19069195, 0.4712714 ],
+                         [0.44695116, 0.26594138, 0.60046927]]),
+        columns = ['l1', 'lower_bound', 'upper_bound'],
+        index = pd.date_range(start='2022-01-24', periods=24, freq='D')
+    )
+    backtest_predictions = backtest_predictions.asfreq('D')
+                                   
+    pd.testing.assert_frame_equal(expected_metric, metrics_levels)
     pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)
```

### Comparing `skforecast-0.8.1/skforecast/model_selection_multiseries/tests/test_evaluate_grid_hyperparameters.py` & `skforecast-0.9.0/skforecast/model_selection_multiseries/tests/test_evaluate_grid_hyperparameters.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection_multiseries/tests/test_grid_search_forecaster_multiseries.py` & `skforecast-0.9.0/skforecast/model_selection_multiseries/tests/test_grid_search_forecaster_multiseries.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection_multiseries/tests/test_random_search_forecaster_multiseries.py` & `skforecast-0.9.0/skforecast/model_selection_multiseries/tests/test_random_search_forecaster_multiseries.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection_sarimax/model_selection_sarimax.py` & `skforecast-0.9.0/skforecast/model_selection_sarimax/model_selection_sarimax.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,341 +1,236 @@
 ################################################################################
 #                      skforecast.model_selection_sarimax                      #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
-from typing import Union, Tuple, Optional, Any, Callable
+from typing import Union, Tuple, Optional, Callable
 import numpy as np
 import pandas as pd
 import warnings
 import logging
 from copy import deepcopy
+from joblib import Parallel, delayed, cpu_count
 from tqdm.auto import tqdm
+import sklearn.pipeline
 from sklearn.model_selection import ParameterGrid
 from sklearn.model_selection import ParameterSampler
 
 from ..exceptions import LongTrainingWarning
-from ..exceptions import IgnoredArgumentWarning
 from ..model_selection.model_selection import _get_metric
-from ..model_selection.model_selection import _backtesting_forecaster_verbose
 from ..model_selection.model_selection import _create_backtesting_folds
 from ..utils import check_backtesting_input
+from ..utils import select_n_jobs_backtesting
 
 logging.basicConfig(
     format = '%(name)-10s %(levelname)-5s %(message)s', 
     level  = logging.INFO,
 )
 
 
-def _backtesting_sarimax_refit(
+def _backtesting_sarimax(
     forecaster,
     y: pd.Series,
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
+    refit: Optional[Union[bool, int]]=False,
     alpha: Optional[float]=None,
     interval: Optional[list]=None,
+    n_jobs: Optional[Union[int, str]]='auto',
     verbose: bool=False,
     show_progress: bool=True
 ) -> Tuple[Union[float, list], pd.DataFrame]:
     """
-    Backtesting of ForecasterSarimax model with a re-fitting strategy. A copy of the  
-    original forecaster is created so it is not modified during the process.
+    Backtesting of ForecasterSarimax.
+
+    - If `refit` is `False`, the model will be trained only once using the 
+    `initial_train_size` first observations. 
+    - If `refit` is `True`, the model is trained on each iteration, increasing
+    the training set. 
+    - If `refit` is an `integer`, the model will be trained every that number 
+    of iterations.
     
-    In each iteration:
-        - Fit forecaster with the training set.
-        - A number of `steps` ahead are predicted.
-        - The training set increases with `steps` observations.
-        - The model is re-fitted using the new training set.
-
-    In order to apply backtesting with refit, an initial training set must be
-    available, otherwise it would not be possible to increase the training set 
-    after each iteration. `initial_train_size` must be provided.
+    A copy of the original forecaster is created so that it is not modified during 
+    the process.
     
     Parameters
     ----------
     forecaster : ForecasterSarimax
         Forecaster model.
-        
     y : pandas Series
         Training time series.
-        
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-    
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int
         Number of samples in the initial train split. The backtest forecaster is
         trained using the first `initial_train_size` observations.
-        
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-        
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-            
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     alpha : float, default `0.05`
         The confidence intervals for the forecasts are (1 - alpha) %.
         If both, `alpha` and `interval` are provided, `alpha` will be used.
-        
     interval : list, default `None`
         Confidence of the prediction interval estimated. The values must be
         symmetric. Sequence of percentiles to compute, which must be between 
         0 and 100 inclusive. For example, interval of 95% should be as 
         `interval = [2.5, 97.5]`. If both, `alpha` and `interval` are 
         provided, `alpha` will be used.
-            
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `False`
-        Print number of folds and index of training and validation sets used for backtesting.
-
+        Print number of folds and index of training and validation sets used 
+        for backtesting.
     show_progress: bool, default `True`
-        Whether to show a progress bar. Defaults to True.
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
     metrics_value : float, list
         Value(s) of the metric(s).
-
-    backtest_predictions : pandas Dataframe
+    backtest_predictions : pandas DataFrame
         Value of predictions and their estimated interval if `interval` is not `None`.
-            column pred = predictions.
-            column lower_bound = lower bound of the interval.
-            column upper_bound = upper bound interval of the interval.
+
+            - column pred: predictions.
+            - column lower_bound: lower bound of the interval.
+            - column upper_bound: upper bound of the interval.
     
     """
 
     forecaster = deepcopy(forecaster)
+    
+    if refit == False:
+        n_jobs = 1
+    else:
+        if n_jobs == 'auto':        
+            n_jobs = select_n_jobs_backtesting(
+                         forecaster_name = type(forecaster).__name__,
+                         regressor_name  = type(forecaster.regressor).__name__,
+                         refit           = refit
+                     )
+        else:
+            n_jobs = n_jobs if n_jobs > 0 else cpu_count()
 
     if not isinstance(metric, list):
         metrics = [_get_metric(metric=metric) if isinstance(metric, str) else metric]
     else:
         metrics = [_get_metric(metric=m) if isinstance(m, str) else m for m in metric]
+
+    # initial_train_size cannot be None because of append method in Sarimax
+    # First model training, this is done to allow parallelization when `refit` 
+    # is `False`. The initial Forecaster fit is outside the auxiliary function.
+    exog_train = exog.iloc[:initial_train_size, ] if exog is not None else None
+    forecaster.fit(
+        y    = y.iloc[:initial_train_size, ],
+        exog = exog_train
+    )
+    window_size = forecaster.window_size
+    externally_fitted = False
     
     folds = _create_backtesting_folds(
                 data                  = y,
-                test_size             = steps,
+                window_size           = window_size,
                 initial_train_size    = initial_train_size,
-                gap                   = gap,
-                refit                 = True,
+                test_size             = steps,
+                externally_fitted     = externally_fitted,
+                refit                 = refit,
                 fixed_train_size      = fixed_train_size,
+                gap                   = gap,
                 allow_incomplete_fold = allow_incomplete_fold,
                 return_all_indexes    = False,
                 verbose               = verbose  
             )
     
-    if len(folds) > 50:
-        warnings.warn(
-            (f"The forecaster will be fit {len(folds)} times. This can take substantial "
-             f"amounts of time. If not feasible, try with `refit = False`.\n"),
-            LongTrainingWarning
-        )
+    if refit:
+        n_of_fits = int(len(folds)/refit)
+        if n_of_fits > 50:
+            warnings.warn(
+                (f"The forecaster will be fit {n_of_fits} times. This can take substantial "
+                f"amounts of time. If not feasible, try with `refit = False`.\n"),
+                LongTrainingWarning
+            )
+       
+    folds_tqdm = tqdm(folds) if show_progress else folds
+
+    def _fit_predict_forecaster(y, exog, forecaster, alpha, interval, fold, steps):
+        """
+        Fit the forecaster and predict `steps` ahead. This is an auxiliary 
+        function used to parallelize the backtesting_forecaster function.
+        """
 
-    backtest_predictions = []
-    
-    for fold in tqdm(folds) if show_progress else folds:
         # In each iteration the model is fitted before making predictions. 
         # if fixed_train_size the train size doesn't increase but moves by `steps` 
         # in each iteration. if False the train size increases by `steps` in each 
         # iteration.
         train_idx_start = fold[0][0]
         train_idx_end   = fold[0][1]
-        test_idx_start  = fold[1][0]
-        test_idx_end    = fold[1][1]
-        
-        y_train = y.iloc[train_idx_start:train_idx_end, ]
-        exog_train = exog.iloc[train_idx_start:train_idx_end, ] if exog is not None else None
-        next_window_exog = exog.iloc[test_idx_start:test_idx_end, ] if exog is not None else None
+        test_idx_start  = fold[2][0]
+        test_idx_end    = fold[2][1]
 
-        forecaster.fit(y=y_train, exog=exog_train)
-        steps = len(range(test_idx_start, test_idx_end))
-        if alpha is None and interval is None:
-            pred = forecaster.predict(steps=steps, exog=next_window_exog)
+        if refit:
+            last_window_start = fold[0][1] # Same as train_idx_end
+            last_window_end   = fold[1][1]
         else:
-            pred = forecaster.predict_interval(
-                       steps    = steps,
-                       alpha    = alpha,
-                       interval = interval,
-                       exog     = next_window_exog,
-                   )
-
-        pred = pred.iloc[gap:, ]            
-        backtest_predictions.append(pred)
-    
-    backtest_predictions = pd.concat(backtest_predictions)
-    if isinstance(backtest_predictions, pd.Series):
-        backtest_predictions = pd.DataFrame(backtest_predictions)
-
-    metrics_values = [m(
-                        y_true = y.loc[backtest_predictions.index],
-                        y_pred = backtest_predictions['pred']
-                      ) for m in metrics
-                     ]
-    
-    if not isinstance(metric, list):
-        metrics_values = metrics_values[0]
-
-    return metrics_values, backtest_predictions
-
-
-def _backtesting_sarimax_no_refit(
-    forecaster,
-    y: pd.Series,
-    steps: int,
-    metric: Union[str, Callable, list],
-    initial_train_size: int,
-    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
-    alpha: Optional[float]=None,
-    interval: Optional[list]=None,
-    verbose: bool=False,
-    show_progress: bool=True
-) -> Tuple[Union[float, list], pd.DataFrame]:
-    """
-    Backtesting of ForecasterSarimax without iterative re-fitting. In each iteration,
-    a number of `steps` are predicted. A copy of the original forecaster is
-    created so it is not modified during the process.
-
-    If `forecaster` is already trained and `initial_train_size` is `None`,
-    no initial train is done and all data is used to evaluate the model.
-    However, the first `len(forecaster.last_window)` observations are needed
-    to create the initial predictors, so no predictions are calculated for them.
-    
-    Parameters
-    ----------
-    forecaster : ForecasterSarimax
-        Forecaster model.
-        
-    y : pandas Series
-        Training time series.
-        
-    steps : int
-        Number of steps to predict.
-        
-    metric : str, Callable, list
-        Metric used to quantify the goodness of fit of the model.
-        
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
-             'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-    
-    initial_train_size : int
-        Number of samples in the initial train split. The backtest forecaster is
-        trained using the first `initial_train_size` observations.
-        
-    exog : pandas Series, pandas DataFrame, default `None`
-        Exogenous variable/s included as predictor/s. Must have the same
-        number of observations as `y` and should be aligned so that y[i] is
-        regressed on exog[i].
-            
-    alpha : float, default `0.05`
-        The confidence intervals for the forecasts are (1 - alpha) %.
-        If both, `alpha` and `interval` are provided, `alpha` will be used.
-        
-    interval : list, default `None`
-        Confidence of the prediction interval estimated. The values must be
-        symmetric. Sequence of percentiles to compute, which must be between 
-        0 and 100 inclusive. For example, interval of 95% should be as 
-        `interval = [2.5, 97.5]`. If both, `alpha` and `interval` are 
-        provided, `alpha` will be used.
-            
-    verbose : bool, default `False`
-        Print number of folds and index of training and validation sets used 
-        for backtesting.
-
-    show_progress: bool, default `True`
-        Whether to show a progress bar. Defaults to True.
-
-    Returns 
-    -------
-    metrics_value : float, list
-        Value(s) of the metric(s).
+            last_window_end   = fold[2][0] # test_idx_start
+            last_window_start = last_window_end - steps
 
-    backtest_predictions : pandas DataFrame
-        Value of predictions and their estimated interval if `interval` is not `None`.
-            column pred = predictions.
-            column lower_bound = lower bound of the interval.
-            column upper_bound = upper bound interval of the interval.
-    
-    """
-
-    forecaster = deepcopy(forecaster)
-
-    if not isinstance(metric, list):
-        metrics = [_get_metric(metric=metric) if isinstance(metric, str) else metric]
-    else:
-        metrics = [_get_metric(metric=m) if isinstance(m, str) else m for m in metric]
-
-    # initial_train_size cannot be None because of append method in Sarimax
-    exog_train = exog.iloc[:initial_train_size, ] if exog is not None else None
-    forecaster.fit(y=y.iloc[:initial_train_size], exog=exog_train)
-    
-    folds     = int(np.ceil((len(y) - initial_train_size) / steps))
-    remainder = (len(y) - initial_train_size) % steps
-    
-    if verbose:
-        _backtesting_forecaster_verbose(
-            index_values       = y.index,
-            steps              = steps,
-            initial_train_size = initial_train_size,
-            folds              = folds,
-            remainder          = remainder,
-            refit              = False
-        )
+        if fold[4] is False:
+            # When the model is not fitted, last_window and last_window_exog must 
+            # be updated to include the data needed to make predictions.
+            last_window_y = y.iloc[last_window_start:last_window_end]
+            last_window_exog = exog.iloc[last_window_start:last_window_end] if exog is not None else None 
+        else:
+            # The model is fitted before making predictions. If `fixed_train_size`  
+            # the train size doesn't increase but moves by `steps` in each iteration. 
+            # If `False` the train size increases by `steps` in each  iteration.
+            y_train = y.iloc[train_idx_start:train_idx_end, ]
+            exog_train = exog.iloc[train_idx_start:train_idx_end, ] if exog is not None else None
+            last_window_y = None
+            last_window_exog = None
+            forecaster.fit(y=y_train, exog=exog_train)
 
-    backtest_predictions = []
+        next_window_exog = exog.iloc[test_idx_start:test_idx_end, ] if exog is not None else None
 
-    for i in tqdm(range(folds)) if show_progress else range(folds):
-        # Since the model is only fitted with the initial_train_size, last_window
-        # and next_window_exog must be updated to include the data needed to make
-        # predictions.
-        last_window_start = initial_train_size + steps * (i-1)
-        last_window_end   = initial_train_size + steps * i
-
-        last_window_y    = y.iloc[last_window_start:last_window_end] if i != 0 else None
-        last_window_exog = exog.iloc[last_window_start:last_window_end, ] if exog is not None and i != 0 else None 
-        next_window_exog = exog.iloc[last_window_end:last_window_end + steps, ] if exog is not None else None
-
-        if i == folds - 1: # last fold
-            # If remainder > 0, only the remaining steps need to be predicted
-            steps = steps if remainder == 0 else remainder
+        # After the first fit, ARIMA must use the last windows stored in the model
+        if fold == folds[0]:
+            last_window_y = None
+            last_window_exog = None
 
+        steps = len(range(test_idx_start, test_idx_end))
         if alpha is None and interval is None:
             pred = forecaster.predict(
                        steps            = steps,
                        last_window      = last_window_y,
                        last_window_exog = last_window_exog,
                        exog             = next_window_exog
                    )
@@ -344,17 +239,34 @@
                        steps            = steps,
                        exog             = next_window_exog,
                        alpha            = alpha,
                        interval         = interval,
                        last_window      = last_window_y,
                        last_window_exog = last_window_exog
                    )
+
+        pred = pred.iloc[gap:, ]            
         
-        backtest_predictions.append(pred)
+        return pred
 
+    backtest_predictions = (
+        Parallel(n_jobs=n_jobs)
+        (delayed(_fit_predict_forecaster)
+        (
+            y=y, 
+            exog=exog, 
+            forecaster=forecaster, 
+            alpha=alpha, 
+            interval=interval, 
+            fold=fold, 
+            steps=steps
+        )
+        for fold in folds_tqdm)
+    )
+    
     backtest_predictions = pd.concat(backtest_predictions)
     if isinstance(backtest_predictions, pd.Series):
         backtest_predictions = pd.DataFrame(backtest_predictions)
 
     metrics_values = [m(
                         y_true = y.loc[backtest_predictions.index],
                         y_pred = backtest_predictions['pred']
@@ -373,103 +285,98 @@
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
-    refit: bool=False,
+    refit: Optional[Union[bool, int]]=False,
     alpha: Optional[float]=None,
     interval: Optional[list]=None,
+    n_jobs: Optional[Union[int, str]]='auto',
     verbose: bool=False,
     show_progress: bool=True
 ) -> Tuple[Union[float, list], pd.DataFrame]:
     """
     Backtesting of ForecasterSarimax.
 
-    If `refit` is False, the model is trained only once using the `initial_train_size`
-    first observations. If `refit` is True, the model is trained in each iteration
-    increasing the training set. A copy of the original forecaster is created so 
-    it is not modified during the process.
+    - If `refit` is `False`, the model will be trained only once using the 
+    `initial_train_size` first observations. 
+    - If `refit` is `True`, the model is trained on each iteration, increasing
+    the training set. 
+    - If `refit` is an `integer`, the model will be trained every that number 
+    of iterations.
+    
+    A copy of the original forecaster is created so that it is not modified during 
+    the process.
 
     Parameters
     ----------
     forecaster : ForecasterSarimax
         Forecaster model.
-        
     y : pandas Series
         Training time series.
-    
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-    
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int
         Number of samples in the initial train split. The backtest forecaster is
         trained using the first `initial_train_size` observations.
-    
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration.
-            
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     alpha : float, default `0.05`
         The confidence intervals for the forecasts are (1 - alpha) %.
         If both, `alpha` and `interval` are provided, `alpha` will be used.
-        
     interval : list, default `None`
         Confidence of the prediction interval estimated. The values must be
         symmetric. Sequence of percentiles to compute, which must be between 
         0 and 100 inclusive. For example, interval of 95% should be as 
         `interval = [2.5, 97.5]`. If both, `alpha` and `interval` are 
         provided, `alpha` will be used.
-                  
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**     
     verbose : bool, default `False`
         Print number of folds and index of training and validation sets used 
         for backtesting.
-
     show_progress: bool, default `True`
-        Whether to show a progress bar. Defaults to True.
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
     metrics_value : float, list
         Value(s) of the metric(s).
-
     backtest_predictions : pandas DataFrame
         Value of predictions and their estimated interval if `interval` is not `None`.
-            column pred = predictions.
-            column lower_bound = lower bound of the interval.
-            column upper_bound = upper bound interval of the interval.
+
+            - column pred: predictions.
+            - column lower_bound: lower bound of the interval.
+            - column upper_bound: upper bound of the interval.
     
     """
     
     if type(forecaster).__name__ not in ['ForecasterSarimax']:
         raise TypeError(
             ("`forecaster` must be of type `ForecasterSarimax`, for all other "
              "types of forecasters use the functions available in the other "
@@ -484,54 +391,36 @@
         initial_train_size    = initial_train_size,
         fixed_train_size      = fixed_train_size,
         gap                   = gap,
         allow_incomplete_fold = allow_incomplete_fold,
         refit                 = refit,
         interval              = interval,
         alpha                 = alpha,
+        n_jobs                = n_jobs,
         verbose               = verbose,
         show_progress         = show_progress
     )
     
-    if refit:
-        metrics_values, backtest_predictions = _backtesting_sarimax_refit(
-            forecaster            = forecaster,
-            y                     = y,
-            steps                 = steps,
-            metric                = metric,
-            initial_train_size    = initial_train_size,
-            fixed_train_size      = fixed_train_size,
-            gap                   = gap,
-            allow_incomplete_fold = allow_incomplete_fold,
-            exog                  = exog,
-            alpha                 = alpha,
-            interval              = interval,
-            verbose               = verbose,
-            show_progress         = show_progress
-        )
-    else:
-        if gap != 0 or allow_incomplete_fold is not True:
-            warnings.warn(
-                ("When using `refit=False`, the `gap` and `allow_incomplete_fold`"
-                 "arguments are ignored. Set `refit=True` to used them."), 
-                 IgnoredArgumentWarning
-            )
-
-        metrics_values, backtest_predictions = _backtesting_sarimax_no_refit(
-            forecaster            = forecaster,
-            y                     = y,
-            steps                 = steps,
-            metric                = metric,
-            initial_train_size    = initial_train_size,
-            exog                  = exog,
-            alpha                 = alpha,
-            interval              = interval,
-            verbose               = verbose,
-            show_progress         = show_progress
-        )
+    metrics_values, backtest_predictions = _backtesting_sarimax(
+        forecaster            = forecaster,
+        y                     = y,
+        steps                 = steps,
+        metric                = metric,
+        initial_train_size    = initial_train_size,
+        fixed_train_size      = fixed_train_size,
+        gap                   = gap,
+        allow_incomplete_fold = allow_incomplete_fold,
+        exog                  = exog,
+        refit                 = refit,
+        alpha                 = alpha,
+        interval              = interval,
+        n_jobs                = n_jobs,
+        verbose               = verbose,
+        show_progress         = show_progress
+    )
 
     return metrics_values, backtest_predictions
 
 
 def grid_search_sarimax(
     forecaster,
     y: pd.Series,
@@ -539,87 +428,81 @@
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
-    refit: bool=False,
+    refit: Optional[Union[bool, int]]=False,
     return_best: bool=True,
-    verbose: bool=True
+    n_jobs: Optional[Union[int, str]]='auto',
+    verbose: bool=True,
+    show_progress: bool=True
 ) -> pd.DataFrame:
     """
     Exhaustive search over specified parameter values for a ForecasterSarimax object.
     Validation is done using time series backtesting.
     
     Parameters
     ----------
     forecaster : ForecasterSarimax
         Forcaster model.
-        
     y : pandas Series
         Training time series values. 
-        
     param_grid : dict
         Dictionary with parameters names (`str`) as keys and lists of parameter
         settings to try as values.
-
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int 
         Number of samples in the initial train split. The backtest forecaster is
         trained using the first `initial_train_size` observations.
- 
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-        
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration of backtesting.
-        
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     return_best : bool, default `True`
         Refit the `forecaster` using the best found parameters on the whole data.
-        
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `True`
         Print number of folds used for cv or backtesting.
+    show_progress: bool, default `True`
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
     results : pandas DataFrame
         Results for each combination of parameters.
-            column lags = predictions.
-            column params = lower bound of the interval.
-            column metric = metric value estimated for the combination of parameters.
-            additional n columns with param = value.
+
+            - column params: parameters configuration for each iteration.
+            - column metric: metric value estimated for each iteration.
+            - additional n columns with param = value.
     
     """
 
     param_grid = list(ParameterGrid(param_grid))
 
     results = _evaluate_grid_hyperparameters_sarimax(
         forecaster            = forecaster,
@@ -630,15 +513,17 @@
         initial_train_size    = initial_train_size,
         fixed_train_size      = fixed_train_size,
         gap                   = gap,
         allow_incomplete_fold = allow_incomplete_fold,
         exog                  = exog,
         refit                 = refit,
         return_best           = return_best,
-        verbose               = verbose
+        n_jobs                = n_jobs,
+        verbose               = verbose,
+        show_progress         = show_progress
     )
 
     return results
 
 
 def random_search_sarimax(
     forecaster,
@@ -647,96 +532,88 @@
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
-    refit: bool=False,
+    refit: Optional[Union[bool, int]]=False,
     n_iter: int=10,
     random_state: int=123,
     return_best: bool=True,
-    verbose: bool=True
+    n_jobs: Optional[Union[int, str]]='auto',
+    verbose: bool=True,
+    show_progress: bool=True
 ) -> pd.DataFrame:
     """
-    Random search over specified parameter values or distributions for a Forecaster object.
-    Validation is done using time series backtesting.
+    Random search over specified parameter values or distributions for a Forecaster 
+    object. Validation is done using time series backtesting.
     
     Parameters
     ----------
     forecaster : ForecasterSarimax
         Forcaster model.
-        
     y : pandas Series
         Training time series. 
-        
     param_distributions : dict
         Dictionary with parameters names (`str`) as keys and 
         distributions or lists of parameters to try.
-
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int 
         Number of samples in the initial train split. The backtest forecaster is
         trained using the first `initial_train_size` observations.
- 
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-        
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration of backtesting.
-
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     n_iter : int, default `10`
         Number of parameter settings that are sampled. 
         n_iter trades off runtime vs quality of the solution.
-
     random_state : int, default `123`
         Sets a seed to the random sampling for reproducible output.
-
     return_best : bool, default `True`
         Refit the `forecaster` using the best found parameters on the whole data.
-        
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `True`
         Print number of folds used for cv or backtesting.
+    show_progress: bool, default `True`
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
     results : pandas DataFrame
         Results for each combination of parameters.
-            column lags = predictions.
-            column params = lower bound of the interval.
-            column metric = metric value estimated for the combination of parameters.
-            additional n columns with param = value.
+
+            - column params: parameters configuration for each iteration.
+            - column metric: metric value estimated for each iteration.
+            - additional n columns with param = value.
     
     """
 
     param_grid = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=random_state))
 
     results = _evaluate_grid_hyperparameters_sarimax(
         forecaster            = forecaster,
@@ -747,15 +624,17 @@
         initial_train_size    = initial_train_size,
         fixed_train_size      = fixed_train_size,
         gap                   = gap,
         allow_incomplete_fold = allow_incomplete_fold,
         exog                  = exog,
         refit                 = refit,
         return_best           = return_best,
-        verbose               = verbose
+        n_jobs                = n_jobs,
+        verbose               = verbose,
+        show_progress         = show_progress
     )
 
     return results
 
 
 def _evaluate_grid_hyperparameters_sarimax(
     forecaster,
@@ -764,85 +643,80 @@
     steps: int,
     metric: Union[str, Callable, list],
     initial_train_size: int,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,
-    refit: bool=False,
+    refit: Optional[Union[bool, int]]=False,
     return_best: bool=True,
-    verbose: bool=True
+    n_jobs: Optional[Union[int, str]]='auto',
+    verbose: bool=True,
+    show_progress: bool=True
 ) -> pd.DataFrame:
     """
     Evaluate parameter values for a Forecaster object using time series backtesting.
     
     Parameters
     ----------
     forecaster : ForecasterSarimax
         Forcaster model.
-        
     y : pandas Series
         Training time series values. 
-        
     param_grid : dict
         Dictionary with parameters names (`str`) as keys and lists of parameter
         settings to try as values.
-
     steps : int
         Number of steps to predict.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
         
-        If string:
-            {'mean_squared_error', 'mean_absolute_error',
+            - If `string`: {'mean_squared_error', 'mean_absolute_error',
              'mean_absolute_percentage_error', 'mean_squared_log_error'}
-    
-        If Callable:
-            Function with arguments y_true, y_pred that returns a float.
-
-        If list:
-            List containing multiple strings and/or Callables.
-
+            - If `Callable`: Function with arguments y_true, y_pred that returns 
+            a float.
+            - If `list`: List containing multiple strings and/or Callables.
     initial_train_size : int 
         Number of samples in the initial train split. The backtest forecaster is
         trained using the first `initial_train_size` observations.
- 
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s. Must have the same
         number of observations as `y` and should be aligned so that y[i] is
         regressed on exog[i].
-        
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration of backtesting.
-        
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     return_best : bool, default `True`
         Refit the `forecaster` using the best found parameters on the whole data.
-        
+    n_jobs : int, 'auto', default `'auto'`
+        The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+        set to the number of cores. If 'auto', `n_jobs` is set using the function
+        skforecast.utils.select_n_jobs_backtesting.
+        **New in version 0.9.0**
     verbose : bool, default `True`
         Print number of folds used for cv or backtesting.
+    show_progress: bool, default `True`
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
     results : pandas DataFrame
         Results for each combination of parameters.
-            column params = lower bound of the interval.
-            column metric = metric value estimated for the combination of parameters.
-            additional n columns with param = value.
+
+            - column params: lower bound of the interval.
+            - column metric: metric value estimated for the combination of parameters.
+            - additional n columns with param = value.
 
     """
 
     if return_best and exog is not None and (len(exog) != len(y)):
         raise ValueError(
             (f'`exog` must have same number of samples as `y`. '
              f'length `exog`: ({len(exog)}), length `y`: ({len(y)})')
@@ -855,16 +729,19 @@
     
     if len(metric_dict) != len(metric):
         raise ValueError(
             'When `metric` is a `list`, each metric name must be unique.'
         )
 
     print(f"Number of models compared: {len(param_grid)}.")
+
+    if show_progress:
+        param_grid = tqdm(param_grid, desc='params grid', position=0)
   
-    for params in tqdm(param_grid, desc='params grid', position=0):
+    for params in param_grid:
 
         forecaster.set_params(params)
         metrics_values = backtesting_sarimax(
                             forecaster            = forecaster,
                             y                     = y,
                             steps                 = steps,
                             metric                = metric,
@@ -872,14 +749,15 @@
                             fixed_train_size      = fixed_train_size,
                             gap                   = gap,
                             allow_incomplete_fold = allow_incomplete_fold,
                             exog                  = exog,
                             refit                 = refit,
                             alpha                 = None,
                             interval              = None,
+                            n_jobs                = n_jobs,
                             verbose               = verbose,
                             show_progress         = False
                          )[0]
         warnings.filterwarnings('ignore', category=RuntimeWarning, message= "The forecaster will be fit.*")   
         params_list.append(params)
         for m, m_value in zip(metric, metrics_values):
             m_name = m if isinstance(m, str) else m.__name__
```

### Comparing `skforecast-0.8.1/skforecast/model_selection_sarimax/test/test_backtesting_sarimax.py` & `skforecast-0.9.0/skforecast/model_selection_sarimax/test/test_backtesting_sarimax.py`

 * *Files 5% similar despite different names*

```diff
@@ -46,15 +46,17 @@
             alpha                 = None,
             interval              = None,
             verbose               = False,
             show_progress         = False
         )
 
 
-def test_output_backtesting_sarimax_no_refit_no_exog_no_remainder_with_mocked():
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'],
+                         ids=lambda n: f'n_jobs: {n}')
+def test_output_backtesting_sarimax_no_refit_no_exog_no_remainder_with_mocked(n_jobs):
     """
     Test output of backtesting_sarimax with backtesting mocked, Series y is mocked, no exog, 
     no refit, 12 observations to backtest, steps=3 (no remainder), metric='mean_squared_error'. 
     Mocked done with skforecast 0.7.0.
     """
     forecaster = ForecasterSarimax(regressor=ARIMA(maxiter=10000, trend=None, method='nm', ftol=1e-19,  order=(2,2,2)))
 
@@ -64,14 +66,15 @@
                                         steps              = 3,
                                         metric             = 'mean_squared_error',
                                         initial_train_size = len(y_datetime)-12,
                                         fixed_train_size   = False,
                                         refit              = False,
                                         alpha              = None,
                                         interval           = None,
+                                        n_jobs             = n_jobs,
                                         verbose            = True
                                    )
     
     expected_metric = 0.10564449116792594
     expected_values = np.array([0.6380200425, 0.5532980001, 0.714519703 , 0.8145688855,
                                 0.7383540136, 0.7175581892, 0.3371878999, 0.3404664486,
                                 0.3920279171, 0.6650885959, 0.541608158, 0.5345377188])
@@ -118,32 +121,35 @@
                                         index   = pd.date_range(start='2038', periods=12, freq='A')
                                     )                                                     
 
     assert expected_metric == approx(metric, abs=0.0001)
     pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions, atol=0.0001)
 
 
-def test_output_backtesting_sarimax_yes_refit_no_exog_no_remainder_with_mocked():
-    """
-    Test output of backtesting_sarimax with backtesting mocked, Series y is mocked, no exog, 
-    yes refit, 12 observations to backtest, steps=3 (no remainder), metric='mean_squared_error'. 
-    Mocked done with skforecast 0.7.0.
+@pytest.mark.parametrize("n_jobs", [1, -1, 'auto'],
+                         ids=lambda n: f'n_jobs: {n}')
+def test_output_backtesting_sarimax_yes_refit_no_exog_no_remainder_with_mocked(n_jobs):
+    """
+    Test output of backtesting_sarimax with backtesting mocked, Series y is mocked, 
+    no exog, yes refit, 12 observations to backtest, steps=3 (no remainder), 
+    metric='mean_squared_error'. (Mocked done with skforecast 0.7.0.)
     """
     forecaster = ForecasterSarimax(regressor=ARIMA(maxiter=10000, trend=None, method='nm', ftol=1e-19,  order=(2,2,2)))
 
     metric, backtest_predictions = backtesting_sarimax(
                                         forecaster         = forecaster,
                                         y                  = y_datetime,
                                         steps              = 3,
                                         metric             = 'mean_squared_error',
                                         initial_train_size = len(y_datetime)-12,
                                         fixed_train_size   = False,
                                         refit              = True,
                                         alpha              = None,
                                         interval           = None,
+                                        n_jobs             = n_jobs,
                                         verbose            = False
                                    )
     
     expected_metric = 0.11191023692999214
     expected_values = np.array([0.6380200425, 0.5532980001, 0.714519703 , 0.8236634405,
                                 0.7671966066, 0.7318098972, 0.4753534544, 0.4878701598,
                                 0.4884851128, 0.5211869394, 0.5170146169, 0.516800887 ])
@@ -153,32 +159,35 @@
                           index   = pd.date_range(start='2038', periods=12, freq='A')
                       )                                                     
     print(metric)
     assert expected_metric == approx(metric, abs=0.0001)
     pd.testing.assert_frame_equal(expected_values, backtest_predictions, atol=0.0001)
 
 
-def test_output_backtesting_sarimax_yes_refit_no_exog_remainder_with_mocked():
-    """
-    Test output of backtesting_sarimax with backtesting mocked, Series y is mocked, no exog, 
-    yes refit, 12 observations to backtest, steps=5 (remainder), metric='mean_squared_error'. 
-    Mocked done with skforecast 0.7.0.
+@pytest.mark.parametrize("n_jobs", [1, -1, "auto"],
+                         ids=lambda n: f'n_jobs: {n}')
+def test_output_backtesting_sarimax_yes_refit_no_exog_remainder_with_mocked(n_jobs):
+    """
+    Test output of backtesting_sarimax with backtesting mocked, Series y is mocked, 
+    no exog, yes refit, 12 observations to backtest, steps=5 (remainder), 
+    metric='mean_squared_error'. (Mocked done with skforecast 0.7.0.)
     """
     forecaster = ForecasterSarimax(regressor=ARIMA(maxiter=10000, trend=None, method='nm', ftol=1e-19,  order=(2,2,2)))
 
     metric, backtest_predictions = backtesting_sarimax(
                                         forecaster         = forecaster,
                                         y                  = y_datetime,
                                         steps              = 5,
                                         metric             = 'mean_squared_error',
                                         initial_train_size = len(y_datetime)-12,
                                         fixed_train_size   = False,
                                         refit              = True,
                                         alpha              = None,
                                         interval           = None,
+                                        n_jobs             = n_jobs,
                                         verbose            = False
                                    )
     
     expected_metric = 0.09044168640090938
     expected_values = np.array([0.6380200425, 0.5532980001, 0.714519703 , 0.7305617801,
                                 0.6913258666, 0.4709966524, 0.5031823976, 0.5018454029,
                                 0.5010863298, 0.5036654154, 0.6937025582, 0.5734803045])
```

### Comparing `skforecast-0.8.1/skforecast/model_selection_sarimax/test/test_evaluate_grid_hyperparameters_sarimax.py` & `skforecast-0.9.0/skforecast/model_selection_sarimax/test/test_evaluate_grid_hyperparameters_sarimax.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection_sarimax/test/test_grid_search_sarimax.py` & `skforecast-0.9.0/skforecast/model_selection_sarimax/test/test_grid_search_sarimax.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/model_selection_sarimax/test/test_random_search_sarimax.py` & `skforecast-0.9.0/skforecast/model_selection_sarimax/test/test_random_search_sarimax.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/plot/plot.py` & `skforecast-0.9.0/skforecast/plot/plot.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 ################################################################################
 #                                   Plot                                       #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
  
 from typing import Union, Any, Optional
 import numpy as np
 import pandas as pd
 from ..utils import check_optional_dependency
@@ -30,31 +30,28 @@
 ) -> matplotlib.figure.Figure:
     """
     Parameters
     ----------
     residuals : pandas Series, numpy ndarray, default `None`.
         Values of residuals. If `None`, residuals are calculated internally using
         `y_true` and `y_true`.
-
     y_true : pandas Series, numpy ndarray, default `None`.
         Ground truth (correct) values. Ignored if residuals is not `None`.
-
     y_pred : pandas Series, numpy ndarray, default `None`. 
         Values of predictions. Ignored if residuals is not `None`.
-        
     fig : matplotlib.figure.Figure, default `None`. 
         Pre-existing fig for the plot. Otherwise, call matplotlib.pyplot.figure()
         internally.
-        
     fig_kw : dict
         Other keyword arguments are passed to matplotlib.pyplot.figure()
-        
+
     Returns
     -------
     fig: matplotlib.figure.Figure
+        Matplotlib Figure.
     
     """
     
     if residuals is None and (y_true is None or y_pred is None):
         raise ValueError(
             "If `residuals` argument is None then, `y_true` and `y_pred` must be provided."
         )
@@ -89,25 +86,24 @@
     """
     Heatmap plot of a correlation matrix.
 
     Parameters
     ----------
     corr : pandas DataFrame
         correlation matrix
-
     ax : matplotlib.axes.Axes, default `None`. 
-        Pre-existing ax for the plot. Otherwise, call matplotlib.pyplot.subplots()
+        Pre-existing ax for the plot. Otherwise, call matplotlib.pyplot.subplots() 
         internally.
-
     fig_kw : dict
         Other keyword arguments are passed to matplotlib.pyplot.subplots()
     
     Returns
     -------
     fig: matplotlib.figure.Figure
+        Matplotlib Figure.
 
     """
 
     if ax is None:
         fig, ax = plt.subplots(1, 1, **fig_kw)
     
     sns.heatmap(
@@ -125,34 +121,33 @@
 
 def plot_prediction_distribution(
     bootstrapping_predictions: pd.DataFrame,
     bw_method: Optional[Any]=None,
     **fig_kw
 ) -> matplotlib.figure.Figure:
     """
-    Ridge plot of bootstrapping predictions. This plot is very useful to understand the
-    uncertainty of forecasting predictions.
+    Ridge plot of bootstrapping predictions. This plot is very useful to understand 
+    the uncertainty of forecasting predictions.
 
     Parameters
     ----------
     bootstrapping_predictions : pandas DataFrame
         Bootstrapping predictions created with `Forecaster.predict_bootstrapping`.
-
     bw_method : str, scalar, Callable, default `None`
-        The method used to calculate the estimator bandwidth. This can be 'scott',
-        'silverman', a scalar constant or a Callable. If None (default), 'scott' is used.
-        See scipy.stats.gaussian_kde for more information.
-
+        The method used to calculate the estimator bandwidth. This can be 'scott', 
+        'silverman', a scalar constant or a Callable. If None (default), 'scott' 
+        is used. See scipy.stats.gaussian_kde for more information.
     fig_kw : dict
         All additional keyword arguments are passed to the `pyplot.figure` call.
 
     Returns
-    ------
+    -------
     fig : matplotlib.figure.Figure
-    axes: numpy.ndarray of matplotlib.axes.Axes
+        Matplotlib Figure.
+    
     """
 
     index = bootstrapping_predictions.index.astype(str).to_list()[::-1]
     palette = sns.cubehelix_palette(len(index), rot=-.25, light=.7, reverse=False)
     fig, axs = plt.subplots(len(index), 1, sharex=True, **fig_kw)
     if not isinstance(axs, np.ndarray):
         axs = np.array([axs])
```

### Comparing `skforecast-0.8.1/skforecast/plot/tests/test_plot_residuals.py` & `skforecast-0.9.0/skforecast/plot/tests/test_plot_residuals.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_check_backtesting_input.py` & `skforecast-0.9.0/skforecast/utils/tests/test_check_backtesting_input.py`

 * *Files 9% similar despite different names*

```diff
@@ -377,14 +377,53 @@
             random_state          = 123,
             in_sample_residuals   = True,
             verbose               = False,
             show_progress         = False
         )
 
 
+def test_check_backtesting_input_ValueError_when_series_different_length_initial_train_size():
+    """
+    Test ValueError is raised in check_backtesting_input when series have different 
+    length and initial_train_size is not enough to reach the first non-null value.
+    """
+    forecaster = ForecasterAutoregMultiSeries(
+                     regressor = Ridge(random_state=123),
+                     lags      = 2
+                 )
+    series_nan = series.copy()
+    series_nan['l2'].iloc[:20] = np.nan
+    
+    err_msg = re.escape(
+                    ("All values of series 'l2' are NaN. When working "
+                     "with series of different lengths, make sure that "
+                     "`initial_train_size` has an appropriate value so that "
+                     "all series reach the first non-null value.")
+                )
+    with pytest.raises(ValueError, match = err_msg):
+        check_backtesting_input(
+            forecaster            = forecaster,
+            steps                 = 3,
+            metric                = 'mean_absolute_error',
+            y                     = None,
+            series                = series_nan,
+            initial_train_size    = 15,
+            fixed_train_size      = False,
+            gap                   = 0,
+            allow_incomplete_fold = False,
+            refit                 = False,
+            interval              = None,
+            n_boot                = 500,
+            random_state          = 123,
+            in_sample_residuals   = True,
+            verbose               = False,
+            show_progress         = False
+        )
+
+
 def test_check_backtesting_input_ValueError_ForecasterSarimax_when_initial_train_size_is_None():
     """
     Test ValueError is raised in check_backtesting_input when initial_train_size 
     is None with a ForecasterSarimax.
     """
     forecaster = ForecasterSarimax(regressor=ARIMA(order=(1,1,1)))
 
@@ -487,47 +526,78 @@
             alpha                 = None,
             n_boot                = 500,
             random_state          = 123,
             in_sample_residuals   = True,
             verbose               = False,
             show_progress         = False
         )
+        
+
+@pytest.mark.parametrize("refit", 
+                         ['not_bool_int', -1, 1.5], 
+                         ids = lambda value : f'refit: {value}' )
+def test_check_backtesting_input_TypeError_when_refit_not_bool_or_int(refit):
+    """
+    Test TypeError is raised in check_backtesting_input when `refit` is not a 
+    boolean or a integer greater than 0.
+    """
+    forecaster = ForecasterAutoreg(
+                    regressor = Ridge(random_state=123),
+                    lags      = 2
+                 )
+    
+    err_msg = re.escape(f"`refit` must be a boolean or an integer greater than 0. Got {refit}.")
+    with pytest.raises(TypeError, match = err_msg):
+        check_backtesting_input(
+            forecaster            = forecaster,
+            steps                 = 3,
+            metric                = 'mean_absolute_error',
+            y                     = y,
+            series                = series,
+            initial_train_size    = len(y[:-12]),
+            refit                 = refit,
+            gap                   = 0,
+            interval              = None,
+            alpha                 = None,
+            n_boot                = 500,
+            random_state          = 123,
+        )
 
 
 @pytest.mark.parametrize("boolean_argument", 
-                         ['fixed_train_size', 'allow_incomplete_fold', 'refit',
+                         ['fixed_train_size', 'allow_incomplete_fold', 
                           'in_sample_residuals', 'verbose', 'show_progress'], 
                          ids = lambda argument : f'{argument}' )
 def test_check_backtesting_input_TypeError_when_boolean_arguments_not_bool(boolean_argument):
     """
     Test TypeError is raised in check_backtesting_input when boolean arguments 
     are not boolean.
     """
     forecaster = ForecasterAutoreg(
                     regressor = Ridge(random_state=123),
                     lags      = 2
                  )
     
     boolean_arguments = {'fixed_train_size': False,
                          'allow_incomplete_fold': False,
-                         'refit': False,
                          'in_sample_residuals': False,
                          'verbose': False,
                          'show_progress': False}
     boolean_arguments[boolean_argument] = 'not_bool'
     
     err_msg = re.escape(f"`{boolean_argument}` must be a boolean: `True`, `False`.")
     with pytest.raises(TypeError, match = err_msg):
         check_backtesting_input(
             forecaster            = forecaster,
             steps                 = 3,
             metric                = 'mean_absolute_error',
             y                     = y,
             series                = series,
             initial_train_size    = len(y[:-12]),
+            refit                 = False,
             gap                   = 0,
             interval              = None,
             alpha                 = None,
             n_boot                = 500,
             random_state          = 123,
             **boolean_arguments
         )
@@ -571,14 +641,52 @@
             in_sample_residuals   = True,
             verbose               = False,
             show_progress         = False,
             **integer_arguments
         )
 
 
+@pytest.mark.parametrize("n_jobs", 
+                         [1.0, 'not_int_auto'], 
+                         ids = lambda value : f'n_jobs: {value}')
+def test_check_backtesting_input_TypeError_when_n_jobs_not_int_or_auto(n_jobs):
+    """
+    Test TypeError is raised in check_backtesting_input when n_jobs  
+    is not an integer or 'auto'.
+    """
+    forecaster = ForecasterAutoreg(
+                     regressor = Ridge(random_state=123),
+                     lags      = 2
+                 )
+    
+    err_msg = re.escape(
+            (f"`n_jobs` must be an integer or `'auto'`. Got {n_jobs}.")
+        )
+    with pytest.raises(TypeError, match = err_msg):
+        check_backtesting_input(
+            forecaster            = forecaster,
+            steps                 = 3,
+            metric                = 'mean_absolute_error',
+            y                     = y,
+            series                = None,
+            initial_train_size    = len(y[:-12]),
+            fixed_train_size      = False,
+            gap                   = 0,
+            allow_incomplete_fold = False,
+            refit                 = False,
+            interval              = None,
+            n_boot                = 500,
+            random_state          = 123,
+            in_sample_residuals   = True,
+            n_jobs                = n_jobs,
+            verbose               = False,
+            show_progress         = False
+        )
+
+
 @pytest.mark.parametrize("forecaster", 
                          [ForecasterAutoreg(regressor=Ridge(), lags=2),
                           ForecasterAutoregMultiSeries(regressor=Ridge(), lags=2)], 
                          ids = lambda fr : f'forecaster: {type(fr).__name__}' )
 def test_check_backtesting_input_ValueError_when_not_enough_data_to_create_a_fold(forecaster):
     """
     Test ValueError is raised in check_backtesting_input when there is not enough
```

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_check_exog.py` & `skforecast-0.9.0/skforecast/utils/tests/test_check_exog.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_check_exog_dtypes.py` & `skforecast-0.9.0/skforecast/utils/tests/test_check_exog_dtypes.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_check_interval.py` & `skforecast-0.9.0/skforecast/utils/tests/test_check_interval.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_check_optional_dependency.py` & `skforecast-0.9.0/skforecast/utils/tests/test_check_optional_dependency.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_check_predict_input.py` & `skforecast-0.9.0/skforecast/utils/tests/test_check_predict_input.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_check_select_fit_kwargs.py` & `skforecast-0.9.0/skforecast/utils/tests/test_check_select_fit_kwargs.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_check_y.py` & `skforecast-0.9.0/skforecast/utils/tests/test_check_y.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_exog_to_direct.py` & `skforecast-0.9.0/skforecast/utils/tests/test_exog_to_direct.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_exog_to_direct_numpy.py` & `skforecast-0.9.0/skforecast/utils/tests/test_exog_to_direct_numpy.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_expand_index.py` & `skforecast-0.9.0/skforecast/utils/tests/test_expand_index.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_initialize_lags.py` & `skforecast-0.9.0/skforecast/utils/tests/test_initialize_lags.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_initialize_weights.py` & `skforecast-0.9.0/skforecast/utils/tests/test_initialize_weights.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_multivariate_time_series_corr.py` & `skforecast-0.9.0/skforecast/utils/tests/test_multivariate_time_series_corr.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_preproces_exog.py` & `skforecast-0.9.0/skforecast/utils/tests/test_preproces_exog.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_preproces_last_window.py` & `skforecast-0.9.0/skforecast/utils/tests/test_preproces_last_window.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_preproces_y.py` & `skforecast-0.9.0/skforecast/utils/tests/test_preproces_y.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_save_load_forecaster.py` & `skforecast-0.9.0/skforecast/utils/tests/test_save_load_forecaster.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_transform_dataframe.py` & `skforecast-0.9.0/skforecast/utils/tests/test_transform_dataframe.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/tests/test_transform_series.py` & `skforecast-0.9.0/skforecast/utils/tests/test_transform_series.py`

 * *Files identical despite different names*

### Comparing `skforecast-0.8.1/skforecast/utils/utils.py` & `skforecast-0.9.0/skforecast/utils/utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 ################################################################################
 #                             skforecast.utils                                 #
 #                                                                              #
 # This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #
-# under a Creative Commons Attribution 4.0 International License.              #
+# under the BSD 3-Clause License.                                              #
 ################################################################################
 # coding=utf-8
 
 from typing import Union, Any, Optional, Tuple, Callable
 import warnings
 import importlib
 import joblib
@@ -20,37 +20,38 @@
 
 from ..exceptions import MissingValuesExogWarning
 from ..exceptions import DataTypeWarning
 from ..exceptions import IgnoredArgumentWarning
 
 optional_dependencies = {
     "sarimax": ['pmdarima>=2.0, <2.1'],
-    "plotting": ['matplotlib>=3.3, <3.8', 'seaborn>=0.11, <0.13', 'statsmodels>=0.12, <0.14']
+    "plotting": ['matplotlib>=3.3, <3.8', 
+                 'seaborn>=0.11, <0.13', 
+                 'statsmodels>=0.12, <0.15']
 }
 
 
 def initialize_lags(
     forecaster_name: str,
     lags: Any
 ) -> np.ndarray:
     """
     Check lags argument input and generate the corresponding numpy ndarray.
-    
+
     Parameters
     ----------
     forecaster_name : str
         Forecaster name. ForecasterAutoreg, ForecasterAutoregCustom, 
         ForecasterAutoregDirect, ForecasterAutoregMultiSeries, 
-        ForecasterAutoregMultiVariate.
-
+        ForecasterAutoregMultiSeriesCustom, ForecasterAutoregMultiVariate.
     lags : Any
         Lags used as predictors.
-        
+
     Returns
-    ----------
+    -------
     lags : numpy ndarray
         Lags used as predictors.
     
     """
 
     if isinstance(lags, int) and lags < 1:
         raise ValueError("Minimum value of lags allowed is 1.")
@@ -85,45 +86,39 @@
 
 
 def initialize_weights(
     forecaster_name: str,
     regressor: object,
     weight_func: Union[Callable, dict],
     series_weights: dict
-) -> Tuple[Union[Callable, dict], Union[Callable, dict], dict]:
+) -> Tuple[Union[Callable, dict], Union[str, dict], dict]:
     """
     Check weights arguments, `weight_func` and `series_weights` for the different 
     forecasters. Create `source_code_weight_func`, source code of the custom 
     function(s) used to create weights.
     
     Parameters
     ----------
     forecaster_name : str
         Forecaster name. ForecasterAutoreg, ForecasterAutoregCustom, 
         ForecasterAutoregDirect, ForecasterAutoregMultiSeries, 
-        ForecasterAutoregMultiVariate, ForecasterAutoregMultiSeriesCustom.
-
+        ForecasterAutoregMultiSeriesCustom, ForecasterAutoregMultiVariate.
     regressor : regressor or pipeline compatible with the scikit-learn API
         Regressor of the forecaster.
-
     weight_func : Callable, dict
         Argument `weight_func` of the forecaster.
-
     series_weights : dict
         Argument `series_weights` of the forecaster.
-        
-        
+
     Returns
-    ----------
+    -------
     weight_func : Callable, dict
         Argument `weight_func` of the forecaster.
-
     source_code_weight_func : str, dict
         Argument `source_code_weight_func` of the forecaster.
-
     series_weights : dict
         Argument `series_weights` of the forecaster.
     
     """
 
     source_code_weight_func = None
 
@@ -181,18 +176,16 @@
     Check if `fit_kwargs` is a dict and select only the keys that are used by
     the `fit` method of the regressor.
 
     Parameters
     ----------
     regressor : object
         Regressor object.
-
     fit_kwargs : dict, default `None`
-        Dictionary with the arguments to pass to the `fit' method of the 
-        forecaster.
+        Dictionary with the arguments to pass to the `fit' method of the forecaster.
 
     Returns
     -------
     fit_kwargs : dict
         Dictionary with the arguments to be passed to the `fit` method of the 
         regressor after removing the unused keys.
     
@@ -235,20 +228,20 @@
 def check_y(
     y: Any
 ) -> None:
     """
     Raise Exception if `y` is not pandas Series or if it has missing values.
     
     Parameters
-    ----------        
+    ----------
     y : Any
         Time series values.
-        
+    
     Returns
-    ----------
+    -------
     None
     
     """
     
     if not isinstance(y, pd.Series):
         raise TypeError("`y` must be a pandas Series.")
         
@@ -263,50 +256,50 @@
     allow_nan: bool=True
 ) -> None:
     """
     Raise Exception if `exog` is not pandas Series or pandas DataFrame.
     If `allow_nan = True`, issue a warning if `exog` contains NaN values.
     
     Parameters
-    ----------        
-    exog :  Any
+    ----------
+    exog : Any
         Exogenous variable/s included as predictor/s.
-    allow_nan: bool, default True
+    allow_nan : bool, default `True`
         If True, allows the presence of NaN values in `exog`. If False (default),
         issue a warning if `exog` contains NaN values.
 
     Returns
-    ----------
+    -------
     None
 
     """
-        
+    
     if not isinstance(exog, (pd.Series, pd.DataFrame)):
         raise TypeError("`exog` must be a pandas Series or DataFrame.")
 
     if not allow_nan:
         if exog.isnull().any().any():
             warnings.warn(
                 ("`exog` has missing values. Most machine learning models do not allow "
                  "missing values. Fitting the forecaster may fail."), 
                  MissingValuesExogWarning
             )
-         
+    
     return
 
 
 def get_exog_dtypes(
     exog: Union[pd.DataFrame, pd.Series]
 ) -> dict:
     """
     Store dtypes of `exog`.
 
     Parameters
     ----------
-    exog :  pandas DataFrame, pandas Series
+    exog : pandas DataFrame, pandas Series
         Exogenous variable/s included as predictor/s.
 
     Returns
     -------
     exog_dtypes : dict
         Dictionary with the dtypes in `exog`.
     
@@ -326,23 +319,24 @@
     """
     Raise Exception if `exog` has categorical columns with non integer values.
     This is needed when using machine learning regressors that allow categorical
     features.
     Issue a Warning if `exog` has columns that are not `init`, `float`, or `category`.
     
     Parameters
-    ----------        
-    exog :  pandas DataFrame, pandas Series
+    ----------
+    exog : pandas DataFrame, pandas Series
         Exogenous variable/s included as predictor/s.
 
     Returns
-    ----------
+    -------
     None
 
     """
+
     check_exog(exog=exog, allow_nan=False)
 
     if isinstance(exog, pd.DataFrame):
         if not exog.select_dtypes(exclude=[np.number, 'category']).columns.empty:
             warnings.warn(
                 ("`exog` may contain only `int`, `float` or `category` dtypes. Most "
                  "machine learning models do not allow other types of values. "
@@ -385,17 +379,20 @@
 
     Parameters
     ----------
     interval : list, default `None`
         Confidence of the prediction interval estimated. Sequence of percentiles
         to compute, which must be between 0 and 100 inclusive. For example, 
         interval of 95% should be as `interval = [2.5, 97.5]`.
-
     alpha : float, default `None`
         The confidence intervals used in ForecasterSarimax are (1 - alpha) %.
+
+    Returns
+    -------
+    None
     
     """
 
     if interval is not None:
         if not isinstance(interval, list):
             raise TypeError(
                 ("`interval` must be a `list`. For example, interval of 95% "
@@ -465,73 +462,61 @@
     trained.
 
     Parameters
     ----------
     forecaster_name : str
         Forecaster name. ForecasterAutoreg, ForecasterAutoregCustom, 
         ForecasterAutoregDirect, ForecasterAutoregMultiSeries, 
-        ForecasterAutoregMultiVariate, ForecasterAutoregMultiSeriesCustom.
-
+        ForecasterAutoregMultiSeriesCustom, ForecasterAutoregMultiVariate.
     steps : int, list
         Number of future steps predicted.
-
-    fitted: Bool
+    fitted: bool
         Tag to identify if the regressor has been fitted (trained).
-
     included_exog : bool
         If the forecaster has been trained using exogenous variable/s.
-
     index_type : type
         Type of index of the input used in training.
-
     index_freq : str
         Frequency of Index of the input used in training.
-
     window_size: int
-        Size of the window needed to create the predictors. It is equal to
+        Size of the window needed to create the predictors. It is equal to 
         `max_lag`.
-
     last_window : pandas Series, pandas DataFrame, default `None`
         Values of the series used to create the predictors (lags) need in the 
         first iteration of prediction (t + 1).
-
     last_window_exog : pandas Series, pandas DataFrame, default `None`
         Values of the exogenous variables aligned with `last_window` in 
         ForecasterSarimax predictions.
-
     exog : pandas Series, pandas DataFrame, default `None`
         Exogenous variable/s included as predictor/s.
-
     exog_type : type, default `None`
         Type of exogenous variable/s used in training.
-        
     exog_col_names : list, default `None`
         Names of columns of `exog` if `exog` used in training was a pandas
         DataFrame.
-
     interval : list, default `None`
         Confidence of the prediction interval estimated. Sequence of percentiles
         to compute, which must be between 0 and 100 inclusive. For example, 
         interval of 95% should be as `interval = [2.5, 97.5]`.
-
     alpha : float, default `None`
         The confidence intervals used in ForecasterSarimax are (1 - alpha) %.
-
     max_steps: int, default `None`
         Maximum number of steps allowed (`ForecasterAutoregDirect` and 
         `ForecasterAutoregMultiVariate`).
-            
     levels : str, list, default `None`
         Time series to be predicted (`ForecasterAutoregMultiSeries` and
         `ForecasterAutoregMultiSeriesCustom`).
-
     series_col_names : list, default `None`
         Names of the columns used during fit (`ForecasterAutoregMultiSeries`, 
-        `ForecasterAutoregMultiVariate` and `ForecasterAutoregMultiSeriesCustom`).
-    
+        `ForecasterAutoregMultiSeriesCustom` and `ForecasterAutoregMultiVariate`).
+
+    Returns
+    -------
+    None
+
     """
 
     if not fitted:
         raise sklearn.exceptions.NotFittedError(
             ("This Forecaster instance is not fitted yet. Call `fit` with "
              "appropriate arguments before using predict.")
         )
@@ -554,18 +539,20 @@
                  f"the value of steps defined when initializing the forecaster. "
                  f"Got {max(steps)}, but the maximum is {max_steps}.")
             )
 
     if interval is not None or alpha is not None:
         check_interval(interval=interval, alpha=alpha)
     
-    if forecaster_name in ['ForecasterAutoregMultiSeries', 'ForecasterAutoregMultiSeriesCustom']:
+    if forecaster_name in ['ForecasterAutoregMultiSeries', 
+                           'ForecasterAutoregMultiSeriesCustom']:
         if levels is not None and not isinstance(levels, (str, list)):
             raise TypeError(
-                "`levels` must be a `list` of column names, a `str` of a column name or `None`."
+                ("`levels` must be a `list` of column names, a `str` of a "
+                 "column name or `None`.")
             )
         if len(set(levels) - set(series_col_names)) != 0:
             raise ValueError(
                 f"`levels` must be in `series_col_names` : {series_col_names}."
             )
 
     if exog is None and included_exog:
@@ -578,25 +565,28 @@
         raise ValueError(
             ("Forecaster trained without exogenous variable/s. "
              "`exog` must be `None` when predicting.")
         )
         
     # Checks last_window
     # Check last_window type (pd.Series or pd.DataFrame according to forecaster)
-    if forecaster_name in ['ForecasterAutoregMultiSeries', 'ForecasterAutoregMultiVariate',
-                           'ForecasterAutoregMultiSeriesCustom']:
+    if forecaster_name in ['ForecasterAutoregMultiSeries', 
+                           'ForecasterAutoregMultiSeriesCustom',
+                           'ForecasterAutoregMultiVariate']:
         if not isinstance(last_window, pd.DataFrame):
             raise TypeError(
                 f"`last_window` must be a pandas DataFrame. Got {type(last_window)}."
             )
         
-        if forecaster_name in ['ForecasterAutoregMultiSeries', 'ForecasterAutoregMultiSeriesCustom'] and \
+        if forecaster_name in ['ForecasterAutoregMultiSeries', 
+                               'ForecasterAutoregMultiSeriesCustom'] and \
             len(set(levels) - set(last_window.columns)) != 0:
             raise ValueError(
-                (f"`last_window` must contain a column(s) named as the level(s) to be predicted.\n"
+                (f"`last_window` must contain a column(s) named as the level(s) "
+                 f"to be predicted.\n"
                  f"    `levels` : {levels}.\n"
                  f"    `last_window` columns : {list(last_window.columns)}.")
             )
         
         if forecaster_name == 'ForecasterAutoregMultiVariate' and \
             (series_col_names != list(last_window.columns)):
             raise ValueError(
@@ -747,41 +737,40 @@
                          f"Got {last_window_exog.columns.to_list()}.") 
                     )
 
     return
 
 
 def preprocess_y(
-    y: pd.Series,
+    y: Union[pd.Series, pd.DataFrame],
     return_values: bool=True
 ) -> Tuple[Union[None, np.ndarray], pd.Index]:
     """
-    Returns values and index of series separately. Index is overwritten 
+    Return values and index of series separately. Index is overwritten 
     according to the next rules:
-        If index is of type DatetimeIndex and has frequency, nothing is 
-        changed.
-        If index is of type RangeIndex, nothing is changed.
-        If index is of type DatetimeIndex but has no frequency, a 
-        RangeIndex is created.
-        If index is not of type DatetimeIndex, a RangeIndex is created.
+    
+    - If index is of type `DatetimeIndex` and has frequency, nothing is 
+    changed.
+    - If index is of type `RangeIndex`, nothing is changed.
+    - If index is of type `DatetimeIndex` but has no frequency, a 
+    `RangeIndex` is created.
+    - If index is not of type `DatetimeIndex`, a `RangeIndex` is created.
     
     Parameters
-    ----------        
-    y : pandas Series
+    ----------
+    y : pandas Series, pandas DataFrame
         Time series.
-
     return_values : bool, default `True`
         If `True` return the values of `y` as numpy ndarray. This option is 
         intended to avoid copying data when it is not necessary.
 
-    Returns 
+    Returns
     -------
     y_values : None, numpy ndarray
         Numpy array with values of `y`.
-
     y_index : pandas Index
         Index of `y` modified according to the rules.
     
     """
     
     if isinstance(y.index, pd.DatetimeIndex) and y.index.freq is not None:
         y_index = y.index
@@ -814,37 +803,36 @@
 
 
 def preprocess_last_window(
     last_window: Union[pd.Series, pd.DataFrame],
     return_values: bool=True
  ) -> Tuple[np.ndarray, pd.Index]:
     """
-    Returns values and index of series separately. Index is overwritten 
+    Return values and index of series separately. Index is overwritten 
     according to the next rules:
-        If index is of type DatetimeIndex and has frequency, nothing is 
-        changed.
-        If index is of type RangeIndex, nothing is changed.
-        If index is of type DatetimeIndex but has no frequency, a 
-        RangeIndex is created.
-        If index is not of type DatetimeIndex, a RangeIndex is created.
+    
+    - If index is of type `DatetimeIndex` and has frequency, nothing is 
+    changed.
+    - If index is of type `RangeIndex`, nothing is changed.
+    - If index is of type `DatetimeIndex` but has no frequency, a 
+    `RangeIndex` is created.
+    - If index is not of type `DatetimeIndex`, a `RangeIndex` is created.
     
     Parameters
-    ----------        
+    ----------
     last_window : pandas Series, pandas DataFrame
         Time series values.
-
     return_values : bool, default `True`
         If `True` return the values of `last_window` as numpy ndarray. This option 
         is intended to avoid copying data when it is not necessary.
 
-    Returns 
+    Returns
     -------
     last_window_values : numpy ndarray
         Numpy array with values of `last_window`.
-
     last_window_index : pandas Index
         Index of `last_window` modified according to the rules.
     
     """
     
     if isinstance(last_window.index, pd.DatetimeIndex) and last_window.index.freq is not None:
         last_window_index = last_window.index
@@ -877,37 +865,36 @@
 
 
 def preprocess_exog(
     exog: Union[pd.Series, pd.DataFrame],
     return_values: bool=True
 ) -> Tuple[Union[None, np.ndarray], pd.Index]:
     """
-    Returns values and index of series or data frame separately. Index is
+    Return values and index of series or data frame separately. Index is
     overwritten  according to the next rules:
-        If index is of type DatetimeIndex and has frequency, nothing is 
-        changed.
-        If index is of type RangeIndex, nothing is changed.
-        If index is of type DatetimeIndex but has no frequency, a 
-        RangeIndex is created.
-        If index is not of type DatetimeIndex, a RangeIndex is created.
+    
+    - If index is of type `DatetimeIndex` and has frequency, nothing is 
+    changed.
+    - If index is of type `RangeIndex`, nothing is changed.
+    - If index is of type `DatetimeIndex` but has no frequency, a 
+    `RangeIndex` is created.
+    - If index is not of type `DatetimeIndex`, a `RangeIndex` is created.
 
     Parameters
-    ----------        
+    ----------
     exog : pandas Series, pandas DataFrame
         Exogenous variables.
-
     return_values : bool, default `True`
         If `True` return the values of `exog` as numpy ndarray. This option is 
         intended to avoid copying data when it is not necessary.
 
-    Returns 
+    Returns
     -------
     exog_values : None, numpy ndarray
         Numpy array with values of `exog`.
-
     exog_index : pandas Index
         Index of `exog` modified according to the rules.
     
     """
     
     if isinstance(exog.index, pd.DatetimeIndex) and exog.index.freq is not None:
         exog_index = exog.index
@@ -941,33 +928,35 @@
     
 
 def cast_exog_dtypes(
     exog: Union[pd.Series, pd.DataFrame],
     exog_dtypes: dict,
 ) -> Union[pd.Series, pd.DataFrame]: # pragma: no cover
     """
-    Cast `exog` to a specified types.
-    If `exog` is a pandas Series, `exog_dtypes` must be a dict with a single value.
-    If `exog_dtypes` is `category` but the current type of `exog` is `float`, then
-    the type is cast to `int` and then to `category`. This is done because, for
-    a forecaster to accept a categorical exog, it must contain only integer values.
-    Due to the internal modifications of numpy, the values may be casted to `float`,
-    so they have to be re-converted to `int`.
+    Cast `exog` to a specified types. This is done because, for a forecaster to 
+    accept a categorical exog, it must contain only integer values. Due to the 
+    internal modifications of numpy, the values may be casted to `float`, so 
+    they have to be re-converted to `int`.
+
+    - If `exog` is a pandas Series, `exog_dtypes` must be a dict with a 
+    single value.
+    - If `exog_dtypes` is `category` but the current type of `exog` is `float`, 
+    then the type is cast to `int` and then to `category`. 
 
     Parameters
     ----------
     exog : pandas Series, pandas DataFrame
         Exogenous variables.
-    
     exog_dtypes: dict
         Dictionary with name and type of the series or data frame columns.
 
-    Returns 
+    Returns
     -------
-    exog
+    exog : pandas Series, pandas DataFrame
+        Exogenous variables casted to the indicated dtypes.
 
     """
 
     # Remove keys from exog_dtypes not in exog.columns
     exog_dtypes = {k:v for k, v in exog_dtypes.items() if k in exog.columns}
     
     if isinstance(exog, pd.Series) and exog.dtypes != list(exog_dtypes.values())[0]:
@@ -991,19 +980,18 @@
     Transforms `exog` to a pandas DataFrame with the shape needed for Direct
     forecasting.
     
     Parameters
     ----------
     exog : pandas Series, pandas DataFrame
         Exogenous variables.
-
     steps : int.
         Number of steps that will be predicted using exog.
 
-    Returns 
+    Returns
     -------
     exog_transformed : pandas DataFrame
         Exogenous variables transformed.
     
     """
 
     if not isinstance(exog, (pd.Series, pd.DataFrame)):
@@ -1015,15 +1003,16 @@
     n_rows = len(exog)
     exog_idx = exog.index
     exog_transformed = []
 
     for i in range(steps):
         exog_column_transformed = exog.iloc[i : n_rows - (steps - 1 - i), ]
         exog_column_transformed.index = pd.RangeIndex(len(exog_column_transformed))
-        exog_column_transformed.columns = [f"{col}_step_{i+1}" for col in exog_column_transformed.columns]
+        exog_column_transformed.columns = [f"{col}_step_{i+1}" 
+                                           for col in exog_column_transformed.columns]
         exog_transformed.append(exog_column_transformed)
 
     if len(exog_transformed) > 1:
         exog_transformed = pd.concat(exog_transformed, axis=1, copy=False)
     else:
         exog_transformed = exog_column_transformed
 
@@ -1033,26 +1022,25 @@
 
 
 def exog_to_direct_numpy(
     exog: np.ndarray,
     steps: int
 )-> np.ndarray:
     """
-    Transforms `exog` to `np.ndarray` with the shape needed for Direct
+    Transforms `exog` to numpy ndarray with the shape needed for Direct
     forecasting.
     
     Parameters
-    ----------        
+    ----------
     exog : numpy ndarray, shape(samples,)
         Exogenous variables.
-
     steps : int.
         Number of steps that will be predicted using exog.
 
-    Returns 
+    Returns
     -------
     exog_transformed : numpy ndarray
         Exogenous variables transformed.
 
     """
 
     if not isinstance(exog, np.ndarray):
@@ -1080,33 +1068,32 @@
     index: Union[pd.Index, None], 
     steps: int
 ) -> pd.Index:
     """
     Create a new index of length `steps` starting at the end of the index.
     
     Parameters
-    ----------        
-    index : pd.Index, None
-        Index of last window.
-    
+    ----------
+    index : pandas Index, None
+        Original index.
     steps : int
         Number of steps to expand.
 
-    Returns 
+    Returns
     -------
-    new_index : pd.Index
+    new_index : pandas Index
         New index.
 
     """
     
     if isinstance(index, pd.Index):
         
         if isinstance(index, pd.DatetimeIndex):
             new_index = pd.date_range(
-                            index[-1] + index.freq,
+                            start   = index[-1] + index.freq,
                             periods = steps,
                             freq    = index.freq
                         )
         elif isinstance(index, pd.RangeIndex):
             new_index = pd.RangeIndex(
                             start = index[-1] + 1,
                             stop  = index[-1] + 1 + steps
@@ -1124,31 +1111,28 @@
     series: pd.Series,
     transformer,
     fit: bool=False,
     inverse_transform: bool=False
 ) -> Union[pd.Series, pd.DataFrame]:
     """      
     Transform raw values of pandas Series with a scikit-learn alike transformer
-    (preprocessor). The transformer used must have the following methods: fit, transform,
-    fit_transform and inverse_transform. ColumnTransformers are not allowed since they
-    do not have inverse_transform method.
+    (preprocessor). The transformer used must have the following methods: fit, 
+    transform, fit_transform and inverse_transform. ColumnTransformers are not 
+    allowed since they do not have inverse_transform method.
 
     Parameters
     ----------
     series : pandas Series
         Series to be transformed.
-
     transformer : scikit-learn alike transformer (preprocessor).
         scikit-learn alike transformer (preprocessor) with methods: fit, transform,
         fit_transform and inverse_transform. ColumnTransformers are not allowed 
         since they do not have inverse_transform method.
-
     fit : bool, default `False`
         Train the transformer before applying it.
-
     inverse_transform : bool, default `False`
         Transform back the data to the original representation.
 
     Returns
     -------
     series_transformed : pandas Series, pandas DataFrame
         Transformed Series. Depending on the transformer used, the output may 
@@ -1215,31 +1199,28 @@
     Transform raw values of pandas DataFrame with a scikit-learn alike
     transformer, preprocessor or ColumnTransformer. `inverse_transform` is not 
     available when using ColumnTransformers.
 
     Parameters
     ----------
     df : pandas DataFrame
-        Pandas DataFrame to be transformed.
-
+        DataFrame to be transformed.
     transformer : scikit-learn alike transformer, preprocessor or ColumnTransformer.
         scikit-learn alike transformer, preprocessor or ColumnTransformer.
-
     fit : bool, default `False`
         Train the transformer before applying it.
-
     inverse_transform : bool, default `False`
         Transform back the data to the original representation. This is not available
         when using transformers of class scikit-learn ColumnTransformers.
 
     Returns
     -------
     df_transformed : pandas DataFrame
         Transformed DataFrame.
-    
+
     """
     
     if not isinstance(df, pd.DataFrame):
         raise TypeError(
             f"`df` argument must be a pandas DataFrame. Got {type(df)}"
         )
 
@@ -1285,24 +1266,22 @@
     verbose: bool=True
 ) -> None:
     """
     Save forecaster model using joblib.
 
     Parameters
     ----------
-    forecaster: forecaster object from skforecast library.
+    forecaster: forecaster
         Forecaster created with skforecast library.
-
     file_name: str
         File name given to the object.
-        
     verbose: bool, default `True`
         Print summary about the forecaster saved.
 
-    Returns 
+    Returns
     -------
     None
 
     """
 
     joblib.dump(forecaster, filename=file_name)
 
@@ -1317,21 +1296,20 @@
     """
     Load forecaster model using joblib.
 
     Parameters
     ----------
     file_name: str
         Object file name.
-
     verbose: bool, default `True`
         Print summary about the forecaster loaded.
 
-    Returns 
+    Returns
     -------
-    Forecaster
+    forecaster: forecaster
         Forecaster created with skforecast library.
     
     """
 
     forecaster = joblib.load(filename=file_name)
 
     if verbose:
@@ -1341,30 +1319,28 @@
 
 
 def _find_optional_dependency(
     package_name: str, 
     optional_dependencies: dict=optional_dependencies
 ) -> Tuple[str, str]:
     """
-    Find if a package is an optional dependency. If true, find the version and 
+    Find if a package is an optional dependency. If True, find the version and 
     the extension it belongs to.
 
     Parameters
     ----------
     package_name : str
         Name of the package to check.
-
-    optional_dependencies : dict, default optional_dependencies
+    optional_dependencies : dict, default `optional_dependencies`
         Skforecast optional dependencies.
 
-    Return
-    ------
+    Returns
+    -------
     extra: str
         Name of the extra extension where the optional dependency is needed.
-
     package_version: srt
         Name and versions of the dependency.
 
     """
 
     for extra, packages in optional_dependencies.items():
         package_version = [package for package in packages if package_name in package]
@@ -1379,14 +1355,18 @@
     Check if an optional dependency is installed, if not raise an ImportError  
     with installation instructions.
 
     Parameters
     ----------
     package_name : str
         Name of the package to check.
+
+    Returns
+    -------
+    None
     
     """
 
     if importlib.util.find_spec(package_name) is None:
         try:
             extra, package_version = _find_optional_dependency(package_name=package_name)
             msg = (
@@ -1410,26 +1390,23 @@
     Compute correlation between a time_series and the lagged values of other 
     time series. 
 
     Parameters
     ----------
     time_series : pandas Series
         Target time series.
-
     other : pandas DataFrame
         Time series whose lagged values are correlated to `time_series`.
-
-    lags : Union[int, list, numpy ndarray]
+    lags : int, list, numpy ndarray
         Lags to be included in the correlation analysis.
-    
     method : str, default 'pearson'
-        - pearson : standard correlation coefficient.
-        - kendall : Kendall Tau correlation coefficient.
-        - spearman : Spearman rank correlation.
-        
+        - 'pearson': standard correlation coefficient.
+        - 'kendall': Kendall Tau correlation coefficient.
+        - 'spearman': Spearman rank correlation.
+
     Returns
     -------
     corr : pandas DataFrame
         Correlation values.
 
     """
 
@@ -1465,96 +1442,88 @@
     metric: Union[str, Callable, list],
     y: Optional[pd.Series]=None,
     series: Optional[pd.DataFrame]=None,
     initial_train_size: Optional[int]=None,
     fixed_train_size: bool=True,
     gap: int=0,
     allow_incomplete_fold: bool=True,
-    refit: bool=False,
+    refit: Optional[Union[bool, int]]=False,
     interval: Optional[list]=None,
     alpha: Optional[float]=None,
     n_boot: int=500,
     random_state: int=123,
     in_sample_residuals: bool=True,
+    n_jobs: Optional[Union[int, str]]='auto',
     verbose: bool=False,
     show_progress: bool=True
 ) -> None:
     """
     This is a helper function to check most inputs of backtesting functions in 
     modules `model_selection`, `model_selection_multiseries` and 
     `model_selection_sarimax`.
 
     Parameters
     ----------
     forecaster : object
         Forecaster model.
-
     steps : int, list
         Number of future steps predicted.
-        
     metric : str, Callable, list
         Metric used to quantify the goodness of fit of the model.
-        
     y : pandas Series
         Training time series for uni-series forecasters.
-
     series : pandas DataFrame
         Training time series for multi-series forecasters.
-    
     initial_train_size : int, default `None`
         Number of samples in the initial train split. If `None` and `forecaster` 
         is already trained, no initial train is done and all data is used to 
         evaluate the model.
-    
     fixed_train_size : bool, default `True`
         If True, train size doesn't increase but moves by `steps` in each iteration.
-
     gap : int, default `0`
         Number of samples to be excluded after the end of each training set and 
         before the test set.
-        
     allow_incomplete_fold : bool, default `True`
         Last fold is allowed to have a smaller number of samples than the 
         `test_size`. If `False`, the last fold is excluded.
-
-    refit : bool, default `False`
-        Whether to re-fit the forecaster in each iteration.
-
+    refit : bool, int, default `False`
+        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, 
+        the Forecaster will be trained every that number of iterations.
     interval : list, default `None`
         Confidence of the prediction interval estimated. Sequence of percentiles
         to compute, which must be between 0 and 100 inclusive.
-
     alpha : float, default `None`
-        The confidence intervals used in ForecasterSarimax are (1 - alpha) %.
-            
+        The confidence intervals used in ForecasterSarimax are (1 - alpha) %. 
     n_boot : int, default `500`
         Number of bootstrapping iterations used to estimate prediction
         intervals.
-
     random_state : int, default `123`
         Sets a seed to the random generator, so that boot intervals are always 
         deterministic.
-
     in_sample_residuals : bool, default `True`
         If `True`, residuals from the training data are used as proxy of prediction 
         error to create prediction intervals.  If `False`, out_sample_residuals 
         are used if they are already stored inside the forecaster.
-                  
+    n_jobs : int, 'auto', default `'auto'`
+            The number of jobs to run in parallel. If `-1`, then the number of jobs is 
+            set to the number of cores. If 'auto', `n_jobs` is set using the fuction
+            skforecast.utils.select_n_jobs_fit_forecaster.
+            **New in version 0.9.0**
     verbose : bool, default `False`
         Print number of folds and index of training and validation sets used 
         for backtesting.
-
     show_progress: bool, default `True`
-        Whether to show a progress bar. Defaults to True.
+        Whether to show a progress bar.
 
-    Returns 
+    Returns
     -------
-        
+    None
+    
     """
-
+    
     forecasters_uni = ['ForecasterAutoreg', 'ForecasterAutoregCustom', 
                        'ForecasterAutoregDirect', 'ForecasterSarimax']
     forecasters_multi = ['ForecasterAutoregMultiSeries', 
                          'ForecasterAutoregMultiSeriesCustom', 
                          'ForecasterAutoregMultiVariate']
 
     if type(forecaster).__name__ in forecasters_uni:
@@ -1601,14 +1570,23 @@
             )
         if initial_train_size + gap >= data_length:
             raise ValueError(
                 (f"The combination of initial_train_size {initial_train_size} and "
                  f"gap {gap} cannot be greater than the length of `{data_name}` "
                  f"({data_length}).")
             )
+        if data_name == 'series':
+            for serie in series:
+                if np.isnan(series[serie].to_numpy()[:initial_train_size]).all():
+                    raise ValueError(
+                        (f"All values of series '{serie}' are NaN. When working "
+                         f"with series of different lengths, make sure that "
+                         f"`initial_train_size` has an appropriate value so that "
+                         f"all series reach the first non-null value.")
+                    )
     else:
         if type(forecaster).__name__ == 'ForecasterSarimax':
             raise ValueError(
                 (f"`initial_train_size` must be an integer smaller than the "
                  f"length of `{data_name}` ({data_length}).")
             )    
         else:
@@ -1622,22 +1600,24 @@
                     "`refit` is only allowed when `initial_train_size` is not `None`."
                 )
     
     if not isinstance(fixed_train_size, bool):
         raise TypeError("`fixed_train_size` must be a boolean: `True`, `False`.")
     if not isinstance(allow_incomplete_fold, bool):
         raise TypeError("`allow_incomplete_fold` must be a boolean: `True`, `False`.")
-    if not isinstance(refit, bool):
-        raise TypeError("`refit` must be a boolean: `True`, `False`.")
+    if not isinstance(refit, (bool, int, np.integer)) or refit < 0:
+        raise TypeError(f"`refit` must be a boolean or an integer greater than 0. Got {refit}.")
     if not isinstance(n_boot, (int, np.integer)) or n_boot < 0:
         raise TypeError(f"`n_boot` must be an integer greater than 0. Got {n_boot}.")
     if not isinstance(random_state, (int, np.integer)) or random_state < 0:
         raise TypeError(f"`random_state` must be an integer greater than 0. Got {random_state}.")
     if not isinstance(in_sample_residuals, bool):
         raise TypeError("`in_sample_residuals` must be a boolean: `True`, `False`.")
+    if not isinstance(n_jobs, int) and n_jobs != 'auto':
+        raise TypeError(f"`n_jobs` must be an integer or `'auto'`. Got {n_jobs}.")
     if not isinstance(verbose, bool):
         raise TypeError("`verbose` must be a boolean: `True`, `False`.")
     if not isinstance(show_progress, bool):
         raise TypeError("`show_progress` must be a boolean: `True`, `False`.")
 
     if interval is not None or alpha is not None:
         check_interval(interval=interval, alpha=alpha)
@@ -1646,8 +1626,122 @@
         raise ValueError(
             (f"There is not enough data to evaluate {steps} steps in a single "
              f"fold. Set `allow_incomplete_fold` to `True` to allow incomplete folds.\n"
              f"    Data available for test : {data_length - (initial_train_size + gap)}\n"
              f"    Steps                   : {steps}")
         )
     
-    return
+    return
+
+
+def select_n_jobs_backtesting(
+    forecaster_name: str,
+    regressor_name: str,
+    refit: Union[bool, int]
+) -> int:
+    """
+    Select the optimal number of jobs to use in the backtesting process. This
+    selection is based on heuristics and is not guaranteed to be optimal.
+
+    The number of jobs is chosen as follows:
+
+    - If `refit` is an integer, then n_jobs=1. This is because parallelization doesn't 
+    work with intermittent refit.
+    - If forecaster_name is 'ForecasterAutoreg' or 'ForecasterAutoregCustom' and
+    regressor_name is a linear regressor, then n_jobs=1.
+    - If forecaster_name is 'ForecasterAutoreg' or 'ForecasterAutoregCustom',
+    regressor_name is not a linear regressor and refit=`True`, then
+    n_jobs=cpu_count().
+    - If forecaster_name is 'ForecasterAutoreg' or 'ForecasterAutoregCustom',
+    regressor_name is not a linear regressor and refit=`False`, then
+    n_jobs=1.
+    - If forecaster_name is 'ForecasterAutoregDirect' or 'ForecasterAutoregMultiVariate'
+    and refit=`True`, then n_jobs=cpu_count().
+    - If forecaster_name is 'ForecasterAutoregDirect' or 'ForecasterAutoregMultiVariate'
+    and refit=`False`, then n_jobs=1.
+    - If forecaster_name is 'ForecasterAutoregMultiseries', then n_jobs=cpu_count().
+
+    Parameters
+    ----------
+    forecaster_name : str
+        The type of Forecaster.
+    regressor_name : str
+        The type of regressor.
+    refit : bool, int
+        If the forecaster is refitted during the backtesting process.
+
+    Returns
+    -------
+    n_jobs : int
+        The number of jobs to run in parallel.
+    
+    """
+
+    linear_regressors = [
+        regressor_name
+        for regressor_name in dir(sklearn.linear_model)
+        if not regressor_name.startswith('_')
+    ]
+    
+    refit = False if refit == 0 else refit
+    if not isinstance(refit, bool) and refit != 1:
+        n_jobs = 1
+    else:
+        if forecaster_name in ['ForecasterAutoreg', 'ForecasterAutoregCustom']:
+            if regressor_name in linear_regressors:
+                n_jobs = 1
+            else:
+                n_jobs = joblib.cpu_count() if refit else 1
+        elif forecaster_name in ['ForecasterAutoregDirect', 'ForecasterAutoregMultiVariate']:
+            n_jobs = 1
+        elif forecaster_name in ['ForecasterAutoregMultiseries', 'ForecasterAutoregMultiSeriesCustom']:
+            n_jobs = joblib.cpu_count()
+        elif forecaster_name in ['ForecasterSarimax']:
+            n_jobs = 1
+        else:
+            n_jobs = 1
+
+    return n_jobs
+
+
+def select_n_jobs_fit_forecaster(
+    forecaster_name: str,
+    regressor_name: str,
+) -> int:
+    """
+    Select the optimal number of jobs to use in the fitting process. This
+    selection is based on heuristics and is not guaranteed to be optimal. 
+    
+    The number of jobs is chosen as follows:
+    
+    - If forecaster_name is 'ForecasterAutoregDirect' or 'ForecasterAutoregMultiVariate'
+    and regressor_name is a linear regressor, then n_jobs=1, otherwise n_jobs=cpu_count().
+    
+    Parameters
+    ----------
+    forecaster_name : str
+        The type of Forecaster.
+    regressor_name : str
+        The type of regressor.
+
+    Returns
+    -------
+    n_jobs : int
+        The number of jobs to run in parallel.
+    
+    """
+
+    linear_regressors = [
+        regressor_name
+        for regressor_name in dir(sklearn.linear_model)
+        if not regressor_name.startswith('_')
+    ]
+
+    if forecaster_name in ['ForecasterAutoregDirect', 'ForecasterAutoregMultiVariate']:
+        if regressor_name in linear_regressors:
+            n_jobs = 1
+        else:
+            n_jobs = joblib.cpu_count()
+    else:
+        n_jobs = 1
+
+    return n_jobs
```

### Comparing `skforecast-0.8.1/skforecast.egg-info/PKG-INFO` & `skforecast-0.9.0/skforecast.egg-info/PKG-INFO`

 * *Files 22% similar despite different names*

```diff
@@ -1,68 +1,79 @@
 Metadata-Version: 2.1
 Name: skforecast
-Version: 0.8.1
+Version: 0.9.0
 Summary: Forecasting time series with scikit-learn regressors. It also works with any regressor compatible with the scikit-learn API (pipelines, CatBoost, LightGBM, XGBoost, Ranger...).
 Home-page: https://github.com/JoaquinAmatRodrigo/skforecast
 Author: Joaquin Amat Rodrigo and Javier Escobar Ortiz
 Author-email: j.amatrodrigo@gmail.com, javier.escobar.ortiz@gmail.com
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
-Classifier: License :: OSI Approved :: MIT License
+Classifier: License :: OSI Approved :: BSD License
 Description-Content-Type: text/markdown
 Provides-Extra: sarimax
 Provides-Extra: plotting
 Provides-Extra: test
 Provides-Extra: full
 Provides-Extra: all
 License-File: LICENSE
 
 <h1 align="left">
-<img src="https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/images/banner-landing-page-skforecast.png?raw=true#only-light" style= margin-top: 0px;">
-</h1><br>
+<img src="https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/images/banner-landing-page-skforecast.png?raw=true#only-light" style= margin-top: 0px;>
+</h1>
 
 ![Python](https://img.shields.io/badge/python-3.8%20%7C%203.9%20%7C%203.10%20%7C%203.11-blue)
 [![PyPI](https://img.shields.io/pypi/v/skforecast)](https://pypi.org/project/skforecast/)
 [![codecov](https://codecov.io/gh/JoaquinAmatRodrigo/skforecast/branch/master/graph/badge.svg)](https://codecov.io/gh/JoaquinAmatRodrigo/skforecast)
 [![Build status](https://github.com/JoaquinAmatRodrigo/skforecast/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/JoaquinAmatRodrigo/skforecast/actions/workflows/unit-tests.yml/badge.svg)
 [![Project Status: Active](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)
 [![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/JoaquinAmatRodrigo/skforecast/graphs/commit-activity)
 [![License](https://img.shields.io/github/license/JoaquinAmatRodrigo/skforecast)](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/LICENSE)
 [![Downloads](https://static.pepy.tech/personalized-badge/skforecast?period=total&units=international_system&left_color=grey&right_color=blue&left_text=Downloads)](https://pepy.tech/project/skforecast)
 
 
+# About The Project
+
 **Skforecast** is a Python library that eases using scikit-learn regressors as single and multi-step forecasters. It also works with any regressor compatible with the scikit-learn API (LightGBM, XGBoost, CatBoost, ...).
 
 **Why use skforecast?**
 
 The fields of statistics and machine learning have developed many excellent regression algorithms that can be useful for forecasting, but applying them effectively to time series analysis can still be a challenge. To address this issue, the skforecast library provides a comprehensive set of tools for training, validation and prediction in a variety of scenarios commonly encountered when working with time series. The library is built using the widely used scikit-learn API, making it easy to integrate into existing workflows. With skforecast, users have access to a wide range of functionalities such as feature engineering, model selection, hyperparameter tuning and many others. This allows users to focus on the essential aspects of their projects and leave the intricacies of time series analysis to skforecast. In addition, skforecast is developed according to the following priorities:
 
 + Fast and robust prototyping. :zap:
 + Validation and backtesting methods to have a realistic assessment of model performance. :mag:
 + Models must be deployed in production. :hammer:
 + Models must be interpretable. :crystal_ball:
 
-**Documentation: https://skforecast.org** :books:
+**Share Your Thoughts with Us**
+
+Thank you for choosing skforecast! We value your suggestions, bug reports and recommendations as they help us identify areas for improvement and ensure that skforecast meets the needs of the community. Please consider sharing your experiences, reporting bugs, making suggestions or even contributing to the codebase on GitHub. Together, let's make time series forecasting more accessible and accurate for everyone.
+
+
+# Documentation
+
+For detailed information on how to use and leverage the full potential of **skforecast** please refer to the comprehensive documentation available at:
+
+**https://skforecast.org** :books:
 
 
 # Installation
 
 The default installation of skforecast only installs hard dependencies.
 
 ```bash
 pip install skforecast
 ```
 
 Specific version:
 
 ```bash
-pip install skforecast==0.8.1
+pip install skforecast==0.9.0
 ```
 
 Latest (unstable):
 
 ```bash
 pip install git+https://github.com/JoaquinAmatRodrigo/skforecast#master
 ```
@@ -85,89 +96,88 @@
 
 # Dependencies
 
 + Python >= 3.8
 
 ## Hard dependencies
 
-+ numpy>=1.20, <1.25
++ numpy>=1.20, <1.26
 + pandas>=1.2, <2.1
-+ tqdm>=4.57.0, <4.65
-+ scikit-learn>=1.0, <1.3
-+ optuna>=2.10.0, <3.2
-+ joblib>=1.1.0, <1.3.0
++ tqdm>=4.57.0, <4.66
++ scikit-learn>=1.0, <1.4
++ optuna>=2.10.0, <3.3
++ joblib>=1.1.0, <1.4
 
 ## Optional dependencies
 
 + matplotlib>=3.3, <3.8
 + seaborn>=0.11, <0.13
-+ statsmodels>=0.12, <0.14
++ statsmodels>=0.12, <0.15
 + pmdarima>=2.0, <2.1
 
-# Features
+# What is new in skforecast 0.9.0?
 
-+ Create recursive autoregressive forecasters from any regressor that follows the scikit-learn API
-+ Create direct autoregressive forecasters from any regressor that follows the scikit-learn API
-+ Create multi-series autoregressive forecasters from any regressor that follows the scikit-learn API
-+ Include exogenous variables as predictors
-+ Include custom predictors (rolling mean, rolling variance ...)
-+ Multiple backtesting methods for model validation
-+ Grid search, random search and Bayesian search to find optimal lags (predictors) and best hyperparameters
-+ Include custom metrics for model validation and grid search
-+ Prediction interval estimated by bootstrapping and quantile regression
-+ Get predictor importance
-+ Forecaster in production
-
-## What is new in skforecast 0.8.1?
-
-- [x] Support for `pandas 2.0.x`.
-- [x] New user guide on how to include **categorical variables** in the Forecasters.
-- [x] New user guide on how to use **GPU in Google Colab** with XGBoost and LightGBM regressors.
-- [x] Include custom kwargs during fit.
-- [x] The dtypes of exogenous variables are maintained when generating the training matrices with the `create_train_X_y` method in all the Forecasters.
-- [x] Include `gap` argument in backtesting functions to omit observations between training and prediction.
+Visit the [release notes](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/changelog.md) to view all notable changes.
+
+- [x] `ForecasterAutoregDirect` and `ForecasterAutoregMultiVariate` include the `n_jobs` argument in their `fit` method, allowing multi-process parallelization for improved performance.
+- [x] All backtesting and grid search functions have been extended to include the `n_jobs` argument, allowing multi-process parallelization for improved performance.
+- [x] Argument `refit` now can be also an `integer` in all backtesting dependent functions in modules `model_selection`, `model_selection_multiseries`, and `model_selection_sarimax`. This allows the Forecaster to be trained every this number of iterations.
+- [x] `ForecasterAutoregMultiSeries` and `ForecasterAutoregMultiSeriesCustom` can be trained using series of different lengths. This means that the model can handle datasets with different numbers of data points in each series.
 - [x] Bug fixes and performance improvements.
 
-Visit the [release notes](https://github.com/JoaquinAmatRodrigo/skforecast/blob/feature_update_category_docs/changelog.md) to view all notable changes.
 
+# Forecasters
 
-# Documentation
+A **Forecaster** object in the skforecast library is a comprehensive container that provides essential functionality and methods for training a forecasting model and generating predictions for future points in time.
+
+The **skforecast** library offers a variety of forecaster types, each tailored to specific requirements such as single or multiple time series, direct or recursive strategies, or custom predictors. Regardless of the specific forecaster type, all instances share the same API.
 
-The documentation for the latest release is at [skforecast docs](https://skforecast.org).
+| Forecaster | Single series | Multiple series | Recursive strategy | Direct strategy | Probabilistic prediction | Exogenous features | Custom features |
+|:-----------|:-------------:|:---------------:|:------------------:|:---------------:|:------------------------:|:------------------:|:---------------:|
+|[ForecasterAutoreg](https://skforecast.org/latest/user_guides/autoregresive-forecaster.html)|:heavy_check_mark:||:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:||
+|[ForecasterAutoregCustom](https://skforecast.org/latest/user_guides/custom-predictors.html)|:heavy_check_mark:||:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|
+|[ForecasterAutoregDirect](https://skforecast.org/latest/user_guides/direct-multi-step-forecasting.html)|:heavy_check_mark:|||:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:||
+|[ForecasterMultiSeries](https://skforecast.org/latest/user_guides/independent-multi-time-series-forecasting.html)||:heavy_check_mark:|:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:||
+|[ForecasterMultiSeriesCustom](https://skforecast.org/latest/user_guides/custom-predictors.html)||:heavy_check_mark:|:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|
+|[ForecasterMultiVariate](https://skforecast.org/latest/user_guides/dependent-multi-series-multivariate-forecasting.html)||:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:||
+|[ForecasterSarimax](https://skforecast.org/latest/user_guides/forecasting-sarimax-arima.html)|:heavy_check_mark:||:heavy_check_mark:||:heavy_check_mark:|:heavy_check_mark:||
 
-Recent improvements are highlighted in the [release notes](https://skforecast.org/latest/releases/releases.html).
 
-+ [Introduction to time series and forecasting](https://skforecast.org/latest/user_guides/quick-start-skforecast.html)
+# Main User Guides
+
++ [Introduction to time series and forecasting](https://skforecast.org/latest/introduction-forecasting/introduction-forecasting.html)
 
 + [Recursive multi-step forecasting](https://skforecast.org/latest/user_guides/autoregresive-forecaster.html)
 
++ [Direct multi-step forecasting](https://skforecast.org/latest/user_guides/direct-multi-step-forecasting.html)
+
 + [Independent multi-series forecasting](https://skforecast.org/latest/user_guides/independent-multi-time-series-forecasting.html)
 
 + [Dependent multi-series forecasting (Multivariate forecasting)](https://skforecast.org/latest/user_guides/dependent-multi-series-multivariate-forecasting.html)
 
 + [Backtesting (validation) of forecasting models](https://skforecast.org/latest/user_guides/backtesting.html)
 
 + [Hyperparameter tuning and lags selection of forecasting models](https://skforecast.org/latest/user_guides/hyperparameter-tuning-and-lags-selection.html)
 
 + [Probabilistic forecasting](https://skforecast.org/latest/user_guides/probabilistic-forecasting.html)
 
 + [Using forecasters in production](https://skforecast.org/latest/user_guides/forecaster-in-production.html)
 
 
-# Examples and tutorials 
+# Examples and tutorials
 
 **English**
 
 + [**Skforecast: time series forecasting with Python and Scikit-learn**](https://www.cienciadedatos.net/documentos/py27-time-series-forecasting-python-scikitlearn.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1X1DJF4pZlklIt5srQnyTYoyFVLunr_OQ)
 
-+ [**Forecasting electricity demand with Python**](https://www.cienciadedatos.net/documentos/py29-forecasting-electricity-power-demand-python.html)
++ [**Forecasting electricity demand with Python**](https://www.cienciadedatos.net/documentos/py29-forecasting-electricity-power-demand-python.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1efCKQtuHOlw7MLojIwqi2zrU2NZbG-FP)
 
-+ [**Forecasting web traffic with machine learning and Python**](https://www.cienciadedatos.net/documentos/py37-forecasting-web-traffic-machine-learning.html)
++ [**Forecasting web traffic with machine learning and Python**](https://www.cienciadedatos.net/documentos/py37-forecasting-web-traffic-machine-learning.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QhLkJAAEfvgYoVkQXy58-T_sloNFCV1o)
 
-+ [**Forecasting time series with gradient boosting: skforecast, XGBoost, LightGBM and CatBoost**](https://www.cienciadedatos.net/documentos/py39-forecasting-time-series-with-skforecast-xgboost-lightgbm-catboost.html)
++ [**Forecasting with gradient boosting: skforecast, XGBoost, LightGBM and CatBoost**](https://www.cienciadedatos.net/documentos/py39-forecasting-time-series-with-skforecast-xgboost-lightgbm-catboost.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Imy8ZM3DqPXg7UllRDH9gqWb_XSrqzzh)
 
 + [**Bitcoin price prediction with Python**](https://www.cienciadedatos.net/documentos/py41-forecasting-cryptocurrency-bitcoin-machine-learning-python.html)
 
 + [**Prediction intervals in forecasting models**](https://www.cienciadedatos.net/documentos/py42-forecasting-prediction-intervals-machine-learning.html)
 
 + [**Multi-series forecasting**](https://www.cienciadedatos.net/documentos/py44-multi-series-forecasting-skforecast.html)
 
@@ -178,63 +188,72 @@
 + [**Intermittent demand forecasting**](https://www.cienciadedatos.net/documentos/py48-intermittent-demand-forecasting.html)
 
 
 **Espaol**
 
 + [**Skforecast: forecasting series temporales con Python y Scikit-learn**](https://www.cienciadedatos.net/documentos/py27-forecasting-series-temporales-python-scikitlearn.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mjmccrMA-XxOVXm-3wKSIQ9__oo9dJ5a)
 
-+ [**Forecasting de la demanda elctrica**](https://www.cienciadedatos.net/documentos/py29-forecasting-demanda-energia-electrica-python.html)
++ [**Forecasting de la demanda elctrica**](https://www.cienciadedatos.net/documentos/py29-forecasting-demanda-energia-electrica-python.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/15kQpANRBCLfNf77nmNcV6GjGPoYdOmmF)
 
-+ [**Forecasting de las visitas a una pgina web**](https://www.cienciadedatos.net/documentos/py37-forecasting-visitas-web-machine-learning.html)
++ [**Forecasting de las visitas a una pgina web**](https://www.cienciadedatos.net/documentos/py37-forecasting-visitas-web-machine-learning.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1uw2nyjA9XMcstfkpbWC4zCULN7Qp7MWV)
 
-+ [**Forecasting series temporales con gradient boosting: skforecast, XGBoost, LightGBM y CatBoost**](https://www.cienciadedatos.net/documentos/py39-forecasting-series-temporales-con-skforecast-xgboost-lightgbm-catboost.html)
++ [**Forecasting con gradient boosting: skforecast, XGBoost, LightGBM y CatBoost**](https://www.cienciadedatos.net/documentos/py39-forecasting-series-temporales-con-skforecast-xgboost-lightgbm-catboost.html) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1UAjX8vUKDoY0XJtq5WtHlJ4qwPvSgLrD)
 
 + [**Prediccin del precio de Bitcoin con Python**](https://www.cienciadedatos.net/documentos/py41-forecasting-criptomoneda-bitcoin-machine-learning-python.html)
 
 + [**Workshop prediccin de series temporales con machine learning Universidad de Deusto / Deustuko Unibertsitatea**](https://youtu.be/MlktVhReO0E)
 
 + [**Intervalos de prediccin en modelos de forecasting**](https://www.cienciadedatos.net/documentos/py42-intervalos-prediccion-modelos-forecasting-machine-learning.html)
 
 + [**Multi-series forecasting**](https://www.cienciadedatos.net/documentos/py44-multi-series-forecasting-skforecast-espaol.html)
 
 + [**Prediccin de demanda intermitente**](https://www.cienciadedatos.net/documentos/py48-forecasting-demanda-intermitente.html)
 
 
-# Donating
-
-If you found skforecast useful, you can support us with a donation. Your contribution will help to continue developing and improving this project. Many thanks!
-
-[![paypal](https://www.paypalobjects.com/en_US/ES/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/donate/?hosted_button_id=D2JZSWRLTZDL6)
+# How to contribute
 
+Primarily, skforecast development consists of adding and creating new *Forecasters*, new validation strategies, or improving the performance of the current code. However, there are many other ways to contribute:
 
-# How to contribute
+- Submit a bug report or feature request on [GitHub Issues](https://github.com/JoaquinAmatRodrigo/skforecast/issues).
+- Contribute a Jupyter notebook to our [examples](https://joaquinamatrodrigo.github.io/skforecast/latest/examples/examples.html).
+- Write [unit or integration tests](https://docs.pytest.org/en/latest/) for our project.
+- Answer questions on our issues, Stack Overflow, and elsewhere.
+- Translate our documentation into another language.
+- Write a blog post, tweet, or share our project with others.
 
 For more information on how to contribute to skforecast, see our [Contribution Guide](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/CONTRIBUTING.md).
 
 
 # Citation
 
 If you use this software, please cite it using the following metadata.
 
 **APA**:
 ```
-Amat Rodrigo, J., & Escobar Ortiz, J. skforecast (Version 0.8.1) [Computer software]
+Amat Rodrigo, J., & Escobar Ortiz, J. skforecast (Version 0.9.0) [Computer software]
 ```
 
 **BibTeX**:
 ```
 @software{skforecast,
 author = {Amat Rodrigo, Joaquin and Escobar Ortiz, Javier},
-license = {MIT},
-month = {5},
+license = {BSD 3-Clause License},
+month = {7},
 title = {{skforecast}},
-version = {0.8.1},
+version = {0.9.0},
 year = {2023}
 }
 ```
 
 View the [citation file](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/CITATION.cff).
 
 
+# Donating
+
+If you found skforecast useful, you can support us with a donation. Your contribution will help to continue developing and improving this project. Many thanks!
+
+[![paypal](https://www.paypalobjects.com/en_US/ES/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/donate/?hosted_button_id=D2JZSWRLTZDL6)
+
+
 # License
 
 [BSD 3-Clause License](https://github.com/JoaquinAmatRodrigo/skforecast/blob/master/LICENSE)
```

### Comparing `skforecast-0.8.1/skforecast.egg-info/SOURCES.txt` & `skforecast-0.9.0/skforecast.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -185,11 +185,13 @@
 skforecast/utils/tests/test_initialize_lags.py
 skforecast/utils/tests/test_initialize_weights.py
 skforecast/utils/tests/test_multivariate_time_series_corr.py
 skforecast/utils/tests/test_preproces_exog.py
 skforecast/utils/tests/test_preproces_last_window.py
 skforecast/utils/tests/test_preproces_y.py
 skforecast/utils/tests/test_save_load_forecaster.py
+skforecast/utils/tests/test_select_n_jobs_backtesting.py
+skforecast/utils/tests/test_select_n_jobs_fit_forecaster.py
 skforecast/utils/tests/test_transform_dataframe.py
 skforecast/utils/tests/test_transform_series.py
 tests/__init__.py
 tests/test_skforecast_version.py
```

### Comparing `skforecast-0.8.1/skforecast.egg-info/requires.txt` & `skforecast-0.9.0/skforecast.egg-info/requires.txt`

 * *Files 10% similar despite different names*

```diff
@@ -1,43 +1,43 @@
-numpy<1.25,>=1.20
+numpy<1.26,>=1.20
 pandas<2.1,>=1.2
-tqdm<4.65,>=4.57.0
-scikit-learn<1.3,>=1.0
-optuna<3.2,>=2.10.0
-joblib<1.3.0,>=1.1.0
+tqdm<4.66,>=4.57.0
+scikit-learn<1.4,>=1.0
+optuna<3.3,>=2.10.0
+joblib<1.4,>=1.1.0
 
 [all]
 pmdarima<2.1,>=2.0
 matplotlib<3.8,>=3.3
 seaborn<0.13,>=0.11
-statsmodels<0.14,>=0.12
-pytest==7.1.2
-pytest-cov==3.0.0
+statsmodels<0.15,>=0.12
+pytest<7.5,>=7.1.2
+pytest-cov<4.2,>=3.0.0
 xgboost<1.8,>=1.6.1
 lightgbm<3.4
-pytest-xdist==2.5.0
+pytest-xdist<3.4
 
 [full]
 pmdarima<2.1,>=2.0
 matplotlib<3.8,>=3.3
 seaborn<0.13,>=0.11
-statsmodels<0.14,>=0.12
-pytest==7.1.2
-pytest-cov==3.0.0
+statsmodels<0.15,>=0.12
+pytest<7.5,>=7.1.2
+pytest-cov<4.2,>=3.0.0
 xgboost<1.8,>=1.6.1
 lightgbm<3.4
-pytest-xdist==2.5.0
+pytest-xdist<3.4
 
 [plotting]
 matplotlib<3.8,>=3.3
 seaborn<0.13,>=0.11
-statsmodels<0.14,>=0.12
+statsmodels<0.15,>=0.12
 
 [sarimax]
 pmdarima<2.1,>=2.0
 
 [test]
-pytest==7.1.2
-pytest-cov==3.0.0
+pytest<7.5,>=7.1.2
+pytest-cov<4.2,>=3.0.0
 xgboost<1.8,>=1.6.1
 lightgbm<3.4
-pytest-xdist==2.5.0
+pytest-xdist<3.4
```

